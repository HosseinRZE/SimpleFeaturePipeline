{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv(\"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\")\n",
    "label[\"seq_len\"] = label[\"endIndex\"] - label[\"startIndex\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e027af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "276b5b3c-e85b-4fb2-8da6-147dc065c148",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles_prop.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b8d98",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab1e7f",
   "metadata": {},
   "source": [
    "## two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_loss_reg\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_len\", loss_len, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb2dd1",
   "metadata": {},
   "source": [
    "## two head lstm sum of logits loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec80a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b88b10",
   "metadata": {},
   "source": [
    "## two head lstm soft thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5, k_soft=20.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "        self.k_soft = k_soft  # slope for soft thresholding\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Soft threshold length loss ---\n",
    "        # Convert logits into soft 0-1 mask around threshold\n",
    "        soft_mask = torch.sigmoid(self.k_soft * (len_logits - self.threshold))\n",
    "        # Compute soft expected length per sample\n",
    "        soft_len = soft_mask.sum(dim=1)\n",
    "        # True length\n",
    "        true_len = lengths.float()\n",
    "        # MSE loss on soft expected length\n",
    "        loss_len = F.mse_loss(soft_len, true_len)\n",
    "\n",
    "        # Combine losses\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b75a48",
   "metadata": {},
   "source": [
    "## FNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c70fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b1d4",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368a03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    B = y_true.shape[0]\n",
    "\n",
    "    # Keep track if any valid lines are found\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]  # (B,1)\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "\n",
    "        mask = (y_target != 0).squeeze()\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        valid_line_found = True\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_loss = -log_likelihood.mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        # Avoid returning a Python float; create a tensor with requires_grad\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a057d",
   "metadata": {},
   "source": [
    "## LSTM weightening with pi order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce6729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15,hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base network\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        \n",
    "        if lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3*n_components)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f1d12",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb7ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class cnn_lstm(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base feature projection\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "\n",
    "        # Parallel conv1d branches\n",
    "        self.k1 = nn.Conv1d(feature_eng, feature_eng, kernel_size=1, padding=0)\n",
    "        self.k3 = nn.Conv1d(feature_eng, feature_eng, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fusion via conv2d\n",
    "        # Input channels = 2 (from k1 + k3), Output = 1, kernel size (1,1) to fuse\n",
    "        self.fusion_conv2d = nn.Conv2d(2, 1, kernel_size=(1, 1))\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: dict with key \"main\", value shape (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]  # (B, T, input_dim)\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # Fully connected projection\n",
    "        x = F.relu(self.ln1(self.fc1(x)))  # (B, T, F)\n",
    "\n",
    "        # Conv1d expects (B, F, T)\n",
    "        x_cnn = x.transpose(1, 2)  # (B, F, T)\n",
    "\n",
    "        # Parallel convs\n",
    "        x1 = self.k1(x_cnn)  # (B, F, T)\n",
    "        x3 = self.k3(x_cnn)  # (B, F, T)\n",
    "\n",
    "        # Stack into 2-channel feature map\n",
    "        stacked = torch.stack([x1, x3], dim=1)  # (B, 2, F, T)\n",
    "\n",
    "        # Fuse with conv2d → (B, 1, F, T)\n",
    "        fused = self.fusion_conv2d(stacked).squeeze(1)  # (B, F, T)\n",
    "\n",
    "        # Back to (B, T, F)\n",
    "        fused = fused.transpose(1, 2)\n",
    "\n",
    "        # LSTM with packed sequence\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(fused, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(packed)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(fused)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3 * n_components)\n",
    "\n",
    "        # Assume you have mdn_split_params(pi, mu, sigma)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e7f3",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening with sigma confidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e3bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll_with_sigma_penalty(y_true, mdn_params, weights, lambda_sigma=0.01):\n",
    "    \"\"\"\n",
    "    Calculates weighted MDN NLL and adds a penalty for large sigmas.\n",
    "    \n",
    "    Args:\n",
    "        lambda_sigma (float): The strength of the sigma penalty.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "        mask = (y_target != -1).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # --- 1. NLL Loss Calculation (same as before) ---\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_nll_loss = -log_likelihood.mean()\n",
    "\n",
    "        # --- 2. NEW: Sigma Penalty Calculation ---\n",
    "        # We penalize the mean of the sigmas for the most likely component\n",
    "        # This focuses the penalty on the component the model actually uses\n",
    "        most_likely_idx = torch.argmax(pi_masked, dim=1)\n",
    "        most_likely_sigma = sigma_masked.gather(1, most_likely_idx.unsqueeze(1)).squeeze()\n",
    "        sigma_penalty = torch.mean(most_likely_sigma)\n",
    "        \n",
    "        # --- 3. Combine and Weight ---\n",
    "        combined_line_loss = line_nll_loss + (lambda_sigma * sigma_penalty)\n",
    "        total_loss += weights[i] * combined_line_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# In your training_step, you would call this new function:\n",
    "# loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights, lambda_sigma=0.01)\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6484b7d",
   "metadata": {},
   "source": [
    "## CNNlSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2139f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # Inside your CNNLSTM_MDN class\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 50% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e8361",
   "metadata": {},
   "source": [
    "## CNNLSTM scalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a359387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components, mu_scale=10, mu_bias=.9, sigma_scale=10.0):\n",
    "    \"\"\"\n",
    "    Split raw MDN parameters into (pi, mu, sigma).\n",
    "\n",
    "    Args:\n",
    "        raw_params: (B, 3 * K) from the network\n",
    "        n_components: number of mixture components\n",
    "        mu_scale: scaling factor for mu (default 1.0 = no scaling)\n",
    "        mu_bias: shift/bias applied after scaling\n",
    "        sigma_scale: scaling factor for sigma (default 10.0)\n",
    "    \"\"\"\n",
    "    B = raw_params.size(0)\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi_raw = raw[..., 0]\n",
    "    mu_raw = raw[..., 1]\n",
    "    sigma_raw = raw[..., 2]\n",
    "\n",
    "    pi = F.softmax(pi_raw, dim=-1)\n",
    "    mu = mu_raw / mu_scale + mu_bias\n",
    "    sigma = F.softplus(sigma_raw / sigma_scale) + 1e-4\n",
    "\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] \n",
    "\n",
    "        # --- Debug print first candle ---\n",
    "        # if x.ndim == 3:  # batched: (B, T, F)\n",
    "        #     first_candle = x[0, 0, :]   # first sample, first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # elif x.ndim == 2:  # single sequence: (T, F)\n",
    "        #     first_candle = x[0, :]      # first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # else:\n",
    "        #     print(\"Unexpected shape for x:\", x.shape)\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # # Inside your CNNLSTM_MDN class\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 80% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    # def configure_optimizers(self):\n",
    "    #     return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccc1c2",
   "metadata": {},
   "source": [
    "## CNNtransformer wheightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9609ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "\n",
    "# --- Helper Functions and Modules ---\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma).\n",
    "    This function is used by each individual MDN head.\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-6 # Added a small epsilon for stability\n",
    "    return pi, mu, sigma\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Injects positional information into the input sequence for the Transformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- Weighted Loss Function for Multi-Head Architecture ---\n",
    "\n",
    "def weighted_mdn_nll_multihead(y_true, mdn_params_list, weights, padding_value=-1):\n",
    "    \"\"\"\n",
    "    Calculates the weighted negative log-likelihood for a multi-headed MDN.\n",
    "    This version correctly handles multiple heads and calculates the full NLL for each.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensor): Padded target values, shape (B, num_lines).\n",
    "        mdn_params_list (list): A list of dicts, one for each head.\n",
    "        weights (Tensor): A 1D tensor of importance weights, shape (num_lines,).\n",
    "        padding_value (int): Value used for padding in y_true.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    \n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params_list[i]['pi'], mdn_params_list[i]['mu'], mdn_params_list[i]['sigma']\n",
    "\n",
    "        # Create a mask for valid (non-padded) targets for this line\n",
    "        mask = (y_target != padding_value).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:  # Skip if no valid targets for this line in the batch\n",
    "            continue\n",
    "\n",
    "        # Select only the valid data for this line's loss calculation\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # Use torch.distributions for a clean and stable calculation\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        \n",
    "        # Calculate log probabilities of the target values in each Gaussian component\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        \n",
    "        # Mix the probabilities using the mixture weights (pi)\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        \n",
    "        # Use logsumexp for numerical stability to get the log-likelihood\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        \n",
    "        # Calculate the mean negative log-likelihood for this line\n",
    "        line_loss = -log_likelihood.mean()\n",
    "\n",
    "        # Apply the importance weight and add to total loss\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    # If no valid lines were found in the entire batch, return a zero tensor\n",
    "    if not isinstance(total_loss, torch.Tensor):\n",
    "        return torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "# --- The CNN-Transformer Model ---\n",
    "\n",
    "class cnn_transformer(pl.LightningModule):\n",
    "    def __init__(self, input_dim, cnn_out_channels=64, d_model=128, nhead=4, num_encoder_layers=2,\n",
    "                 n_components=9, num_lines=9, lr=1e-4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "        \n",
    "        # 1. CNN Feature Extractor Block\n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, cnn_out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(cnn_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(cnn_out_channels, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # 4. Multi-Head MDN Output\n",
    "        self.mdn_heads = nn.ModuleList([\n",
    "            nn.Linear(d_model, 3 * n_components) for _ in range(num_lines)\n",
    "        ])\n",
    "        \n",
    "        # Importance weights for lines (exponential decay)\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, X, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        src_key_padding_mask: (B, T) boolean mask for padded elements in X\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        \n",
    "        # 1. CNN Feature Extraction\n",
    "        # Input for Conv1d needs to be (B, C_in, L), so we permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn_extractor(x)\n",
    "        # Permute back to (B, T, C_out) for Transformer\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 2. Add Positional Encoding\n",
    "        # Transformer expects (T, B, C), so permute again\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.pos_encoder(x)\n",
    "        # Permute back to (B, T, C) for batch_first=True\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        # The mask should indicate which key values are NOT to be attended to\n",
    "        encoded_seq = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # We use the representation of the last valid timestep for prediction\n",
    "        # (A common strategy, alternatively you could use mean pooling)\n",
    "        # For simplicity, we'll take the last hidden state of the sequence.\n",
    "        sequence_summary = encoded_seq[:, -1, :] # (B, d_model)\n",
    "        \n",
    "        # 4. Get parameters from all MDN heads\n",
    "        mdn_params_list = []\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](sequence_summary)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            mdn_params_list.append({\"pi\": pi, \"mu\": mu, \"sigma\": sigma})\n",
    "\n",
    "        return mdn_params_list\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        # Create the padding mask for the transformer\n",
    "        # True values indicate positions that should be ignored.\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "\n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        # Use a padding value of -1 for the loss function\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "        \n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefa26",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95badad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6d37502b-8844-4574-b3cd-d3f9d9cfeb6c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1515456000",
         "1514937600",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516492800",
         "1516147200",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1520121600",
         "1519862400",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "46",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "49",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "50",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 320
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1515456000</td>\n",
       "      <td>1514937600</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1651795200</td>\n",
       "      <td>1649116800</td>\n",
       "      <td>1555</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.873150</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.938913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1652054400</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1589</td>\n",
       "      <td>1591</td>\n",
       "      <td>1.063729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1652572800</td>\n",
       "      <td>1651881600</td>\n",
       "      <td>1587</td>\n",
       "      <td>1595</td>\n",
       "      <td>0.813907</td>\n",
       "      <td>0.870793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788406</td>\n",
       "      <td>0.904141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1653264000</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1591</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.042211</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.958532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1648598400</td>\n",
       "      <td>1640304000</td>\n",
       "      <td>1453</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.884394</td>\n",
       "      <td>0.71872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1515456000  1514937600           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "328  1651795200  1649116800        1555      1586     0.873150     0.825739   \n",
       "330  1652054400  1652227200        1589      1591     1.063729          NaN   \n",
       "331  1652572800  1651881600        1587      1595     0.813907     0.870793   \n",
       "332  1653264000  1652227200        1591      1603     1.042211     1.075683   \n",
       "333  1648598400  1640304000        1453      1549     0.781703     0.741996   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "328     0.905267     0.938913          NaN          NaN          NaN   \n",
       "330          NaN     1.023085          NaN          NaN          NaN   \n",
       "331          NaN          NaN          NaN          NaN          NaN   \n",
       "332     0.992004     0.958532          NaN          NaN          NaN   \n",
       "333     0.993930     0.847425     0.884394      0.71872          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "328     0.955736          NaN  \n",
       "330          NaN          NaN  \n",
       "331     0.788406     0.904141  \n",
       "332          NaN          NaN  \n",
       "333          NaN     0.647521  \n",
       "\n",
       "[320 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_labels = pd.read_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\")\n",
    "cols = [f'price_line{i}' for i in range(1, 10)]\n",
    "df_labels = df_labels.dropna(subset=cols, how='all')\n",
    "df_labels = df_labels.rename(columns={c: c.replace('price_line', 'linePrice_') \n",
    "                        for c in df_labels.columns if c.startswith('price_line')})\n",
    "df_labels.to_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\", index=False)      \n",
    "#     # overwrites the old file\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4dd53",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677dbff",
   "metadata": {},
   "source": [
    "## simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e281d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# ---------------- Evaluation ---------------- #\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, zero_idx=0, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (last-output version).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    zero_idx : which mixture component is considered \"no-line\" (usually 0)\n",
    "    threshold : if pi[:,zero_idx] > threshold → predict invalid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            if isinstance(X_batch, dict):\n",
    "                X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            else:\n",
    "                X_batch = X_batch.to(device)\n",
    "\n",
    "            y_batch = y_batch.to(device)\n",
    "            mdn = model(X_batch, lengths)\n",
    "            pi, mu, sigma = mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"]  # (B,K)\n",
    "\n",
    "            # regression expectation\n",
    "            y_pred = (pi * mu).sum(dim=-1)  # (B,)\n",
    "            B = y_batch.size(0)\n",
    "            y_len = (y_batch > 0).sum(dim=1)                # (B,)\n",
    "            idx = torch.clamp(y_len - 1, min=0)             # last valid index\n",
    "            y_true = y_batch[torch.arange(B, device=y_batch.device), idx]  # (B,)\n",
    "            # only last step\n",
    "            # print(\"lengths(features):\", lengths[:10])\n",
    "            # print(\"lengths(labels):\", y_len[:10])\n",
    "\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "            # validity classification\n",
    "            pi_zero = pi[:, zero_idx]  # (B,)\n",
    "            pred_valid = (pi_zero < (1 - threshold)).long()\n",
    "            true_valid = torch.ones_like(pred_valid)  # last step always valid\n",
    "\n",
    "            all_preds_len.extend(pred_valid.cpu().numpy().tolist())\n",
    "            all_labels_len.extend(true_valid.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "        # ----- Regression metrics -----\n",
    "    all_preds_reg = np.concatenate(all_preds_reg)  # (N,)\n",
    "    all_labels_reg = np.concatenate(all_labels_reg)\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "    # ----- Validity metrics -----\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (MDN, last-output):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Validity   → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=1000,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNLSTM_MDN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a7940",
   "metadata": {},
   "source": [
    "## ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb16e4",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d529c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 16:07:13.851383: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-12 16:07:14.092198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757680634.176325   39011 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757680634.202129   39011 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757680631.927969   39011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757680631.928000   39011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757680631.928001   39011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757680631.928002   39011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-12 16:07:11.951577: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type      | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | fc1           | Linear    | 75     | train\n",
      "1 | ln1           | LayerNorm | 30     | train\n",
      "2 | k1            | Conv1d    | 240    | train\n",
      "3 | k3            | Conv1d    | 690    | train\n",
      "4 | fusion_conv2d | Conv2d    | 3      | train\n",
      "5 | lstm          | LSTM      | 6.3 K  | train\n",
      "6 | mdn_head      | Linear    | 891    | train\n",
      "----------------------------------------------------\n",
      "8.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.2 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9105b218de43349030914e612945d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab08d8cdaad459d8950e69932483e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7280111fad884c7daf25f0d9dd452aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dd7085c375496791447379d2e2799e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.14302027225494385 mae: 0.2753087878227234 acc: 1.0 f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    feature_eng=15,\n",
    "    n_components=9,\n",
    "    dropout = 0.1,\n",
    "    batch_size=32,\n",
    "    max_epochs=2,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(add_candle_shape_features,seperatable = \"complete\"),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        norm_methods={\n",
    "            \"main\": {\n",
    "                \"upper_shadow\": \"standard\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "                # \"open_dif\":\"standard\",\"close_dif\":\"standard\",\"high_dif\":\"standard\",\"low_dif\":\"standard\"\n",
    "                # \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "                # \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "            }\n",
    "        },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "          True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_cols)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_lstm(input_dim=input_dim, feature_eng= feature_eng, hidden_dim=hidden_dim, \n",
    "                     n_components=n_components,  lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    init_args = get_init_args(model, input_dim=input_dim,feature_eng= feature_eng\n",
    "                              ,hidden_dim=hidden_dim, n_components=n_components,\n",
    "                              lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        # test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fd2dc",
   "metadata": {},
   "source": [
    "### cnn transforemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948aa8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (5, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      " [ 0.00938704  0.12409948  0.04899828  0.12622231]\n",
      " [ 0.12622082 -0.00192766  0.09665822  0.00645032]\n",
      " [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-09-11 22:54:43.322679: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-11 22:54:43.587133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757618683.667056     774 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757618683.692416     774 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757618683.885895     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757618683.885924     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757618683.885926     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757618683.885927     774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-11 22:54:43.908483: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | cnn_extractor       | Sequential         | 25.9 K | train\n",
      "1 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "2 | transformer_encoder | TransformerEncoder | 1.2 M  | train\n",
      "3 | mdn_heads           | ModuleList         | 31.3 K | train\n",
      "-------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.973     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bdf327716740459539121b166d1f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db02243a0e6242768053e55896754b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bed584861bb40d1bbd6b543fab57ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649c589547684e6a9d4e30f724585ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1947330b869045e598327e3f6bb7b51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a61f659e19423091d7eac3487a2689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da558a473d6427dbfa0e8659a9f9ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a6493ed1a547af8d6f4688c72b37a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8262abcf914b1cb9764b27ad75ff1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a47f3e9fc444a4180e81d5f287b718d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc695a86b164e3ca624c5f514baa647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce6aaa7ec214b289ccf5ad0abc270c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc5924c36c0446b9d590d2c61a4a049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdcf229634d4f768d8674b2efe1b1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492c4d41d0c6460cba3b4acf25bdb9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace64de7033247ba8419588dba65b219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d664a180d0f4fcfba1c4f7714efae55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b634284bd64234a1cd3914534deeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a39c2edd9844959f69f58a7309e179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9016fd287705441ba17dd0775f0d37de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f856fdecfc04d2ba03fc78775d2547b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb70b377db5c45b4b592abe44003058c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14806086b52b44ff8608459d45e28784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c02b398a11a4d259d23210a474bdea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661812b1480e4fe9b6f141e4a263e69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710d86f665df4c369bb3fb5573f4ff51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0642fba609407e822a268106ba73f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d09bb79c4134224857981c3bef3327a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c525e83a7914f06945785ab78c4a11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c64224da1ff495d8f5cd32124e4d26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef14cad4de94d248dad6b4c55bfc352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6905c67a80e442178ecd8a687dcdb1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637c2ee3e6bb4695b2ee35d75519e531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a371741ce04598b1002a56cb9913ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24560c14e964157968d8e0569b2692e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3964095afbe640c6b2e16c3c338083ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56de0b5252b64af0a6905fe1ad1f754b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791e5017b0b74bcb8dc920d55a687ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbafbb7f7cb4adb85b805936a40437c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b5ea689e484204b334358a1c421285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7f92ded5164323a4fd52134040fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed5bccd790a473cbb02932a546ed2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d242693040ff4bbabb847dd0bea7d74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f83cfc6c45a4d20aeef6e1462b7ab6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56194dfb2077421685271612242885a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4532e4599e1049df890338dbfae2764c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5937f8411d1648498565f66ee09d2c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec76d89a6a3467096ac2428b66e6910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7624a374a07f44eea13b4433039a0cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac6c1afc387415cb0d5ad86f00f26ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56654241b9874b8eb28c796b35310d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56d360448c840eeb0909fc8edade9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0410bd315f044e988ea514d18c05b39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786993e27a1b45b98a39b745f051cfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f6f87b62ee4a73804be90c0109f65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d45d796e354affaa375cd0a3fbfc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31cc7c598214c62ace55b20bbe964d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7613c16dbfd740f3a3f590904ed517a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e666ce409e6c485198f6304d27ab4f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6063db732243c4a1e0926144a06243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b733b022cfa4d9ea5b089741beffebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634e27efdc4d4a47940e82bf17ce6f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ed035afd514fd984d126ad07262460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06084495256c41229e52a3d02d639bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313d4536ea90414e97026925ae2dbfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15c283e7c174b9bb2add2b29eae5796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4853b548ad4c9287f5ce7575ce7f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c27ded39b3743cc9b7a3a7fef6cfd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95481a807434eedb6aeca142f82a1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e6db874efa4a84a09df7df411b8980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86da1c2f3e9e47d6b934ec234f5dd04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d697f7b23fe4cc085eaf1e516b492ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c02b564e46845f19d1393b0dba40e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22447de63d3a448a8984340af8738100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a67a040da634fdea9e39df95e9a925f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bd66dc3b474d88bd9408ce66e405f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39896a82900b4586a082e9145c9b12b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebf3bfda09b49a8952f94160810c59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c6c3fc67f9466ea3dc404fb55c4a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2459a13d7baf4a91ba0486c04fcdc58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a92e13672fa49c591d5a6a5e93b188d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9661b87cf74ed789767422a52097d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860533cc2c654dcb8815ef538b7be392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6127ad1349f4966b2a461a18d6d2901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681a77d5a0454c7c9d8e7754a23da332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a5ba66c5134cd2b907ba5aa69e46c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b37bae3f9be44819fccdb69be837c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998db2da104b472892cc0689856bda22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ddfb49e6b44f778542cb82f19a3144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8324cf218b824c2da466c2ce77c18944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1a16d3cd5541039626d1b4c4895aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c069875ea440f59414998c13cc220b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04300f943d2d4f5998af1cf5eba26d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecdbe5489a64abda1295e756ad9582e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e722b38db0848d381e2952a9b0f50cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735cc24324c74845b172bbf5bd06168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd14062546e4e00811aad8b50d656d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3767c89ec1ad427683a63128f38128b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b04dcff1304177997d8893494ac998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b157d1d453f2449b932bdb71d68eb34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2392afbc37e043e7bcec9233a28024b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf148cd1410d4b65bd3afb332469d627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db861977519433483ec73615972a34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a507fc8676864af09ae34af1ea77ee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72adeb17d2114ad0bb83cb7aeb5c23b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837a57a4a24a48c5ae8d63166dd0446a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6236af956d644ccfb5a636007fd3246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18001abe255e43d98836bc4738dfaf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0b265ef341437596c31599cfd4f2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8435655f20854bb99a177c7a21428ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af97b5cf6d1d4ab2b84a51459353ddc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195de10fc9884e22b6877b61bb567b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb293f7feb446cd80c7b812f2737f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a64fcdc6b740dda29e28ec9b9d686d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ff1a6e61384a3ebdf13de816172812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2af521eb3748e5be09645e56b59ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8830143dbe4756b997a7b6b597aa21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fcec113a7f4fc597628c300121af06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95501dd277d64f338bef535096ae8bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97886db64b9b43bb8cb482ad4063e245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21ba3385b9e4ea08913ccc7a394ecf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da35463bc484440906d78157a5f9e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4796b535d65e4721852730920a4c1e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9284101dd64e8e8b43c0def63c0cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb59340cca264fb0a87ff332f9e9cb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b4d3317ff045f6ae7e554d5447bc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3ac044f9e44cc3a92b69d57e63b292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6def2b9bf04586bbc81ca055e44d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8fe6976f554fa2ae071074bd0a75c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe699c224d147a2bbae6e168309b184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55036e1795f4161a126cf0a16b42af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384d959a99334adfbc791be618b8769c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f382a8583e3541848fed7031aed5164c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4897687de93348ca97f73f91b2b493c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21608f749a2455981295dd4febccccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04056c9c409944a580b70fd3105b41a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5720e0a56a904155ad70759a779fb56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ccb72f373d414e84074a1f1ff5a897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f312f7931644d2495d7e9792ee06005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3b932025524431a45e921a4b371bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd4424d9ac64b1f8fbf9d70dfd947f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976092504a264a4289ff1cddc6a67580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3a083669774b918955f9729862eda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f966f022b08b4c58a96b6bc0ac6a654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab760d69ceb4f8e850d20edf4dde2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fafaf9cfbd64be19fee8fbefd2f126a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3460d0015249ef800dd2b7c7d5a473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b5a9958eec496e975802e94a30c8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d53c5f39aa4b76907961e5c862074a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bd97af5bbc439b85ee71decc60b354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00f0edd72eb493d855711c2aef3f179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac66bf5f044405ebf6ff28428f99ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af27d1202644966995b9927775e493c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4017ca52984dfd86c1d6a6a23917c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5e53499a9d408bbffc891ba2271df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4a54c7bd64456b9c47b98fd8426fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516513a87ba64d85a220ac724fe8c580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a094cbf9f7674bc7bb8fbe28edf4f09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea9d14ff3454f0ba16747af1ffabefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f682a02546bb46ef9ecd1aa3ad323ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8923158003466db5fc61cddec64599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f17cb863be4f0ab4da328778342ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76af2cf215f49fe9cee367e031295db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d78ee59799b40da8dc7ab86b129e65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046f9d8fc1cd4c6291b2ceff339c77e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5910e0dba08f4da9aa7aca5a1c6ed095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c89c08f328444d92b86496aec4e148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6a2ea481a54a679ed046a2fea2687a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e63a2703d6e46c6a34cf4423260b26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7521b75df3e4352b016e568873ff710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90baf2af8bf44dca969de262cc617d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee01874557d404c9940b2c4a355d9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b06eafde7548a0b719c171bc8208f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9c123deb4c45369ddea9df5c869b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8a25bf406f41368a7ade391ac20f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a840626f284d4186a4732dbe008f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9d587cf0b64d75a695210d115ab7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fc5eead47e4c29af08ff0ec10b9d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4052598a19974dc39d0748152c0f8763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72171e06e6c42678bec1cc52a361769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747e1c8c8749498da079734f68940a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773a82e5b5f34fa19f129682e700cee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14323c9c71284235a3db8357cf93258f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2713eec45bcf4446a8692d24d6d87c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63b1ec59deb4010a640adbec8177416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe6a047ce6b47239d9b7e6c123a36ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30482bf065c949769052b6848a8e7983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd047ec2bc9454ea2ab5aea182b3a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e4733a39a5444283d916680f04648b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3518cc44bd6c493c9070f1722f1d64b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d401b73abe04990b30ef61665e1d2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56fe0aacf3143b1bf8abd4dbf9c31bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b66477307664dfd935f5dd332b3016f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ffba289487438e9b2258e50fe92a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12b441e43d84ce2b6a58b670dbe5b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c134d5dca2564151ad8cdcf38b2d1d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605353f53f114d2ab1828685c8975985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de3c9eb2558461ab03771072fd4ab64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa1146eddf64bd6bf194ea8a6dba7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc04e9cbb56f4024901a1f3d25422536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da60f3738594ca298348d1d65cb7474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032a242ea46c481980d7ca20f7092fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e52fe9dc384b76a611184992ab9383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10fdd83861549c9a992fbe4de939ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14de4498e76343e98f3a753b5c18fadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722758ce5c8c44bdbd85de33b1748ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc807c2776f4dabb5f4c37aa31a21f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f36e9916944596a0ef0720b21577db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36df81525c5454fa84a1e83f4e18051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951e9e2a403e4707b1470e3e546d3067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e54c3dafa145e1bfb954ef459914ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300526b6db7c48f197ea949a81191a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbc9993e69345a89bdc19a9df89fa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e77feb2a6f49dab7d621295fd2dd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98637aaf4b5d4d9e9e4878f9a33fc8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12ceec9d0d64edf87d78d4fb4ded773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdbd43124ac4540a26a53e36c695db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c2a6223bfc44338d14839c1ec737cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d65ff0581ec4b8896fb9794f238fe8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a63ed6d8d64cd181920ab302332c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdd09215df34989ad1dccc9cb103708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cbdc106f764361ad0857d661af78e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aab8752d1b84d1b8619265af14b7cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3462fd8b0c4f5a8693ced373df5430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0964d62e982144bb9e799e825b82da57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36796af5539449e4a71cc1b77dd2233c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bd48c867a241aba09e3d8f3023d1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403e7bd7c0bf429a8f4dbfdeab206a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb67583916bf400eb7cf4da306465346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fc381a730444ab956ed85dc0ec1a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c83a6d0f594b3b97d55fdd8d4eda4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfeb38db7f03419dae6861bba890484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d68f99a53954495845d04b5329ad0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf76ddee6e74d2cbdb217f5fc15c787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1a2960b28b4923b53111eda7b99c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c6942362114272be7d0dad13f81476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6816f05d1fd6469c9b32b2f0d5127c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db9b235178b45baa2d26b60e05bfccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e264c45f33d4f17b39b72c1d8cb48b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc56692e52b43d398770aed9c53e5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53b5b03c7974ede990c0db0e1b3bcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0489e4985308470391a0ced6c518b01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc60f08a06a84b1da2eb46d8f2ced00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5244ffe66f24648b1bc5d9b3369da61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236d3c3be47f4f0699a9c3dd2abbc5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7776e26f2fec43fca8772af18ae3c2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b3fb3474354f3d90d5953c90e1fe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7371c427694e8bb57d2a60fb6f393d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4637003be3f340b392a24263bc2c407b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0a1c0e2fe24191aa262a2a2f8d3e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fedbc179d64c38904a4d1ec3aac286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ad4090330b451e86681d54d91aef1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5736d15a194e4ca8a06e4bf31b2ecb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e530beef874fec94c658b2a23e57c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287c2b70f991457ca2952cec847bed34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950f3975fffd4d5282674a6cdfbb7af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97925bf1bccf480a800679ddc1555ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ed6623bdf54e5688ce6f6a6df3d2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec1c2c08d8e4fb0834058e400b82de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe195fbcdc6408cbb90b0ce723b5f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd790f19394c4e9096e385cba11479c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3effae320e9438580ea28491718b5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a63d4bb30b74bd096e878001fb36568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262138d0591342c0996b4d96605411d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511cf7039362469a91f6fbc3629eb334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500a602bc9df48ffa61de4357d42f056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de030158290548878381134b55ea55ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde68237400c4953b49da99460685cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c723e02d9e5c4d57a2ad6130ff723af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232ce2f17ceb44a4a664197be2fb545f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe7d89cfc6140ae9122db764b489e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d04941fa28b42f0abd70372ef0bc813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690bcb66c3df445aa30c2f7c0f2f319d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba29cd15e4245178db5d212e9f2776a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50f0cbf1df0497f94b56431a7923b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fd1e4365304bf08b54d17384490ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59550b655ad849318a5579ec9d47f6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448bc2eb85ca435dbf30fbf7e700a30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c50eefc7534ff38358154962d00919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838907d765af4a48b98f72e67d4230e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600730e42cb3490b9ce210810162c143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667421fed014143bb53e98180673591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f609d0e650ea4e32a3039bc2b379b109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc017fa4d6a463d8f7253bf949e0350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52b9fa31d214c059b44dc63bf476307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56183feb9725492cb14c17f4f15031b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a63447af80b4293a992c429f193ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de835c58e091488a84dd2f9ee239c333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0770eb7ad08040bb8883491e38682467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d39522f2a443969077775c0555b51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c929d910b0bf44e595fb4ac4b71f90ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0026ecad49491fa41bd0fc80fde6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24bd3ee646243598124c60a3df91c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a2c4e7cb044715b8332500c95abd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9c66f6d2a94197a2ebdd3e78cf8d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f05303a27ed4b84b28a192a77f8544f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376d3d781868448faaf026e06fdeecad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e08a582dd48918cdfebd1b23c29d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5c7c82b21c4805ae2d0e4c2d6873ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b27296ce376456db7994cfa84d30c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a1a48c540c45dda42952d97076f975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfe5d58ddb84b829c65204bd4b4c474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d4289add024c6ba7c6eb7c75798063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48a5fe14a0444699bd87f4ff12c4c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c28dd8e884410d957211d34c02f2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f223cb5bf2416eb5d738e106423460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eb0b5c15184687a5345391071a20d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07803f332c6847729b2ac601ebe28c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3221c1cdd42d4f2f9b2e66db833b2b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203344775f9d47d49308d72a29d2eff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cb9f6d598e4ac1afe55fec8bd813e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c098004d7c1541259dbf0e47a5cd0b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9557d00d7cd647d18fbd3ad6a287fa66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0b6646a74c48fb901b3d7a27750a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ec1232b3d24b5cab999cc76c334d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f758881179e4a2ea72ad653d2da90f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efffaf786efd452ab2597c6f085ba4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d828b37323804aaca36b40f12563ec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb0a5f0107d46649478e28921b4477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd1553bade243309e22f082b7cb87cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08e9d52264342af817832e170073579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e46a2455c248f2a3037985a11aa19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5358663c6cb64dce91aab360d7c12e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204428aff5324b64bb6fa46be67ee3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e53f7ea5a04ab899ebfcac18eb55a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69f06bb5bb84033be3be447c8dd895c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6362ca18f6cc4ce79766b384b9e40f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d877e2703aef4af896fe4bcbbeb6763b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0f094b90a943fe85e954c9a2d95896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863b31ca6d7446abb1388ae1763c510d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50907854a26f47e1920719e6ccc96eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73590cc8ef2a48e48d26205a774f94f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cb1dd53e4043eeafac2a4bfecba4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f760134f8b45d4851abdfa253d4157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1478df969c404a64a715e6469eb69691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45cd5c1f3fe4196817536a20311ee3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3c7d4395e44f9d85e7fc05477f83f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f598dc9ae14f019d350cf1b334c55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2f867a96484033a10a33f33179b953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c6385802984b53b6c8cc98dbde00a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d3a16d98474211853e0ef728d2771f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922122657e6b458ca9bca26a17de0ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0868c1a315444dcab6c62d765740028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f88c3e005694b3085fe4d823d2c3ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65ad9a706274807af102327e3da6f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a31d1375ff48f4ac7416adcf371b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783a837f51d341419462740ecaab1574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68369eb6d81439b8a582f9863deb5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2548b0b715e04c139f0a626875ecc072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ac79ccd5854e2caa19d4e72a31539f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bfee3d1c17439783463a270913f21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7afe814c7441f4aba968a7f24ef8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0d57c65cd14db7a3fd103847977e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7504df7d328249348fac8a03ffb26ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c27dfc09604d1b83bbf23ed9bccd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51763378f0ed4d1da6d73687277fe442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f076ed8d0b043058570677ec18859ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fc749d72af4fc48b1002196ad6aa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f7bd7734fd4995bd9d324ec7d33cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14878ef8b31c429fb3e3f03b9125e4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b6165e704b4744b659b2b1d5918f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fde09120e24311bd1948d52073a667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad30c355c14b4d57a441020a5bf24f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24150b94c4c44e14b5faee32d3d1c1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fde02ec0624f7c853d3d88a09b181b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bdc0491c104881a79253c9b50edec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69204788bc6343b596e4ecc9a00a666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86440cf83102440995a1a49d5c67b0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aa57ad03f24c4fb28fdc54cd87c313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd91aa3c66d34388b094f34e4e6fb717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e876831074416fb51295c283920a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf2974d1b844232978dbd7822a5cee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05d63b68b1c4101888407dd4ccd78e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12792a4404e54eb89fa695aa17a828ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4044c91032b14289aab87ae0c0df313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43f60bcca9449d0bbf0ebec90a036ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325648b4747248edbce1e2fb63ef6c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2208492057d24942ae890d2409aedf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d335ba1bb9743d792fde8e783edc4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb89dbbd70a4135bebbd979064ff97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ff79783b164694b7409d2b5df25482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e17a3417d6c4e7080e12e523fced40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c242478f76444f48fc1420dbb594f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b423b8e91c8548e49872087b546cda1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc952be22ff416aa3b35759901ef4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce41c0b5764da9bb69d859cf658b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c763d55622c42d692e67b8cda9bdccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afabdd86a344d5e9fde895571241a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be48823953944398ecab8fdf05efa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de80ea428f745baa437e560d210b629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344374866b7649b59f55f15e36a5b034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e478d546f6a54b96ae835130e0617ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7a9aabb0e348ffb0dadb7eb15b069d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94afe893798b462a9bbb490c14ce9e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cddb5bf8c2449eea79119bb4cf8be9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fe0f75718e4be59cc2361792f25460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab0705c09f34d6e965f2015ae7aeb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc19dfef389f482e8ea57c1e36d9adab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987fd141f7f647d7964bbbb160fcec1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a56a0f41f064307b79b718cdd13ba72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39d3c434b444693ba669f0882143658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e758605fda43c2973e30e5880ca255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8765e0fd827e45fd8316ad1eedba1c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6998c79f288e4c6788a8b182d486fa69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c356cbb9051b407aa9c1bbc6ca8bd43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e17e2909aff4492a7cc459205b11846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93583a52b8c14537a00c96a2f118472f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adc54f92ff2414b8ea0f91eef444b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57d7e2800164291b10e82f76f33046c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc554a217c99496eaabc994c5344f185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0faf77cce574d9c835865489ddb6b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048613c5837b43fca54f99c050e32d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef161a89e84e4950aafaf438d3d36e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e18eea3070e40e29024c42220714d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003354a700ea4b0585ad8038b751631b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a3e647f6014699832b6b09040c074e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b3cff91a3643e489c4c4da935b67be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755a398a2f044030be91ad8760092b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7516de35139431b94146ce5132a8b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d14bb5338024118bfa7fc4a7ba8905f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864c99fe6cda48d3a5cdda5c16062765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2692b44fe71d48bfb550f2faa218dd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c2940caf554677a77f02ed68a8b101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a574fe0afe584b7c88bf5be39a130378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990407717c294c0c8aabacc1ab752fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe07011760b44eb95b1cd3f043fe473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3265b076c64dd6b523681cde4567e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bbac29b61e42c2944bf763e7b51d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcc90e7ea7642c58e7947b009e3c48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfbe15271a24666acc4d8d9383ac135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73c7198bd974964b609b4bf6076b348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ffee14559d48e89127858588d2fa87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535cb5bec5a4d2bb8002f8a323905d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451661c36aeb465ca8b23bd51cd3ff8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d8e10879c64dab8382acef2821c71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66514d4b0f304e32aace5958fe39ae87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dd4f0ebe514233a099dfc5b75058e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074df8348e554d2aa208be5279b39a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbea1948954a499fabf70ca128765706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0a639daf954a2a98ed5ec14b937b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a31892b35a45c2b6962ca3b0fc1647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629f6930e205492db31191a3a7d374ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63faf47ae074bdf8c2e709933d330c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab364e8e33342dfb8d7c8bc78ddf116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e11c85e8344e80922b71842ffd7c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8143004bd1884e139b0ca0738be871b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04008c5500f14968853d9182ca60c76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f2b62e9bef4790aa44591e2fe1aba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046589c04e134a66864253b734a73f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf87aa0f81274e8e94104f0440a40d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b241a68fa02d423d9365464c7e2036fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293c369f00074b35bcc9e8d1311225ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543106741474484cb509f58c56307b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0419e69f7d4176809739caf2797f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e3e1ad30bd443db22947ce2e1606f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e8700e6d264a158f9d2a9edd27a4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a2234b65ce421d97bd9105d8e77643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12e64ecac274d5291f1d57bd859e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6605d8a8785c42c5878c0140c50391da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f7d861ed9d4ca8820d00b66476e540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca539103dbb4dc3a6b4211854a077f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cdb7130f2640d5bde4cb164685f94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647cbeed66954b09aa80a30b4dd5ff01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a17874614eb47089757e2c4347c9af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fcf6facb48476b9d33c035c4d85d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b91548a17f4d12bb7404f066633a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6574d9c2d5a8457d9fe72f1c51124d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a877b80bddff433aae1b7eaf15b9f866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c2d6e6d683400ebde483fdab23bac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259487f9b67d478c8092d42ab51fcc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afe1b19e07143f28e566e23ea55d857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b934d6927c4868a818f8e58dbc79f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064c9fb4b3ea4359bdf2c8647701a3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc962db2c4f48a4907a9a41ad1c5695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e27b4d946f408a9c85e6a24666a281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b14312dbe848fba97db0d8d12ae8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf266b70e6cd40fca638c8b0eaf6e62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795a87b4c854484a9d9cc1b4661ade86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ebc860797940308002db0eb3f6abcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26ab94057d4460b830ffd98c0c0c01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd72988c49d461c9b0b94250f30f58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c359afa180743839d97ec9fb4a3686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b2e710c1ab41509cae3a7c050f48d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ade2dfea9fa4292a1f272ba73dc610d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e495be2fd849e6bac379bb7def5cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea76b477e8a43cda0311abc5ed40cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725f7c98c3694a48a2ef521223f6b83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89baf417f2af400aa5d306001e628db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d9ab081e84d18a2aa4d75133ffe5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc48c0f12e0340039a606e26ed608d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bd034eae404a9aadfdd403170702f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fadb0f8182c44cfa026275d944d2d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b526f24c13334c36918aede06ca7b19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df31c3dca1514fcea049a1d0cadaea0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68d2eb20eb445e97f6e8df76fa40c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbb9d401175443f9a35c230d9250044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387d8297e3eb4c409d6a581bf3e77465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f8a457948145bc98db3a34863f7014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27717cf3d25f4328a14ce374b3024516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69ac782e6a348cbb5212abaa0e01281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30eecd8b5b643c09847232a64b1b46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5373b4c72d9b4d048573110d79f39fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "only bool and floating types of src_key_padding_mask are supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 306\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 301\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, early_stop)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# --- Evaluation --- #\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_validation:\n\u001b[0;32m--> 301\u001b[0m     mse, mae, acc, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_mdn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_val_accuracy:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m, in \u001b[0;36mevaluate_model_mdn\u001b[0;34m(model, val_loader, threshold)\u001b[0m\n\u001b[1;32m     62\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m mdn_params \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m B, num_lines \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     68\u001b[0m y_pred_lines \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 168\u001b[0m, in \u001b[0;36mcnn_transformer.forward\u001b[0;34m(self, X, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    164\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# 3. Transformer Encoder\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# The mask should indicate which key values are NOT to be attended to\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m encoded_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# We use the representation of the last valid timestep for prediction\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# (A common strategy, alternatively you could use mean pooling)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# For simplicity, we'll take the last hidden state of the sequence.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m sequence_summary \u001b[38;5;241m=\u001b[39m encoded_seq[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# (B, d_model)\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/transformer.py:414\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    392\u001b[0m     src: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m     is_causal: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Pass the input through the encoder layers in turn.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m        see the docs in :class:`~torch.nn.Transformer`.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     src_key_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_canonical_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc_key_padding_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_none_or_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m     mask \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39m_canonical_mask(\n\u001b[1;32m    423\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    424\u001b[0m         mask_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m         check_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    431\u001b[0m     output \u001b[38;5;241m=\u001b[39m src\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/functional.py:5957\u001b[0m, in \u001b[0;36m_canonical_mask\u001b[0;34m(mask, mask_name, other_type, other_name, target_type, check_other)\u001b[0m\n\u001b[1;32m   5955\u001b[0m _mask_is_float \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_floating_point(mask)\n\u001b[1;32m   5956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _mask_dtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbool \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mask_is_float:\n\u001b[0;32m-> 5957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   5958\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly bool and floating types of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5959\u001b[0m     )\n\u001b[1;32m   5960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_other \u001b[38;5;129;01mand\u001b[39;00m other_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _mask_dtype \u001b[38;5;241m!=\u001b[39m other_type:\n",
      "\u001b[0;31mAssertionError\u001b[0m: only bool and floating types of src_key_padding_mask are supported"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=500,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_transformer(input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim,num_lines= max_len_y )\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3023ae",
   "metadata": {},
   "source": [
    "## two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91951ca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm        | LSTM              | 68.6 K | train\n",
      "1 | fc_reg      | Linear            | 774    | train\n",
      "2 | fc_len      | Linear            | 774    | train\n",
      "3 | loss_fn_reg | MSELoss           | 0      | train\n",
      "4 | loss_fn_len | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "70.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 K    Total params\n",
      "0.281     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.086008 1.126277 1.165107 0.970955 0.       0.      ] Encoded (padded): [1.086008 1.126277 1.165107 0.970955 0.       0.      ]\n",
      "Shape: (5, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]\n",
      " [-0.08115927 -0.05037893  0.09358804 -0.03372177]\n",
      " [-0.03365467 -0.03511871 -0.06278902  0.03521458]\n",
      " [ 0.03742796  0.00087057 -0.13184595 -0.11191386]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb4ca39a9104d4db486b4db8d24f6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250910_154556.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250910_154556.pkl\n",
      "\n",
      "📊 Validation Metrics:\n",
      "  Regression → MSE: 0.439017, MAE: 0.504375\n",
      "  Length     → Acc: 0.0667, F1: 0.0096\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            # Send to same device as model\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression + length logits\n",
    "            y_pred, len_logits = model(X_batch, lengths)\n",
    "\n",
    "            # Regression targets\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_batch.cpu().numpy())\n",
    "\n",
    "            # Length targets\n",
    "            true_lengths = lengths.cpu().numpy()\n",
    "            pred_lengths = model.predict_length(len_logits).cpu().numpy()\n",
    "\n",
    "            all_labels_len.extend(true_lengths.tolist())\n",
    "            all_preds_len.extend(pred_lengths.tolist())\n",
    "\n",
    "    # ----- Regression metrics -----\n",
    "    all_preds_reg = np.vstack(all_preds_reg)\n",
    "    all_labels_reg = np.vstack(all_labels_reg)\n",
    "\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    # ----- Length metrics -----\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics:\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Length     → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=50,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838866e",
   "metadata": {},
   "source": [
    "## xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439210d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "# ---------------- Evaluation ---------------- #\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def evaluate_model(model, length_model, X_val, y_val, true_lengths, return_sequences=False):\n",
    "    \"\"\"\n",
    "    Evaluate multi-output regression with predicted sequence lengths.\n",
    "    Permutation-invariant: sorts both predictions and true values before computing metrics.\n",
    "    Can optionally return the predicted vs true sequences for inspection.\n",
    "    \"\"\"\n",
    "    y_pred_full = model.predict(X_val)\n",
    "    pred_lengths = np.round(length_model.predict(X_val)).astype(int)\n",
    "\n",
    "    print(\"\\n📊 Validation Report (Multi-Regression with variable-length sequences):\")\n",
    "    mse_list, mae_list, r2_list = [], [], []\n",
    "\n",
    "    pred_vs_true_list = []  # store predicted vs true sequences if needed\n",
    "\n",
    "    for i, (pred, pred_len, true_y, true_len) in enumerate(zip(y_pred_full, pred_lengths, y_val, true_lengths)):\n",
    "        L = min(pred_len, true_len)\n",
    "        pred_trunc = np.sort(pred[:L])       # sort predictions for permutation-invariant metrics\n",
    "        true_trunc = np.sort(true_y[:L])     # sort true values\n",
    "\n",
    "        mse = mean_squared_error(true_trunc, pred_trunc)\n",
    "        mae = mean_absolute_error(true_trunc, pred_trunc)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            try:\n",
    "                r2 = r2_score(true_trunc, pred_trunc)\n",
    "            except ValueError:\n",
    "                r2 = np.nan\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  Predicted length: {pred_len}, True length: {true_len}\")\n",
    "        print(f\"  MSE: {mse:.6f}, MAE: {mae:.6f}, R²: {r2:.6f}\")\n",
    "        print(f\"  Predicted lines: {pred_trunc}\")\n",
    "        print(f\"  True lines     : {true_trunc}\")\n",
    "\n",
    "        if return_sequences:\n",
    "            pred_vs_true_list.append((pred_trunc, true_trunc))\n",
    "\n",
    "    print(\"\\n--- Global Scores ---\")\n",
    "    print(f\"Mean MSE: {np.mean(mse_list):.6f}\")\n",
    "    print(f\"Mean MAE: {np.mean(mae_list):.6f}\")\n",
    "    print(f\"Mean R²: {np.nanmean(r2_list):.6f}\")\n",
    "\n",
    "    results = {\"mse\": np.mean(mse_list), \"mae\": np.mean(mae_list), \"r2\": np.nanmean(r2_list)}\n",
    "    \n",
    "    if return_sequences:\n",
    "        results[\"pred_vs_true\"] = pred_vs_true_list\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=1000,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor with a linked sequence-length predictor.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.pkl\"\n",
    "    length_model_out = f\"{model_out_dir}/xgb_model_seq_len_{timestamp}.pkl\"\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # --- Preprocess data ---\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, df, feature_cols, max_len_y, seq_lengths_true = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, df, feature_cols, max_len_y, seq_lengths_true = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "\n",
    "    # --- Sequence length targets ---\n",
    "    if do_validation:\n",
    "        idx_train, idx_val = train_test_split(\n",
    "            np.arange(len(seq_lengths_true)),\n",
    "            test_size=0.2,  # match your preprocess split\n",
    "            random_state=42\n",
    "        )\n",
    "        train_lengths = np.array(seq_lengths_true)[idx_train]\n",
    "        val_lengths   = np.array(seq_lengths_true)[idx_val]\n",
    "    else:\n",
    "        train_lengths = np.array(seq_lengths_true)\n",
    "\n",
    "    # --- Train max-line regression ---\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "    model = MultiOutputRegressor(xgb_model, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Train length predictor ---\n",
    "    xgb_len_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "    xgb_len_model.fit(X_train, train_lengths)\n",
    "\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Save trained models\n",
    "        joblib.dump(model, model_out)\n",
    "        joblib.dump(xgb_len_model, length_model_out)\n",
    "        \n",
    "        # Save full metadata\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"multioutput_wrapper\": {\n",
    "                \"class\": model.__class__.__name__,\n",
    "                \"module\": model.__class__.__module__,\n",
    "            }\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Length predictor saved to {length_model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, xgb_len_model, X_val, y_val, val_lengths, return_sequences=True)\n",
    "\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "399de860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "high_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "low_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "close_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "color",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "9c26590e-b077-4584-9444-d4d9586e7fb5",
       "rows": [
        [
         "0",
         "-0.0068055624",
         "-0.0018210557",
         "0.0068285237",
         "-0.0006807154",
         "0.007333628",
         "0.010903704",
         "0.00088069274",
         "0.3"
        ],
        [
         "1",
         "-0.0010943405",
         "-0.0057572033",
         "0.002917143",
         "-0.0031939948",
         "0.0026314235",
         "0.0048398324",
         "0.0029807962",
         "0.3"
        ],
        [
         "2",
         "-0.00285208",
         "-0.00048262547",
         "-0.016986681",
         "-0.0049213697",
         "0.0050139083",
         "0.016906133",
         "0.0050498187",
         "0.3"
        ],
        [
         "3",
         "-0.00520802",
         "-0.0077257366",
         "0.004962294",
         "-0.0061933547",
         "0.002470321",
         "0.0058707357",
         "0.00603531",
         "0.3"
        ],
        [
         "4",
         "-0.006068482",
         "-0.0016525547",
         "-0.0027655975",
         "-0.0030261625",
         "0.0069241854",
         "0.0056109144",
         "0.0029928894",
         "0.3"
        ],
        [
         "5",
         "-0.0030498218",
         "0.0065295254",
         "-0.044257425",
         "0.008595066",
         "0.007878535",
         "0.049565744",
         "0.008578437",
         "0.7"
        ],
        [
         "6",
         "0.008594573",
         "-0.004261501",
         "0.042307056",
         "-0.007389482",
         "0.0036412624",
         "0.010542268",
         "0.0073323115",
         "0.3"
        ],
        [
         "7",
         "-0.007397718",
         "-0.010144928",
         "-0.016040526",
         "-0.017917922",
         "0.0008635001",
         "0.008650774",
         "0.01785321",
         "0.3"
        ],
        [
         "8",
         "-0.01797516",
         "-0.008617725",
         "-0.004649495",
         "0.0042537893",
         "0.0059956904",
         "0.013137509",
         "0.0043594143",
         "0.7"
        ],
        [
         "9",
         "0.00429638",
         "-0.0038665873",
         "-0.024172999",
         "-0.032567978",
         "0.002187863",
         "0.008913396",
         "0.032488868",
         "0.3"
        ],
        [
         "10",
         "-0.032493856",
         "-0.025373159",
         "-0.1888325",
         "-0.12462161",
         "0.00956381",
         "0.081611745",
         "0.1246171",
         "0.3"
        ],
        [
         "11",
         "-0.12416256",
         "-0.10872804",
         "0.05328718",
         "-0.007428348",
         "0.027354943",
         "0.025434013",
         "0.007943466",
         "0.3"
        ],
        [
         "12",
         "-0.007943466",
         "-0.030241696",
         "-0.056677263",
         "-0.043454073",
         "0.00426332",
         "0.038906313",
         "0.043454073",
         "0.3"
        ],
        [
         "39",
         "0.00078487874",
         "0.024657143",
         "0.010343597",
         "0.044932652",
         "0.0056655793",
         "0.0037865022",
         "0.04317775",
         "0.7"
        ],
        [
         "40",
         "0.044650245",
         "-0.0051417896",
         "0.018004237",
         "-0.017405028",
         "0.0009504914",
         "0.012450813",
         "0.01695735",
         "0.3"
        ],
        [
         "41",
         "-0.01695735",
         "-0.008000314",
         "0.0010403421",
         "-0.0010502199",
         "0.010070696",
         "0.010384111",
         "0.0010502199",
         "0.3"
        ],
        [
         "42",
         "-0.0010365214",
         "0.035162725",
         "0.009993072",
         "0.03471769",
         "0.011567499",
         "0.0005085139",
         "0.033539563",
         "0.7"
        ],
        [
         "43",
         "0.03469893",
         "0.001155095",
         "0.027320517",
         "0.008525978",
         "0.004174387",
         "0.007635864",
         "0.00845828",
         "0.7"
        ],
        [
         "44",
         "0.008421097",
         "0.0019629225",
         "-0.016749207",
         "-0.026853178",
         "0.006254593",
         "0.0058132075",
         "0.026747666",
         "0.3"
        ],
        [
         "78",
         "-0.11196716",
         "-0.06856559",
         "-0.07827628",
         "0.028492898",
         "0.02427655",
         "0.088856496",
         "0.027543899",
         "0.7"
        ],
        [
         "79",
         "0.028324053",
         "0.047515854",
         "0.09991321",
         "0.035943583",
         "0.035718497",
         "0.025425136",
         "0.034696467",
         "0.7"
        ],
        [
         "80",
         "0.0358513",
         "0.0119549325",
         "0.01905028",
         "0.029248113",
         "0.0183166",
         "0.041232284",
         "0.028503519",
         "0.7"
        ],
        [
         "81",
         "0.02933951",
         "0.005722704",
         "-0.031330984",
         "-0.088816084",
         "0.02414442",
         "0.009797542",
         "0.08881582",
         "0.3"
        ],
        [
         "82",
         "-0.089057006",
         "-0.07802817",
         "-0.03593925",
         "0.022137476",
         "0.013825884",
         "0.045131933",
         "0.021916976",
         "0.7"
        ],
        [
         "83",
         "0.022408094",
         "0.061686527",
         "0.060444098",
         "0.07485802",
         "0.0014022917",
         "0.009608579",
         "0.06964456",
         "0.7"
        ],
        [
         "84",
         "0.07492461",
         "0.015790671",
         "0.059088714",
         "-0.0059206914",
         "0.017152084",
         "0.018326482",
         "0.00598228",
         "0.3"
        ],
        [
         "85",
         "-0.00598228",
         "0.036894463",
         "0.010711189",
         "0.04107391",
         "0.019165603",
         "0.007811592",
         "0.039453406",
         "0.7"
        ],
        [
         "86",
         "0.04107362",
         "-0.013661202",
         "-0.0060738465",
         "-0.02413501",
         "0.0052428567",
         "0.02931802",
         "0.024134738",
         "0.3"
        ],
        [
         "87",
         "-0.024134738",
         "-0.028876178",
         "-0.038408116",
         "-0.043952346",
         "0.0003586817",
         "0.023688922",
         "0.043952346",
         "0.3"
        ],
        [
         "88",
         "-0.044019688",
         "-0.030821588",
         "-0.00036684907",
         "0.008412554",
         "0.0056380425",
         "0.023978332",
         "0.008412223",
         "0.7"
        ],
        [
         "89",
         "0.008483291",
         "0.028506603",
         "0.018891403",
         "0.02612223",
         "0.007974818",
         "0.013905241",
         "0.025457518",
         "0.7"
        ],
        [
         "90",
         "0.026122237",
         "0.029252315",
         "0.031228155",
         "0.017807772",
         "0.019308796",
         "0.008998497",
         "0.017496487",
         "0.7"
        ],
        [
         "91",
         "0.017854795",
         "-0.018740904",
         "-0.03584698",
         "-0.045240235",
         "0.0001601105",
         "0.016758315",
         "0.045284066",
         "0.3"
        ],
        [
         "92",
         "-0.045283783",
         "-0.0049555474",
         "0.012269985",
         "0.015727747",
         "0.02626738",
         "0.0046942504",
         "0.015483923",
         "0.7"
        ],
        [
         "93",
         "0.015727742",
         "-0.0017025031",
         "0.0073294165",
         "-0.010458501",
         "0.024519857",
         "0.002490984",
         "0.01045879",
         "0.3"
        ],
        [
         "94",
         "-0.010459082",
         "-0.03221561",
         "-0.050351754",
         "-0.02913019",
         "0.0019942643",
         "0.024294836",
         "0.029129904",
         "0.3"
        ],
        [
         "95",
         "-0.029129904",
         "0.005020979",
         "0.0057383794",
         "0.02859558",
         "0.0084040575",
         "0.01869587",
         "0.027800607",
         "0.7"
        ],
        [
         "96",
         "0.02859558",
         "0.0047507333",
         "0.023052862",
         "-0.009254252",
         "0.013194716",
         "0.014867084",
         "0.009254252",
         "0.3"
        ],
        [
         "97",
         "-0.009254252",
         "0.011791489",
         "0.009140797",
         "0.022568813",
         "0.011880386",
         "0.0058621843",
         "0.022070704",
         "0.7"
        ],
        [
         "98",
         "0.02256911",
         "0.00035856458",
         "-0.019459583",
         "-0.034220506",
         "0.012242914",
         "0.012944504",
         "0.03422079",
         "0.3"
        ],
        [
         "99",
         "-0.03421174",
         "-0.03859546",
         "-0.013965499",
         "-0.010785625",
         "0.007648335",
         "0.016117437",
         "0.010794894",
         "0.3"
        ],
        [
         "100",
         "-0.010814539",
         "-0.0067777443",
         "-0.020254796",
         "0.0027574284",
         "0.008958252",
         "0.036026634",
         "0.002769651",
         "0.7"
        ],
        [
         "101",
         "0.0027776489",
         "0.00215075",
         "-0.013217116",
         "-0.028641665",
         "0.011127961",
         "0.023431618",
         "0.02864196",
         "0.3"
        ],
        [
         "102",
         "-0.028809845",
         "-0.028207412",
         "-0.0036295892",
         "-0.015562422",
         "0.011755168",
         "0.011594173",
         "0.015392247",
         "0.3"
        ],
        [
         "103",
         "-0.01539256",
         "-0.009093565",
         "0.0046521598",
         "0.004339809",
         "0.013827697",
         "0.006995634",
         "0.0043213735",
         "0.7"
        ],
        [
         "104",
         "0.004340129",
         "0.014991901",
         "-0.0017757493",
         "0.008200807",
         "0.020656694",
         "0.0130424835",
         "0.008134101",
         "0.7"
        ],
        [
         "105",
         "0.008201124",
         "-0.016525358",
         "-0.02255073",
         "-0.029545391",
         "0.0037896608",
         "0.014014751",
         "0.029545696",
         "0.3"
        ],
        [
         "106",
         "-0.029545696",
         "-0.026205523",
         "-0.03714354",
         "-0.03402438",
         "0.0072445697",
         "0.017198522",
         "0.03402438",
         "0.3"
        ],
        [
         "107",
         "-0.034024704",
         "0.057783406",
         "0.006988524",
         "0.07902425",
         "0.022196325",
         "0.010329858",
         "0.07323708",
         "0.7"
        ],
        [
         "117",
         "0.041484717",
         "0.0069704666",
         "0.04278997",
         "0.0042830794",
         "0.014912753",
         "0.008700135",
         "0.004423538",
         "0.7"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 317
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_dif</th>\n",
       "      <th>high_dif</th>\n",
       "      <th>low_dif</th>\n",
       "      <th>close_dif</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006806</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001094</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002852</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>-0.016987</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.016906</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005208</td>\n",
       "      <td>-0.007726</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>-0.006193</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006068</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>-0.002766</td>\n",
       "      <td>-0.003026</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>-0.041315</td>\n",
       "      <td>0.060291</td>\n",
       "      <td>0.021794</td>\n",
       "      <td>0.106569</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.096806</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.107181</td>\n",
       "      <td>0.076916</td>\n",
       "      <td>0.090062</td>\n",
       "      <td>0.058212</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.055011</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.033486</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.072815</td>\n",
       "      <td>0.039727</td>\n",
       "      <td>0.086572</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>0.080029</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0.086990</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>-0.059434</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>0.059434</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      open_dif  high_dif   low_dif  close_dif  upper_shadow  lower_shadow  \\\n",
       "0    -0.006806 -0.001821  0.006829  -0.000681      0.007334      0.010904   \n",
       "1    -0.001094 -0.005757  0.002917  -0.003194      0.002631      0.004840   \n",
       "2    -0.002852 -0.000483 -0.016987  -0.004921      0.005014      0.016906   \n",
       "3    -0.005208 -0.007726  0.004962  -0.006193      0.002470      0.005871   \n",
       "4    -0.006068 -0.001653 -0.002766  -0.003026      0.006924      0.005611   \n",
       "...        ...       ...       ...        ...           ...           ...   \n",
       "1212 -0.041315  0.060291  0.021794   0.106569      0.004192      0.000254   \n",
       "1213  0.107181  0.076916  0.090062   0.058212      0.021941      0.015712   \n",
       "1214  0.058297  0.010164  0.039187   0.015989      0.016082      0.033486   \n",
       "1215  0.015517  0.072815  0.039727   0.086572      0.003218      0.010444   \n",
       "1216  0.086990  0.017962  0.002985  -0.059434      0.021237      0.029223   \n",
       "\n",
       "          body  color  \n",
       "0     0.000881    0.3  \n",
       "1     0.002981    0.3  \n",
       "2     0.005050    0.3  \n",
       "3     0.006035    0.3  \n",
       "4     0.002993    0.3  \n",
       "...        ...    ...  \n",
       "1212  0.096806    0.7  \n",
       "1213  0.055011    0.7  \n",
       "1214  0.015658    0.7  \n",
       "1215  0.080029    0.7  \n",
       "1216  0.059434    0.3  \n",
       "\n",
       "[317 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = df_seq.loc[~(df_seq==0).all(axis=1)]\n",
    "df_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc099c49",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754255c5",
   "metadata": {},
   "source": [
    "## MDN server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67861978",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f0d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:33] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"GET /get_and_add_data?init=1 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning initial candles: [{'time': 1514764800, 'open': 13707.91, 'high': 13818.55, 'low': 12750.0, 'close': 13380.0}, {'time': 1514851200, 'open': 13382.16, 'high': 15473.49, 'low': 12890.02, 'close': 14675.11}, {'time': 1514937600, 'open': 14690.0, 'high': 15307.56, 'low': 14150.0, 'close': 14919.51}, {'time': 1515024000, 'open': 14919.51, 'high': 15280.0, 'low': 13918.04, 'close': 15059.54}, {'time': 1515110400, 'open': 15059.56, 'high': 17176.24, 'low': 14600.0, 'close': 16960.39}, {'time': 1515196800, 'open': 16960.39, 'high': 17143.13, 'low': 16011.21, 'close': 17069.79}, {'time': 1515283200, 'open': 17069.79, 'high': 17099.96, 'low': 15610.0, 'close': 16150.03}, {'time': 1515369600, 'open': 16218.85, 'high': 16322.3, 'low': 12812.0, 'close': 14902.54}, {'time': 1515456000, 'open': 14902.54, 'high': 15500.0, 'low': 14011.05, 'close': 14400.0}, {'time': 1515542400, 'open': 14401.0, 'high': 14955.66, 'low': 13131.31, 'close': 14907.09}, {'time': 1515628800, 'open': 14940.0, 'high': 14968.68, 'low': 11400.0, 'close': 13238.78}, {'time': 1515715200, 'open': 13238.76, 'high': 14109.78, 'low': 12500.0, 'close': 13740.01}, {'time': 1515801600, 'open': 13749.95, 'high': 14580.0, 'low': 13706.15, 'close': 14210.0}, {'time': 1515888000, 'open': 14210.0, 'high': 14339.5, 'low': 12569.2, 'close': 13474.99}, {'time': 1515974400, 'open': 13477.98, 'high': 14249.99, 'low': 13147.79, 'close': 13539.93}, {'time': 1516060800, 'open': 13500.0, 'high': 13542.93, 'low': 9035.0, 'close': 10900.0}, {'time': 1516147200, 'open': 10899.99, 'high': 11680.99, 'low': 9037.94, 'close': 10988.79}, {'time': 1516233600, 'open': 10972.59, 'high': 11878.82, 'low': 10435.33, 'close': 10961.97}, {'time': 1516320000, 'open': 10960.0, 'high': 11795.0, 'low': 10360.0, 'close': 11474.98}, {'time': 1516406400, 'open': 11474.98, 'high': 13099.0, 'low': 11412.45, 'close': 12799.94}, {'time': 1516492800, 'open': 12799.8, 'high': 12799.8, 'low': 10965.0, 'close': 11530.0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"GET /get_and_add_data?idx=21 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:34] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (3, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (3, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (5, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (5, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (8, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (8, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (13, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (13, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (20, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (20, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2025 17:53:38] \"GET /get_and_add_data?idx=22 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:38] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:38] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:38] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:38] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:38] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (3, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (3, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (5, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (5, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (8, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (8, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (20, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (20, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (13, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (13, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"GET /get_and_add_data?idx=23 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"GET /get_and_add_data?idx=24 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (3, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (3, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (5, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (5, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (13, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (13, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (8, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (8, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (20, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (20, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (3, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (3, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (5, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (5, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (8, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (8, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (13, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (13, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (20, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (20, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"GET /get_and_add_data?idx=25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2025 17:53:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (3, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (3, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (5, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (5, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (8, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (8, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (13, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (13, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "=== Final seq_dict keys and shapes ===\n",
      "main: shape (20, 4), columns: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "add_candle_shape_features: shape (20, 4), columns: ['upper_shadow', 'lower_shadow', 'body', 'color']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.cnn_lstm_mdn import CNNLSTM_MDN  # <-- your updated \"last-output\" model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg*.pt\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\",FEATURES)\n",
    "# ---------------- Model ----------------\n",
    "# Reconstruct model class\n",
    "#for python file:\n",
    "# model_cls_info = meta[\"model_class_info\"]\n",
    "# ModelClass = import_class(model_cls_info[\"module\"], model_cls_info[\"class\"])\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "ModelClass = cnn_lstm\n",
    "# Initialize model with original args\n",
    "model = ModelClass(**model_cls_info[\"init_args\"])\n",
    "model = cnn_lstm.load_from_checkpoint(state_path)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv( \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"sequential.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        print(\"Returning initial candles:\", candles)\n",
    "\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            print(\"Reached end of data at index:\", next_idx)\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        # ✅ Add to preproc automatically\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # prepare subsequence from current state\n",
    "        seq_dict = preproc.prepare_seq(seq_len)  # returns dict of DataFrames\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mdn_out = model(dict_x)\n",
    "\n",
    "    pi    = mdn_out['pi'][0].cpu().numpy()\n",
    "    mu    = mdn_out['mu'][0].cpu().numpy()\n",
    "    sigma = mdn_out['sigma'][0].cpu().numpy()\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "\n",
    "    return jsonify({\n",
    "        'pred_prices': (last_close * mu).tolist(),\n",
    "        'pred_sigmas': (last_close * sigma).tolist(),\n",
    "        'pi': pi.tolist()\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65996c",
   "metadata": {},
   "source": [
    "## lstm two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fced27d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:57] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:57] \"GET /get_and_add_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:58] \"GET /get_and_add_data?idx=21 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:07:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[2.9861, 2.6310, 2.6556, 2.9212, 2.7351, 2.5645]])\n",
      "len tensor([[3.2939, 2.8888, 2.9717, 3.2023, 3.0238, 2.8708]])\n",
      "len tensor([[3.2047, 2.8153, 2.9138, 3.1162, 2.9445, 2.8013]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:20] \"GET /get_and_add_data?idx=22 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:20] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:20] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:24] \"GET /get_and_add_data?idx=23 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:24] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:26] \"GET /get_and_add_data?idx=24 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:26] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:26] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:26] \"GET /get_and_add_data?idx=25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:26] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:26] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"GET /get_and_add_data?idx=26 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"GET /get_and_add_data?idx=27 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"GET /get_and_add_data?idx=28 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"GET /get_and_add_data?idx=29 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"GET /get_and_add_data?idx=30 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"GET /get_and_add_data?idx=31 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"GET /get_and_add_data?idx=32 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"GET /get_and_add_data?idx=33 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"GET /get_and_add_data?idx=34 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"GET /get_and_add_data?idx=35 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"GET /get_and_add_data?idx=36 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"GET /get_and_add_data?idx=37 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:28] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"GET /get_and_add_data?idx=38 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"GET /get_and_add_data?idx=39 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"GET /get_and_add_data?idx=40 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"GET /get_and_add_data?idx=41 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"GET /get_and_add_data?idx=42 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:29] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"GET /get_and_add_data?idx=43 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"GET /get_and_add_data?idx=44 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"GET /get_and_add_data?idx=45 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"GET /get_and_add_data?idx=46 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"GET /get_and_add_data?idx=47 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"GET /get_and_add_data?idx=48 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:30] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"GET /get_and_add_data?idx=49 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"GET /get_and_add_data?idx=50 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"GET /get_and_add_data?idx=51 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenlen  tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"GET /get_and_add_data?idx=52 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"GET /get_and_add_data?idx=53 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"GET /get_and_add_data?idx=54 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"GET /get_and_add_data?idx=55 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"GET /get_and_add_data?idx=56 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"GET /get_and_add_data?idx=57 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"GET /get_and_add_data?idx=58 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"GET /get_and_add_data?idx=59 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "len tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n",
      "len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"GET /get_and_add_data?idx=60 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Sep/2025 16:08:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len len tensor([[1.9650, 1.7708, 1.7662, 1.9512, 1.7988, 1.6682]])\n",
      "tensor([[1.0439, 0.9929, 0.9968, 1.0580, 0.9667, 0.8891]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = LSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"two_head.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_df = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    X_np = seq_df[FEATURES].values.astype(np.float32)\n",
    "    X_t = torch.from_numpy(X_np).unsqueeze(0)\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred, len_logits = model({\"main\": X_t}, lengths)\n",
    "\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "    pred_len = model.predict_length(len_logits).item()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices,\n",
    "        \"pred_len\": pred_len\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4c8b3",
   "metadata": {},
   "source": [
    "## xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "from servers.pre_process.multi_reg_dif_seq import ServerPreprocess, build_pipeline_from_config\n",
    "\n",
    "# ---------------- Flask ----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load models + meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_meta_multireg_*.pkl\")[0]\n",
    "model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_multireg_*.pkl\")[0]\n",
    "len_model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_seq_len_*.pkl\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Models\n",
    "model = joblib.load(model_path)       # MultiOutputRegressor with XGBRegressor inside\n",
    "len_model = joblib.load(len_model_path)\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"xgboost_seq.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Use your XGBoost + preproc logic\n",
    "        X_np = preproc.prepare_xgboost_seq(seq_len, model=len_model)\n",
    "        pred_len = int(np.round(len_model.predict(X_np))[0])\n",
    "        y_pred_full = model.predict(X_np)[0]\n",
    "        pred_trunc = np.sort(y_pred_full[:pred_len])\n",
    "        last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "        pred_scaled = (last_close * pred_trunc).tolist()\n",
    "\n",
    "        return jsonify({\n",
    "            'pred_length': pred_len,\n",
    "            'pred_lines': pred_scaled\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # <-- This will print the actual exception in the console\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc07d3a",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06403bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching TensorBoard for: lightning_logs/version_120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 16:16:54.726542: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-10 16:16:54.736657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757508414.749226    4333 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757508414.752893    4333 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757508414.762872    4333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757508414.762904    4333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757508414.762906    4333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757508414.762907    4333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-10 16:16:54.766048: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0910 16:16:57.287815 126933973667968 program.py:300] TensorBoard could not bind to port 6006, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6006, it was already in use\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "logdir = \"lightning_logs\"\n",
    "\n",
    "# 1. Find all version folders\n",
    "versions = [d for d in os.listdir(logdir) if d.startswith(\"version_\")]\n",
    "if not versions:\n",
    "    raise ValueError(\"No version folders found in lightning_logs\")\n",
    "\n",
    "# 2. Sort numerically and get the latest\n",
    "versions.sort(key=lambda x: int(x.split(\"_\")[1]))\n",
    "latest_version = versions[-1]\n",
    "latest_logdir = os.path.join(logdir, latest_version)\n",
    "print(f\"Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\"tensorboard\", f\"--logdir={latest_logdir}\", f\"--port={port}\"])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c39a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
