{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c93e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "seq_len",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b930cdd8-fd68-4c11-880c-494460928287",
       "rows": [
        [
         "0",
         "1514764800",
         "1515196800",
         "0",
         "5",
         "0.774234",
         "0.941543",
         "1.004005",
         null,
         null,
         null,
         "5"
        ],
        [
         "1",
         "1515283200",
         "1515628800",
         "6",
         "10",
         "1.086008",
         "1.126277",
         "1.165107",
         "0.970955",
         null,
         null,
         "4"
        ],
        [
         "2",
         "1515628800",
         "1516060800",
         "10",
         "15",
         "1.193264",
         "1.336497",
         "1.235186",
         null,
         null,
         null,
         "5"
        ],
        [
         "3",
         "1516060800",
         "1517184000",
         "15",
         "28",
         "0.863277",
         "0.996965",
         "1.088347",
         null,
         null,
         null,
         "13"
        ],
        [
         "4",
         "1517097600",
         "1517875200",
         "27",
         "36",
         "1.351391",
         "1.197126",
         "0.861228",
         null,
         null,
         null,
         "9"
        ],
        [
         "5",
         "1517875200",
         "1519084800",
         "36",
         "50",
         "0.91305",
         "0.749693",
         "0.805304",
         "0.664539",
         null,
         null,
         "14"
        ],
        [
         "6",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.015686",
         "1.058311",
         null,
         null,
         null,
         null,
         "5"
        ],
        [
         "7",
         "1519516800",
         "1520208000",
         "55",
         "63",
         "0.894581",
         "1.005045",
         null,
         null,
         null,
         null,
         "8"
        ],
        [
         "8",
         "1520208000",
         "1521331200",
         "63",
         "76",
         "1.134643",
         "0.949258",
         "1.011053",
         null,
         null,
         null,
         "13"
        ],
        [
         "9",
         "1521590400",
         "1522540800",
         "79",
         "90",
         "0.952544",
         "1.223968",
         null,
         null,
         null,
         null,
         "11"
        ],
        [
         "10",
         "1523232000",
         "1525478400",
         "98",
         "124",
         "0.888803",
         "0.981552",
         "0.827628",
         null,
         null,
         null,
         "26"
        ],
        [
         "11",
         "1525478400",
         "1527465600",
         "124",
         "147",
         "1.193822",
         "1.31115",
         "1.114156",
         "1.041731",
         null,
         null,
         "23"
        ],
        [
         "12",
         "1527465600",
         "1528329600",
         "147",
         "157",
         "0.969558",
         null,
         null,
         null,
         null,
         null,
         "10"
        ],
        [
         "13",
         "1528329600",
         "1529798400",
         "157",
         "174",
         "1.022398",
         "1.099473",
         "1.049206",
         null,
         null,
         null,
         "17"
        ],
        [
         "14",
         "1530230400",
         "1532476800",
         "179",
         "205",
         "0.899944",
         "0.931975",
         "0.778048",
         "0.810079",
         "1.037855",
         null,
         "26"
        ],
        [
         "15",
         "1532476800",
         "1534204800",
         "205",
         "225",
         "1.271149",
         "1.335279",
         "1.32027",
         "1.145617",
         "0.988702",
         "1.056926",
         "20"
        ],
        [
         "16",
         "1536364800",
         "1537574400",
         "250",
         "264",
         "0.960264",
         "0.913796",
         null,
         null,
         null,
         null,
         "14"
        ],
        [
         "17",
         "1537574400",
         "1539216000",
         "264",
         "283",
         "1.023049",
         "1.078415",
         null,
         null,
         null,
         null,
         "19"
        ],
        [
         "18",
         "1539561600",
         "1542240000",
         "287",
         "318",
         "1.126735",
         "1.179985",
         "1.087177",
         null,
         null,
         null,
         "31"
        ],
        [
         "19",
         "1542153600",
         "1544832000",
         "317",
         "348",
         "1.200769",
         "1.391551",
         "1.263454",
         "1.347943",
         "1.042692",
         "0.999085",
         "31"
        ],
        [
         "20",
         "1544918400",
         "1546905600",
         "349",
         "372",
         "0.930514",
         "0.983124",
         "1.020145",
         "0.901287",
         "0.948051",
         null,
         "23"
        ],
        [
         "21",
         "1546905600",
         "1549584000",
         "372",
         "403",
         "0.974219",
         "1.005812",
         "0.921565",
         "1.085846",
         null,
         null,
         "31"
        ],
        [
         "22",
         "1549584000",
         "1550966400",
         "403",
         "419",
         "0.974868",
         "0.956341",
         "1.040744",
         "1.079858",
         "1.110737",
         null,
         "16"
        ],
        [
         "23",
         "1550966400",
         "1554163200",
         "419",
         "456",
         "0.797801",
         "0.848962",
         "0.827036",
         null,
         null,
         null,
         "37"
        ],
        [
         "24",
         "1554163200",
         "1557446400",
         "456",
         "494",
         "0.804541",
         "0.786374",
         "0.837573",
         "0.883817",
         "0.916848",
         null,
         "38"
        ],
        [
         "25",
         "1557187200",
         "1559174400",
         "491",
         "514",
         "0.959915",
         "0.822445",
         "1.059199",
         "0.898818",
         null,
         null,
         "23"
        ],
        [
         "26",
         "1559174400",
         "1560124800",
         "514",
         "525",
         "0.97726",
         "1.076155",
         "0.933746",
         null,
         null,
         null,
         "11"
        ],
        [
         "27",
         "1560038400",
         "1561507200",
         "524",
         "541",
         "0.711745",
         "0.681577",
         null,
         null,
         null,
         null,
         "17"
        ],
        [
         "28",
         "1561507200",
         "1564272000",
         "541",
         "573",
         "1.298719",
         "1.21132",
         "1.065656",
         "1.140788",
         "1.008923",
         null,
         "32"
        ],
        [
         "29",
         "1564272000",
         "1565136000",
         "573",
         "583",
         "0.960277",
         null,
         null,
         null,
         null,
         null,
         "10"
        ],
        [
         "30",
         "1565136000",
         "1567123200",
         "583",
         "606",
         "1.250152",
         "1.17841",
         "1.088351",
         "1.02882",
         "1.140249",
         null,
         "23"
        ],
        [
         "31",
         "1567036800",
         "1567728000",
         "605",
         "613",
         "1.019979",
         "0.927642",
         null,
         null,
         null,
         null,
         "8"
        ],
        [
         "32",
         "1567728000",
         "1571875200",
         "613",
         "661",
         "1.387543",
         "1.318462",
         "1.105299",
         "1.06385",
         null,
         null,
         "48"
        ],
        [
         "33",
         "1571875200",
         "1572220800",
         "661",
         "665",
         "0.804214",
         "1.036258",
         null,
         null,
         null,
         null,
         "4"
        ],
        [
         "34",
         "1572048000",
         "1574640000",
         "663",
         "693",
         "1.286138",
         "1.343756",
         "1.21823",
         "1.024796",
         null,
         null,
         "30"
        ],
        [
         "35",
         "1574640000",
         "1578441600",
         "693",
         "737",
         "0.904404",
         "0.946173",
         "0.871715",
         "0.799072",
         null,
         null,
         "44"
        ],
        [
         "36",
         "1578614400",
         "1581552000",
         "739",
         "773",
         "0.800902",
         "0.850958",
         "0.911025",
         "0.996835",
         null,
         null,
         "34"
        ],
        [
         "37",
         "1581552000",
         "1584057600",
         "773",
         "802",
         "1.424052",
         "1.591895",
         "1.510596",
         "1.738757",
         "1.859395",
         null,
         "29"
        ],
        [
         "38",
         "1584057600",
         "1588809600",
         "802",
         "857",
         "0.682698",
         "0.616772",
         "0.503967",
         "0.558172",
         "0.773528",
         "0.887799",
         "55"
        ],
        [
         "39",
         "1588809600",
         "1591056000",
         "857",
         "883",
         "1.026785",
         "0.966838",
         "0.917651",
         "0.936097",
         null,
         null,
         "26"
        ],
        [
         "40",
         "1591056000",
         "1593907200",
         "883",
         "916",
         "1.063058",
         "0.99692",
         null,
         null,
         null,
         null,
         "33"
        ],
        [
         "41",
         "1593907200",
         "1595808000",
         "916",
         "938",
         "0.836963",
         "0.868797",
         "0.823699",
         null,
         null,
         null,
         "22"
        ],
        [
         "42",
         "1595721600",
         "1598918400",
         "937",
         "974",
         "0.98554",
         "0.888977",
         "0.935274",
         null,
         null,
         null,
         "37"
        ],
        [
         "43",
         "1599004800",
         "1602115200",
         "975",
         "1011",
         "0.948399",
         "0.993145",
         "1.02057",
         "0.97005",
         null,
         null,
         "36"
        ],
        [
         "44",
         "1602115200",
         "1604534400",
         "1011",
         "1039",
         "0.739499",
         "0.724325",
         "0.878082",
         null,
         null,
         null,
         "28"
        ],
        [
         "45",
         "1604534400",
         "1606176000",
         "1039",
         "1058",
         "0.809127",
         "0.771266",
         "0.848635",
         "0.973743",
         null,
         null,
         "19"
        ],
        [
         "46",
         "1606262400",
         "1608076800",
         "1059",
         "1080",
         "0.901803",
         "0.923977",
         "0.86928",
         "0.844149",
         "0.803495",
         null,
         "21"
        ],
        [
         "47",
         "1608076800",
         "1609632000",
         "1080",
         "1098",
         "0.733311",
         "0.719861",
         "0.684744",
         "0.792338",
         "0.861079",
         null,
         "18"
        ],
        [
         "48",
         "1609632000",
         "1612310400",
         "1098",
         "1129",
         "1.086558",
         "0.945543",
         "0.853577",
         "0.781026",
         null,
         null,
         "31"
        ],
        [
         "49",
         "1612396800",
         "1613865600",
         "1130",
         "1147",
         "0.669818",
         "0.809765",
         "0.841906",
         "0.891456",
         "0.912883",
         "0.970469",
         "17"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 73
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515196800</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.774234</td>\n",
       "      <td>0.941543</td>\n",
       "      <td>1.004005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1515283200</td>\n",
       "      <td>1515628800</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.086008</td>\n",
       "      <td>1.126277</td>\n",
       "      <td>1.165107</td>\n",
       "      <td>0.970955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515628800</td>\n",
       "      <td>1516060800</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1.193264</td>\n",
       "      <td>1.336497</td>\n",
       "      <td>1.235186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1516060800</td>\n",
       "      <td>1517184000</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>1.088347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1517097600</td>\n",
       "      <td>1517875200</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>1.351391</td>\n",
       "      <td>1.197126</td>\n",
       "      <td>0.861228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1644451200</td>\n",
       "      <td>1645660800</td>\n",
       "      <td>1501</td>\n",
       "      <td>1515</td>\n",
       "      <td>0.996103</td>\n",
       "      <td>0.955050</td>\n",
       "      <td>1.165443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1645660800</td>\n",
       "      <td>1648512000</td>\n",
       "      <td>1515</td>\n",
       "      <td>1548</td>\n",
       "      <td>0.833872</td>\n",
       "      <td>0.898831</td>\n",
       "      <td>0.785499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1648512000</td>\n",
       "      <td>1651622400</td>\n",
       "      <td>1548</td>\n",
       "      <td>1584</td>\n",
       "      <td>1.046141</td>\n",
       "      <td>1.174980</td>\n",
       "      <td>1.118819</td>\n",
       "      <td>0.980070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1651708800</td>\n",
       "      <td>1652313600</td>\n",
       "      <td>1585</td>\n",
       "      <td>1592</td>\n",
       "      <td>1.071227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1652313600</td>\n",
       "      <td>1653264000</td>\n",
       "      <td>1592</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.009742</td>\n",
       "      <td>0.949503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0   1514764800  1515196800           0         5     0.774234     0.941543   \n",
       "1   1515283200  1515628800           6        10     1.086008     1.126277   \n",
       "2   1515628800  1516060800          10        15     1.193264     1.336497   \n",
       "3   1516060800  1517184000          15        28     0.863277     0.996965   \n",
       "4   1517097600  1517875200          27        36     1.351391     1.197126   \n",
       "..         ...         ...         ...       ...          ...          ...   \n",
       "68  1644451200  1645660800        1501      1515     0.996103     0.955050   \n",
       "69  1645660800  1648512000        1515      1548     0.833872     0.898831   \n",
       "70  1648512000  1651622400        1548      1584     1.046141     1.174980   \n",
       "71  1651708800  1652313600        1585      1592     1.071227          NaN   \n",
       "72  1652313600  1653264000        1592      1603     1.009742     0.949503   \n",
       "\n",
       "    linePrice_3  linePrice_4  linePrice_5  linePrice_6  seq_len  \n",
       "0      1.004005          NaN          NaN          NaN        5  \n",
       "1      1.165107     0.970955          NaN          NaN        4  \n",
       "2      1.235186          NaN          NaN          NaN        5  \n",
       "3      1.088347          NaN          NaN          NaN       13  \n",
       "4      0.861228          NaN          NaN          NaN        9  \n",
       "..          ...          ...          ...          ...      ...  \n",
       "68     1.165443          NaN          NaN          NaN       14  \n",
       "69     0.785499          NaN          NaN          NaN       33  \n",
       "70     1.118819     0.980070          NaN          NaN       36  \n",
       "71          NaN          NaN          NaN          NaN        7  \n",
       "72          NaN          NaN          NaN          NaN       11  \n",
       "\n",
       "[73 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv(\"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\")\n",
    "label[\"seq_len\"] = label[\"endIndex\"] - label[\"startIndex\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e027af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "276b5b3c-e85b-4fb2-8da6-147dc065c148",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "235bdf69-4062-412b-b007-7297a3902ae0",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles_prop.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b8d98",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ccb9c",
   "metadata": {},
   "source": [
    "## Hungarian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5ef5c",
   "metadata": {},
   "source": [
    "depricated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import  load_attention\n",
    "from importlib import import_module\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_layer = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.v_context = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_outputs, lengths):\n",
    "        energy = torch.tanh(self.attn_layer(lstm_outputs))\n",
    "        attn_scores = self.v_context(energy).squeeze(2)\n",
    "        mask = torch.arange(\n",
    "            lstm_outputs.size(1), device=lstm_outputs.device\n",
    "        )[None, :] < lengths[:, None]\n",
    "        attn_scores = attn_scores.masked_fill(mask == 0, -1e10)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        context_vector = torch.bmm(attn_weights.unsqueeze(1), lstm_outputs).squeeze(1)\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Multi-branch 1D convolutions\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ) for k in [3, 5, 7, 11]\n",
    "        ])\n",
    "\n",
    "        # Fusion with Conv2d over (branches × seq)\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # LSTM takes feature_dim = 32 after fusion\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(hidden_dim)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Input: x[\"main\"] → (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "\n",
    "        # Branch outputs\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)  # (B, 4, 32, T)\n",
    "\n",
    "        # Fusion conv2d\n",
    "        fused = self.fusion_conv2d(stacked)  # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)             # (B, 32, T)\n",
    "\n",
    "        # Prepare for LSTM\n",
    "        lstm_input = fused.transpose(1, 2)   # (B, T, 32)\n",
    "\n",
    "        # LSTM with packing\n",
    "        packed_input = pack_padded_sequence(lstm_input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)  # (B, T, H)\n",
    "\n",
    "        # Attention\n",
    "        context_vector = self.attention(lstm_outputs, lengths)  # (B, H)\n",
    "\n",
    "        # Regression\n",
    "        y_pred = self.regressor(context_vector)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss with position-based weighting.\n",
    "        Earlier ground-truth positions in y_true get higher weight.\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            # Extract ground-truth values and their positions\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)  # positions in y_true\n",
    "\n",
    "            preds = y_pred[i]  # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Cost matrix (L x max_len_y) using squared error\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Matched pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            # --- weighting logic ---\n",
    "            # Lower index = higher weight (inverse rank)\n",
    "            gt_pos = gt_indices[row_ind]  # actual positions of matched gts\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())  # e.g. pos=0 -> 1.0, pos=2 -> 0.33\n",
    "\n",
    "            # Compute weighted MSE\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "    \n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Same Hungarian matching but without weights (baseline).\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Import optimizer dynamically\n",
    "        opt_module = import_module(f\"model.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr)\n",
    "\n",
    "        # No scheduler\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "\n",
    "        # Import scheduler dynamically\n",
    "        sch_module = import_module(f\"model.schedulers.{self.scheduler_name}\")\n",
    "        # OneCycle needs trainer\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer)\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer)\n",
    "\n",
    "        # Lightning accepts dict or list depending on scheduler type\n",
    "        if isinstance(scheduler, dict):\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler._LRScheduler):\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler return type: {type(scheduler)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541ef27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import  load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, attention_name=\"tanh_attention\",optimizer_name=\"adamw\",kernels= [3, 5, 7, 11],\n",
    "    cnn_out_channels=32,first_drop= 0.3, second_drop=0.3, third_drop= 0.3,scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.kernels = kernels\n",
    "        # Multi-branch 1D convolutions\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim[\"main\"], out_channels=cnn_out_channels, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(cnn_out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(first_drop)\n",
    "            ) for k in self.kernels\n",
    "        ])\n",
    "        # Fusion with Conv2d over (branches × seq)\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(second_drop)\n",
    "        )\n",
    "        \n",
    "        # LSTM takes feature_dim = 32 after fusion\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_out_channels,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(third_drop),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # Input: x[\"main\"] → (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "        # Branch outputs\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)  # (B, 4, 32, T)\n",
    "        # Fusion conv2d\n",
    "        fused = self.fusion_conv2d(stacked)  # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)             # (B, 32, T)\n",
    "        # Prepare for LSTM\n",
    "        lstm_input = fused.transpose(1, 2)   # (B, T, 32)\n",
    "        # LSTM with packing\n",
    "        packed_input = pack_padded_sequence(lstm_input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)  # (B, T, H)\n",
    "        # Attention\n",
    "        context_vector = self.attention(lstm_outputs, lengths)  # (B, H)\n",
    "        # Regression\n",
    "        y_pred = self.regressor(context_vector)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Import optimizer dynamically\n",
    "        opt_module = import_module(f\"models.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr)\n",
    "\n",
    "        # No scheduler\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "\n",
    "        # Import scheduler dynamically\n",
    "        sch_module = import_module(f\"models.schedulers.{self.scheduler_name}\")\n",
    "        # OneCycle needs trainer\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer)\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer)\n",
    "\n",
    "        # Lightning accepts dict or list depending on scheduler type\n",
    "        if isinstance(scheduler, dict):\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler._LRScheduler):\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler return type: {type(scheduler)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0236de84",
   "metadata": {},
   "source": [
    "### CNN simple attention lstm weightening`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c47cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from typing import Optional\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, attention_name=\"tanh_attention\",optimizer_name=\"adamw\",kernels= [3, 5, 7, 11],fusion_out_channels = 10,\n",
    "    cnn_out_channels=32,first_drop= 0.3, second_drop=0.3, third_drop= 0.3,scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim[\"candle_shape\"]\n",
    "        self.cnn_out_channels = cnn_out_channels\n",
    "        self.kernels = kernels\n",
    "        self.num_branches = len(kernels)\n",
    "        self.fusion_out_channels = fusion_out_channels\n",
    "        self.main_feat_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        # ----- Branches: multiple Conv1d with different kernel sizes -----\n",
    "        branches = []\n",
    "        for k in kernels:\n",
    "            pad = (k - 1) // 2  # 'same' padding for odd kernels; for even kernels behavior approximated\n",
    "            branches.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=self.input_dim , out_channels=cnn_out_channels, kernel_size=k, padding=pad),\n",
    "                    nn.BatchNorm1d(cnn_out_channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(first_drop)\n",
    "                )\n",
    "            )\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "\n",
    "        # ----- Fusion Conv2d: we will stack branch outputs into shape (B, num_branches, C, T)\n",
    "        # in_channels should equal number of branches.\n",
    "        # Kernel height must be cnn_out_channels to cover \"full feature height\".\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.num_branches,\n",
    "                out_channels=self.fusion_out_channels,\n",
    "                kernel_size=(self.cnn_out_channels, 1),\n",
    "                padding=(0, 0)\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.fusion_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(second_drop)\n",
    "        )\n",
    "\n",
    "        # After fusion we will have (B, fusion_out_channels, 1, T) -> squeeze -> (B, fusion_out_channels, T)\n",
    "\n",
    "        # ----- LSTM: input_size should be fusion_out_channels + main_feat_dim -----\n",
    "        lstm_input_size = self.fusion_out_channels + self.main_feat_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=third_drop if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Regressor (maps attention context to target length)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(third_drop),\n",
    "            nn.Linear(hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass through the model\n",
    "        \"\"\"\n",
    "        # Get the inputs\n",
    "        candle = x[\"candle_shape\"]\n",
    "        main = x[\"main\"]\n",
    "        \n",
    "        # ---- Permute candle_shape for CNN (B, C, T) ----\n",
    "        candle = candle.permute(0, 2, 1)  # (B, T, input_dim) -> (B, input_dim, T)\n",
    "        \n",
    "        # ---- Main features require permutation ----\n",
    "        main = main.permute(0, 2, 1)  # (B, T, main_feat_dim) -> (B, main_feat_dim, T)\n",
    "        \n",
    "        # ---- Validate shapes ----\n",
    "        B, _, T = candle.shape\n",
    "        assert main.shape[0] == B and main.shape[2] == T, \\\n",
    "            f\"main must match batch and time dims, got {main.shape} vs candle {candle.shape}\"\n",
    "        \n",
    "        # ---- Branches: each branch returns (B, C, T) ----\n",
    "        branch_feats = [branch(candle) for branch in self.branches]  # list of (B, C, T)\n",
    "        \n",
    "        # ---- Stack all branches into (B, num_branches, C, T) ----\n",
    "        stacked = torch.stack(branch_feats, dim=1)\n",
    "\n",
    "        # ---- Fusion Conv2d expects (B, in_channels=num_branches, height=C, width=T) ----\n",
    "        fused = self.fusion_conv2d(stacked)  # -> (B, fusion_out_channels, 1, T)\n",
    "        fused = fused.squeeze(2)  # -> (B, fusion_out_channels, T)\n",
    "\n",
    "        # ---- Concatenate with main features along channel dimension -> (B, fusion_out + m, T) ----\n",
    "        combined = torch.cat([fused, main], dim=1)\n",
    "\n",
    "        # ---- Prepare for LSTM: LSTM batch_first expects (B, T, feat) ----\n",
    "        combined_t = combined.permute(0, 2, 1)  # (B, T, feat_dim)\n",
    "        packed_input = pack_padded_sequence(combined_t, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # ---- Initialize hidden and cell states as zeros for each sample in the batch ----\n",
    "        h0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(combined.device)  # (num_layers, B, hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(combined.device)  # (num_layers, B, hidden_dim)\n",
    "\n",
    "        # ---- LSTM ----\n",
    "        packed_output, (hn, cn) = self.lstm(packed_input, (h0, c0))  # lstm_out: (B, T, 2 * hidden_dim)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # ---- Attention over LSTM outputs ----\n",
    "        context = self.attention(lstm_outputs, lengths)  # context: (B, hidden_dim)\n",
    "\n",
    "        # ---- Regressor -> (B, max_len_y) ----\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    # ---------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5dc124",
   "metadata": {},
   "source": [
    "### CNN LSTM PURE 2 bidirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from utils.load_attention import load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "class ConvLSTMBidirectionalRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, kernel_size=1,\n",
    "                 cnn_out_channels=32, first_drop=0.3, second_drop=0.3, third_drop=0.3,\n",
    "                 lr=0.001, bidirectional=True, scheduler_name=None, scheduler_params={},\n",
    "                 optimizer_params=None, optimizer_name=\"adamw\"):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        # Hyperparameters\n",
    "        self.input_dim = input_dim[\"main\"]   # use \"main\"\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.kernel_size = kernel_size\n",
    "        self.cnn_out_channels = cnn_out_channels\n",
    "        self.first_drop = first_drop\n",
    "        self.second_drop = second_drop\n",
    "        self.third_drop = third_drop\n",
    "        self.lr = lr\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        # Conv1d with kernel size 1\n",
    "        self.conv1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.input_dim, out_channels=self.cnn_out_channels, kernel_size=self.kernel_size),\n",
    "            nn.BatchNorm1d(self.cnn_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.first_drop)\n",
    "        )\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.cnn_out_channels,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=self.third_drop if self.num_layers > 1 else 0.0,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "        # Regressor\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim * (2 if self.bidirectional else 1), self.hidden_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hidden_dim // 2, self.max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: dict containing 'main' -> (B, T, input_dim)\n",
    "        lengths: tensor of sequence lengths\n",
    "        \"\"\"\n",
    "        candle = x[\"main\"]  # (B, T, input_dim)\n",
    "\n",
    "        # Conv1d expects (B, input_dim, T)\n",
    "        candle = candle.permute(0, 2, 1)\n",
    "        conv_output = self.conv1d(candle)              # (B, cnn_out_channels, T)\n",
    "        conv_output = conv_output.permute(0, 2, 1)     # (B, T, cnn_out_channels)\n",
    "\n",
    "        # Pack for LSTM\n",
    "        packed_input = pack_padded_sequence(conv_output, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # Initialize hidden and cell states as zeros for each sample in the batch\n",
    "        B = conv_output.size(0)  # Batch size\n",
    "        h0 = torch.zeros(self.num_layers * (2 if self.bidirectional else 1), B, self.hidden_dim).to(conv_output.device)  # (num_layers * 2, B, hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers * (2 if self.bidirectional else 1), B, self.hidden_dim).to(conv_output.device)  # (num_layers * 2, B, hidden_dim)\n",
    "\n",
    "        # LSTM\n",
    "        packed_output, _ = self.lstm(packed_input, (h0, c0))  # lstm_out: (B, T, 2 * hidden_dim)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # Extract last hidden states\n",
    "        if self.bidirectional:\n",
    "            # concat last forward + last backward\n",
    "            forward_last = lstm_out[:, -1, :self.hidden_dim]\n",
    "            backward_last = lstm_out[:, 0, self.hidden_dim:]\n",
    "            lstm_out = torch.cat([forward_last, backward_last], dim=1)  # (B, hidden_dim*2)\n",
    "        else:\n",
    "            lstm_out = lstm_out[:, -1, :]  # (B, hidden_dim)\n",
    "\n",
    "        # Regression head\n",
    "        output = self.regressor(lstm_out)\n",
    "        return output\n",
    "\n",
    "        # ---------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734bec2",
   "metadata": {},
   "source": [
    "### simple lstm + weighted hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from importlib import import_module\n",
    "from typing import Optional\n",
    "\n",
    "from utils.load_class import load_class\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Simple LSTM Regressor\n",
    "# ---------------------------\n",
    "class SimpleLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y,\n",
    "                 lr=0.001, optimizer_name=\"adamw\",\n",
    "                 first_drop=0.3, scheduler_name=None,\n",
    "                 scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "\n",
    "        self.input_dim = input_dim[\"main\"]  # use \"main\" features directly\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=first_drop if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Regressor head\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(first_drop),\n",
    "            nn.Linear(hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: dict containing 'main' -> (B, T, feat_dim)\n",
    "        lengths: tensor of sequence lengths\n",
    "        \"\"\"\n",
    "        main = x[\"main\"]  # -> (B, T, feat_dim)\n",
    "\n",
    "        # Pack the input for LSTM\n",
    "        packed_input = pack_padded_sequence(main, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Initialize hidden and cell states as zeros for each sample in the batch\n",
    "        B = main.size(0)  # Batch size\n",
    "        h0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "\n",
    "        # LSTM processing\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed_input, (h0, c0))  # lstm_out: (B, T, hidden_dim)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # Take last hidden state (h_n from final layer): (num_layers, B, hidden_dim)\n",
    "        context = h_n[-1]  # Last layer hidden state (B, hidden_dim)\n",
    "\n",
    "        # Regression head\n",
    "        y_pred = self.regressor(context)\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a7c1a",
   "metadata": {},
   "source": [
    "### attention lstm + weighted hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ec280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from importlib import import_module\n",
    "from typing import Optional\n",
    "\n",
    "from utils.load_class import load_class\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "# ---------------------------\n",
    "# 2. Attention LSTM Regressor\n",
    "# ---------------------------\n",
    "class AttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y,\n",
    "                 lr=0.001, optimizer_name=\"adamw\",\n",
    "                 first_drop=0.3, attention_name=\"tanh_attention\",\n",
    "                 scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "\n",
    "        self.input_dim = input_dim[\"main\"]\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=first_drop if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Attention\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "\n",
    "        # Regressor\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(first_drop),\n",
    "            nn.Linear(hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: dict containing 'main' -> (B, T, feat_dim)\n",
    "        lengths: tensor of sequence lengths\n",
    "        \"\"\"\n",
    "        main = x[\"main\"]  # -> (B, T, feat_dim)\n",
    "\n",
    "        # Pack the input for LSTM\n",
    "        packed_input = pack_padded_sequence(main, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # Initialize hidden and cell states as zeros for each sample in the batch\n",
    "        B = main.size(0)  # Batch size\n",
    "        h0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "\n",
    "        # LSTM processing\n",
    "        packed_output, _ = self.lstm(packed_input, (h0, c0))  # lstm_out: (B, T, hidden_dim)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # Attention over LSTM outputs\n",
    "        context = self.attention(lstm_outputs, lengths)  # (B, hidden_dim)\n",
    "\n",
    "        # Regression head\n",
    "        y_pred = self.regressor(context)\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475caeea",
   "metadata": {},
   "source": [
    "### lstm kernel + pure lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7656e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class LSTMKernelAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, attention_name=\"tanh_attention\", optimizer_name=\"adamw\", kernels=[3], fusion_out_channels=10,\n",
    "                 lstm_out_channels=32, first_drop=0.3, scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim['main']  # Only using 'main' feature\n",
    "        self.lstm_out_channels = lstm_out_channels\n",
    "        self.kernels = kernels\n",
    "        self.num_branches = len(kernels)\n",
    "        self.fusion_out_channels = fusion_out_channels\n",
    "        self.main_feat_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "\n",
    "        # Fully connected layers before LSTM\n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # LSTM-based Kernels: we use LSTM for each kernel window\n",
    "        lstm_kernels = []\n",
    "        for k in kernels:\n",
    "            lstm_kernels.append(\n",
    "                nn.LSTM(input_size=hidden_dim, hidden_size=lstm_out_channels, num_layers=1, batch_first=True)\n",
    "            )\n",
    "        self.lstm_kernels = nn.ModuleList(lstm_kernels)\n",
    "\n",
    "        # Fusion LSTM for the concatenated kernel outputs\n",
    "        self.fusion_lstm = nn.LSTM(\n",
    "            input_size=self.num_branches * lstm_out_channels + hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=first_drop if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Regressor after fusion LSTM\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(first_drop),\n",
    "            nn.Linear(hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        x is a dict with:\n",
    "        - x[\"main\"]: Tensor shape (B, main_feat_dim, T)\n",
    "\n",
    "        Returns:\n",
    "        - out: (B, max_len_y)\n",
    "        \"\"\"\n",
    "        main = x[\"main\"]  # (B, T, main_feat_dim)\n",
    "\n",
    "        # ---- Validate shapes ----\n",
    "        B, T, _ = main.shape\n",
    "        assert main.shape[0] == B and main.shape[2] == self.input_dim, \\\n",
    "            f\"main must match batch and feature dims, got {main.shape}\"\n",
    "\n",
    "        # ---- Apply the fully connected layers (FNN) ----\n",
    "        fnn_out = self.fnn(main)  # (B, T, hidden_dim)\n",
    "\n",
    "        # ---- Initialize hidden and cell states for each LSTM kernel ----\n",
    "        h0 = torch.zeros(1, B, self.lstm_out_channels).to(main.device)  # (1, B, lstm_out_channels)\n",
    "        c0 = torch.zeros(1, B, self.lstm_out_channels).to(main.device)  # (1, B, lstm_out_channels)\n",
    "\n",
    "        # ---- LSTM-based Kernels: process each kernel size ----\n",
    "        kernel_outputs = []\n",
    "        for k, lstm_kernel in zip(self.kernels, self.lstm_kernels):\n",
    "            # Reset the hidden and cell states for each kernel\n",
    "            packed_input = pack_padded_sequence(fnn_out, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            \n",
    "            # Unpack the LSTM's output and hidden states\n",
    "            packed_output, _ = lstm_kernel(packed_input, (h0, c0))  # (B, T, lstm_out_channels)\n",
    "            \n",
    "            # Unpack the packed sequence back to (B, T, lstm_out_channels)\n",
    "            lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)  # (B, T, lstm_out_channels)\n",
    "            \n",
    "            # Append the last hidden state (lstm_out is (B, T, lstm_out_channels))\n",
    "            kernel_outputs.append(lstm_out[:, -1, :])  # Take the last hidden state\n",
    "\n",
    "        # ---- Concatenate all kernel outputs with the main feature ----\n",
    "        kernel_out = torch.cat(kernel_outputs, dim=-1)  # (B, num_branches * lstm_out_channels)\n",
    "        fusion_input = torch.cat([kernel_out, fnn_out[:, -1, :]], dim=-1)  # Concatenate with last feature from FNN (B, num_branches * lstm_out_channels + hidden_dim)\n",
    "\n",
    "        # ---- Apply Fusion LSTM ----\n",
    "        fusion_h0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "        fusion_c0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "        fusion_out, _ = self.fusion_lstm(fusion_input.unsqueeze(1), (fusion_h0, fusion_c0))  # (B, 1, hidden_dim)\n",
    "        fusion_out = fusion_out.squeeze(1)  # (B, hidden_dim)\n",
    "\n",
    "        # ---- Apply Regressor ----\n",
    "        y_pred = self.regressor(fusion_out)\n",
    "\n",
    "        return y_pred\n",
    "    # ---------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0664c0",
   "metadata": {},
   "source": [
    "### lstm kernel + attention lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50a2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from typing import Optional\n",
    "\n",
    "class LSTMKernelAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, attention_name=\"tanh_attention\", optimizer_name=\"adamw\", kernels=[3], fusion_out_channels=10,\n",
    "                 lstm_out_channels=32, first_drop=0.3, scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim['main']  # Only using 'main' feature\n",
    "        self.lstm_out_channels = lstm_out_channels\n",
    "        self.kernels = kernels\n",
    "        self.num_branches = len(kernels)\n",
    "        self.fusion_out_channels = fusion_out_channels\n",
    "        self.main_feat_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "\n",
    "        # Fully connected layers before LSTM\n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # LSTM-based Kernels: we use LSTM for each kernel window\n",
    "        lstm_kernels = []\n",
    "        for k in kernels:\n",
    "            lstm_kernels.append(\n",
    "                nn.LSTM(input_size=hidden_dim, hidden_size=lstm_out_channels, num_layers=1, batch_first=True)\n",
    "            )\n",
    "        self.lstm_kernels = nn.ModuleList(lstm_kernels)\n",
    "\n",
    "        # Fusion LSTM for the concatenated kernel outputs\n",
    "        self.fusion_lstm = nn.LSTM(\n",
    "            input_size=self.num_branches * lstm_out_channels + hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=first_drop if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Attention applied to the output of the Fusion LSTM\n",
    "        self.attention_fusion = load_class(f\"models.attention.{attention_name}\", hidden_dim=self.hidden_dim)\n",
    "\n",
    "        # Regressor after fusion and attention\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(first_drop),\n",
    "            nn.Linear(hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        main = x[\"main\"]  # -> (B, T, feat_dim)\n",
    "\n",
    "        # ---- Apply the fully connected layers (FNN) ----\n",
    "        fnn_out = self.fnn(main)  # (B, T, hidden_dim)\n",
    "\n",
    "        # ---- Initialize hidden and cell states for each LSTM kernel ----\n",
    "        B = main.size(0)  # Batch size\n",
    "        h0_kernel = torch.zeros(1, B, self.lstm_out_channels).to(main.device)  # (1, B, lstm_out_channels)\n",
    "        c0_kernel = torch.zeros(1, B, self.lstm_out_channels).to(main.device)  # (1, B, lstm_out_channels)\n",
    "\n",
    "        # ---- LSTM-based Kernels: process each kernel size ----\n",
    "        kernel_outputs = []\n",
    "        for k, lstm_kernel in zip(self.kernels, self.lstm_kernels):\n",
    "            # Apply the LSTM to the FNN-processed input with reset hidden/cell states\n",
    "            packed_input = pack_padded_sequence(fnn_out, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            lstm_out, _ = lstm_kernel(packed_input, (h0_kernel, c0_kernel))  # (B, T, lstm_out_channels)\n",
    "            \n",
    "            # Unpack the packed sequence to get full tensor shape (B, T, lstm_out_channels)\n",
    "            lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "            # Append the last hidden state (lstm_out is (B, T, lstm_out_channels))\n",
    "            kernel_outputs.append(lstm_out[:, -1, :])  # Take the last hidden state\n",
    "\n",
    "        # ---- Concatenate all kernel outputs with the main feature ----\n",
    "        kernel_out = torch.cat(kernel_outputs, dim=-1)  # (B, num_branches * lstm_out_channels)\n",
    "        fusion_input = torch.cat([kernel_out, fnn_out[:, -1, :]], dim=-1)  # Concatenate with last feature from FNN (B, num_branches * lstm_out_channels + hidden_dim)\n",
    "\n",
    "        # ---- Apply Fusion LSTM ----\n",
    "        fusion_h0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "        fusion_c0 = torch.zeros(self.num_layers, B, self.hidden_dim).to(main.device)  # (num_layers, B, hidden_dim)\n",
    "        fusion_out, _ = self.fusion_lstm(fusion_input.unsqueeze(1), (fusion_h0, fusion_c0))  # (B, 1, hidden_dim)\n",
    "        fusion_out = fusion_out.squeeze(1)  # (B, hidden_dim)\n",
    "\n",
    "        # ---- Apply Attention to Fusion Output ----\n",
    "        context = self.attention_fusion(fusion_out.unsqueeze(1), lengths)  # (B, hidden_dim)\n",
    "\n",
    "        # ---- Apply Regressor ----\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    # ---------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Debugging prints for tensor shapes\n",
    "        print(f\"y shape: {y.shape}\")\n",
    "        print(f\"y_pred shape: {y_pred.shape}\")\n",
    "        print(f\"mask shape: {mask.shape}\")\n",
    "\n",
    "        # Ensure y has the expected shape (B, max_len_y)\n",
    "        if len(y.shape) == 1:\n",
    "            print(\"Warning: Squeezing detected, adding extra dimension to y.\")\n",
    "            y = y.unsqueeze(-1)  # Adds the missing dimension, resulting in shape (B, max_len_y)\n",
    "            print(f\"New y shape: {y.shape}\")\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        \n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        # Log the losses\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        \n",
    "        # Return the weighted loss\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0124a79",
   "metadata": {},
   "source": [
    "### lstm + attention gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01732814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from importlib import import_module\n",
    "from models.utils.mish import Mish\n",
    "from models.utils.swish import Swish\n",
    "# Assuming these utilities and losses are in your project structure\n",
    "from utils.load_class import load_class\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "\n",
    "class LSTMAttentionSetRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001,\n",
    "                 attention_name=\"tanh_attention\", optimizer_name=\"adamw\",\n",
    "                 bidirectional=True, first_drop=0.3,\n",
    "                 scheduler_name=None, scheduler_params={}, optimizer_params=None, normal_loss = False):\n",
    "        super().__init__()\n",
    "        # This saves all hyperparameters to the checkpoint and makes them accessible via self.hparams\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Core Hyperparameters ---\n",
    "        self.input_dim = self.hparams.input_dim['main']\n",
    "        self.hidden_dim = self.hparams.hidden_dim\n",
    "        self.max_len_y = self.hparams.max_len_y\n",
    "        lstm_output_dim = self.hidden_dim * 2 if self.hparams.bidirectional else self.hidden_dim\n",
    "\n",
    "        # --- Loss Functions ---\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        # --- Model Architecture ---\n",
    "\n",
    "        # 1. FNN pre-processor: Maps input features to the hidden dimension for the LSTM.\n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim), \n",
    "            Swish(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        # 2. Main LSTM: Processes the entire sequence to capture temporal patterns.\n",
    "        # Bidirectional is highly recommended as it allows the LSTM to see past and future context.\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.hparams.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.hparams.bidirectional,\n",
    "            dropout=self.hparams.first_drop if self.hparams.num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # 3. Attention Mechanism: Weighs the importance of each time step from the LSTM's output.\n",
    "        # The input to the attention layer is the full output sequence from the LSTM.\n",
    "        self.attention = load_class(f\"models.attention.{self.hparams.attention_name}\", hidden_dim=lstm_output_dim)\n",
    "\n",
    "        # 4. Regressor: Takes the final context vector from attention and predicts the set of values.\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(self.hparams.first_drop),\n",
    "            nn.Linear(lstm_output_dim, self.hidden_dim),\n",
    "            Swish(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),  # Additional ReLU layer before the final output\n",
    "            Swish(),  # New ReLU added here\n",
    "            nn.Linear(self.hidden_dim,self.max_len_y)\n",
    "        )\n",
    "        self.normal = normal_loss\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        Processes the input sequence using LSTM and attention to predict a set of values.\n",
    "        \"\"\"\n",
    "        main = x[\"main\"]  # Shape: (B, T, main_feat_dim)\n",
    "        B, T, _ = main.shape\n",
    "\n",
    "        # 1. Pass input through the pre-processing FNN\n",
    "        # Shape: (B, T, hidden_dim)\n",
    "        fnn_out = self.fnn(main)\n",
    "\n",
    "        # 2. Pack the sequence to handle variable lengths efficiently (avoids computations on padding)\n",
    "        # Using lengths.cpu() is important as lengths from the dataloader are often on the CPU.\n",
    "        packed_input = pack_padded_sequence(fnn_out, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # ---- Reset LSTM hidden and cell states manually ----\n",
    "        h0 = torch.zeros(self.hparams.num_layers * (2 if self.hparams.bidirectional else 1), B, self.hidden_dim).to(main.device)  # (num_layers * num_directions, B, hidden_dim)\n",
    "        c0 = torch.zeros(self.hparams.num_layers * (2 if self.hparams.bidirectional else 1), B, self.hidden_dim).to(main.device)  # (num_layers * num_directions, B, hidden_dim)\n",
    "\n",
    "        # 3. Process the sequence with the LSTM\n",
    "        # The LSTM now outputs the hidden state for *every* time step, not just the last one.\n",
    "        packed_output, _ = self.lstm(packed_input, (h0, c0))\n",
    "\n",
    "        # Unpack the sequence back to its padded form\n",
    "        # lstm_out shape: (B, T, hidden_dim * num_directions)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True, total_length=T)\n",
    "\n",
    "        # 4. Apply the attention mechanism over the LSTM outputs. This is the key step.\n",
    "        # It creates a context vector by taking a weighted sum of all time steps, avoiding the bottleneck.\n",
    "        # context shape: (B, hidden_dim * num_directions)\n",
    "        context = self.attention(lstm_out, lengths)\n",
    "\n",
    "        # 5. Use the rich context vector to make the final prediction.\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        # You can also return attn_weights for visualization to see what the model is \"looking at\".\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "        # Log the losses\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        # Debugging: Print the input features, target, and prediction for inspection\n",
    "        if batch_idx == 0:  # Print only for the first batch to avoid clutter\n",
    "            print(\"Input batch (X):\", X)\n",
    "            print(\"Target batch (y):\", y)\n",
    "            print(\"Predicted output (y_pred):\", y_pred)\n",
    "            # Return the weighted loss\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2fad7",
   "metadata": {},
   "source": [
    "### transformer + weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0912bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from typing import Optional\n",
    "from models.positional_encoders import sinusoidal,relative,rotary,learnable\n",
    "\n",
    "class TransformerWithPositionalEncoding(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hidden_dim, \n",
    "                 num_layers, \n",
    "                 max_len_y, \n",
    "                 lr=0.001, \n",
    "                 optimizer_name=\"adamw\", \n",
    "                 positional_encoding=\"sinusoidal\", \n",
    "                 num_heads=4,\n",
    "                 feedforward_dim=128,\n",
    "                 first_drop=0.1, \n",
    "                 scheduler_name=None, \n",
    "                 scheduler_params=None, \n",
    "                 optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.feedforward_dim = feedforward_dim\n",
    "        self.max_len_y = max_len_y\n",
    "        self.lr = lr\n",
    "        self.positional_encoding_type = positional_encoding\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        # Choose the Positional Encoding based on the parameter\n",
    "        if positional_encoding == \"sinusoidal\":\n",
    "            self.positional_encoding = sinusoidal.SinusoidalPositionalEncoding(d_model=self.input_dim)\n",
    "        elif positional_encoding == \"learnable\":\n",
    "            self.positional_encoding = learnable.LearnablePositionalEncoding(d_model=self.input_dim)\n",
    "        elif positional_encoding == \"relative\":\n",
    "            self.positional_encoding = relative.RelativePositionBias(head_dim=self.input_dim, clip_distance=4)\n",
    "        elif positional_encoding == \"rotary\":\n",
    "            self.positional_encoding = rotary.RotaryPositionalEncoding(dim=self.input_dim)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid positional encoding type\")\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.input_dim, \n",
    "            nhead=self.num_heads, \n",
    "            dim_feedforward=self.feedforward_dim, \n",
    "            dropout=first_drop\n",
    "        )\n",
    "\n",
    "        # Stack of Encoder Layers\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, \n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Regressor for output\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.input_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        x is a dict with:\n",
    "          - x[\"main\"]: Tensor shape (B, main_feat_dim, T)\n",
    "\n",
    "        Returns:\n",
    "          - out: (B, max_len_y)\n",
    "        \"\"\"\n",
    "        main = x[\"main\"]  # (B, T, main_feat_dim)\n",
    "        # ---- Apply Positional Encoding ----\n",
    "        if isinstance(self.positional_encoding, (learnable.LearnablePositionalEncoding, sinusoidal.SinusoidalPositionalEncoding)):\n",
    "            main = self.positional_encoding(main)\n",
    "        elif isinstance(self.positional_encoding, relative.RelativePositionBias):\n",
    "            relative_logits = self.positional_encoding(main)\n",
    "            # (apply relative logits to the attention mechanism)\n",
    "            main = main  # placeholder for applying relative logits in attention\n",
    "        elif isinstance(self.positional_encoding,  relative.RelativePositionBias):\n",
    "            cos, sin = self.positional_encoding(main)\n",
    "            main, _ = rotary.apply_rotary_pos_emb(main, main, cos, sin)\n",
    "\n",
    "        # ---- Create a mask for padding ----\n",
    "        # Mask where padding is 1 (True) and non-padding is 0 (False)\n",
    "        # Padding tokens should have values 0, and non-padding values should have > 0 (assuming 0 is the padding value)\n",
    "        padding_mask = (main.sum(dim=-1) == 0).to(torch.bool)  # (B, T)\n",
    "        # Ensure the mask shape is correct: (B, T)\n",
    "        padding_mask = padding_mask.T\n",
    "        # ---- Apply Transformer Encoder ----\n",
    "        transformer_out = self.transformer_encoder(main, src_key_padding_mask=padding_mask)  # (B, T, input_dim)\n",
    "        # ---- Apply regressor to transformer output ----\n",
    "        context = transformer_out.mean(dim=1)  # Take the mean of the sequence (or you could use the last token)\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Import optimizer dynamically\n",
    "        opt_module = import_module(f\"models.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr)\n",
    "\n",
    "        # No scheduler\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "\n",
    "        # Import scheduler dynamically\n",
    "        sch_module = import_module(f\"models.schedulers.{self.scheduler_name}\")\n",
    "        # OneCycle needs trainer\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer)\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer)\n",
    "\n",
    "        # Lightning accepts dict or list depending on scheduler type\n",
    "        if isinstance(scheduler, dict):\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler._LRScheduler):\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler return type: {type(scheduler)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6796e",
   "metadata": {},
   "source": [
    "### transformer + pre fnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0e08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from importlib import import_module\n",
    "\n",
    "# (Assuming these imports point to your files)\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from models.positional_encoders import sinusoidal, relative, rotary, learnable\n",
    "from models.positional_encoders.rotary import CustomEncoderLayer\n",
    "# ===================================================================\n",
    "#  YOUR MODIFIED LIGHTNING MODULE\n",
    "# ===================================================================\n",
    "\n",
    "class TransformerWithPositionalEncoding(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hidden_dim, \n",
    "                 num_layers, \n",
    "                 max_len_y, \n",
    "                 lr=0.001, \n",
    "                 optimizer_name=\"adamw\", \n",
    "                 positional_encoding=\"sinusoidal\", \n",
    "                 num_heads=4,\n",
    "                 feedforward_dim=128,\n",
    "                 first_drop=0.1, \n",
    "                 scheduler_name=None, \n",
    "                 scheduler_params=None, \n",
    "                 optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # --- Unchanged initializations ---\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.feedforward_dim = feedforward_dim\n",
    "        self.max_len_y = max_len_y\n",
    "        self.lr = lr\n",
    "        self.positional_encoding_type = positional_encoding\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        # --- Extract clip_distance from optimizer_params (with default 4) ---\n",
    "        self.clip_distance = optimizer_params.get('clip_distance', 4) if optimizer_params else 4\n",
    "        # --- Modified Positional Encoding and Encoder Setup ---\n",
    "\n",
    "        # Project input to hidden_dim (divisible by num_heads)\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "\n",
    "        # Choose the Positional Encoding based on the parameter\n",
    "        if positional_encoding == \"sinusoidal\":\n",
    "            # Applied to hidden_dim after embedding\n",
    "            self.positional_encoding = sinusoidal.SinusoidalPositionalEncoding(d_model=self.hidden_dim)\n",
    "        elif positional_encoding == \"learnable\":\n",
    "            self.positional_encoding = learnable.LearnablePositionalEncoding(d_model=self.hidden_dim)\n",
    "        elif positional_encoding == \"rotary\":\n",
    "            # RoPE's dimension must match Q and K, which is hidden_dim\n",
    "            self.positional_encoding = rotary.RotaryPositionalEncoding(dim=self.hidden_dim)\n",
    "        elif positional_encoding == \"relative\":\n",
    "            # Note: A full relative implementation also requires a custom attention layer\n",
    "            self.positional_encoding = relative.RelativePositionBias(head_dim=self.input_dim, clip_distance=self.clip_distance )\n",
    "        else:\n",
    "            self.positional_encoding = None # No positional encoding\n",
    "        \n",
    "        # <<< CHANGE >>>: Replace standard nn.TransformerEncoder with our custom layers\n",
    "        self.custom_encoder_layers = nn.ModuleList([\n",
    "            CustomEncoderLayer(\n",
    "                d_model=self.hidden_dim,\n",
    "                num_heads=self.num_heads,\n",
    "                d_ff=self.feedforward_dim,\n",
    "                dropout=first_drop\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # --- Unchanged Regressor ---\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        main = x[\"main\"]  # (B, T, input_dim)\n",
    "        B, T, _ = main.shape\n",
    "\n",
    "        # 1. Project to hidden_dim FIRST\n",
    "        main = self.embedding(main)  # (B, T, hidden_dim)\n",
    "\n",
    "        # 2. Prepare Positional Encodings\n",
    "        cos_emb, sin_emb = None, None # Default for non-rotary\n",
    "        \n",
    "        if self.positional_encoding_type in [\"sinusoidal\", \"learnable\"]:\n",
    "            main = self.positional_encoding(main)\n",
    "        elif self.positional_encoding_type == \"rotary\":\n",
    "            # For RoPE, we just generate the embeddings to pass to the encoder\n",
    "            cos_emb, sin_emb = self.positional_encoding(main)\n",
    "        # Add other cases like 'relative' if needed\n",
    "\n",
    "        # 3. Create Padding Mask (more robustly using lengths)\n",
    "        max_len = main.size(1)\n",
    "        indices = torch.arange(max_len, device=self.device).expand(B, -1)\n",
    "        padding_mask = indices >= lengths.unsqueeze(1) # (B, T)\n",
    "\n",
    "        # 4. <<< CHANGE >>>: Pass through custom encoder layers\n",
    "        transformer_out = main\n",
    "        for layer in self.custom_encoder_layers:\n",
    "            transformer_out = layer(\n",
    "                transformer_out, \n",
    "                cos=cos_emb, \n",
    "                sin=sin_emb, \n",
    "                key_padding_mask=padding_mask\n",
    "            )\n",
    "\n",
    "        # 5. Pool & Regress\n",
    "        context = transformer_out.mean(dim=1)\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    # --- Unchanged training/validation/optimizer steps ---\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr, **self.optimizer_params)\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.scheduler_name}\")\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer, **self.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f6300",
   "metadata": {},
   "source": [
    "### transformer CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from importlib import import_module\n",
    "\n",
    "# (Assuming these imports point to your files)\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from models.positional_encoders import sinusoidal, relative, rotary, learnable\n",
    "from models.positional_encoders.rotary import CustomEncoderLayer\n",
    "# ===================================================================\n",
    "#  YOUR MODIFIED LIGHTNING MODULE\n",
    "# ===================================================================\n",
    "\n",
    "class TransformerWithPositionalEncoding(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hidden_dim, \n",
    "                 num_layers, \n",
    "                 max_len_y, \n",
    "                 lr=0.001, \n",
    "                 optimizer_name=\"adamw\", \n",
    "                 positional_encoding=\"sinusoidal\", \n",
    "                 num_heads=1,\n",
    "                 feedforward_dim=128,\n",
    "                 first_drop=0.1, \n",
    "                 scheduler_name=None, \n",
    "                 scheduler_params=None, \n",
    "                 optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # --- Unchanged initializations ---\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.feedforward_dim = feedforward_dim\n",
    "        self.max_len_y = max_len_y\n",
    "        self.lr = lr\n",
    "        self.positional_encoding_type = positional_encoding\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        # --- Extract clip_distance from optimizer_params (with default 4) ---\n",
    "        self.clip_distance = optimizer_params.get('clip_distance', 4) if optimizer_params else 4\n",
    "        # --- Modified Positional Encoding and Encoder Setup ---\n",
    "\n",
    "        # Project input to hidden_dim (divisible by num_heads)\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "\n",
    "        # Choose the Positional Encoding based on the parameter\n",
    "        if positional_encoding == \"sinusoidal\":\n",
    "            # Applied to hidden_dim after embedding\n",
    "            self.positional_encoding = sinusoidal.SinusoidalPositionalEncoding(d_model=self.hidden_dim)\n",
    "        elif positional_encoding == \"learnable\":\n",
    "            self.positional_encoding = learnable.LearnablePositionalEncoding(d_model=self.hidden_dim)\n",
    "        elif positional_encoding == \"rotary\":\n",
    "            # RoPE's dimension must match Q and K, which is hidden_dim\n",
    "            self.positional_encoding = rotary.RotaryPositionalEncoding(dim=self.hidden_dim)\n",
    "        elif positional_encoding == \"relative\":\n",
    "            # Note: A full relative implementation also requires a custom attention layer\n",
    "            self.positional_encoding = relative.RelativePositionBias(head_dim=self.input_dim, clip_distance=self.clip_distance )\n",
    "        else:\n",
    "            self.positional_encoding = None # No positional encoding\n",
    "        \n",
    "        # <<< CHANGE >>>: Replace standard nn.TransformerEncoder with our custom layers\n",
    "        self.custom_encoder_layers = nn.ModuleList([\n",
    "            CustomEncoderLayer(\n",
    "                d_model=self.hidden_dim,\n",
    "                num_heads=self.num_heads,\n",
    "                d_ff=self.feedforward_dim,\n",
    "                dropout=first_drop\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.hidden_dim))\n",
    "        # --- Unchanged Regressor ---\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        main = x[\"main\"]  # (B, T, input_dim)\n",
    "        B, T, _ = main.shape\n",
    "\n",
    "        # 1. Project to hidden_dim FIRST\n",
    "        main = self.embedding(main)  # (B, T, hidden_dim)\n",
    "\n",
    "        # --- Prepend the [CLS] token to the sequence ---\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, hidden_dim)\n",
    "        main_with_cls = torch.cat((cls_tokens, main), dim=1)  # (B, T+1, hidden_dim)\n",
    "\n",
    "        # 2. Prepare Positional Encodings\n",
    "        cos_emb, sin_emb = None, None  # Default for non-rotary\n",
    "        if self.positional_encoding_type in [\"sinusoidal\", \"learnable\"]:\n",
    "            main_with_cls = self.positional_encoding(main_with_cls)\n",
    "        elif self.positional_encoding_type == \"rotary\":\n",
    "            cos_emb, sin_emb = self.positional_encoding(main_with_cls)\n",
    "\n",
    "        # 3. Create Padding Mask CORRECTLY\n",
    "        # Original mask for the actual candle data\n",
    "        max_len_data = main.size(1)  # T\n",
    "        indices_data = torch.arange(max_len_data, device=self.device).expand(B, -1)\n",
    "        data_padding_mask = indices_data >= lengths.unsqueeze(1)  # (B, T)\n",
    "\n",
    "        # Mask for the [CLS] token (it's never padded)\n",
    "        cls_padding_mask = torch.zeros(B, 1, dtype=torch.bool, device=self.device)  # (B, 1), all False\n",
    "\n",
    "        # Concatenate them\n",
    "        # The final mask will correctly mask only the padded candles\n",
    "        key_padding_mask = torch.cat((cls_padding_mask, data_padding_mask), dim=1)  # (B, T+1)\n",
    "\n",
    "        # 4. Pass through custom encoder layers\n",
    "        transformer_out = main_with_cls\n",
    "        for layer in self.custom_encoder_layers:\n",
    "            transformer_out = layer(\n",
    "                transformer_out, \n",
    "                cos=cos_emb, \n",
    "                sin=sin_emb, \n",
    "                key_padding_mask=key_padding_mask\n",
    "            )\n",
    "\n",
    "        # 5. Use the output of the [CLS] token (first token) as context\n",
    "        context = transformer_out[:, 0, :]  # Shape: (B, hidden_dim), output of [CLS] token\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "    # --- Unchanged training/validation/optimizer steps ---\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr, **self.optimizer_params)\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.scheduler_name}\")\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer, **self.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcaf36b",
   "metadata": {},
   "source": [
    "### vanilla fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad780435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.utils.swish import Swish\n",
    "from models.utils.mish import Mish\n",
    "\n",
    "class VanillaFNN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=0.001,\n",
    "                 scheduler_name=None, \n",
    "                 optimizer_name=\"adamw\",\n",
    "                 scheduler_params=None, \n",
    "                 optimizer_params=None,\n",
    "                 use_mse_loss=False,\n",
    "                 activation_function=\"relu\"):\n",
    "        # Added use_mse_loss parameter\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Define the activation function based on the passed parameter\n",
    "        if activation_function == \"relu\":\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        elif activation_function == \"elu\":\n",
    "            self.activation_fn = nn.ELU()\n",
    "        elif activation_function == \"leaky_relu\":\n",
    "            self.activation_fn = nn.LeakyReLU()\n",
    "        elif activation_function == \"sigmoid\":\n",
    "            self.activation_fn = nn.Sigmoid()\n",
    "        elif activation_function == \"tanh\":\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        elif activation_function == \"swish\":\n",
    "            self.activation_fn = Swish()  # Use custom Swish activation\n",
    "        elif activation_function == \"mish\":\n",
    "            self.activation_fn = Mish()   \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation_function}\")\n",
    "        \n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.use_mse_loss = use_mse_loss  # Store whether to use MSE loss or Hungarian loss\n",
    "        # Define the fully connected layers\n",
    "        self.flatten = nn.Flatten(start_dim=1)  # Flatten input to a 1D vector\n",
    "        self.fc1 = nn.Linear(input_dim[\"main\"] * 3, hidden_dim)  # First FC layer\n",
    "        self.relu = nn.ReLU()  # ReLU activation\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer\n",
    "        self.lr = lr\n",
    "        # Define the loss functions\n",
    "        if self.use_mse_loss:\n",
    "            self.loss_fn = nn.MSELoss()  # Use MSE Loss\n",
    "        else:\n",
    "            self.hungarian_loss = hungarian_loss_weighted\n",
    "            self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "            self.loss_fn = self.hungarian_loss  # Default to Hungarian loss\n",
    "\n",
    "    def forward(self, x, length):\n",
    "        \"\"\"\n",
    "        x is expected to have shape (B, input_dim).\n",
    "        Returns:\n",
    "        - out: (B, output_dim)\n",
    "        \"\"\"\n",
    "        x = x[\"main\"]\n",
    "        x = self.flatten(x)  # Flatten input\n",
    "        x = self.fc1(x)  # Apply first fully connected layer\n",
    "        x = self.activation_fn(x)  # Apply ReLU activation\n",
    "        out = self.fc2(x)  # Apply output layer\n",
    "        return out\n",
    "\n",
    "    # ---------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Use the selected loss function (MSE or Hungarian)\n",
    "        if self.use_mse_loss:\n",
    "            loss_reg = self.loss_fn(y_pred, y)  # MSE loss\n",
    "        else:\n",
    "            # Hungarian matching loss (weighted)\n",
    "            loss_reg = self.loss_fn(y_pred, y, mask)\n",
    "        \n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        if not self.use_mse_loss:\n",
    "            unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask, loss_type=\"mae\")\n",
    "            self.log(\"train_loss_unweighted\", unweighted_loss)  # reference\n",
    "\n",
    "        # Log the loss\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        \n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        # Use the selected loss function (MSE or Hungarian)\n",
    "        if self.use_mse_loss:\n",
    "            loss_reg = self.loss_fn(y_pred, y)  # MSE loss\n",
    "        else:\n",
    "            loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt_module = import_module(f\"models.optimizer.{self.hparams.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.hparams.lr, **self.hparams.optimizer_params)\n",
    "        if self.hparams.scheduler_name is None:\n",
    "            return optimizer\n",
    "        sch_module = import_module(f\"models.schedulers.{self.hparams.scheduler_name}\")\n",
    "        if self.hparams.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.hparams.lr, self.trainer, **self.hparams.scheduler_params)\n",
    "            interval = \"step\"\n",
    "        elif self.hparams.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer, **self.hparams.scheduler_params)\n",
    "            interval = \"epoch\"\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": interval,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab1e7f",
   "metadata": {},
   "source": [
    "## two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccb5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        print(\"x\",x)\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_loss_reg\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_len\", loss_len, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702411e",
   "metadata": {},
   "source": [
    "## two head lstm greedy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def match_and_loss(y_pred, y_true, mask, loss_fn):\n",
    "    \"\"\"\n",
    "    y_pred: (B, max_len_y)\n",
    "    y_true: (B, max_len_y)\n",
    "    mask: (B, max_len_y)  1 if real, 0 if padding\n",
    "    loss_fn: pointwise loss, e.g. MSELoss(reduction=\"none\")\n",
    "    for each target find closest line\n",
    "    \"\"\"\n",
    "    B, max_len = y_true.shape\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for i in range(B):\n",
    "        gt_vals = y_true[i][mask[i] > 0]  # real targets\n",
    "        preds = y_pred[i]\n",
    "\n",
    "        if len(gt_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        # greedy matching: for each gt, find closest prediction\n",
    "        used = set()\n",
    "        for gt in gt_vals:\n",
    "            dists = torch.abs(preds - gt)\n",
    "            for u in used:\n",
    "                dists[u] = float(\"inf\")  # prevent reuse\n",
    "            j = torch.argmin(dists)     # index of closest prediction\n",
    "            used.add(j.item())\n",
    "\n",
    "            total_loss += loss_fn(preds[j], gt)\n",
    "            total_count += 1\n",
    "\n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        # --- New greedy-matching regression loss ---\n",
    "        loss_reg = match_and_loss(y_pred, y, mask, nn.MSELoss())\n",
    "\n",
    "        # --- Length loss (unchanged) ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb2dd1",
   "metadata": {},
   "source": [
    "## two head lstm sum of logits loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models.losses.two_head_logit_sum import sum_of_logits\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # masked regression\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # multi-label classification\n",
    "        self.compute_loss = sum_of_logits()\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)\n",
    "        len_logits = self.fc_len(last_h)\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        loss, loss_reg, loss_len = self.compute_loss(y_pred, len_logits, y, lengths)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"loss_reg\", loss_reg, prog_bar=False)\n",
    "        self.log(\"loss_len\", loss_len, prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b88b10",
   "metadata": {},
   "source": [
    "## two head lstm soft thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "from models.losses.soft_thresholding_two_head import soft_thresholding_loss\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5, k_soft=20.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "        self.k_soft = k_soft\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()\n",
    "        self.compute_loss = soft_thresholding_loss\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)\n",
    "        len_logits = self.fc_len(last_h)\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        loss, loss_reg, loss_len = self.compute_loss(y_pred, len_logits, y, lengths)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"loss_reg\", loss_reg, prog_bar=False)\n",
    "        self.log(\"loss_len\", loss_len, prog_bar=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b75a48",
   "metadata": {},
   "source": [
    "## FNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c70fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b1d4",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    B = y_true.shape[0]\n",
    "\n",
    "    # Keep track if any valid lines are found\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]  # (B,1)\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "\n",
    "        mask = (y_target != 0).squeeze()\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        valid_line_found = True\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_loss = -log_likelihood.mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        # Avoid returning a Python float; create a tensor with requires_grad\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a057d",
   "metadata": {},
   "source": [
    "## LSTM weightening with pi order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15,hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base network\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        \n",
    "        if lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3*n_components)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f1d12",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class cnn_lstm(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base feature projection\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "\n",
    "        # Parallel conv1d branches\n",
    "        self.k1 = nn.Conv1d(feature_eng, feature_eng, kernel_size=1, padding=0)\n",
    "        self.k3 = nn.Conv1d(feature_eng, feature_eng, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fusion via conv2d\n",
    "        # Input channels = 2 (from k1 + k3), Output = 1, kernel size (1,1) to fuse\n",
    "        self.fusion_conv2d = nn.Conv2d(2, 1, kernel_size=(1, 1))\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: dict with key \"main\", value shape (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]  # (B, T, input_dim)\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # Fully connected projection\n",
    "        x = F.relu(self.ln1(self.fc1(x)))  # (B, T, F)\n",
    "\n",
    "        # Conv1d expects (B, F, T)\n",
    "        x_cnn = x.transpose(1, 2)  # (B, F, T)\n",
    "\n",
    "        # Parallel convs\n",
    "        x1 = self.k1(x_cnn)  # (B, F, T)\n",
    "        x3 = self.k3(x_cnn)  # (B, F, T)\n",
    "\n",
    "        # Stack into 2-channel feature map\n",
    "        stacked = torch.stack([x1, x3], dim=1)  # (B, 2, F, T)\n",
    "\n",
    "        # Fuse with conv2d → (B, 1, F, T)\n",
    "        fused = self.fusion_conv2d(stacked).squeeze(1)  # (B, F, T)\n",
    "\n",
    "        # Back to (B, T, F)\n",
    "        fused = fused.transpose(1, 2)\n",
    "\n",
    "        # LSTM with packed sequence\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(fused, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(packed)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(fused)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3 * n_components)\n",
    "\n",
    "        # Assume you have mdn_split_params(pi, mu, sigma)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e7f3",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening with sigma confidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll_with_sigma_penalty(y_true, mdn_params, weights, lambda_sigma=0.01):\n",
    "    \"\"\"\n",
    "    Calculates weighted MDN NLL and adds a penalty for large sigmas.\n",
    "    \n",
    "    Args:\n",
    "        lambda_sigma (float): The strength of the sigma penalty.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "        mask = (y_target != -1).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # --- 1. NLL Loss Calculation (same as before) ---\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_nll_loss = -log_likelihood.mean()\n",
    "\n",
    "        # --- 2. NEW: Sigma Penalty Calculation ---\n",
    "        # We penalize the mean of the sigmas for the most likely component\n",
    "        # This focuses the penalty on the component the model actually uses\n",
    "        most_likely_idx = torch.argmax(pi_masked, dim=1)\n",
    "        most_likely_sigma = sigma_masked.gather(1, most_likely_idx.unsqueeze(1)).squeeze()\n",
    "        sigma_penalty = torch.mean(most_likely_sigma)\n",
    "        \n",
    "        # --- 3. Combine and Weight ---\n",
    "        combined_line_loss = line_nll_loss + (lambda_sigma * sigma_penalty)\n",
    "        total_loss += weights[i] * combined_line_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# In your training_step, you would call this new function:\n",
    "# loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights, lambda_sigma=0.01)\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6484b7d",
   "metadata": {},
   "source": [
    "## CNNlSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2139f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # Inside your CNNLSTM_MDN class\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 50% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e8361",
   "metadata": {},
   "source": [
    "## CNNLSTM scalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a359387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components, mu_scale=10, mu_bias=.9, sigma_scale=10.0):\n",
    "    \"\"\"\n",
    "    Split raw MDN parameters into (pi, mu, sigma).\n",
    "\n",
    "    Args:\n",
    "        raw_params: (B, 3 * K) from the network\n",
    "        n_components: number of mixture components\n",
    "        mu_scale: scaling factor for mu (default 1.0 = no scaling)\n",
    "        mu_bias: shift/bias applied after scaling\n",
    "        sigma_scale: scaling factor for sigma (default 10.0)\n",
    "    \"\"\"\n",
    "    B = raw_params.size(0)\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi_raw = raw[..., 0]\n",
    "    mu_raw = raw[..., 1]\n",
    "    sigma_raw = raw[..., 2]\n",
    "\n",
    "    pi = F.softmax(pi_raw, dim=-1)\n",
    "    mu = mu_raw / mu_scale + mu_bias\n",
    "    sigma = F.softplus(sigma_raw / sigma_scale) + 1e-4\n",
    "\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] \n",
    "\n",
    "        # --- Debug print first candle ---\n",
    "        # if x.ndim == 3:  # batched: (B, T, F)\n",
    "        #     first_candle = x[0, 0, :]   # first sample, first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # elif x.ndim == 2:  # single sequence: (T, F)\n",
    "        #     first_candle = x[0, :]      # first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # else:\n",
    "        #     print(\"Unexpected shape for x:\", x.shape)\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # # Inside your CNNLSTM_MDN class\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 80% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    # def configure_optimizers(self):\n",
    "    #     return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccc1c2",
   "metadata": {},
   "source": [
    "## CNNtransformer wheightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "\n",
    "# --- Helper Functions and Modules ---\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma).\n",
    "    This function is used by each individual MDN head.\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-6 # Added a small epsilon for stability\n",
    "    return pi, mu, sigma\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Injects positional information into the input sequence for the Transformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- Weighted Loss Function for Multi-Head Architecture ---\n",
    "\n",
    "def weighted_mdn_nll_multihead(y_true, mdn_params_list, weights, padding_value=-1):\n",
    "    \"\"\"\n",
    "    Calculates the weighted negative log-likelihood for a multi-headed MDN.\n",
    "    This version correctly handles multiple heads and calculates the full NLL for each.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensor): Padded target values, shape (B, num_lines).\n",
    "        mdn_params_list (list): A list of dicts, one for each head.\n",
    "        weights (Tensor): A 1D tensor of importance weights, shape (num_lines,).\n",
    "        padding_value (int): Value used for padding in y_true.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    \n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params_list[i]['pi'], mdn_params_list[i]['mu'], mdn_params_list[i]['sigma']\n",
    "\n",
    "        # Create a mask for valid (non-padded) targets for this line\n",
    "        mask = (y_target != padding_value).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:  # Skip if no valid targets for this line in the batch\n",
    "            continue\n",
    "\n",
    "        # Select only the valid data for this line's loss calculation\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # Use torch.distributions for a clean and stable calculation\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        \n",
    "        # Calculate log probabilities of the target values in each Gaussian component\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        \n",
    "        # Mix the probabilities using the mixture weights (pi)\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        \n",
    "        # Use logsumexp for numerical stability to get the log-likelihood\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        \n",
    "        # Calculate the mean negative log-likelihood for this line\n",
    "        line_loss = -log_likelihood.mean()\n",
    "\n",
    "        # Apply the importance weight and add to total loss\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    # If no valid lines were found in the entire batch, return a zero tensor\n",
    "    if not isinstance(total_loss, torch.Tensor):\n",
    "        return torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "# --- The CNN-Transformer Model ---\n",
    "\n",
    "class cnn_transformer(pl.LightningModule):\n",
    "    def __init__(self, input_dim, cnn_out_channels=64, d_model=128, nhead=4, num_encoder_layers=2,\n",
    "                 n_components=9, num_lines=9, lr=1e-4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "        \n",
    "        # 1. CNN Feature Extractor Block\n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, cnn_out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(cnn_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(cnn_out_channels, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # 4. Multi-Head MDN Output\n",
    "        self.mdn_heads = nn.ModuleList([\n",
    "            nn.Linear(d_model, 3 * n_components) for _ in range(num_lines)\n",
    "        ])\n",
    "        \n",
    "        # Importance weights for lines (exponential decay)\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, X, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        src_key_padding_mask: (B, T) boolean mask for padded elements in X\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        \n",
    "        # 1. CNN Feature Extraction\n",
    "        # Input for Conv1d needs to be (B, C_in, L), so we permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn_extractor(x)\n",
    "        # Permute back to (B, T, C_out) for Transformer\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 2. Add Positional Encoding\n",
    "        # Transformer expects (T, B, C), so permute again\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.pos_encoder(x)\n",
    "        # Permute back to (B, T, C) for batch_first=True\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        # The mask should indicate which key values are NOT to be attended to\n",
    "        encoded_seq = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # We use the representation of the last valid timestep for prediction\n",
    "        # (A common strategy, alternatively you could use mean pooling)\n",
    "        # For simplicity, we'll take the last hidden state of the sequence.\n",
    "        sequence_summary = encoded_seq[:, -1, :] # (B, d_model)\n",
    "        \n",
    "        # 4. Get parameters from all MDN heads\n",
    "        mdn_params_list = []\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](sequence_summary)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            mdn_params_list.append({\"pi\": pi, \"mu\": mu, \"sigma\": sigma})\n",
    "\n",
    "        return mdn_params_list\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        # Create the padding mask for the transformer\n",
    "        # True values indicate positions that should be ignored.\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "\n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        # Use a padding value of -1 for the loss function\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "        \n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefa26",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95badad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6d37502b-8844-4574-b3cd-d3f9d9cfeb6c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1515456000",
         "1514937600",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516492800",
         "1516147200",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1520121600",
         "1519862400",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "46",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "49",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "50",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 320
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1515456000</td>\n",
       "      <td>1514937600</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1651795200</td>\n",
       "      <td>1649116800</td>\n",
       "      <td>1555</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.873150</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.938913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1652054400</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1589</td>\n",
       "      <td>1591</td>\n",
       "      <td>1.063729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1652572800</td>\n",
       "      <td>1651881600</td>\n",
       "      <td>1587</td>\n",
       "      <td>1595</td>\n",
       "      <td>0.813907</td>\n",
       "      <td>0.870793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788406</td>\n",
       "      <td>0.904141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1653264000</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1591</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.042211</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.958532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1648598400</td>\n",
       "      <td>1640304000</td>\n",
       "      <td>1453</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.884394</td>\n",
       "      <td>0.71872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1515456000  1514937600           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "328  1651795200  1649116800        1555      1586     0.873150     0.825739   \n",
       "330  1652054400  1652227200        1589      1591     1.063729          NaN   \n",
       "331  1652572800  1651881600        1587      1595     0.813907     0.870793   \n",
       "332  1653264000  1652227200        1591      1603     1.042211     1.075683   \n",
       "333  1648598400  1640304000        1453      1549     0.781703     0.741996   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "328     0.905267     0.938913          NaN          NaN          NaN   \n",
       "330          NaN     1.023085          NaN          NaN          NaN   \n",
       "331          NaN          NaN          NaN          NaN          NaN   \n",
       "332     0.992004     0.958532          NaN          NaN          NaN   \n",
       "333     0.993930     0.847425     0.884394      0.71872          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "328     0.955736          NaN  \n",
       "330          NaN          NaN  \n",
       "331     0.788406     0.904141  \n",
       "332          NaN          NaN  \n",
       "333          NaN     0.647521  \n",
       "\n",
       "[320 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_labels = pd.read_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\")\n",
    "cols = [f'price_line{i}' for i in range(1, 10)]\n",
    "df_labels = df_labels.dropna(subset=cols, how='all')\n",
    "df_labels = df_labels.rename(columns={c: c.replace('price_line', 'linePrice_') \n",
    "                        for c in df_labels.columns if c.startswith('price_line')})\n",
    "df_labels.to_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\", index=False)      \n",
    "#     # overwrites the old file\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f918ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prices 14910.53342206 14907.09\n",
      "Mean Squared Error: 118.36232187340579\n",
      "Mean Absolute Error: 6.968826326025471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load your datasets\n",
    "label_df = pd.read_csv('/home/iatell/projects/meta-learning/data/baseline_regression.csv')  # Your label dataset\n",
    "candles_df = pd.read_csv('/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv')  # Your candles dataset\n",
    "\n",
    "# Convert timestamp to integer or datetime if needed (for simplicity assuming timestamp in seconds)\n",
    "candles_df['timestamp'] = pd.to_datetime(candles_df['timestamp'], format='%Y-%m-%d')\n",
    "# Prepare a dictionary for efficient lookup of the close prices by index\n",
    "candles_df.set_index('timestamp', inplace=True)\n",
    "# Lists to store results for MSE and MAE\n",
    "predicted_prices = []\n",
    "actual_prices = []\n",
    "\n",
    "# Loop through each row of the label dataset\n",
    "for _, row in label_df.iterrows():\n",
    "    start_index = row['startTime']\n",
    "    end_index = row['endTime']\n",
    "    line_price = row['linePrice_1']\n",
    "    \n",
    "    # Find the middle index\n",
    "    middle_index = (start_index + end_index) // 2\n",
    "    \n",
    "    # Get the middle timestamp and convert to date-only\n",
    "    middle_time = pd.to_datetime(middle_index, unit='s').date()  # Strip time part, keep only date\n",
    "    \n",
    "    # Get the close price for middle and next indices (you can also handle possible out of bounds errors)\n",
    "    try:\n",
    "        # Use the date-only value to find the row in candles_df\n",
    "        close_middle = candles_df.loc[candles_df.index.date == middle_time, 'close'].iloc[0]\n",
    "        \n",
    "        # If you want the next day, you can add one day to middle_time\n",
    "        next_day = middle_time + pd.Timedelta(days=1)\n",
    "        close_next = candles_df.loc[candles_df.index.date == next_day, 'close'].iloc[0]\n",
    "        \n",
    "        # Multiply the next close price with linePrice_1\n",
    "        predicted_price = close_next * line_price\n",
    "        \n",
    "        # Append the actual and predicted prices\n",
    "        predicted_prices.append(predicted_price)\n",
    "        actual_prices.append(close_middle)\n",
    "    except IndexError:\n",
    "        print(f\"Timestamp for index {middle_time} is not available in candles data.\")\n",
    "    except KeyError:\n",
    "        print(f\"KeyError: Timestamp {middle_time} or {next_day} not found.\")\n",
    "\n",
    "# Compute the MSE and MAE\n",
    "print(\"prices\",predicted_prices[0],actual_prices[0])\n",
    "# print(predicted_prices[0])\n",
    "\n",
    "mse = mean_squared_error(actual_prices, predicted_prices)\n",
    "mae = mean_absolute_error(actual_prices, predicted_prices)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e598967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prices 1.1260168988381105 1.126277\n",
      "Mean Squared Error: 3.0552651929706174e-07\n",
      "Mean Absolute Error: 0.00040706352500020096\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load your datasets\n",
    "label_df = pd.read_csv('/home/iatell/projects/meta-learning/data/baseline_regression.csv')  # Your label dataset\n",
    "candles_df = pd.read_csv('/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv')  # Your candles dataset\n",
    "\n",
    "# Convert timestamp to integer or datetime if needed (for simplicity assuming timestamp in seconds)\n",
    "candles_df['timestamp'] = pd.to_datetime(candles_df['timestamp'], format='%Y-%m-%d')\n",
    "# Prepare a dictionary for efficient lookup of the close prices by index\n",
    "candles_df.set_index('timestamp', inplace=True)\n",
    "# Lists to store results for MSE and MAE\n",
    "predicted_prices = []\n",
    "actual_prices = []\n",
    "\n",
    "# Loop through each row of the label dataset\n",
    "for _, row in label_df.iterrows():\n",
    "    start_index = row['startTime']\n",
    "    end_index = row['endTime']\n",
    "    line_price = row['linePrice_1']\n",
    "    \n",
    "    # Find the middle index\n",
    "    middle_index = (start_index + end_index) // 2\n",
    "    \n",
    "    # Get the middle timestamp and convert to date-only\n",
    "    middle_time = pd.to_datetime(middle_index, unit='s').date()  # Strip time part, keep only date\n",
    "    \n",
    "    # Get the close price for middle and end indices (you can also handle possible out of bounds errors)\n",
    "    try:\n",
    "        # Get the close price for the middle time and the end time\n",
    "        close_middle = candles_df.loc[candles_df.index.date == middle_time, 'close'].iloc[0]\n",
    "        # Get the close price for the end time\n",
    "        end_time = pd.to_datetime(end_index, unit='s').date()\n",
    "        close_end = candles_df.loc[candles_df.index.date == end_time, 'close'].iloc[0]\n",
    "        \n",
    "        # Compute predicted price: divide the middle price by the end price\n",
    "        predicted_price = close_middle / close_end\n",
    "        \n",
    "        # Compare predicted price with linePrice_1\n",
    "        # predicted_comparison = predicted_price * line_price\n",
    "        \n",
    "        # Append the actual and predicted prices\n",
    "        predicted_prices.append(predicted_price)\n",
    "        actual_prices.append(line_price)\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f\"Timestamp for index {middle_time} or {end_time} not available in candles data.\")\n",
    "    except KeyError:\n",
    "        print(f\"KeyError: Timestamp {middle_time} or {end_time} not found.\")\n",
    "print(\"prices\",predicted_prices[0],actual_prices[0])\n",
    "\n",
    "# Compute the MSE and MAE\n",
    "mse = mean_squared_error(actual_prices, predicted_prices)\n",
    "mae = mean_absolute_error(actual_prices, predicted_prices)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4dd53",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677dbff",
   "metadata": {},
   "source": [
    "## simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e281d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# ---------------- Evaluation ---------------- #\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, zero_idx=0, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (last-output version).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    zero_idx : which mixture component is considered \"no-line\" (usually 0)\n",
    "    threshold : if pi[:,zero_idx] > threshold → predict invalid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            if isinstance(X_batch, dict):\n",
    "                X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            else:\n",
    "                X_batch = X_batch.to(device)\n",
    "\n",
    "            y_batch = y_batch.to(device)\n",
    "            mdn = model(X_batch, lengths)\n",
    "            pi, mu, sigma = mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"]  # (B,K)\n",
    "\n",
    "            # regression expectation\n",
    "            y_pred = (pi * mu).sum(dim=-1)  # (B,)\n",
    "            B = y_batch.size(0)\n",
    "            y_len = (y_batch > 0).sum(dim=1)                # (B,)\n",
    "            idx = torch.clamp(y_len - 1, min=0)             # last valid index\n",
    "            y_true = y_batch[torch.arange(B, device=y_batch.device), idx]  # (B,)\n",
    "            # only last step\n",
    "            # print(\"lengths(features):\", lengths[:10])\n",
    "            # print(\"lengths(labels):\", y_len[:10])\n",
    "\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "            # validity classification\n",
    "            pi_zero = pi[:, zero_idx]  # (B,)\n",
    "            pred_valid = (pi_zero < (1 - threshold)).long()\n",
    "            true_valid = torch.ones_like(pred_valid)  # last step always valid\n",
    "\n",
    "            all_preds_len.extend(pred_valid.cpu().numpy().tolist())\n",
    "            all_labels_len.extend(true_valid.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "        # ----- Regression metrics -----\n",
    "    all_preds_reg = np.concatenate(all_preds_reg)  # (N,)\n",
    "    all_labels_reg = np.concatenate(all_labels_reg)\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "    # ----- Validity metrics -----\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (MDN, last-output):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Validity   → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=1000,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNLSTM_MDN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44de2e9",
   "metadata": {},
   "source": [
    "### hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression only\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per batch ---\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg)\n",
    "    all_labels_reg = np.array(all_labels_reg)\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=300,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return metrics\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a7940",
   "metadata": {},
   "source": [
    "## ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb16e4",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.235186 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.235186 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (3, 12)\n",
      "[main] First few rows:\n",
      " [[ 0.0334583  -0.0164952  -0.08295181 -0.05172484  0.0091133   0.06722008\n",
      "   0.05172484  0.3         1.3036697   1.3155504   1.1531377   1.2362376 ]\n",
      " [-0.05151443 -0.0062422   0.04603237  0.0048193   0.05244192  0.02449848\n",
      "   0.00457536  0.7         1.236512    1.3073386   1.2062193   1.2421954 ]\n",
      " [ 0.00163378 -0.04961828 -0.31281227 -0.19497368  0.00318     0.17110091\n",
      "   0.19259259  0.3         1.2385321   1.2424706   0.8288991   1.        ]]\n",
      "==========================\n",
      "\n",
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([2, 9])\n",
      "  First label in batch: tensor([1.2352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([2, 3, 12])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[ 0.0335, -0.0165, -0.0830, -0.0517,  0.0091,  0.0672,  0.0517,  0.3000,\n",
      "          1.3037,  1.3156,  1.1531,  1.2362],\n",
      "        [-0.0515, -0.0062,  0.0460,  0.0048,  0.0524,  0.0245,  0.0046,  0.7000,\n",
      "          1.2365,  1.3073,  1.2062,  1.2422],\n",
      "        [ 0.0016, -0.0496, -0.3128, -0.1950,  0.0032,  0.1711,  0.1926,  0.3000,\n",
      "          1.2385,  1.2425,  0.8289,  1.0000]])\n",
      "\n",
      "✅ Combined df_seq shape: (6, 12)\n",
      "✅ Column names in df_seq: ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type      | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | fc1           | Linear    | 195    | train\n",
      "1 | ln1           | LayerNorm | 30     | train\n",
      "2 | k1            | Conv1d    | 240    | train\n",
      "3 | k3            | Conv1d    | 690    | train\n",
      "4 | fusion_conv2d | Conv2d    | 3      | train\n",
      "5 | lstm          | LSTM      | 6.3 K  | train\n",
      "6 | mdn_head      | Linear    | 891    | train\n",
      "----------------------------------------------------\n",
      "8.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.3 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4a0ac5bd0e4c7a834a906ea7f5a3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=False,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    feature_eng=15,\n",
    "    n_components=9,\n",
    "    dropout = 0.1,\n",
    "    batch_size=2,\n",
    "    max_epochs=600,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(add_candle_shape_features),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"standard\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         # \"open_dif\":\"standard\",\"close_dif\":\"standard\",\"high_dif\":\"standard\",\"low_dif\":\"standard\"\n",
    "        #         # \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         # \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "          True,\n",
    "          True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_cols)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_lstm(input_dim=input_dim, feature_eng= feature_eng, hidden_dim=hidden_dim, \n",
    "                     n_components=n_components,  lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    init_args = get_init_args(model, input_dim=input_dim,feature_eng= feature_eng\n",
    "                              ,hidden_dim=hidden_dim, n_components=n_components,\n",
    "                              lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/debug_test_seq.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=False,\n",
    "        test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fd2dc",
   "metadata": {},
   "source": [
    "### cnn transforemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948aa8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (5, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      " [ 0.00938704  0.12409948  0.04899828  0.12622231]\n",
      " [ 0.12622082 -0.00192766  0.09665822  0.00645032]\n",
      " [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnn_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 304\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 190\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, early_stop)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# single tensor\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     input_dim \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 190\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_transformer\u001b[49m(input_dim, feature_eng\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, num_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m init_args \u001b[38;5;241m=\u001b[39m get_init_args(model, input_dim\u001b[38;5;241m=\u001b[39minput_dim,num_lines\u001b[38;5;241m=\u001b[39m max_len_y )\n\u001b[1;32m    194\u001b[0m model_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_args\n\u001b[1;32m    198\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=500,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_transformer(input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim,num_lines= max_len_y )\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3023ae",
   "metadata": {},
   "source": [
    "### two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91951ca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm        | LSTM              | 68.6 K | train\n",
      "1 | fc_reg      | Linear            | 774    | train\n",
      "2 | fc_len      | Linear            | 774    | train\n",
      "3 | loss_fn_reg | MSELoss           | 0      | train\n",
      "4 | loss_fn_len | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "70.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 K    Total params\n",
      "0.281     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.086008 1.126277 1.165107 0.970955 0.       0.      ] Encoded (padded): [1.086008 1.126277 1.165107 0.970955 0.       0.      ]\n",
      "[main] Shape: (5, 4)\n",
      "[main] First few rows:\n",
      " [[ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]\n",
      " [-0.08115927 -0.05037893  0.09358804 -0.03372177]\n",
      " [-0.03365467 -0.03511871 -0.06278902  0.03521458]\n",
      " [ 0.03742796  0.00087057 -0.13184595 -0.11191386]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6b9bc314ea4e17b85c57d428d1d2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250913_143827.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250913_143827.pkl\n",
      "\n",
      "📊 Validation Metrics:\n",
      "  Regression → MSE: 0.454865, MAE: 0.510467\n",
      "  Length     → Acc: 0.0667, F1: 0.0096\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            # Send to same device as model\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression + length logits\n",
    "            y_pred, len_logits = model(X_batch, lengths)\n",
    "\n",
    "            # Regression targets\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_batch.cpu().numpy())\n",
    "\n",
    "            # Length targets\n",
    "            true_lengths = lengths.cpu().numpy()\n",
    "            pred_lengths = model.predict_length(len_logits).cpu().numpy()\n",
    "\n",
    "            all_labels_len.extend(true_lengths.tolist())\n",
    "            all_preds_len.extend(pred_lengths.tolist())\n",
    "\n",
    "    # ----- Regression metrics -----\n",
    "    all_preds_reg = np.vstack(all_preds_reg)\n",
    "    all_labels_reg = np.vstack(all_labels_reg)\n",
    "\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    # ----- Length metrics -----\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics:\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Length     → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=50,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838866e",
   "metadata": {},
   "source": [
    "### xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439210d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG SAMPLE 1 ---\n",
      "Target (raw vector): [0.828937 0.923251 1.05529  0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Transformed features shape: (600,)\n",
      "First few features: [ 1.          0.46831214  0.93835616  3.6208599   0.89041096  1.0190262\n",
      "  0.10273973  2.2397478   0.         -0.05749728]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 3 ---\n",
      "Target (raw vector): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Transformed features shape: (600,)\n",
      "First few features: [ 1.          0.5981996   0.9246575   4.4519453   0.8767123   1.2397392\n",
      "  0.10273973  2.71271     0.         -0.07422142]\n",
      "------------------------------\n",
      "\n",
      "📊 Validation Report (Multi-Regression with variable-length sequences):\n",
      "\n",
      "Sample 0:\n",
      "  Predicted length: 4, True length: 3\n",
      "  MSE: 0.009823, MAE: 0.081410, R²: -0.049669\n",
      "  Predicted lines: [1.0500662 1.114291  1.1458886]\n",
      "  True lines     : [1.04857  1.233659 1.269253]\n",
      "\n",
      "Sample 1:\n",
      "  Predicted length: 5, True length: 6\n",
      "  MSE: 0.195629, MAE: 0.283974, R²: -24.387863\n",
      "  Predicted lines: [0.0049967  0.65657175 1.041897   1.0455115  1.087508  ]\n",
      "  True lines     : [0.933635 0.97799  1.057056 1.111053 1.17662 ]\n",
      "\n",
      "Sample 2:\n",
      "  Predicted length: 7, True length: 3\n",
      "  MSE: 0.014318, MAE: 0.112056, R²: -2.273095\n",
      "  Predicted lines: [0.6323594  0.83222556 0.87402207]\n",
      "  True lines     : [0.803359 0.908825 0.962592]\n",
      "\n",
      "Sample 3:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.000001, MAE: 0.000918, R²: 0.990017\n",
      "  Predicted lines: [1.0196117 1.0338057 1.0428904]\n",
      "  True lines     : [1.018789 1.033092 1.041673]\n",
      "\n",
      "Sample 4:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.123825, MAE: 0.245751, R²: -85.262794\n",
      "  Predicted lines: [0.33663067 0.9426052  0.94627357]\n",
      "  True lines     : [0.938085 0.994583 1.030095]\n",
      "\n",
      "Sample 5:\n",
      "  Predicted length: 5, True length: 5\n",
      "  MSE: 0.411964, MAE: 0.578451, R²: -47.432182\n",
      "  Predicted lines: [0.12831894 0.21012242 0.3370278  0.90688026 0.97459215]\n",
      "  True lines     : [0.942873 1.042404 1.104875 1.145111 1.213935]\n",
      "\n",
      "Sample 6:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.007708, MAE: 0.083877, R²: -11.184835\n",
      "  Predicted lines: [0.80700076 0.88498425 0.92979383]\n",
      "  True lines     : [0.926356 0.959136 0.987919]\n",
      "\n",
      "Sample 7:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.112067, MAE: 0.254714, R²: -73.762222\n",
      "  Predicted lines: [0.3786155  0.8922516  0.94140977]\n",
      "  True lines     : [0.940353 1.002637 1.03343 ]\n",
      "\n",
      "Sample 8:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.064542, MAE: 0.154611, R²: -203.293732\n",
      "  Predicted lines: [0.5162574 0.9691182 1.0112177]\n",
      "  True lines     : [0.955955 0.981318 0.999283]\n",
      "\n",
      "Sample 9:\n",
      "  Predicted length: 4, True length: 2\n",
      "  MSE: 0.042671, MAE: 0.188208, R²: -6.498780\n",
      "  Predicted lines: [0.72381884 1.0449642 ]\n",
      "  True lines     : [0.997165 1.148034]\n",
      "\n",
      "Sample 10:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.037589, MAE: 0.123518, R²: -109.731926\n",
      "  Predicted lines: [0.6365072 0.9641155 1.012613 ]\n",
      "  True lines     : [0.970615 0.997764 1.015411]\n",
      "\n",
      "Sample 11:\n",
      "  Predicted length: 4, True length: 2\n",
      "  MSE: 0.038107, MAE: 0.164393, R²: -50.888470\n",
      "  Predicted lines: [0.8165266 1.0812718]\n",
      "  True lines     : [1.086192 1.140392]\n",
      "\n",
      "Sample 12:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.001850, MAE: 0.040417, R²: 0.038275\n",
      "  Predicted lines: [0.7744877  0.78433245 0.9183683  0.966634  ]\n",
      "  True lines     : [0.797651 0.836186 0.889542 0.90881 ]\n",
      "\n",
      "Sample 13:\n",
      "  Predicted length: 7, True length: 4\n",
      "  MSE: 0.344931, MAE: 0.582863, R²: -8.127190\n",
      "  Predicted lines: [0.62680715 0.73164874 0.84295684 0.9581607 ]\n",
      "  True lines     : [1.13575  1.262153 1.440862 1.652261]\n",
      "\n",
      "Sample 14:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.140390, MAE: 0.260483, R²: -323.131256\n",
      "  Predicted lines: [0.2992646 0.6838705 0.9738465 1.0422652]\n",
      "  True lines     : [0.976588 1.002056 1.012475 1.034471]\n",
      "\n",
      "Sample 15:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.009392, MAE: 0.081738, R²: -2.028193\n",
      "  Predicted lines: [0.9430055 1.0325257 1.130528  1.2256751]\n",
      "  True lines     : [1.082921 1.145985 1.202043 1.227736]\n",
      "\n",
      "Sample 16:\n",
      "  Predicted length: 4, True length: 2\n",
      "  MSE: 0.054845, MAE: 0.189552, R²: -26.200745\n",
      "  Predicted lines: [0.46112335 0.82599735]\n",
      "  True lines     : [0.788209 0.878016]\n",
      "\n",
      "Sample 17:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.038440, MAE: 0.129749, R²: -318.745758\n",
      "  Predicted lines: [0.6161581  0.9441993  0.95107424]\n",
      "  True lines     : [0.953735 0.966367 0.980577]\n",
      "\n",
      "Sample 18:\n",
      "  Predicted length: 6, True length: 3\n",
      "  MSE: 0.455117, MAE: 0.562511, R²: -433.577362\n",
      "  Predicted lines: [0.09342565 0.4941688  1.0789613 ]\n",
      "  True lines     : [1.079072 1.116709 1.158308]\n",
      "\n",
      "Sample 19:\n",
      "  Predicted length: 9, True length: 5\n",
      "  MSE: 0.201623, MAE: 0.224954, R²: -352.771912\n",
      "  Predicted lines: [-0.01771747  0.96261734  0.98174     1.003626    1.0435499 ]\n",
      "  True lines     : [0.984109 1.004852 1.020409 1.03683  1.052388]\n",
      "\n",
      "Sample 20:\n",
      "  Predicted length: 7, True length: 2\n",
      "  MSE: 0.029340, MAE: 0.161779, R²: -3.241903\n",
      "  Predicted lines: [0.8909968  0.94477177]\n",
      "  True lines     : [0.996497 1.16283 ]\n",
      "\n",
      "Sample 21:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.006263, MAE: 0.046952, R²: 0.378469\n",
      "  Predicted lines: [0.68512756 0.69888437 0.7612971  0.7675909 ]\n",
      "  True lines     : [0.659905 0.701181 0.7572   0.923782]\n",
      "\n",
      "Sample 22:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.065514, MAE: 0.194642, R²: -93.756493\n",
      "  Predicted lines: [0.52374274 0.67154694 0.9521439  0.9806473 ]\n",
      "  True lines     : [0.941164 0.963754 0.991722 1.010009]\n",
      "\n",
      "Sample 23:\n",
      "  Predicted length: 15, True length: 3\n",
      "  MSE: 0.000006, MAE: 0.002334, R²: 0.962609\n",
      "  Predicted lines: [0.9511337 0.9586485 0.9824015]\n",
      "  True lines     : [0.948224 0.957645 0.979314]\n",
      "\n",
      "Sample 24:\n",
      "  Predicted length: 5, True length: 1\n",
      "  MSE: 0.002202, MAE: 0.046924, R²: nan\n",
      "  Predicted lines: [0.8489074]\n",
      "  True lines     : [0.895831]\n",
      "\n",
      "Sample 25:\n",
      "  Predicted length: 6, True length: 4\n",
      "  MSE: 0.001614, MAE: 0.033905, R²: -0.342353\n",
      "  Predicted lines: [0.88191634 0.9361643  0.9870024  1.0017377 ]\n",
      "  True lines     : [0.94599  0.966843 0.990476 1.039132]\n",
      "\n",
      "Sample 26:\n",
      "  Predicted length: 11, True length: 2\n",
      "  MSE: 0.013528, MAE: 0.102264, R²: -93.192924\n",
      "  Predicted lines: [0.6966571  0.83143514]\n",
      "  True lines     : [0.854326 0.878294]\n",
      "\n",
      "Sample 27:\n",
      "  Predicted length: 14, True length: 3\n",
      "  MSE: 0.008518, MAE: 0.091251, R²: -6.278845\n",
      "  Predicted lines: [0.7519006  0.81570566 0.85408604]\n",
      "  True lines     : [0.860858 0.890957 0.94363 ]\n",
      "\n",
      "Sample 28:\n",
      "  Predicted length: 6, True length: 5\n",
      "  MSE: 0.105578, MAE: 0.209078, R²: -75.950607\n",
      "  Predicted lines: [0.15128462 0.43888915 0.78707665 0.83019716 0.8674008 ]\n",
      "  True lines     : [0.78337  0.79527  0.805007 0.861264 0.875328]\n",
      "\n",
      "Sample 29:\n",
      "  Predicted length: 4, True length: 7\n",
      "  MSE: 0.041441, MAE: 0.116408, R²: -312.193665\n",
      "  Predicted lines: [0.5388932  0.93478596 0.9565662  1.0068126 ]\n",
      "  True lines     : [0.944168 0.958041 0.963152 0.976295]\n",
      "\n",
      "Sample 30:\n",
      "  Predicted length: 6, True length: 2\n",
      "  MSE: 0.033086, MAE: 0.179827, R²: -10.346055\n",
      "  Predicted lines: [0.85342777 1.0161529 ]\n",
      "  True lines     : [1.060616 1.168618]\n",
      "\n",
      "Sample 31:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.148192, MAE: 0.321836, R²: -158.811462\n",
      "  Predicted lines: [0.34009433 0.47742885 0.80525833 0.9334676 ]\n",
      "  True lines     : [0.926176 0.944641 0.964712 1.008065]\n",
      "\n",
      "Sample 32:\n",
      "  Predicted length: 6, True length: 2\n",
      "  MSE: 0.029636, MAE: 0.165759, R²: -3.183786\n",
      "  Predicted lines: [0.7869623 1.0482434]\n",
      "  True lines     : [0.999198 1.167526]\n",
      "\n",
      "Sample 33:\n",
      "  Predicted length: 8, True length: 1\n",
      "  MSE: 0.004392, MAE: 0.066272, R²: nan\n",
      "  Predicted lines: [1.0554659]\n",
      "  True lines     : [1.121738]\n",
      "\n",
      "Sample 34:\n",
      "  Predicted length: 8, True length: 3\n",
      "  MSE: 0.016089, MAE: 0.102353, R²: -17.234655\n",
      "  Predicted lines: [0.75851965 0.96033263 0.9875363 ]\n",
      "  True lines     : [0.966787 1.007275 1.039386]\n",
      "\n",
      "Sample 35:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.000137, MAE: 0.009769, R²: 0.706466\n",
      "  Predicted lines: [0.90779227 0.95339304 0.95738757]\n",
      "  True lines     : [0.9115   0.934695 0.964288]\n",
      "\n",
      "Sample 36:\n",
      "  Predicted length: 3, True length: 1\n",
      "  MSE: 0.000036, MAE: 0.005984, R²: nan\n",
      "  Predicted lines: [1.0900663]\n",
      "  True lines     : [1.09605]\n",
      "\n",
      "Sample 37:\n",
      "  Predicted length: 5, True length: 2\n",
      "  MSE: 0.005108, MAE: 0.071108, R²: -4.757367\n",
      "  Predicted lines: [0.85117084 0.92519283]\n",
      "  True lines     : [0.929502 0.989077]\n",
      "\n",
      "Sample 38:\n",
      "  Predicted length: 8, True length: 2\n",
      "  MSE: 0.067376, MAE: 0.192984, R²: -509.525970\n",
      "  Predicted lines: [0.6549365 1.0250939]\n",
      "  True lines     : [1.021511 1.044487]\n",
      "\n",
      "Sample 39:\n",
      "  Predicted length: 6, True length: 7\n",
      "  MSE: 0.056020, MAE: 0.210128, R²: -3.529845\n",
      "  Predicted lines: [0.4190508  0.74611515 0.82168484 0.8868663  0.97901744 1.009584  ]\n",
      "  True lines     : [0.871406 0.91659  0.964787 1.064193 1.130463 1.175647]\n",
      "\n",
      "Sample 40:\n",
      "  Predicted length: 9, True length: 2\n",
      "  MSE: 0.077352, MAE: 0.214823, R²: -186.299210\n",
      "  Predicted lines: [0.6316188 1.0255502]\n",
      "  True lines     : [1.023085 1.063729]\n",
      "\n",
      "Sample 41:\n",
      "  Predicted length: 6, True length: 3\n",
      "  MSE: 0.070669, MAE: 0.200892, R²: -45.967133\n",
      "  Predicted lines: [0.2872115  0.63895774 0.8333529 ]\n",
      "  True lines     : [0.722513 0.78789  0.814912]\n",
      "\n",
      "Sample 42:\n",
      "  Predicted length: 9, True length: 2\n",
      "  MSE: 0.031354, MAE: 0.166554, R²: -0.909997\n",
      "  Predicted lines: [0.9485917 1.0846056]\n",
      "  True lines     : [1.055028 1.311277]\n",
      "\n",
      "Sample 43:\n",
      "  Predicted length: 5, True length: 2\n",
      "  MSE: 0.000572, MAE: 0.023346, R²: -9.171161\n",
      "  Predicted lines: [0.9512151 1.0129049]\n",
      "  True lines     : [0.96937  0.984368]\n",
      "\n",
      "Sample 44:\n",
      "  Predicted length: 5, True length: 1\n",
      "  MSE: 0.000045, MAE: 0.006672, R²: nan\n",
      "  Predicted lines: [0.9796306]\n",
      "  True lines     : [0.986303]\n",
      "\n",
      "Sample 45:\n",
      "  Predicted length: 5, True length: 6\n",
      "  MSE: 0.006229, MAE: 0.050140, R²: -6.463762\n",
      "  Predicted lines: [0.64731205 0.84695315 0.8676925  0.90924263 0.92852384]\n",
      "  True lines     : [0.817034 0.8321   0.869184 0.880773 0.892362]\n",
      "\n",
      "Sample 46:\n",
      "  Predicted length: 7, True length: 2\n",
      "  MSE: 0.092903, MAE: 0.229575, R²: -314.110107\n",
      "  Predicted lines: [0.5472859 0.9826156]\n",
      "  True lines     : [0.977355 1.011696]\n",
      "\n",
      "Sample 47:\n",
      "  Predicted length: 8, True length: 1\n",
      "  MSE: 0.012146, MAE: 0.110210, R²: nan\n",
      "  Predicted lines: [0.8778638]\n",
      "  True lines     : [0.988074]\n",
      "\n",
      "Sample 48:\n",
      "  Predicted length: 4, True length: 3\n",
      "  MSE: 0.034440, MAE: 0.182846, R²: -3.414863\n",
      "  Predicted lines: [0.9224792 0.9688505 1.0626453]\n",
      "  True lines     : [1.086008 1.126277 1.290228]\n",
      "\n",
      "Sample 49:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.001749, MAE: 0.040228, R²: 0.442272\n",
      "  Predicted lines: [0.9063101  0.95783526 1.0183519 ]\n",
      "  True lines     : [0.93906  0.98939  1.074732]\n",
      "\n",
      "Sample 50:\n",
      "  Predicted length: 6, True length: 4\n",
      "  MSE: 0.001353, MAE: 0.030389, R²: -0.492962\n",
      "  Predicted lines: [1.0867106 1.1013635 1.1050804 1.1144724]\n",
      "  True lines     : [1.095245 1.117475 1.139705 1.176756]\n",
      "\n",
      "Sample 51:\n",
      "  Predicted length: 6, True length: 3\n",
      "  MSE: 0.191030, MAE: 0.297226, R²: -97.579773\n",
      "  Predicted lines: [0.13716577 0.8921861  0.91407734]\n",
      "  True lines     : [0.887439 0.953372 0.994296]\n",
      "\n",
      "Sample 52:\n",
      "  Predicted length: 6, True length: 5\n",
      "  MSE: 0.209053, MAE: 0.372419, R²: -297.678131\n",
      "  Predicted lines: [0.07972346 0.41298598 0.6128113  0.8446488  0.8521778 ]\n",
      "  True lines     : [0.89694  0.914011 0.930077 0.952168 0.971247]\n",
      "\n",
      "Sample 53:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.138503, MAE: 0.307684, R²: -263.531891\n",
      "  Predicted lines: [0.49636665 0.8435141  1.0602458 ]\n",
      "  True lines     : [1.077678 1.112349 1.133152]\n",
      "\n",
      "Sample 54:\n",
      "  Predicted length: 5, True length: 6\n",
      "  MSE: 0.000705, MAE: 0.023341, R²: 0.811102\n",
      "  Predicted lines: [0.85595053 0.8982655  0.98394096 1.0282933  1.0639366 ]\n",
      "  True lines     : [0.893688 0.936594 0.965531 1.012429 1.070302]\n",
      "\n",
      "Sample 55:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.171029, MAE: 0.346931, R²: -138.512543\n",
      "  Predicted lines: [0.39834473 0.49096587 0.97096056]\n",
      "  True lines     : [0.918542 0.982535 0.999988]\n",
      "\n",
      "Sample 56:\n",
      "  Predicted length: 9, True length: 2\n",
      "  MSE: 0.010205, MAE: 0.100402, R²: -1.698700\n",
      "  Predicted lines: [0.7920826  0.93742514]\n",
      "  True lines     : [0.903661 1.026651]\n",
      "\n",
      "Sample 57:\n",
      "  Predicted length: 5, True length: 1\n",
      "  MSE: 0.005452, MAE: 0.073835, R²: nan\n",
      "  Predicted lines: [1.0659395]\n",
      "  True lines     : [1.139775]\n",
      "\n",
      "Sample 58:\n",
      "  Predicted length: 4, True length: 6\n",
      "  MSE: 0.061011, MAE: 0.242043, R²: -5.791095\n",
      "  Predicted lines: [0.7191069 0.7904526 0.8082728 0.8666182]\n",
      "  True lines     : [0.931009 0.970484 1.07763  1.173498]\n",
      "\n",
      "Sample 59:\n",
      "  Predicted length: 12, True length: 2\n",
      "  MSE: 0.129196, MAE: 0.271086, R²: -253.544342\n",
      "  Predicted lines: [0.45087472 0.9679841 ]\n",
      "  True lines     : [0.957986 1.003044]\n",
      "\n",
      "Sample 60:\n",
      "  Predicted length: 7, True length: 2\n",
      "  MSE: 0.060609, MAE: 0.190410, R²: -1147.637573\n",
      "  Predicted lines: [0.5161866 0.8428228]\n",
      "  True lines     : [0.862651 0.877179]\n",
      "\n",
      "Sample 61:\n",
      "  Predicted length: 8, True length: 5\n",
      "  MSE: 0.220812, MAE: 0.391946, R²: -35.719540\n",
      "  Predicted lines: [0.0574288  0.66901517 0.8134234  0.81774634 0.8657628 ]\n",
      "  True lines     : [0.959335 0.980722 0.991784 1.086178 1.165086]\n",
      "\n",
      "Sample 62:\n",
      "  Predicted length: 4, True length: 2\n",
      "  MSE: 0.153229, MAE: 0.280466, R²: -502.844116\n",
      "  Predicted lines: [0.5291227 1.1101413]\n",
      "  True lines     : [1.082659 1.117537]\n",
      "\n",
      "Sample 63:\n",
      "  Predicted length: 6, True length: 3\n",
      "  MSE: 0.212956, MAE: 0.323241, R²: -77.543243\n",
      "  Predicted lines: [0.16467346 0.9240232  0.9513264 ]\n",
      "  True lines     : [0.95219  0.982825 1.074732]\n",
      "\n",
      "Sample 64:\n",
      "  Predicted length: 5, True length: 1\n",
      "  MSE: 0.000003, MAE: 0.001814, R²: nan\n",
      "  Predicted lines: [1.0127531]\n",
      "  True lines     : [1.010939]\n",
      "\n",
      "Sample 65:\n",
      "  Predicted length: 3, True length: 2\n",
      "  MSE: 0.001205, MAE: 0.033862, R²: -3.188929\n",
      "  Predicted lines: [0.94829136 0.9974253 ]\n",
      "  True lines     : [0.989763 1.023678]\n",
      "\n",
      "Sample 66:\n",
      "  Predicted length: 5, True length: 3\n",
      "  MSE: 0.002213, MAE: 0.046169, R²: -0.815307\n",
      "  Predicted lines: [0.8272278 0.8847613 0.8929092]\n",
      "  True lines     : [0.867813 0.923799 0.951792]\n",
      "\n",
      "Sample 67:\n",
      "  Predicted length: 5, True length: 4\n",
      "  MSE: 0.006611, MAE: 0.079715, R²: -8.384803\n",
      "  Predicted lines: [0.9912355 1.0281681 1.0314221 1.0342228]\n",
      "  True lines     : [1.067124 1.089427 1.107748 1.139609]\n",
      "\n",
      "Sample 68:\n",
      "  Predicted length: 4, True length: 1\n",
      "  MSE: 0.000839, MAE: 0.028962, R²: nan\n",
      "  Predicted lines: [1.0854061]\n",
      "  True lines     : [1.114368]\n",
      "\n",
      "Sample 69:\n",
      "  Predicted length: 4, True length: 3\n",
      "  MSE: 0.051195, MAE: 0.156804, R²: -19.738750\n",
      "  Predicted lines: [0.5093833 0.9382182 0.9716899]\n",
      "  True lines     : [0.896841 0.976513 1.01635 ]\n",
      "\n",
      "Sample 70:\n",
      "  Predicted length: 8, True length: 3\n",
      "  MSE: 0.016312, MAE: 0.097335, R²: -19.210499\n",
      "  Predicted lines: [0.74196094 0.9428348  0.99903   ]\n",
      "  True lines     : [0.955074 0.996552 1.024204]\n",
      "\n",
      "Sample 71:\n",
      "  Predicted length: 12, True length: 1\n",
      "  MSE: 0.000481, MAE: 0.021934, R²: nan\n",
      "  Predicted lines: [0.99478006]\n",
      "  True lines     : [1.016714]\n",
      "\n",
      "Sample 72:\n",
      "  Predicted length: 5, True length: 6\n",
      "  MSE: 0.002142, MAE: 0.040124, R²: 0.599975\n",
      "  Predicted lines: [0.8210401  0.907679   0.9716878  0.97596496 0.98492885]\n",
      "  True lines     : [0.790804 0.844171 0.900874 0.950906 0.995934]\n",
      "\n",
      "--- Global Scores ---\n",
      "Mean MSE: 0.067295\n",
      "Mean MAE: 0.159714\n",
      "Mean R²: -106.359581\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "# ---------------- Evaluation ---------------- #\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def evaluate_model(model, length_model, X_val, y_val, true_lengths, return_sequences=False):\n",
    "    \"\"\"\n",
    "    Evaluate multi-output regression with predicted sequence lengths.\n",
    "    Permutation-invariant: sorts both predictions and true values before computing metrics.\n",
    "    Can optionally return the predicted vs true sequences for inspection.\n",
    "    \"\"\"\n",
    "    y_pred_full = model.predict(X_val)\n",
    "    pred_lengths = np.round(length_model.predict(X_val)).astype(int)\n",
    "\n",
    "    print(\"\\n📊 Validation Report (Multi-Regression with variable-length sequences):\")\n",
    "    mse_list, mae_list, r2_list = [], [], []\n",
    "\n",
    "    pred_vs_true_list = []  # store predicted vs true sequences if needed\n",
    "    pred_lengths = np.round(length_model.predict(X_val)).astype(int).flatten()\n",
    "\n",
    "    for i, (pred, pred_len, true_y, true_len) in enumerate(zip(y_pred_full, pred_lengths, y_val, true_lengths)):\n",
    "        L = min(pred_len, int(true_len))   # true_len might still be an array of shape (1,)\n",
    "        if isinstance(L, np.ndarray):\n",
    "            L = int(L[0])\n",
    "        pred_trunc = np.sort(pred[:L])       # sort predictions for permutation-invariant metrics\n",
    "        true_trunc = np.sort(true_y[:L])     # sort true values\n",
    "\n",
    "        mse = mean_squared_error(true_trunc, pred_trunc)\n",
    "        mae = mean_absolute_error(true_trunc, pred_trunc)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            try:\n",
    "                r2 = r2_score(true_trunc, pred_trunc)\n",
    "            except ValueError:\n",
    "                r2 = np.nan\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  Predicted length: {pred_len}, True length: {true_len}\")\n",
    "        print(f\"  MSE: {mse:.6f}, MAE: {mae:.6f}, R²: {r2:.6f}\")\n",
    "        print(f\"  Predicted lines: {pred_trunc}\")\n",
    "        print(f\"  True lines     : {true_trunc}\")\n",
    "\n",
    "        if return_sequences:\n",
    "            pred_vs_true_list.append((pred_trunc, true_trunc))\n",
    "\n",
    "    print(\"\\n--- Global Scores ---\")\n",
    "    print(f\"Mean MSE: {np.mean(mse_list):.6f}\")\n",
    "    print(f\"Mean MAE: {np.mean(mae_list):.6f}\")\n",
    "    print(f\"Mean R²: {np.nanmean(r2_list):.6f}\")\n",
    "\n",
    "    results = {\"mse\": np.mean(mse_list), \"mae\": np.mean(mae_list), \"r2\": np.nanmean(r2_list)}\n",
    "    \n",
    "    if return_sequences:\n",
    "        results[\"pred_vs_true\"] = pred_vs_true_list\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=300,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    num_kernels = 100,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor with a linked sequence-length predictor.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.pkl\"\n",
    "    length_model_out = f\"{model_out_dir}/xgb_model_seq_len_{timestamp}.pkl\"\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        transformations={\"mode\": \"rocket\",\"num_kernels\": num_kernels},\n",
    "        per_window_flags=[\n",
    "            # False, \n",
    "          True, \n",
    "          True\n",
    "                ]\n",
    "    )\n",
    "    # --- Preprocess data ---\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, feature_columns, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[1,3],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= False\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, feature_columns, max_len_y, train_lengths= preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    # --- Train max-line regression ---\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "\n",
    "    model = MultiOutputRegressor(xgb_model, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Train length predictor ---\n",
    "    xgb_len_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "    xgb_len_model.fit(X_train, train_lengths)\n",
    "\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Save trained models\n",
    "        joblib.dump(model, model_out)\n",
    "        joblib.dump(xgb_len_model, length_model_out)\n",
    "        \n",
    "        # Save full metadata\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_columns,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"multioutput_wrapper\": {\n",
    "                \"class\": model.__class__.__name__,\n",
    "                \"module\": model.__class__.__module__,\n",
    "            }\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Length predictor saved to {length_model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        # Unpack val_lengths tuple\n",
    "        x_val_lengths, y_val_lengths = val_lengths\n",
    "\n",
    "        # Only pass true lengths; pred_lengths will be computed inside the function\n",
    "        metrics = evaluate_model(\n",
    "            model, xgb_len_model,\n",
    "            X_val, y_val,\n",
    "            true_lengths=y_val_lengths,   # pass only true label lengths\n",
    "            return_sequences=True\n",
    "        )\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        num_kernels = 300,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed65845",
   "metadata": {},
   "source": [
    "### XG boost 1 head ROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dacf956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG SAMPLE 1 ---\n",
      "Target (raw vector): [1.242173 0.      ]\n",
      "Transformed features shape: (2000,)\n",
      "First few features: [ 0.         -0.37254456  1.          0.70289725  1.          0.6279406\n",
      "  1.          0.2733393   0.         -0.30059353]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 3 ---\n",
      "Target (raw vector): [1.116909 0.      ]\n",
      "Transformed features shape: (2000,)\n",
      "First few features: [ 0.         -0.37254462  1.          0.70289725  1.          0.6279406\n",
      "  1.          0.27333942  0.         -0.30059353]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 5 ---\n",
      "Target (raw vector): [0.928181 0.      ]\n",
      "Transformed features shape: (2000,)\n",
      "First few features: [ 0.         -0.3725446   1.          0.7028973   1.          0.62794054\n",
      "  1.          0.27333936  0.         -0.30059353]\n",
      "------------------------------\n",
      "\n",
      "🚀 Starting model training with native XGBoost API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/xgboost/core.py:2291: FutureWarning: Since 2.1.0, the shape of the gradient and hessian is required to be (n_samples, n_targets) or (n_samples, n_classes).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.50845\tvalidation-rmse:0.50900\n",
      "[50]\ttrain-rmse:0.35144\tvalidation-rmse:0.45852\n",
      "[99]\ttrain-rmse:0.36148\tvalidation-rmse:0.47770\n",
      "✅ Model training complete.\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression -> MSE: 0.001449, MAE: 0.028639 [original units]\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Imports ----------------- #\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "\n",
    "# IMPORTANT: Ensure 'soft_assignment_xg_boost.py' contains the corrected, stable objective function\n",
    "from models.losses.soft_assignment_xg_boost import soft_assignment_loss_objective \n",
    "\n",
    "\n",
    "# ----------------- MODIFIED Evaluation Function ----------------- #\n",
    "def evaluate_model_xgb(model, X_val, y_val, pipeline=None, scale_labels=False):\n",
    "    \"\"\"\n",
    "    Evaluates a NATIVE XGBoost model using Hungarian matching.\n",
    "\n",
    "    Args:\n",
    "        model (xgb.Booster): The trained native XGBoost Booster object.\n",
    "        X_val (np.ndarray): The validation features.\n",
    "        y_val (np.ndarray): The validation labels with padded zeros.\n",
    "        pipeline (object, optional): The scikit-learn pipeline for inverse transformations.\n",
    "        scale_labels (bool, optional): Whether to inverse-transform the labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the computed MSE and MAE.\n",
    "    \"\"\"\n",
    "    # --- KEY CHANGE: Prediction with a native Booster model ---\n",
    "    # 1. Wrap validation data in a DMatrix\n",
    "    # 2. Predict using the booster object\n",
    "    # 3. Reshape the flat 1D output to a 2D array (n_samples, n_outputs)\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    y_pred_flat = model.predict(dval)\n",
    "    y_pred = y_pred_flat.reshape(y_val.shape) # Reshape to match label dimensions\n",
    "    \n",
    "    n_samples, n_preds = y_pred.shape\n",
    "    n_samples_val, n_labels = y_val.shape\n",
    "    \n",
    "    if n_samples != n_samples_val:\n",
    "        raise ValueError(\"Shape mismatch between predictions and true labels.\")\n",
    "\n",
    "    # --- Inverse-transform (remains the same) ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        # ... (This logic does not need to change) ...\n",
    "        pass\n",
    "\n",
    "    all_preds_matched = []\n",
    "    all_labels_matched = []\n",
    "\n",
    "    # --- Hungarian matching (remains the same) ---\n",
    "    for i in range(n_samples):\n",
    "        preds = y_pred[i, :]\n",
    "        true_labels = y_val[i, :]\n",
    "        gt_vals = true_labels[true_labels != 0]\n",
    "\n",
    "        if gt_vals.size == 0:\n",
    "            continue\n",
    "\n",
    "        cost = (preds[None, :] - gt_vals[:, None]) ** 2\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "        matched_preds = preds[col_ind]\n",
    "        matched_labels = gt_vals[row_ind]\n",
    "\n",
    "        all_preds_matched.extend(matched_preds.tolist())\n",
    "        all_labels_matched.extend(matched_labels.tolist())\n",
    "\n",
    "    all_preds_matched = np.array(all_preds_matched, dtype=np.float32)\n",
    "    all_labels_matched = np.array(all_labels_matched, dtype=np.float32)\n",
    "\n",
    "    mse = mean_squared_error(all_labels_matched, all_preds_matched)\n",
    "    mae = mean_absolute_error(all_labels_matched, all_preds_matched)\n",
    "    \n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression -> MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ----------------- MODIFIED Training Function ----------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=100,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    num_kernels=1000,\n",
    "    scale_label=False,\n",
    "    normalise=True,\n",
    "    alpha=1,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor using the native API.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.json\" # Save as .json\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Pipeline and Preprocessing (remains the same) ---\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        transformations={\"mode\": \"rocket\",\"num_kernels\": num_kernels},\n",
    "        per_window_flags=[False, False]\n",
    "    )\n",
    "\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, feature_columns, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[1, 3, 5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order=False,\n",
    "        )\n",
    "    else:\n",
    "        # ... (this part remains the same) ...\n",
    "        X_train, y_train, feature_columns, max_len_y, train_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    # --- KEY CHANGE: Prepare data and train using the Native XGBoost API ---\n",
    "    \n",
    "    # 1. Prepare DMatrix objects\n",
    "    y_train_flat = y_train.flatten()\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train_flat)\n",
    "    \n",
    "    eval_sets = [(dtrain, \"train\")]\n",
    "    if do_validation and X_val is not None and y_val is not None:\n",
    "        y_val_flat = y_val.flatten()\n",
    "        dval = xgb.DMatrix(X_val, label=y_val_flat)\n",
    "        eval_sets.append((dval, \"validation\"))\n",
    "\n",
    "    # 2. Define model parameters\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', # Placeholder, overridden by custom obj\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'seed': 42,\n",
    "        **model_params\n",
    "    }\n",
    "    # 🌟 KEY CHANGE: Use a lambda function to pass 'alpha' to the objective\n",
    "    custom_obj_wrapper = lambda y_pred, dtrain: soft_assignment_loss_objective(y_pred, dtrain, alpha)\n",
    "    # 3. Train using xgb.train (This replaces XGBRegressor, MultiOutputRegressor, and .fit())\n",
    "    print(\"\\n🚀 Starting model training with native XGBoost API...\")\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=n_estimators,\n",
    "        evals=eval_sets,\n",
    "        obj=custom_obj_wrapper, # Using the custom objective\n",
    "        verbose_eval=50\n",
    "    )\n",
    "    print(\"✅ Model training complete.\")\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # KEY CHANGE: Use the native model saving method\n",
    "        model.save_model(model_out)\n",
    "        \n",
    "        # Save metadata (removed the obsolete MultiOutputRegressor part)\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_columns,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        # Pass the native booster 'model' to the updated evaluation function\n",
    "        val_metrics = evaluate_model_xgb(model, X_val, y_val, scale_labels=scale_label)\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/middle_test.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        alpha=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae647727",
   "metadata": {},
   "source": [
    "### XG boost 1 head flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3022b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG SAMPLE 1 ---\n",
      "Target (raw vector): [1.242173 0.      ]\n",
      "Transformed features shape: (20,)\n",
      "First few features: [0.46631768 0.47056738 0.4124729  0.44219747 0.4422956  0.46763\n",
      " 0.43146002 0.44432855 0.4430182  0.44442698]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 3 ---\n",
      "Target (raw vector): [1.116909 0.      ]\n",
      "Transformed features shape: (20,)\n",
      "First few features: [0.36918545 0.37109894 0.32488    0.3359558  0.33570933 0.34213638\n",
      " 0.3183168  0.3375175  0.3375175  0.33915505]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 5 ---\n",
      "Target (raw vector): [0.928181 0.      ]\n",
      "Transformed features shape: (20,)\n",
      "First few features: [0.22773202 0.25852573 0.1968973  0.25111386 0.2512084  0.27814978\n",
      " 0.23463589 0.24937002 0.24937002 0.2717272 ]\n",
      "------------------------------\n",
      "\n",
      "🚀 Starting model training with native XGBoost API...\n",
      "[0]\ttrain-rmse:0.50816\tvalidation-rmse:0.50974\n",
      "[50]\ttrain-rmse:0.34766\tvalidation-rmse:0.44702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/xgboost/core.py:2291: FutureWarning: Since 2.1.0, the shape of the gradient and hessian is required to be (n_samples, n_targets) or (n_samples, n_classes).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99]\ttrain-rmse:0.35800\tvalidation-rmse:0.46435\n",
      "✅ Model training complete.\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression -> MSE: 0.005349, MAE: 0.051518 [original units]\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Imports ----------------- #\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "\n",
    "# IMPORTANT: Ensure 'soft_assignment_xg_boost.py' contains the corrected, stable objective function\n",
    "from models.losses.soft_assignment_xg_boost import soft_assignment_loss_objective \n",
    "\n",
    "\n",
    "# ----------------- MODIFIED Evaluation Function ----------------- #\n",
    "def evaluate_model_xgb(model, X_val, y_val, pipeline=None, scale_labels=False):\n",
    "    \"\"\"\n",
    "    Evaluates a NATIVE XGBoost model using Hungarian matching.\n",
    "\n",
    "    Args:\n",
    "        model (xgb.Booster): The trained native XGBoost Booster object.\n",
    "        X_val (np.ndarray): The validation features.\n",
    "        y_val (np.ndarray): The validation labels with padded zeros.\n",
    "        pipeline (object, optional): The scikit-learn pipeline for inverse transformations.\n",
    "        scale_labels (bool, optional): Whether to inverse-transform the labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the computed MSE and MAE.\n",
    "    \"\"\"\n",
    "    # --- KEY CHANGE: Prediction with a native Booster model ---\n",
    "    # 1. Wrap validation data in a DMatrix\n",
    "    # 2. Predict using the booster object\n",
    "    # 3. Reshape the flat 1D output to a 2D array (n_samples, n_outputs)\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    y_pred_flat = model.predict(dval)\n",
    "    y_pred = y_pred_flat.reshape(y_val.shape) # Reshape to match label dimensions\n",
    "    \n",
    "    n_samples, n_preds = y_pred.shape\n",
    "    n_samples_val, n_labels = y_val.shape\n",
    "    \n",
    "    if n_samples != n_samples_val:\n",
    "        raise ValueError(\"Shape mismatch between predictions and true labels.\")\n",
    "\n",
    "    # --- Inverse-transform (remains the same) ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        # ... (This logic does not need to change) ...\n",
    "        pass\n",
    "\n",
    "    all_preds_matched = []\n",
    "    all_labels_matched = []\n",
    "\n",
    "    # --- Hungarian matching (remains the same) ---\n",
    "    for i in range(n_samples):\n",
    "        preds = y_pred[i, :]\n",
    "        true_labels = y_val[i, :]\n",
    "        gt_vals = true_labels[true_labels != 0]\n",
    "\n",
    "        if gt_vals.size == 0:\n",
    "            continue\n",
    "\n",
    "        cost = (preds[None, :] - gt_vals[:, None]) ** 2\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "        matched_preds = preds[col_ind]\n",
    "        matched_labels = gt_vals[row_ind]\n",
    "\n",
    "        all_preds_matched.extend(matched_preds.tolist())\n",
    "        all_labels_matched.extend(matched_labels.tolist())\n",
    "\n",
    "    all_preds_matched = np.array(all_preds_matched, dtype=np.float32)\n",
    "    all_labels_matched = np.array(all_labels_matched, dtype=np.float32)\n",
    "\n",
    "    mse = mean_squared_error(all_labels_matched, all_preds_matched)\n",
    "    mae = mean_absolute_error(all_labels_matched, all_preds_matched)\n",
    "    \n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression -> MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ----------------- MODIFIED Training Function ----------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=100,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    num_kernels=1000,\n",
    "    scale_label=False,\n",
    "    normalise=True,\n",
    "    alpha=1,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor using the native API.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.json\" # Save as .json\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Pipeline and Preprocessing (remains the same) ---\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        transformations={\"mode\": \"flatten\"},\n",
    "        per_window_flags=[False, False]\n",
    "    )\n",
    "\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, feature_columns, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[1, 3, 5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order=False,\n",
    "        )\n",
    "    else:\n",
    "        # ... (this part remains the same) ...\n",
    "        X_train, y_train, feature_columns, max_len_y, train_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    # --- KEY CHANGE: Prepare data and train using the Native XGBoost API ---\n",
    "    \n",
    "    # 1. Prepare DMatrix objects\n",
    "    y_train_flat = y_train.flatten()\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train_flat)\n",
    "    \n",
    "    eval_sets = [(dtrain, \"train\")]\n",
    "    if do_validation and X_val is not None and y_val is not None:\n",
    "        y_val_flat = y_val.flatten()\n",
    "        dval = xgb.DMatrix(X_val, label=y_val_flat)\n",
    "        eval_sets.append((dval, \"validation\"))\n",
    "\n",
    "    # 2. Define model parameters\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', # Placeholder, overridden by custom obj\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'seed': 42,\n",
    "        **model_params\n",
    "    }\n",
    "    # 🌟 KEY CHANGE: Use a lambda function to pass 'alpha' to the objective\n",
    "    custom_obj_wrapper = lambda y_pred, dtrain: soft_assignment_loss_objective(y_pred, dtrain, alpha)\n",
    "    # 3. Train using xgb.train (This replaces XGBRegressor, MultiOutputRegressor, and .fit())\n",
    "    print(\"\\n🚀 Starting model training with native XGBoost API...\")\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=n_estimators,\n",
    "        evals=eval_sets,\n",
    "        obj=custom_obj_wrapper, # Using the custom objective\n",
    "        verbose_eval=50\n",
    "    )\n",
    "    print(\"✅ Model training complete.\")\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # KEY CHANGE: Use the native model saving method\n",
    "        model.save_model(model_out)\n",
    "        \n",
    "        # Save metadata (removed the obsolete MultiOutputRegressor part)\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_columns,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        # Pass the native booster 'model' to the updated evaluation function\n",
    "        val_metrics = evaluate_model_xgb(model, X_val, y_val, scale_labels=scale_label)\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/middle_test.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        alpha=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f33da1",
   "metadata": {},
   "source": [
    "### XG boost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7f1acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG SAMPLE 0 ---\n",
      "Target (raw vector): [1.126277]\n",
      "Transformed features shape: (12,)\n",
      "First few features: [1.1256732  1.1708027  1.0583339  1.0877135  1.087789   1.1296856\n",
      " 0.99188215 1.1260169  1.1285027  1.1306691 ]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 1 ---\n",
      "Target (raw vector): [1.242173]\n",
      "Transformed features shape: (12,)\n",
      "First few features: [1.3036697 1.3155504 1.1531377 1.2362376 1.236512  1.3073386 1.2062193\n",
      " 1.2421954 1.2385321 1.2424706]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 3 ---\n",
      "Target (raw vector): [1.114845]\n",
      "Transformed features shape: (12,)\n",
      "First few features: [1.2195877 1.2259089 1.0732266 1.109815  1.1090008 1.1302322 1.0515453\n",
      " 1.114974  1.114974  1.1203835]\n",
      "------------------------------\n",
      "\n",
      "--- DEBUG SAMPLE 5 ---\n",
      "Target (raw vector): [1.120154]\n",
      "Transformed features shape: (12,)\n",
      "First few features: [1.147258  1.1587839 1.0902464 1.099486  1.099486  1.143701  1.0899644\n",
      " 1.1211767 1.1211767 1.1248015]\n",
      "------------------------------\n",
      "\n",
      "🚀 Starting model training with native XGBoost API...\n",
      "[0]\ttrain-rmse:0.08672\tvalidation-rmse:0.04017\n",
      "[50]\ttrain-rmse:0.03546\tvalidation-rmse:0.01425\n",
      "[100]\ttrain-rmse:0.01529\tvalidation-rmse:0.01256\n",
      "[150]\ttrain-rmse:0.00748\tvalidation-rmse:0.01250\n",
      "[200]\ttrain-rmse:0.00344\tvalidation-rmse:0.01246\n",
      "[250]\ttrain-rmse:0.00164\tvalidation-rmse:0.01237\n",
      "[300]\ttrain-rmse:0.00080\tvalidation-rmse:0.01235\n",
      "[350]\ttrain-rmse:0.00048\tvalidation-rmse:0.01234\n",
      "[400]\ttrain-rmse:0.00038\tvalidation-rmse:0.01234\n",
      "[450]\ttrain-rmse:0.00037\tvalidation-rmse:0.01234\n",
      "[500]\ttrain-rmse:0.00036\tvalidation-rmse:0.01236\n",
      "[550]\ttrain-rmse:0.00036\tvalidation-rmse:0.01235\n",
      "[600]\ttrain-rmse:0.00035\tvalidation-rmse:0.01235\n",
      "[650]\ttrain-rmse:0.00035\tvalidation-rmse:0.01235\n",
      "[700]\ttrain-rmse:0.00035\tvalidation-rmse:0.01234\n",
      "[750]\ttrain-rmse:0.00035\tvalidation-rmse:0.01234\n",
      "[800]\ttrain-rmse:0.00034\tvalidation-rmse:0.01234\n",
      "[850]\ttrain-rmse:0.00034\tvalidation-rmse:0.01233\n",
      "[900]\ttrain-rmse:0.00034\tvalidation-rmse:0.01234\n",
      "[950]\ttrain-rmse:0.00034\tvalidation-rmse:0.01234\n",
      "[999]\ttrain-rmse:0.00034\tvalidation-rmse:0.01234\n",
      "✅ Model training complete.\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression -> MSE: 0.000152, MAE: 0.006291 [original units]\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Imports ----------------- #\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "\n",
    "# IMPORTANT: Ensure 'soft_assignment_xg_boost.py' contains the corrected, stable objective function\n",
    "from models.losses.soft_assignment_xg_boost import soft_assignment_loss_objective \n",
    "\n",
    "\n",
    "# ----------------- MODIFIED Evaluation Function ----------------- #\n",
    "def evaluate_model_xgb(model, X_val, y_val, pipeline=None, scale_labels=False):\n",
    "    \"\"\"\n",
    "    Evaluates a NATIVE XGBoost model using Hungarian matching.\n",
    "\n",
    "    Args:\n",
    "        model (xgb.Booster): The trained native XGBoost Booster object.\n",
    "        X_val (np.ndarray): The validation features.\n",
    "        y_val (np.ndarray): The validation labels with padded zeros.\n",
    "        pipeline (object, optional): The scikit-learn pipeline for inverse transformations.\n",
    "        scale_labels (bool, optional): Whether to inverse-transform the labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the computed MSE and MAE.\n",
    "    \"\"\"\n",
    "    # --- KEY CHANGE: Prediction with a native Booster model ---\n",
    "    # 1. Wrap validation data in a DMatrix\n",
    "    # 2. Predict using the booster object\n",
    "    # 3. Reshape the flat 1D output to a 2D array (n_samples, n_outputs)\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    y_pred_flat = model.predict(dval)\n",
    "    y_pred = y_pred_flat.reshape(y_val.shape) # Reshape to match label dimensions\n",
    "    \n",
    "    n_samples, n_preds = y_pred.shape\n",
    "    n_samples_val, n_labels = y_val.shape\n",
    "    \n",
    "    if n_samples != n_samples_val:\n",
    "        raise ValueError(\"Shape mismatch between predictions and true labels.\")\n",
    "\n",
    "    # --- Inverse-transform (remains the same) ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        # ... (This logic does not need to change) ...\n",
    "        pass\n",
    "\n",
    "    all_preds_matched = []\n",
    "    all_labels_matched = []\n",
    "\n",
    "    # --- Hungarian matching (remains the same) ---\n",
    "    for i in range(n_samples):\n",
    "        preds = y_pred[i, :]\n",
    "        true_labels = y_val[i, :]\n",
    "        gt_vals = true_labels[true_labels != 0]\n",
    "\n",
    "        if gt_vals.size == 0:\n",
    "            continue\n",
    "\n",
    "        cost = (preds[None, :] - gt_vals[:, None]) ** 2\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "        matched_preds = preds[col_ind]\n",
    "        matched_labels = gt_vals[row_ind]\n",
    "\n",
    "        all_preds_matched.extend(matched_preds.tolist())\n",
    "        all_labels_matched.extend(matched_labels.tolist())\n",
    "\n",
    "    all_preds_matched = np.array(all_preds_matched, dtype=np.float32)\n",
    "    all_labels_matched = np.array(all_labels_matched, dtype=np.float32)\n",
    "\n",
    "    mse = mean_squared_error(all_labels_matched, all_preds_matched)\n",
    "    mae = mean_absolute_error(all_labels_matched, all_preds_matched)\n",
    "    \n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression -> MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=100,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    num_kernels=1000,\n",
    "    scale_label=False,\n",
    "    normalise=True,\n",
    "    alpha=1,\n",
    "    transformation = \"flatten\",\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a single-output XGBoost regressor using the native API.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_single_reg_{timestamp}.json\" # Save as .json\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_single_reg_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Pipeline and Preprocessing (remains the same) ---\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_label_normalized_candles),\n",
    "            # make_step(add_candle_shape_features),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        transformations={\"mode\": transformation},\n",
    "        per_window_flags=[True, \n",
    "                        # True,\n",
    "                        True]\n",
    "    )\n",
    "\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, feature_columns, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[0, 1, 3, 5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order=False,\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, feature_columns, max_len_y, train_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    # --- Prepare data and train using the Native XGBoost API ---\n",
    "    \n",
    "    # y_train_flat = y_train.flatten()\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    eval_sets = [(dtrain, \"train\")]\n",
    "    if do_validation and X_val is not None and y_val is not None:\n",
    "        y_val_flat = y_val.flatten()\n",
    "        dval = xgb.DMatrix(X_val, label=y_val_flat)\n",
    "        eval_sets.append((dval, \"validation\"))\n",
    "\n",
    "    # Define model parameters for regression task\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', # Using simple regression loss\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'seed': 42,\n",
    "        **model_params\n",
    "    }\n",
    "\n",
    "    # 3. Train using xgb.train (This replaces XGBRegressor, MultiOutputRegressor, and .fit())\n",
    "    print(\"\\n🚀 Starting model training with native XGBoost API...\")\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=n_estimators,\n",
    "        evals=eval_sets,\n",
    "        verbose_eval=50\n",
    "    )\n",
    "    print(\"✅ Model training complete.\")\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Use the native model saving method\n",
    "        model.save_model(model_out)\n",
    "        \n",
    "        # Save metadata\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_columns,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        # Pass the native booster 'model' to the updated evaluation function\n",
    "        val_metrics = evaluate_model_xgb(model, X_val, y_val, scale_labels=scale_label)\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        n_estimators=1000,\n",
    "        max_depth=16,\n",
    "        learning_rate=0.04,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        transformation = \"flatten\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ba18e",
   "metadata": {},
   "source": [
    "### Hungarian test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b0b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=3). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | activation_fn | ELU     | 0      | train\n",
      "1 | flatten       | Flatten | 0      | train\n",
      "2 | fc1           | Linear  | 130    | train\n",
      "3 | relu          | ReLU    | 0      | train\n",
      "4 | fc2           | Linear  | 11     | train\n",
      "--------------------------------------------------\n",
      "141       Trainable params\n",
      "0         Non-trainable params\n",
      "141       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.126277 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.126277]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.1256732  1.1708027  1.0583339  1.0877135 ]\n",
      " [1.087789   1.1296856  0.99188215 1.1260169 ]\n",
      " [1.1285027  1.1306691  0.8611065  1.        ]]\n",
      "[candle_shape] Shape: (3, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.04009115 0.02701042 0.03372177 0.3       ]\n",
      " [0.00325818 0.0881668  0.03394962 0.7       ]\n",
      " [0.00191968 0.13889347 0.11387014 0.3       ]]\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.242173 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.242173]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.3036697 1.3155504 1.1531377 1.2362376]\n",
      " [1.236512  1.3073386 1.2062193 1.2421954]\n",
      " [1.2385321 1.2424706 0.8288991 1.       ]]\n",
      "[candle_shape] Shape: (3, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.0091133  0.06722008 0.05172484 0.3       ]\n",
      " [0.05244192 0.02449848 0.00457536 0.7       ]\n",
      " [0.00318    0.17110091 0.19259259 0.3       ]]\n",
      "\n",
      "--- Sequence 2 ---\n",
      "Label: [1.000672 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.000672]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.2315305  1.2354467  0.8242132  0.99434686]\n",
      " [0.99434596 1.0655923  0.8244814  1.0024467 ]\n",
      " [1.0009688  1.0836393  0.9519576  1.        ]]\n",
      "[candle_shape] Shape: (3, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.00318    0.17110091 0.19259259 0.3       ]\n",
      " [0.06299147 0.17083043 0.00808096 0.7       ]\n",
      " [0.08259035 0.04804246 0.00096787 0.3       ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop'], 'candle_shape': ['upper_shadow', 'lower_shadow', 'body', 'color']} max_y 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c0ce349a7248a4a1284c68dfafb89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4daeea57ddc942eaad3d7b3168024346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfa60692e1345f5ab171cf5cdadc089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e704bdeac7814760ad9997126b47b46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190f42c48d914e7496948dbdff8953b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dfa94a90024301995c77ce85cd66c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d15f28de1ad4091b55535b02f26a60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2d2352f0ec4bf288b7165b150e1526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b574cfe6fab44d5bbd953cffe33eeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102f0d4495dc4cffaa4e2bf72f65d709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389177235de94a1284f15e60da5c5d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49e4cc8c2924d6c98486e45255f98a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1ea3db01264e7c852cb3870d034f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcdf6e863954c7c8ed6284850739453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d186462674797a0a3850ece8ca0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daee26d89ec44f6b9d905ef244db9c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7fade83a3a4374bafe8bfca2bb70dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ea0a6f480b47fb80fd53513148f805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb347a0bde041758ce8e563013b6cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16a03423348469d8345098f0ef29988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3ee94f0d7542a1a9de3a78f71c7727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6c61c6d1e64554ac37924be726d4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5706de9ce8e44c49ef6db79aaa7a4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54078246b6c248d4a85dd6c60ccbb147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b24cacdcda4d4d8524c1ab331b4986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618f997a88654794a7b8225d8609cfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23317c29138a4498bcc55eaff2471cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6d2511b023445491a7a21a95378d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00355734ff3d4e4a858fe1baaf968cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b6559f2e8847d3a1dbf1628da55fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e1454a7ea44c4ba9b68ed824de4e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb274eb9c334f17a385a9ab750c980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eca5f7282847008df6e4d82c6a8600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a1b27429de40d6a95205dea52340e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a037d1a19fb453babdac602194c6c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0168649b184c5aa2edc0f3b0487aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df4f3f6e0d74ea2972a303b29d6520b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647b31733c474960ba069f5519894457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9110fc7de74a33be9c961e846d5267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a601ed3069c48cfa1f49f7ea4932790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c86739e4ae43beb48380306eddedbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e1c554fc8d4b0a938b9d793f4513ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9622d0d4c05d4eabb88e9a91242e0a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6402a802d52f4ad1b6b79b4dd8b4c6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0b455f71514f2289cf0981c3ee3105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a543e9c6c894d4b8f67062caf2b4047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9076e6873f9a49808a1070fb85d91bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d5c4f0ce644981bae4bc8702225da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c46fad6e7ed4c2f84cb0a7bbb283962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae08bac007b4305b798bc824d1393db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b51937cb6504a8a9b144782fbc9c5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262e06b4787c4d0dbfb4ebdf6015431c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068b1afdee1d4f5badf496702684bfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdb216b5db342c397745a5121177d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0503b60f2344f69ee7e5604eb16819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2447167dcabc483ab2d4ccf8b05ae383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e21b5cdd73c4539a6d5f5d0e5f37529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badbd05e788940209aaa88a83b50eb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15819bc90d546cba77c8a54af77f81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c43aced246f4ccca8a6d8b473f52de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4324e154ef491ba707b6c7b81f7d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a2abdf5d134ae88a35db823e487b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360a05cfecd14513ac2290726a1d134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b816588abfc54611bf767302f72c3ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6478973decd4efd9a5e04ce6e3bcb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273b1a08e4d4419ca2fd386bf425a231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4569e141ae47470fadd6e47f6a8fc519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de89f9a7ed28485392732c87ea32d241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6765de2760b4687b6beb30683ca824f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bc726c13584a2ca97cda0dd7d5eb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c99b0ad47647b3b59c59c9d0b183ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01254d4c7e14060882c8a2176fdd564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff54af537d3c4d0d88cf337961d51807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba41eb3ef6244879b9bc6b10f1f00e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd8fb5ec62b43ec8d9b6afd0b9a9f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd7a6a9b0334206bf34d37f9f15f698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6505d10e70ec419eac7ff534c2566987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665c0c056d1b4c1ca10d680527f32560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025f0eed07984d968d57ab61e2a01b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0085de6784904c04a9f08213be214a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f71812e610f4aae902328d603e72db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c833cf6cb5914d449ab6030ac93b3dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9173626dca4834a9ca54de3648760d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494c8bf577c34cafa494a0168ff76714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1c35da074f41efa43412d33e83308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f44edf19a684d58837e4454ee4d3e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de312e658a3a47cbaddaa7dc50234668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cac4cb968748ddbbfd426000176e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf31f91c3864ec79be7447466fb1b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a5cf324ee14a5ab04e09af8302128f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973865dd3aa24842820431ec03a28187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7109c3d94826404e844f375e79ad5ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230a102b526c4b3ca89b276d5502c5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70db4925dda4d49b013b5001d97b1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffea28a166b448849f617623f5cf0e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43736b83e58341529180112dff5fe6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352a5f4833a9440e9c86137a0dcb585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0715191e8e894bebb4abba49c04bd837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3e19b6fd54455fbc73c13936922bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17655670c19747b98edd8befae597ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b405b6e8b3e4b7ca6eff8e541dbca51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c53965eb1d4b42b33197281058b0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddb9e0a59b642479b4e24b0dc92afdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c9badd5f8047f1898bb85f44c254bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901f811257924beface472c3918f0033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1804dc7774448d3ba8be263a9f4205a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bab34912fb545e8ad39b396392c658f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4412b89336465e9ee57e4adc3497ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c038c9e53b4a12b51da5b66c80b6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994916d69d0944a3bfdf66e54995da82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec5c6751c5f42e6bdb57f9191c9f598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bf2d15d0dc4fb792f5f1a544bde477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28318500d40471e870d4f7a55792a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf0ac6985044b7ca960d461f8ecfd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92c8591fd9f45b6a296bfd571963530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b95d879fe04903b0a82d36b598b7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d533dbf75a245ecb04e6bd386096a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926d0e9bf37b42d68d3c00aced850383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22871cc49215427282a72a2219a654bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be51f94d21b34e63908660f504ca91dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122661e581ea4f7ea4b4d0f333f4b80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5facbf79a24248e6a30836d25005114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba4f55f9ada4014b0cb5121ca7e161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d553c3f44b42ff991e28301af42643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937439357044b73accb8869df255714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6bfd02679d4068af8af40a879537ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018e46597e774cc8ad34e2e9bfdd0e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4a9a90da124596bc5f6ce82c9150bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7d9204ebeb432ba6eae9fe8de347f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4c5bfc7ea048a49642cfde69f01e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd24af1689aa47348084cf8ee8d005f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da50a25d8d9448c39839f93529456d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8efe9be5f140ddb28621f299714d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d1e63d363c4b11878cc8700989746b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c036f15b4046e286868606d9361f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b4ec8753544593bae16a91b6f06cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0ffe65d66e4e93b91a83514ef7877a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cda9d882114693a8245a67b44fb16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b687d0fdad0a4efd97b58bbdf6b0f8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9694a87cd9a14d3ea3339eee78cadad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2dd436650b4f9694f7c76bff344892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba2c5d0dd704ffb99b7e5d093100972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f5a70c826f486bb928e6e214a38008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab32494fe774bacb8a5619a53c300f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bd5d2bce284234ac50630a9a0f2132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f4280714084d93b62c5d2478bce781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc68e29d9db40399250903b63597db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e8a43ad90449b29922aa833da177c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8632036c574248c9ac23c82ee37c2588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a7af29ff7e4ce6a04a32bef982eb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89284f03182480d991d07b83f7845f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a5da21e7f84dca87c8fa5c113c7ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c4c4be4102483ab90bd3f3539d05ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7306c2e094634823b647c74932deef5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842860deee094b38b05958e4bdc55299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41538ae04f614914ba618d5bbd16e0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a839cf3dd65b40ca9e82fbac70be1037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e50422bff54e9ab47c10313d8344e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07510b065d6c4186a530fe1e416d9dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338f2694b7d84f0681b0aae1e6aa494e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ee0250e8294cf6889e306cdaaf56ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbb9bfa4c7d4fef8adebe23fcb7f3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6847a49777c4b2d8845c4adda3df2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72f8549cd5544188ea2f31f1fe52300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc61445150494380b298f442d3a8ab43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecfd3cb686e48a6ae8637b44f62dd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccb165555ae4836a3a91186da693aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16127522918f4ab5ab8afb027e7d72c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a8d12ab80847758c1fc04ed6797adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a9a84cc0364a1a910ff656dbd582fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647dcf5d853a4e1cb7d34a347185644c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078e5187d07f4a71843a460f17b51967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47122006f76b4b5ba015ce52ad84fc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1804b986f4794550b821512d9ea18c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0928f356f77a4fd0b8768a64584afec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ff0e539fc14f85b122347b7a5a3af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f38d80f363648f3944b47bca638cfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faac7266c2641389c01c5a03c193934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bc3e5501f64ad2b654699809642940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123ae9ad52bb4d01971693682d4851e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11f2dc770f04ed7b50090a083392d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ba3b3b7dd146208c17734b651836ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5ea15411104d059621da1f7159b2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a0cf2e15254cec856bced2fca73d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b863fc3e3f6a4bfd9f0dfa285047b5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef146f79cfc4c18bab9c1639a500f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7688af7bcd4659997d09ac1988b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1650a6add554008be8083df594eecbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65dd514f0804865a1f42082c30dfa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7f99a07b654e0c8e1484e6ea885083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2059da0de86b43c0af447c68486dc841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be90d9b19e00429da597e9af2046fe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7a505e2281419f89e883abd3111ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4ad45a4bc043988b1120f40a9d868f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad169f1ce2042328e69b24f1050ae50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6390119785494208a893cea16b6644f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc384d2b50734e4cbdb4c5c2a26e5a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027f71da84b14dab8d5640df7fb44dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec40bbb437d483aac0057d181065227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8eccab227049f78a93ade12ac1aef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa302afe61ba47fa8fcc4ec38f01fada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c968ec3f4dd4a1ba51700a3aee7f8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deac31e3dafa41e4a2463f631575a328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11c823baf4a41f386a842158347dabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1863ce69f740bdbf7a79ec9545b472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e409e5cba6844e79776cb3a2e6ae0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0214e4243f5b4ead9fe351d4a493a303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01abf86451624fd3b72a1d1ea6ec0502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c00197ef9a14a4faef975bbcdc2509f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca31a28c43a47b08507216bb1083c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd34e0e23a6f4dd792b110c0637c3fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533f16da9086408e8e3f49a0f9fe2f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5f18801fdb4d63896ebc57de522763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71df1e51514450f8c2fbfa11fcbcc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26c0b270e424183b71b1d1969e6360f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aecb0f67858449d97fdc793b9893df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d38e490871448a86243d81dc20c09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff867117163448186b1d3e4bdf86e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b429ba2a36b4456f8e38ee560d1c1109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80149adb28744ae97ecd57fe2971d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5781ede44d34536939b03779901255c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c595b0acd242588ac757e1f6fcffcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b72d7eefc7485f805c19698ab11fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650a15708be845b7932bd602c192fd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b28c247ad0e4e0a9dc6061c1f061b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8a49e37b77467699183ce9b91d0d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38250a6391aa420ea0df0d05a42369da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c35ae63200f4fdeb9434fc6e7b2abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6db5d67df3f4569a822e1922523a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633366baddbe41fdabfad8ba3497a8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85aa2d137319412881a3efbe2eb0ab44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cb865e0a9842a3a7aa41a8e1a50848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c95147d1ca4a82a6f5c305d86fe970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c6a5fef7844e85af43c434d7825fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b65e2f9551341f3bb9c5dc632ac194a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef2eae58d644062930639e1f2b3e678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0afe5f26cc42288d6a811753de2ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27d4a3d14f44f6abf6f08772a600117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97175bed1fbe4d6c97e5a50b5922ec96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6817f31d6ab5450784dadd7d61177a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7c5912a8824bb591d11cfd31276261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830a7639b6804daa9243a7916e885fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2027f9883fe43bb88b56d65a3a5c8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705c3951ef964d359d3590461f31e2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283bd665b1174062b9dd5f7efd22991c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366476c6b5204f76884c362a5fdaa89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fccfa39d16491ea9bbc6d91762d131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3715ab9dc5e7479a9574016f93706e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235be9e41f3a4ac1bed17f4976365546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3535caee47b466596c018fd57cad6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091e7ca5d90d495e9f92e611e94535dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d671928eaea449f99ea7802d1f3e018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2fbda04205450d94aa5eaeb0e6c9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b32c042b334ca1be71be510b6aed13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19ea357cbc44b329b27c91e00444f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4671ada82d104e87a177de22fdd7a1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab3d229397d46babe6d53ae9280f260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c825f6576d40439ad6b47b2eda3144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5093e6bf42c45ccbefc321423b086a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f49c6690c73480ebc407102f1f7f7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fae1a846244244a1eebb690af3b612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a7018607414985b261495f4900501b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc885c670cb46c5bc07c7448bfb5c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4418aef98a894724baddca1e7c5f008b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd7c9dc7b6a4c35aecac65e2ba1c442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b253dbc63f3490e9289dabcc16835d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6363a2a91b44029eb752046b6d5838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e13a3fa5deb49ab9ee2402018aed4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b674f0bcd5049bfb87f80d4a08e42c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1a6fe85b364195a71ba6977f7ef985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ead9ceacffd4374a444fac769b8c50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6c6f04f5334e8f9914f95b5da8e2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469463c66f2241dc9c226e2699cf7231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e234451c8342478e852564d89484752c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252a17ddb2694ddcbb26a28e4d87e697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac1969655eb43fea1c53166ee4c59d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474417e1d0904a43aea14efe8cd248e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03af8257cce45d6b437dc4f2b010ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744e41de4e3741799c9a0d5107cdda2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3207f1d3d6f34813bb1eba5c360e5059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8907f703635a43fea72da3e67fae0a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73f93a906224084adf8bd4f79859821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da5bc85528c490b9f5ad25a2d9dc5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f77af5e911949e9a20ebb6ded38c91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c38b56928f487882585fc823896952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9597168ffa8a4f038d23c37f097c6fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268f07320e5f4c9884c15608a228a95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00d5627cc5647c0bd3b731b4f9d8412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e49884774d7428cb24ad038787a2148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f037737c8d54d499a1231f7a770aefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452fe7b1bfb74a6c9410a9f0d08631eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bf0641dcf14bd2b57e378ac2fe4ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b1c3f5aaec4bc3a349eb61110bd479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa05a3acea6c4784b256422be085480a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e6191796c247da93e4e7242a52d232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44677fb07424645acf63bde2f2b6450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f4580879b044fca4c7377117f7c84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b016fec89484a19a955c425da1190e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0125e96123d54f93b6dfeeead48a20ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23448fb5f5cd437cb46d75ff59481349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b453146b3ec436bbb0a119a965c6477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233fa9f4189f4ba686ebd407d8e00587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : VanillaFNN\n",
      "  init_args:\n",
      "    input_dim: {'main': 4, 'candle_shape': 4}\n",
      "    hidden_dim: 10\n",
      "    max_len_y: 1\n",
      "    lr: 0.001\n",
      "    optimizer_name: adamw\n",
      "    scheduler_name: onecycle\n",
      "    optimizer_params: {}\n",
      "    scheduler_params: {}\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.000149, MAE: 0.008817 [original units]\n"
     ]
    }
   ],
   "source": [
    "import dill  \n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif4 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline6 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from add_ons.after_burner.universal_scaler import universal_scaler\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "    scaler = None\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None:\n",
    "        scaler = pipeline.target_scaler\n",
    "        # 1️⃣ Prefer universal_scaler from afterburners\n",
    "    if hasattr(pipeline, \"afterburner_info\") and \"universal_scaler\" in pipeline.afterburner_info:\n",
    "        scaler = pipeline.afterburner_info[\"universal_scaler\"]\n",
    "    # 3️⃣ Apply inverse transform if scaler found\n",
    "    if scaler is not None:\n",
    "        try:\n",
    "            all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "            all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Warning: Could not inverse-transform labels: {e}\")\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 5} ,\n",
    "    activation_function = \"relu\",\n",
    "    scale_labels = False,\n",
    "    use_mse_loss = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features, seperatable = \"complete\", dict_name = \"candle_shape\"),\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "\n",
    "        # afterburner_steps = [\n",
    "        #     make_step(universal_scaler, feature_columns=[\"open_prop\", \"high_prop\", \"low_prop\",\"close_prop\"], label_columns=None),\n",
    "        #     # You can add more afterburners here\n",
    "        # ],\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/fnn_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/fnn_multireg_multihead_{timestamp}.pkl\"\n",
    "    pipeline_out = f\"{model_out_dir}/feature_pipeline_{timestamp}.pkl\"\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[0,1,2],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns,\"max_y\", max_len_y)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "\n",
    "    model = VanillaFNN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=max_len_y,\n",
    "        lr=lr,\n",
    "        optimizer_name= optimizer_name,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params ,\n",
    "        use_mse_loss = use_mse_loss,\n",
    "        activation_function = activation_function\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "        # 3. Save entire FeaturePipeline object\n",
    "        try:\n",
    "            joblib.dump(pipeline, pipeline_out)\n",
    "            print(f\"✅ Full FeaturePipeline saved to {pipeline_out}\")\n",
    "        except Exception as e:\n",
    "            # Fallback to dill if joblib can't serialize some parts\n",
    "            pipeline_out = pipeline_out.replace(\".pkl\", \".dill\")\n",
    "            with open(pipeline_out, \"wb\") as f:\n",
    "                dill.dump(pipeline, f)\n",
    "            print(f\"⚠️ joblib failed, saved pipeline with dill instead → {pipeline_out}\")\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=300,\n",
    "        hidden_dim=10,\n",
    "        lr=0.001,\n",
    "        batch_size=50,\n",
    "        optimizer_name= \"adamw\",\n",
    "        scheduler_name = \"onecycle\",\n",
    "        optimizer_params={},\n",
    "        scheduler_params={},\n",
    "        save_model= False,\n",
    "        use_mse_loss = False,\n",
    "        activation_function = \"elu\" #\"leaky_relu\" \"sigmoid\" \"tanh\"  \"elu\" \"relu\" \"swish\" \"mish\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e330df",
   "metadata": {},
   "source": [
    "### Hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377d5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [0.       1.05529  0.923251 0.828937 0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.05529  0.923251 0.828937 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[0.44984102 0.45347178 0.41840607 0.43908027]\n",
      " [0.43915114 0.50778055 0.423001   0.4815808 ]\n",
      " [0.48206943 0.50233537 0.4643487  0.48960105]\n",
      " [0.48960105 0.501431   0.45673665 0.49419633]\n",
      " [0.49419695 0.5636583  0.47911596 0.55657494]\n",
      " [0.55657494 0.56257176 0.52542645 0.560165  ]\n",
      " [0.560165   0.5611551  0.5122603  0.52998203]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[0.48206943 0.50233537 0.4643487  0.48960105]\n",
      " [0.48960105 0.501431   0.45673665 0.49419633]\n",
      " [0.49419695 0.5636583  0.47911596 0.55657494]\n",
      " [0.55657494 0.56257176 0.52542645 0.560165  ]\n",
      " [0.560165   0.5611551  0.5122603  0.52998203]\n",
      " [0.5322404  0.53563523 0.42044067 0.4890442 ]\n",
      " [0.4890442  0.50865054 0.4597889  0.47255275]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (6, 4)\n",
      "[main] First few rows:\n",
      " [[0.55657494 0.56257176 0.52542645 0.560165  ]\n",
      " [0.560165   0.5611551  0.5122603  0.52998203]\n",
      " [0.5322404  0.53563523 0.42044067 0.4890442 ]\n",
      " [0.4890442  0.50865054 0.4597889  0.47255275]\n",
      " [0.47258556 0.4907874  0.4309192  0.48919347]\n",
      " [0.49027348 0.49121463 0.37410426 0.43444598]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "input dim {'main': 4}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SimpleLSTMMultiRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 337\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 177\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, early_stop, optimizer_name, first_drop, scheduler_name, optimizer_params, scheduler_params, scale_labels)\u001b[0m\n\u001b[1;32m    175\u001b[0m         input_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]}\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput dim\u001b[39m\u001b[38;5;124m\"\u001b[39m,input_dim)\n\u001b[0;32m--> 177\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleLSTMMultiRegressor\u001b[49m(\n\u001b[1;32m    178\u001b[0m         input_dim\u001b[38;5;241m=\u001b[39minput_dim,\n\u001b[1;32m    179\u001b[0m         hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m    180\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[1;32m    181\u001b[0m         max_len_y\u001b[38;5;241m=\u001b[39mmax_len_y,\n\u001b[1;32m    182\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    183\u001b[0m         optimizer_name\u001b[38;5;241m=\u001b[39m optimizer_name,\n\u001b[1;32m    184\u001b[0m         first_drop \u001b[38;5;241m=\u001b[39m first_drop,\n\u001b[1;32m    185\u001b[0m         scheduler_name \u001b[38;5;241m=\u001b[39m scheduler_name,\n\u001b[1;32m    186\u001b[0m         optimizer_params\u001b[38;5;241m=\u001b[39m optimizer_params,\n\u001b[1;32m    187\u001b[0m         scheduler_params\u001b[38;5;241m=\u001b[39m scheduler_params \n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m     init_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_dim,\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler_params\u001b[39m\u001b[38;5;124m\"\u001b[39m:scheduler_params\n\u001b[1;32m    200\u001b[0m }\n\u001b[1;32m    202\u001b[0m     model_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m ,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m ,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_args\n\u001b[1;32m    206\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SimpleLSTMMultiRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = SimpleLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=100\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc4d35",
   "metadata": {},
   "source": [
    "### Hungarian lstm attnetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afec20b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name        | Type          | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | loss_fn_reg | MSELoss       | 0      | train\n",
      "1 | lstm        | LSTM          | 15.8 K | train\n",
      "2 | attention   | TanhAttention | 3.7 K  | train\n",
      "3 | regressor   | Sequential    | 1.9 K  | train\n",
      "------------------------------------------------------\n",
      "21.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.4 K    Total params\n",
      "0.086     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.242173 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.242173]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.3036697 1.3155504 1.1531377 1.2362376]\n",
      " [1.236512  1.3073386 1.2062193 1.2421954]\n",
      " [1.2385321 1.2424706 0.8288991 1.       ]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.114845 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.114845]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.2195877 1.2259089 1.0732266 1.109815 ]\n",
      " [1.1090008 1.1302322 1.0515453 1.114974 ]\n",
      " [1.114974  1.1203835 0.9486662 1.       ]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.120154 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.120154]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.147258   1.1587839  1.0902464  1.099486  ]\n",
      " [1.099486   1.143701   1.0899644  1.1211767 ]\n",
      " [1.1211767  1.1248015  0.97898066 1.        ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "input dim {'main': 4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f89c7a08834524ad0ad679a68b6674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=3). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194f568d0db6498bb4743ba812c5827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7315dfd0de95434c9cf0dcb2404c292c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295f1cf68868499d8e4a77379cf8fbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af1bb18ea0b47088321ae21eb7061ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539995fc708e407f98ec88db39ecabcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3752f4e0e804284ad496176db60a015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4988a394351c4695b057df7445ea3c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9101546eb809460a8108f98902202625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95faa0ae540487393d6584055e5a6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee7cc070cf643d382c73297452d147c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208e32eff6c345c49141d0dcf5c7a9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1d7b013dd547ad9f4d9553aeac875f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21e1a4df5cb4de591c42dd49b19fdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed55bb40f0ae42f9b040733b6f6f927b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b7fa6011384dc8bbc6b00ff2a17819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427d281bb55e495e97fdc0a167441a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4480c81c65e43748ad761ab89e73e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2c8c3a77e5403cba70a680117eb8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fdf837c0eb4a16b1262ffec2effc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac3bbf2cd6e474ebb0ba67ce0e6ef42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4780318817d4bbe90c1326685541cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfe74fb48e243baa950d8ce1e6e52e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a67dbdf278453eaa0c53dd6c07b1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4fb50aa35a4793b8ee43c41259406b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cac44ffa774bad8faa0060dd63f6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7adcdb2afc74ecf80cf6420f239d4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8359d01c7fa84b94a5ce0c1c18b4ce75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e43059c2d4468f8c462dc9b10423a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd158de63c5a4a8fad7b4b0629f72e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b96f31e04c540529c4b4185d271d192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340031f4350242bf84bb97656f5b73a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b16155af8eb4180bf4a4c2ea7a065c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451e2f0df825485f8c33f94324aa34cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a48c83e1fe545deb2bb475b6685d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dfc8f6f92c45f0a5f3aeb53c0a2bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bac2816e2e04abda9476138c964defc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8220e07fd9f40a980b24d711180d9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5751ceb4989b4f7095a4d9cd140ff64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c017bc7c425471abb483286ab290daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a544993dfca4f56b3801c6d9d8e820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c643805332754a8abbd34aaf2fcc59a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de96fa80fd624369b17313f851d55d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422c5c0e4a7a474ba3cf7ebd68f8c071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e54833fce6746b6b005df15c4221a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9e56e98de44a68847a8a1421611867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64813e3d40be417699fe68e4ee298ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35025dd1bdf04afeab28f0c6ebe962a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c289f46463c4f1f9e7e50258af3d394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da24b23e537649f69cc85167b739aee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efebf184b9e1451ab946174b80657149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c81ffa1a9046bb831b787f17c4484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03324672ace4e1bacca24e04354e13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50182433be564ad1b0f0f32dc0e5308b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637898abdabe48599787ffa1f4811095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37119eb376cc4c03ad0c35d9310ebebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd978d9a7faf47ef95b0cc71d56aee76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceaa527305d41d0bc6dc3d19b057b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28808af233ca4083a958f6bf322d9c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f1e24687034822a163088e7e65b50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9650d5cd3f2941d584dc6307612655e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d825acc556e47298b5be17173f208e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d6c8f740284da1bbaecf1cfb80594d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091d98d9957544dc954a064327bd2bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77302dd469214cd0b7af83a8799c7160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a794f292c2534ab39bea48fec34a532e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1590dbcf92a493bacca88a9507124e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73312c4bfa89477c8186f3e683c0c9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ca4ebaf636423eb12add17fb22909e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1231b17400a44fdc8eb8bc48461ebbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be56ce996dea4fdeb5cdf14dba4300b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e45fd59517646e0b7b10562fc284459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcade123f525420590a1698f465b0e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9e809b72744354be36be41b88bc45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5a07f1ef0545209b5d1992e63d22f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b234743f70c4bc2a1c20984a29c71aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d947ead711a34d8fa541ca26f97088ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fa8ae5a8d94e098d3410b2314c0b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2f4660779b4180b3b2024ad6abb547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd41fdad9fc485a8b997dd9e78f584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecca152bc9d841908d3824cf19944499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9a88fb2ebe476c962be044af69d515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbedf4a932c43ab9584c6810d2bb0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a3541558684ec3916596c94d4bd4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1985704e32184f139e669e43dec652dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996dda5f77ac432ab7aa372d3226329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137deaadf81f4704a3020d7d3193e1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976571987bdc4e429f5d1ceb0965b8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d16289d1a6456391471271ce7c82a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3c115046654a72856500370b9d428a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af38ed4178304ddcbfb1c1eef0ea8cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93351c7e2e3455c8af6ea290563c123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2771598aef474e4b9f9c5526188cd041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc9d47263084d18a1c704431667d307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af982dd3b0245b7827f97975aa0f3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab60725d23b141dcaf680d5d3e1a5f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8d262d1464483ea191534e4209f16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998f076f955544af8ac48ab1f5229121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e6cafba64341fdb5ad5ae501e84898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0543d3353e4a5e9d6975335c011098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b991a7085b440edbd4f5d3394ff9742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c350b11e167245bfa6eff29b13d3acb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368a13d092fb402cb41281f19bcfcdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2a83a90cb9411a8505f3b308a8f93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6a27c9d9ba469787a4b6a21a1cf081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d001907112e44cfaa5e9ea7ab648f239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d86a07ead414ed69bfd3fe161c4e115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1389ec835a04616a98a7f64ed7632f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613e607497f941a0ad5e470a7d39f15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340fc9dd13714f1f864b8bcf2e80a2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb575e0b73b94d759bbb21fc81ec9959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321ecdfade50437cbdfb8fa124fc5f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53a0e4eca854b5bbd39603eb3b943b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7e45d1e53456ea6215b134bf1b36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc071c8b8f8248e18fb2e5994a5cc010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8796ee37bf8e4e0f881720e33b377f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4242a7b266a74255a418d0da50b41f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0614ba1f55848b4a88f55776a9460aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7f8a807c5447f3b994cef550cfaaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90794fad9f14c1ba441da21ab689341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31169193d844d3799fb0e16b33790d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b755f0964c4bf08bc1393e4b7f508f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564491918a8f43eca15a699bbcff8224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2522b49c956643458cea7e8bc47dc703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fa1dc876b34d4d833a740df8c16622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac83af797e9432da3a14a7fa2d6c2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee6f267d8e342af8e07782dcb8ddd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c705d0b4eb2e4d8c8cd79a19411eaba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cef3512d8cd47caafaff77030c726f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab0ad9d4a294370a6f6e0cd55bf6cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18209b3b4e994520b65f850bdbda917f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d655098c814fe0adb8a138945b18eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3d651062d448369410ada8235f4c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7501d4dcef954b9d855dc3155df3a1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6088c0025855406486a44412798efd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a087041cf7894b65b3b662e02ee08e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce42c38aa98f4aecb7d3b141dd52a7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8f7666e343463394fa647e3b96e1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1278480882c7400f913059fa12b263d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a11e81681749edbc3af8d9f76482ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd793b224e240cfb56a573f08402201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a7e8f4e9d54375b857f343b4367b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0914fd7e624d53912582657423414c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd2556b5b894cd492371ffa8a4e8af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d1e40ca4ec464cac21c021ca05ac9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01677051a63b49c3ad4aa89862c3fb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42a0ee3ad384c3daa9814af673d3f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e77848952db4490a1904a8e59925c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2be26932c843dbb379b64552f639ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1276b24d15e04ce9a9189d5746ab1f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924de1a96bbb480f9ced21eb5fbdb524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02076564d774ee287caaa2a6a8b8dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d05ba52a7c4076b60d830535159f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b65e1f33a44d42b986260769415b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c439ce7a2cc944d7989f497500c8bc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0c5c04fa5a4e67b4afb889d247c290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5db0f1e844645b3b21b85602cd6425a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8c8af3b72e47479b8dad67f901082d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ef2b2fc9934812af5de82faf39ea39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cca5f9ab3d4dbabc28a4d5ab227a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb7d46d0a14280bd258fc3eb5b901c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceb6d02fbcd4d3b85e06908b030633e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e9ae032bc84ff0a3efae8f29360025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5fe58b664a421881f81cc076d022ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba8faad657e4a2f9a4bf76b91471ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaa715cd8cf4c658d12f59a2e977d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9e2a365f274c5281721d81b08989f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dae13487c74581a185085fadc2395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717de9e4703d42d0aaf446fc202275fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa8d014248546f5977314e4b4c65f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c32e7f1c32a4f319e4b55d7d8aa610a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa3af364ef74097b2bc03c86ec147f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57ee86724414986a6e14cb2fb8ef552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3679d8d5cc1041259577a14d8232e695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171579b2c01c4eabad93e6c8ff3fc716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c17d1489b549d9b3f68589d8df9b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96682171de134cbda96bd91136b0dc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cb537419424933b14179feb89db27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad6ae43a8754032a5dffaae4ada8ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119ba2abe0574a6980551bd34ed50547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a75f9d7684d4fb99c4d2cda8184d9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee4c45c57ee48e3a53d8dfb40ce9381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaf7a704d3646f1be011f9be55829a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7893301614dd43bab6f55591c21ca0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579e977c0fc04728b35346a06625dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d152e0d917f34913bb072aa0c6e20564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317a16f22d1145318c56bfaea0b4c541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174a8884a90a403ca2bd3818cc947699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce664723c0bc4041bee1d07eb163c0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579db7c7389e4cedba26af42268cf62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4443c654db246b19b05f28d90f96c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e8d5d824714de0b36680a55bd4c0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee4ec5ab76d463da039cb0b5c83bbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ff774175fe434bb8d9c63f4bb4a95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5955f06542343199b3add7456bf7e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f73169bfde4f8d88d8efa98fbe48aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2ffd2ad1d248e3a68e8aeaf4a05dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1e4fe274d24b1aa35c6d0170b852a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a0090775ad4afa9300d8733fd5470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65193f55a0964fbfab9c283ccc4bebcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce575aad94442d68b7304f52422b462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa7b025ff19425b8b1405410cae6b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381bf12a38d04ab28e5cb22726f3394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763e56bcbcdb4eee96a0ec78fac1e314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ba2f271ffa4eca8fe996d2a756fb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceba99f583cf42c69266a96d72a4f6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e02fcd1c3b424d947d42b6b3ee51b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5b88c332894ffabee6084f187feb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f443b37a5d4e23b0325accf31e5f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac2d2cd5ebb4a18a600c75fca1bb7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450b1816def24ebeb5261ecc7e38e31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775062e585984729ac1ba549526551aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6245a747cc4edf9f2d50a34bb21d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85888232d333479e9aea876eb8cb495c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a22ab122b049faafa777724dc893b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca37b7570884ee299c8ee954b310d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19b8ba4817f46aeaada30ceab557147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9484df7d56e48c3a40888c1f8bdbb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2621ab14daec405bbde705996162feb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13770cfba0aa4b7abbd8fb48c0bad041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6cdb1bcb564cffb11b9dd26de97e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b13700104234059bbcbe0c838b523dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b60a7beb8d46d589da4854d9cdefd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5498d191fd5544fda053c02bbf8b300c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e579f11c0349e1992c46b4ff95e6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407096bb3a934c07af597fa83bb61008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6647e659ed4a77920780f379dd1b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf69a4ebf8d493191ccc9dba035662e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f3c4bede7b47ed8f00b26f3050f563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624580dde0794215a9900314e95d2865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b84619c67249269242dab5f0dcaf4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37f0394fe7644f892c2dce3eb42c9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a7f267af0d4225a065b5c36a3acf6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413783d57c714f63af7f3df012a7d0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6637b5b7a47d477a96c370a0d4a98894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6976aa5cde3f44dcb54ef0a09f7b3265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f54a37fe06f4ecdbe8f17892dd00520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa8101b967d45a2b2de604d0c8fcda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c79eaadfcf43a789f7a1651a5f5666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667d2ee256234f1a8505883884cdb3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62db084616b84b53b70497a0efa748f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a58d1d25e564f61ab28bfd5255bd133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f117ee253b34326a4ccf6184489a511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99379f753ad9438bae845979473cf716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7371584bb84f40e4b0c8e3608b0e4f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3340bd869d3f4066917db6a36f23612d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a517878eea64cfcaebe31af4f29a1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b29dac2dc64128bd053dfd9f6d12d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ae687b052f4c658ca85193d207422e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea00ae5333e94546ab36842aa8fd14c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ec8bf2fa3f42d199e20a4ed0610d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab4d09349bf4408be197b73be571246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e686802c32841309f329f45521e3e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c331abcc7134eb68b3a780659cc12a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4ff8b757424984b2ae99094b6a971b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fdbfa706474fde9445eb4ac164c738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd19178885df4c778a8b28b15d1602ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885b08f36f6f473f832a0e87b6cbc79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df163fc9acca4ce2aa7e24414bc0b832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f39856859b1481e8a1498e6a754878c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5a36a9329a4226b8ce8c3d04cf2352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21796e2c508c4ede8b283c785e930bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8aed20217c41a8b51bcf68c6f981c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acd1e6deef947baa786054c8c93d0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8d08b07e5045dd9807b6f767b2bda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b32216f62a4b84b9e31098fe2f13e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9590ac6f7c374e78a43265c35279b82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da2199aec7943d7b9ec60e798e6b6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47969f67907048a7a095cdbbd1ee6c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f11549b371c4315a535c445d55e7f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84a05646078435e8b67d69953be5bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e54278460824148856f7f1dc5097892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4ddd059d9f4f82a76977a6d5ac998d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3ebf77e4ad40c0979a7ff40a858ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c5ce2ef32a4c04bed5715698058402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343762cb0cb8458b9bb0679153b65102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3687ec2f1e74dabb2f4ebbf433b4e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90885681479e449dbf729e34e3242243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9072e79dc4e4fbc97b498e3a61c65e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a3922838604ba49db52717e1a868f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969b1ddf49bb4540915d3769f407d42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f18c430c84e79a17214c61e54a557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2819d36c3f50451da7f5ce5f36094777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f0dfb3c14446539871706f42f6f3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d404d95c1f74b029383b9f423b461ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfc9dfcd0824d7088dc9b130d7d9863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b150e206454ee584adc79ea825879d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de311688191c489a812fe0e900c49735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf6abca2c1341ae88e0579d6af5ad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ab94474d9e482abc80c4623f005ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6f1c1baca74404a2d788d22f33c89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d716afba3c754663a01ecf8f08857c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45eff661bd14bf2952d7941dd11e2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa744a17f1c44a69f7cf41ed71ffe1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cdefc14e0d4ca191ce06642ef70c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd62b42a7e244d41afbcd966961a6782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994a2828487e4b4794c2babdc0072ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99f9d487c3b45d0b79e73b508958f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5aa74cd048f4314b09a425a7b2ff927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848908d9cc914f189578b80d94f336b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcba974fc3e4c8ba4bdf27c4323e4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d92328d088a41b4b4c431b8f340ee76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591c920ed570433b9dd7b0e71db6c906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8218aa9c857b4a2b9a6234ad3760b964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb66a0cd7fd4d2bbd71d5ee39cb044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec98dd9ea0ea4e9eaa0c666e8211910f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781d551cbb4d4df38b8bf63f188667d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e709bf9def0e4b038ab86c9697b4d55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed0cfb6e2b5419ba8537cb00847ff2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a0592e52b64c02a00710b6018b9e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e48305590c54b5884ad14dea866e872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d8c5dbb7df4dc3ba9a8295528f9a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4489d54a28dc4f089692720efe84b196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dada54b58d4c92af2d97a0afa1d001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb594493d46b4ac8b932e5f5b554d810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4ba80f60c54b5698fcd24e15fc2ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e68c8e54216431cbbb1e1c315203a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c198d89e85c4ba1b2f4c7b24f45f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33490bc82b884574b2bce40a6709699b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9f21f50c19408b9a5347339a60feae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fac1e879495475c92ea66798a3c30ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef133ddde1434fca8dda32e38d38e5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd500b77123d46a3a239fbe3b68f316e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c43ee65a26c466ea9f2fb114d3332bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56051306e25a4dc78818757e8751d1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f06cdf7bf934a24af84aa8f71a60eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa56eeeed71249ca9587a82d3037a9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d021d9646235460b8a1416c06292b722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996ed42c1063439cad2cd9ce0b678606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5f36e9039b42988e6fb2ddbeed7589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3483d7f0c704a7683961ead92c141bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8a37c5155a4ff092b22d4a33268a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107f49d4adbd4dcc919e8a04c8c2762c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b19151f69f4409d904ed938e9c0ff20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb474bcf1adb4cdea73474214ccf92ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c453a7c4b73847fc803c00005c85d0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7961f00425c04adda4e3ef4c757f9b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd1cf44b8364104b1e4d77d3d6c101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9ca2cd9046457780b9ca2022770b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8a52a88bb64172b286ac71b4da284a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02db34656f3148d4a31d7896fb1371d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a954cac74a4e4e8588073c3bc81f5c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99349e862b4d4f2eb57301de7dc5455d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbc81fbccd44e32a72eabc7134321d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5494f488b35b4ecdbaf53dcd439f04da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db5261fb32a41a88672a838612deda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8f1dc396e945ffb3cd4e8dc3ccb3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411561d8f30a48f7b980fe740dc1173f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16eef20e97d34659b0e77e41b2b206ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d21df55b2434a4a9f6b45c2f5ca17dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9157f876859a413ca9d57c74e4d58dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2a93956b5942c2a38a56f7fe1c98c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d0799dc8e7406a9f1748f52409f2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7124dd501514adbadab9975e2754f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d35f7aeda174bcd9a3467b5f2e4b7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1b9fd548d0480f9f765465490e4b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df5d746a8ed4ea1a1622081940bc211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13047de020dd469aadd698a00988cbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083e5d93aab8497290afc759bb4cc937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1d216db55a49ad9996a120d16fad02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb5544cd9634bf2bef34fba26629956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69651c25d1448588a6b6fe4fa9818ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6e0927d81a49df9b3992235f9bc4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c41521334b41cfb2923b5ad1859437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a3ce9f98624ff6a37002a8aec20b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86080273c7b4d58a4a29abca0e138f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e22ad89c55483891692e5bc9d6379f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d748ef738743cc9e3c9d8e01840f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7127898da89445d8841758ea8bd6ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467bff0be0ad436e88c7d5fc378bf01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c148af59dbef48068f05bed2649c474c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc6a511ed40478f9e926095c890bad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c318682d8f5487eb27b7e917c27c447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88283f9ffa6041c6807f34520df7ad79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f066d6a36b4dbfa552cc1b4d7a0169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a82df0be89489fa3895a36d5eb275d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1889011e82524b53a24eefcd3dfb1e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83c0c0f928c4ecc8726bbf1025bdff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19232a8b943a4f9c9125cad006f3663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e903f05da84f33b540c9e6252a4f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc39ad07c91a482baa59f60384abcaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45f38b5ca624c2a9d17cb860466c990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdbefd15d9a4f2bad8ed1552960dddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879df5f755f7452d88a985786f92728f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56a1be5325a42039142f18a2fc0c073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cd78df2d0c403c8a08fb6b00740121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e4a61b50d14fa49dc7c4dcc79686ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efae557702d4958b608ab3c6d847dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df2a6ebe6c64c48a177683e2ab50c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99078eb3794a42fca60ce1140ef90f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fef5b29c6c4b02a81ce6d9983993c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953936ead8314f1dadcb0e53db473145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a03e5da12d44f9b4bb75cdf72db12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c889ff0b61416da6fe1ba687df91db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e8fcc3e9a04593b7c59169eecc29ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10abc40bec824637871f04fc25297c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32453801b09c4f06a601df3e3df770d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3085378a6a49549bc70509101a3744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de6fece6f0c407ead0fae3bbcb67020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074cc2775f0442f798bc78fe626a4114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37359eb72e6948c390ca677a49fe6263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8d6ac7cc834405bceabd2a613b9482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31830909da740589abe8b0b60df5fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39cd9bcfeb047a9afe05aa7d5cc845c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4417e6d69db14167970b3a4ef22e90bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2206876248e54e6fabf6e159f91bb396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3862ccb1e88f4066a5804d5a1931a60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9486bf619d438f96334190bc0763be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ed402a0ba749aaa89b29187cb4bacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d77febd60874abe9b2fa6f97a1218dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a40a5d036ed44b39883860f93d10370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e95c59843241dbb3b80d9c0e1416d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc271cabaad4011be56bc2f27c6c31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d9cdcd63ff4f3ba23f5e3cdf1931f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5e832aea1c47a896267e6326b9a28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af580393114d4aed9c7f59fad344b4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7601f671fb4063b629ea1da7335980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4471ae145184f66984b641e3416f3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9370ed0dc24b12a0b0caf0ae65de7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecc966295e947ea9a39e126b925941d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2ebed11ed0454380812af41a525b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d2f1d82cee4e65a2c49b266fa5da75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5df023c4fb4b1185b0ac4830b50171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d522fb420ff4b08b7252762f23779fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efa00e96d5d4464a42f31a23634e1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed959bb2919e41cfab73f808467229cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597ab4c9c20343b7a229810aa8e6b6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c634e953779f4df6a7b7ca0b63068087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a3851307d545eaa7f2b0a339dfda38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17eac9a8797b4d3b801271b4f0dcf60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca14f3782e5b4285997ab7f4bbd61b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efe150cbc5243d1bfb24ab9a18be81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2fbf2d3dcd4bc3b1f5fb68401eb214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca88022f4c5540af9a31ea622121d766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59981c13e3e94cef950c6d8f45e2d940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f6a884bae74176bf48241de2c1a0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a026e70b4bda41f8afdd0ce64483209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62f2e56d61e4eb988a0cdcf04716a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7a1fb15370407da9b07ca97970caeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c21f8a8c694aa887637ad4d431fd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e990115edf3d43aca386356a836e96dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb5527da14c429b8974e6315ce690e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38abe8f1630945ada73dc84433fc3ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d550fa7c8941f380f2953e4e826510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f38c7f10f84f20a91802412425e0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b966ad9bcda40dc99bcbfec0e5de4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1ba93f993a409da2531db5f373a256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0116c25c503941d4b490290c9ceee2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d511932d17144edebd4fe29ce69c19e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad2eed01a044aa5bc72b1b83b77406e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310e5094a73447bca9571f469de906c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7535bdce3b4d4190cb2ad77cbb05a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7a5711ff2c433e9a18d62c22216650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce01f93fa9f44fa1b2668e6bf2ced453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3db9a3169fb4f4dae8cd62734e68c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902d70ba32b64738ab991f6820368db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b4b6fe2dda4decb2239b0d5d0f3e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8839791b162f415ca2ef57a75bc07c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ff7b93c1764cf9a3ca3dadac530a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5452c540dd464f179ccb12ca07c60b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b9a2da136847b3a01c1b82eede670a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569d2ff13ae0430b825a2e5d11321e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091421c00bb7419f84bbf36d84fc3087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73898001a34d4148abfd1759aac709d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0732cc4e0044d9ac4986f23df4d55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e21781955d4d2384cd6aea4db41c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101fccc518524a63b7023a14e2819bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b2333a0d694538901722dd38429e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c37e73b5944f3687d7fa4062666df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d70d31fd146495bacb7b2e95277f09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d34e209da3f4e8e8080d00f0134600e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea492d3eb9e44d8e8c5184e6bd93fc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1d38e4a4a546199d40bed1eddb9d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21032e2bcf06422690c550668807702b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e385d1b1b1784207a618929146155842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab785cc1e4e4761b06c86d8c7c05118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df423576f8a04d99b926a74c8cf3aa85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c1b94b6e234c73822c4820848ca1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60f21d737af474e84b8a16aa0af5376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2d465d0933491d8d0df5aa424904ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cd1b2079a04ef9a18956542232414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd56aff4433a4a0a8487bde7df69c8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f6b3b7a11a405fb90f9190e495e60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d242f8620b24c8fa5ca765b529b1115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9e38d297604af5a8447f785349d21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d7540fe1404f1bb5a1beade8f5600c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdc83b784ef41c0bd70e6adc6f809e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad19a09878e4bb19737fb7c8adb46db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc3f3e6dc514d3da0fd3efbd037ac32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e9fd4b01e444b795418034cfdf5052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c94784cde3c4fb8946ed2548f899b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7010a2558d742dda47be56629e301d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970a49a7c3a0422db19b19249691e11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3831bb41c3f7445388be6eb23ef90a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1898e2435c934e31b4d39de605ac401d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4bef4a786f4ad78ebbb3c3c56055eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e743e9eede8406989f6a368725b78ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6c999064cf4c5283ee2e209d821da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7c63e3b76e40eab0fec52dc9f478a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed67a5180b1417c98e6a8ef478fdd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22e696ab3d741318ee97fccbcf18f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0373ed8fefa24fb784b1f5fd5837c95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : AttentionLSTMMultiRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 4}\n",
      "    hidden_dim: 60\n",
      "    num_layers: 1\n",
      "    max_len_y: 1\n",
      "    lr: 0.0001\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    first_drop: 0.3\n",
      "    scheduler_name: reduce_on_plateau\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "    scheduler_params: {'factor': 0.2, 'patience': 3}\n",
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20251004_142751.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20251004_142751.pkl\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.000344, MAE: 0.014369 [original units]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    attention_name = \"tanh_attention\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        # False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = AttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        attention_name = attention_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"attention_name\": attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=500\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8d4ec",
   "metadata": {},
   "source": [
    "### Hungarian CNN-attention lstm weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1000a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.126277 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.126277]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.1256732  1.1708027  1.0583339  1.0877135 ]\n",
      " [1.087789   1.1296856  0.99188215 1.1260169 ]\n",
      " [1.1285027  1.1306691  0.8611065  1.        ]]\n",
      "[candle_shape] Shape: (3, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.04009115 0.02701042 0.03372177 0.3       ]\n",
      " [0.00325818 0.0881668  0.03394962 0.7       ]\n",
      " [0.00191968 0.13889347 0.11387014 0.3       ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop'], 'candle_shape': ['upper_shadow', 'lower_shadow', 'body', 'color']} max_y 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss_fn_reg   | MSELoss       | 0      | train\n",
      "1 | attention     | TanhAttention | 3.7 K  | train\n",
      "2 | branches      | ModuleList    | 3.7 K  | train\n",
      "3 | fusion_conv2d | Sequential    | 1.3 K  | train\n",
      "4 | lstm          | LSTM          | 18.2 K | train\n",
      "5 | regressor     | Sequential    | 1.9 K  | train\n",
      "--------------------------------------------------------\n",
      "28.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.8 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e346c2e4c50c4f6596d6dbfb81969ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e21932253e64ebdb09907fb6e484462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main', 'candle_shape']\n",
      "  y_batch shape: torch.Size([50, 1])\n",
      "  First label in batch: tensor([1.0067])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([50, 3, 4])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[1.0115, 1.0159, 1.0004, 1.0049],\n",
      "        [1.0049, 1.0089, 0.9908, 1.0063],\n",
      "        [1.0063, 1.0086, 0.9960, 1.0000]])\n",
      "\n",
      "Feature group: candle_shape\n",
      "  X_batch shape: torch.Size([50, 3, 4])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[0.0044, 0.0045, 0.0065, 0.3000],\n",
      "        [0.0026, 0.0140, 0.0014, 0.7000],\n",
      "        [0.0022, 0.0040, 0.0063, 0.3000]])\n",
      "\n",
      "✅ Combined df_seq shape: (150, 8)\n",
      "✅ Column names in df_seq: ['open_prop', 'high_prop', 'low_prop', 'close_prop', 'upper_shadow', 'lower_shadow', 'body', 'color']\n",
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : CNNAttentionLSTMMultiRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 4, 'candle_shape': 4}\n",
      "    hidden_dim: 60\n",
      "    num_layers: 1\n",
      "    max_len_y: 1\n",
      "    lr: 0.0001\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    kernels: [3, 5, 7, 11]\n",
      "    cnn_out_channels: 32\n",
      "    first_drop: 0.3\n",
      "    second_drop: 0.3\n",
      "    third_drop: 0.3\n",
      "    scheduler_name: reduce_on_plateau\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "    scheduler_params: {'factor': 0.2, 'patience': 5}\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.994326, MAE: 0.996342 [original units]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    attention_name = \"tanh_attention\",\n",
    "    optimizer_name= \"adamw\",\n",
    "    kernels = [3,5,7,11],\n",
    "    cnn_out_channels =32,\n",
    "    first_drop = 0.3,\n",
    "    second_drop = 0.3,\n",
    "    third_drop= 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 5} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features, seperatable = \"complete\", dict_name = \"candle_shape\"),\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[0],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns,\"max_y\", max_len_y)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "\n",
    "    model = CNNAttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        attention_name = attention_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        kernels = kernels,\n",
    "        cnn_out_channels =cnn_out_channels,\n",
    "        first_drop = first_drop,\n",
    "        second_drop = second_drop,\n",
    "        third_drop = third_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"attention_name\" : attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"kernels\" : kernels,\n",
    "    \"cnn_out_channels\" :cnn_out_channels,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"second_drop\" : second_drop,\n",
    "    \"third_drop\": third_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True,\n",
    "        scale_labels = False,\n",
    "        max_epochs=500\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517428f",
   "metadata": {},
   "source": [
    "### Hungarian CNN PURE LSTM 2 bidirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b6ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=3). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | conv1d    | Sequential | 2.2 K  | train\n",
      "1 | lstm      | LSTM       | 643 K  | train\n",
      "2 | regressor | Sequential | 40.3 K | train\n",
      "-------------------------------------------------\n",
      "685 K     Trainable params\n",
      "0         Non-trainable params\n",
      "685 K     Total params\n",
      "2.743     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.127715 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.127715 0.      ]\n",
      "[main] Shape: (4, 8)\n",
      "[main] First few rows:\n",
      " [[0.00637838 0.14028078 0.08115927 0.3        1.2251015  1.2329156\n",
      "  0.9677629  1.1256732 ]\n",
      " [0.04009115 0.02701042 0.03372177 0.3        1.1256732  1.1708027\n",
      "  1.0583339  1.0877135 ]\n",
      " [0.00325818 0.0881668  0.03394962 0.7        1.087789   1.1296856\n",
      "  0.99188215 1.1260169 ]\n",
      " [0.00191968 0.13889347 0.11387014 0.3        1.1285027  1.1306691\n",
      "  0.8611065  1.        ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8798408aad7a4d9780b0423dcf4eafe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5018202f93f40e6ad4c917b9a81b906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a08425949c4092913aa191b332f157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b0647e3b2f4a34b3555ec894f83599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4481d51a8e7b4e29bf8a237edf80b4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaafdd9f9a1e4d9da196a5b84c47410a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3eafc50cad4d3f8ed5cf0269dd72fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d562e4b644a4d5b8d76bd70991127a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010dba7ad2644e479ce0bdf03b9cefcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dd4e7d806740fea25483358e790ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0142e11c80fd483aa54a4dd9aef805b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a5e7b1ca834058ad597e2431a5b839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c6cdf8c526424da3bab87aec20c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c874b2beb84c4220bd8593822e2a3a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cec3bacb60f47ca8cc52b63b5af7a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4539e7227eb74c37991e6a5cd761c5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434814b17221481b9c5a9d18be9fe7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bcd4530437497b9bef590c10a3383c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b264ec6fd440caae6f76d40a4e6e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b97c7f2c6df437598cc2a26dd529215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ae430c762d4f98a9d9221b269b9bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060379d9dc874bc787276085d94f06c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef96e5eebb1547c3a433465cdce3493c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322adf7cf3ee4a4f9d301fe820a88ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f90ccb98a1c496d883e60b1dd4a5030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d7206fa8d143b1941847ba46f646bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c592fa1cfe4142049a17144bf56f7bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4298a8ded6754210b949f63deb55ab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf24b9cd3374c719271c6db2d906e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d664dd3b56743a7b3159e5865e3cdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316d5e7fd0e74f2885f22afc7f80629f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea9ae6538624736b08faf6c23c06638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd02d1d7d8d49319361a01588d2f8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cda07ead55c4830ae191636106626ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacee8a835d34b75ba84f1b85c4dc5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd813a6aa3b47a7b54c9e4e55b923d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa37485a149245839c457e2645f757ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658d98c939064763a518e5b82a87454e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847f0d443a9d483db3c124b6770fe2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e4ea5536f3411780069c314963959a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd41bcb587641cc988282b27690705c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb0f806cef6422baf501f87b1c9ca1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f763fe28f4149a88a375d2248c05498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51b1d8eee5342af94d591d70480569b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbd104b18204038a165efe41ed2e069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88db844e66604cd3aeba627e326acb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbecc130ec18495d9f8a81a41fc676d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df05bb29541420a9b916e057f5e4bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b43f6f5a0346709172529f101be05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0715b9aa2747108a0fd30e6b513ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f7d97e657d4edb85eb20ffa5b5339d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba59b2483b444d74ae325defd2e58c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaafecd4abb44e16ae729d151fc89057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9e165e9c094cb6a602d60b689b283e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dfbf6ff6fe4bb98f13ddec593acc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e836e130ecf482b8e6bc3c71f513924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6481b5d95c314c9fb5847271123f1ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769fd2f316e34dfb8e5a6b5623b25845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83744d4e855c4d5eba3845cecbb10c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3333fde90e33411090121f4056310734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d14b5c70f3b4aaba92bff84fbd8302c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c4264c87a746a99ccb8d83958f4b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64f11b2c3654f9a9fbdfad3b3ba60aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6365914603af4159b3a731aad61ad636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214c1cbd7b35479e9425a43ddd0ee614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad03e9890da14a71859666731795337c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb213ff509e4f90813aefdc0827d969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82835ec57eab4da383cd0241f04ffc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5338da7279e44df9c10e6c92d95cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbc6461d59444debbd6d4d01a5b5bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf079e166d4b4443971cad9b73bbb51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70641de39d394dd691ce6babc6f7ca1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6218a061b74c5b80cf91d01c56ade9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e38b57ad4564415ba3ee961e3ac8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fa37cb5a684dd1b2dc14e939e74895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58763bc54433441e95ae113b8cf018e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c640f6c70f404beba53255faced3bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dd3fb4f1814b32b4c022d95ad29b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c915639b40d49a895586294347baef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cdde4b58474c40847a9214370f4035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e0278132404f459d4334f91be173e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39be2c6b99944a78d70ef526da32b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f605df7ff9d4a2990a2605b7f5f347f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6488a21669f4ac9bfc87abc4a1f6415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23038cf113264d3da50f916e52a6627e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad94d400bdda49a6a31bf243006526f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93addc6b7979497992fd5bcd4bdef002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbb59d72492460db213ef8b06388897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c57aac8dbc4841be1ae5ded7a69121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209ff190e90045e99b0cf7545c133cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5056eebe1dcd46b1b6874d547729d697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecc28ea7a4c4f649a83ff1f24c8035e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb96a18d2044152b9f82fe1c28c1808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d913f33cf8ca469689b8e5569050a98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18344185511048d2bd6eeab78088d4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efd2554cebe459c96937307bfbd0818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea04e931af6476d8f45f2a2b132abe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de7a9c3888449ba9b60934769f5bddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8020543b4c414dfc97b1a6622a3e820e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac485649f39434a859d0021742875dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb750f1710b44b128a297a937f08708c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4999e08482422c95801cb2dd143178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f878155409594243b87d83c9bf140277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06635d5ecdbf4b4fa396cc510b6fd679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e15998662a46da8ad9039465ca7543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9c17f183944538b178d7c119f0d8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a883e83a1c451db7c7f870b57fa688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bfaab4962d4c2b99e2406ea5e4e261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9870cce819243dbb6762e3835489c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c698e861b4904075af2160ff59742c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be87335057974ec0a21cae5ac1d2132c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b476972c42478ea7aa5508941c31df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8efb43610884669b1e17c3f0ee09a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e010c603d4cc42cba81d20890e694c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8945f058772042d091f88359c898a917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ba1acdc3074530ba8981993d8b7988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56280431fb46463691fc81af4a7111c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabf484f88c44439a5d05138ce66fcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c2f2d106a34bd0b3bec6c6b443af70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef14b611dd64d79ad9bec7ecc5e601b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f992f47c1eb240f9bb07abf6db6f45ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267372b0eb264cd7b12e3076339dc4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b2863b94a4415b51700a87f1cbda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b5ce6b08d441f097a758d2cc36a867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa1290c39c7421b93474976bb34cbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b02e96cb2f94d959b9750f8ff9cfd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5f72bd6f374f1a8e8c8cb7edf4b603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f136fc0de3ab46b7944bd6fcf299c6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bbd36bad944a018c56b10e1342fd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebad84360f284cffa6fa477785e8988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefd9f55af67490a96a726401f865c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3668010b34844a2ca526161ef65d372e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109d114d53b94221a00a7a158862fafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d132652a839e46a5af8bc23503cdf67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b832a184bab0429e843d40ba9d7d18e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29c92edb82d4fbe8dd1e2d741ebcb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd282d3e27a463caac144d76b8dfa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed4cc8a605942ff89223586a548c7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc001a8086db4c3ea0ced4398a2f7ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565e7b6b9adf4d25b5cc772566a936d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5281a33d18d4307841e4acbce7d40e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7804aa80613049389d364cc62ed5990f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77623cf100bc43b6b6fbc7a27d404c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b6482b31a84e8894322687545e0c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7ee38579174a28ad05953e3963db26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e22e83dd4934ec7a51e86e6a2f88c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5c07474d2441119f79e22d48ed27f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39641ec93e924f3e92db272c6c51466b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e15c36aee754e3f93587dba340b5c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fddea35accf42e0b31d0903d7732307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7fb36b80be439797a2c11263d34ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a7b6f086ac47ffbcadb9afce4e8672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2578e482f49546d6bc08f9abfd89b5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b089de8f3c5543398a01dda99f7d39b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd81a2754b9242d5a8f830f037fef458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f8cb98c88a4ac1861a32b786a9d16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba21d23bed54f1180dd71cd0bf1bb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd13b2f6eac48c289ae5dac83b46924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98a7b858a224cfe94011d73e0ce22d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadb186ce2ec4fba9503682c1427df14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10957737300b46b7adad861353609195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821b6cd5bc114ffdae3f440157e93f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb2b1f2eafd4d4da4375600347e113e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eb97d5603e48a2ae1bdaeeffe2d338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f11ec9a244517bc60c340e5f46e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035bade129db4389863dd2f70647a1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06cbba2cc70432fb878caab53443fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df119c2c3f4d46c799bdddd394951b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071e7c2bcc4e4f048f9ba589d850711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba88214cde1454685912c91fa55aa7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bedcd8cdd74f44abdaeea495230f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbb6234bd4b49f28dcba46ae402aaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63d22427cb6470a9cf659fb149c3e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da7b721e0d547ac85eae0db7009715e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283c67ef405f424fb952b9a11bbc7b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b16348e920448eda6f0d8d977800212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b03714b1584e47807fc1d31d5b82e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26dd23e668d40928be4078f0d1a1f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfc4fb6cdc046919a21286a7dc61d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea125e623fe345c1932e28864f4a9c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efe5c5dbb1f4733a9d17195019ac68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a36bb11bab940119114f899de4527d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5801c366dda34fac8c1da2762733db8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78301f25fdd46ea947e219aa2bcaa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402602649dc44895853c78b16c5a8121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f278b310b6aa48088ea9338c39d9e488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ae9eff2049431192f599c53a058258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e28754d17b84cc58c92ebe3b141d208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086a5efc5d694abdabde112caa173401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f5ca6589a7451da83860ff04c057c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d94b2d6220849deb5a42d13d9c81c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ea7fa5b6484b0b99ea8e0050a9b22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0e84869eb140f3802d343115193705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb2d035e3744e0181e90fa917ab4042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d4c6e58e894b0b8378d4a001e811d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a617d6b38ad470fab43f79f37af7e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e56a6f2ea74c9bb603f50dbe8f3b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8a914cbb2e4e408b449f448a648319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d6523646b14cdd81dcc812887de77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006921f5c4af43468f05d441db5b173d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a27edd046340518d240a31309aa535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096bd2a2c6264a9ca280abf91d6df04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bf15fb178d4a3e94376c192fb22db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822815c1ca984ada89cf527b9134f9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719442b86eda4160988c1d6e4d117f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d623c3c108740e6aa37c9d93b6108ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a58e85bc58423791abdd413d842047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8118af96ec4d4d4e90a430bbdd7c5d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e3dc0c89f49e99507e5dda2602dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a7fb4fc6b24225bedf013c1ad9e960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d654602e28469e9ddf17ff1c351912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bc91a89a5f41efa8c1c5a8c7ea5733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6ab1e8ae424ea3963dd1366856913a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d655fbdfc8d04666b16a225e8f1142e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edf25cd8af34a18bedd41c6fb776d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dd2a9ee1394f4a85f1ca8aa8941588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d3146db0b24200a160c89431124011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4454ea59e22f48c48ef79de0c9528132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927a0ba1eeb34fedb663bd9a14d182d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e082b1fdab144e48bb804e3475199fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b16c72a73c447bb96a7bde0dc96ee17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f529db3d2c432aadc91e7ac8b9c4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8967a31d37744012a4f3ffd1c0940cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8342b884cdb241e3b1f17b9df5c59393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8243ba4e144078bee6dc80dcd99bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d0af40a6ca4474a9efc4e409c6b38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dbae1dc24c4858922ea167f7bc5cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8118ef24b5504f0bb50901fc2144e727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ab3c5ce62845aeac58b953af20c80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f2b0d457a04fe7a1e0f308a2cf9af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796bafcf866a4469a1378185e01861f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba685e059d64c83acc4886a25dd142d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5e23d0b1d14b8aa2132535547fab49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a2a67c459944ef8b39bcdab5072f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b97cd6ead424d40a8517a4ee152d760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2596ba9b2cbb4077870ca07b4693b28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6976b7115fde49bebd89c0b9fa6fe628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b830d1f3809a414a9b4ca8d28ec630c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806ec34c3fd44acdbc94e921571e633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f40ec57ccc54d958b57b78b77a5a942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ada1aa65b8740588479cd0c0ca01d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29f7aca24c54e748dd9e8eaa16fe4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65ded68ed2249eeb4cb000201777c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9496aa13e04d2783eb4efe87aa081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecea753796ca40b9ad9865b0dd623fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f169ae7de9544351ae90ebb28685951b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268b1312109e4dfa86b80676528c1180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050e638ff7c548d08160e0323fa18f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b334c38282b40919d538c983c3cbff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42acc8d527d40dc93983c0c4fe05cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32733ff948b48a3af1cb4b59a367459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3226485d2c40689b6f7012cd777ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a3c8ae52824eb0933b85b09f868a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf58fb0420d4fb3a6b5d72e209c1944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21786ae4852403b811b76089b821901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f7ba61b9f642d5ac885ba3f54a7e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a224c8745914a3fab281d103673fc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3377d4192a54a83b23a7ef72433e679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13629f8c5c844a059c802cafb87b135e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3080e2d63f9417ab578227bb7e040ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4858363dc69d4117b19cdb53cc2be117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b812b63d241c4762ad84fe766a193ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a14d28fbe334c8db411a044e697c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5205e06e2adc4338a512b2a297cb03f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2e830879e442e7882b0baeb12a6d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de6d930e4cd48eaa2a5c56a8d85ba35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032fdfe2ab12435982dc995c33fefde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f73cffd8cc9474cbe6f338b4ba5ee30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11adfe72a394b228d49acb0112b63b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454f01efea714f8ba9f997f53289ac94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7b04ae06a540889eb3d21790f06948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8e575e7056485a9c90f81460dd372d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf74f9d26bd44e48e394e5b7447129d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe503fdde98e44ada460869302c2c7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15cfa578db94052a1bac8639936a618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eeadfc82a744de3bffa4dc79a6c900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7d181bed824d299491fe027aa8a66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0161a6ec6464d86a56171ae502b2738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020846f53ea42849ec5725babf58d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdfc74ee6c94e8abdd929509664f0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4aa8ce7f1e54111bb82e480f8ba2795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b045ce4897184465b56ef0de9fb70416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f653a56dec33444d92053ffa1eacf605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339aaa10bda0487cac772e7aea6a0408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac31166dc39740dc8a175dc231662c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b6d75827fd48169bf2881501965158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6a384651d544c5b26e71717973a797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbe667f17a14834b6874eeee7d259da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c361cdad8f41dc8e29a58510741226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e1d2a44783420aa30c05d4463caab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1158aede26484870960c3ca81e36dc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4be5367ccd4ddfa4f245f39874b80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7834353154414b97deee402169a9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745009dc90c9476585e52f48c7b7115c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4060820d04174816bb8cb3587f330354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af77df23dff14c5a86f30e0cc1f559ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac022900b894f7890b41679e2f40b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99142d678ba643339d3bf695d4bd7bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2dabf71146491c95039a84579f20c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed1bf3c30fe43e98e369e30d6e626fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abdc592bb764173957cf68cdd7999be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cc1633e5b64b6c888cbc3505836615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4824f4fd12274a90a38da912d43b83c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b842c08a542a4d17bf57ad0e03ff785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a3e7d7ae4640b9b55566115f0f419a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae11b0f2838b4e8e8a31582ed95b297f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b06dabdf474d31b7c0b46aa040026f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bfb039f17c403c91bc0cce2f9acfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df17a025efd94a4a8db43ca82ede9b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00f8ac03baf4bb49d12e6a2a87ba241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f752c39a760415c98650c5bda742aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ddcbfbf1b04138b017a10ae67a020b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56bc4e493d34b8fac05b08d00f3b1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3550608eed83402ca3279e7205aaa208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c71eb041f34ae3886662342847a4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fbbee15ee848969fd1937978bcb9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecd3314a3ab488f928b4856f850728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea40089ffee54fdca93af9358a17792b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bc9c4dba5841bdbf294da3a0a25d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9f4125aeb44de1818251c0bcbdc12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019b9c0b90d646bc850e038530aa7aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0a5af546e3438f81117b280f51c51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817d3b8c5bc845bb84628eca925275ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58887b2a1e6241858b0305270e7a7c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4993b6905ba447ceb0a5cde1e2675b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3335d2dfce4c9589cb61ef72b6abc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0285701742740c5ba46b9b637030130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ff336e90ff421c9b62a079546d6aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47346970133b414f9ec59f0edeac956b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14add57c9e8e44649dba89047cd2374f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9add34c2a616468184e13eb87d2fb95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35a663fe6a24b29b83819e7f61f5fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15f8d6065ec437ebaafc8844fa8f912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fce78322c34fabbb9e999020e02685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183d7feed08a443d92dbe77030fbc8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766a44e47fde477c9cfaa836c43fa8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f95310b5dba4bada1dc66a2b58b2f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67670048ab4f4589968367e702b00140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aeb0e859e874751a13fd9e3284bd003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff768e23fd344d5489985949985e6fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2024869d43f4587b303bc643a6711a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf8209ac482438694058e3fe4c561e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185f9b8861604a3fa3348181166cab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6aa454f9f3e4d34a09044649ccd3805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4184f72b5804abf919a1eb78d7ebf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081696deaa3e4e32ac1fa4c6efd745bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a106a6b1ecb4798affedfd92ab67246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85de8b5f4889468bb51ab2dfc113a805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a21db29be43461fbaaba440a98ac694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0b31e6138243a89499367a3bcc675f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7897ed112a7e4cfbbc2d508bfcf9a8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bc2884f71e430381f3074b6ac3c297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e44f606249447428e24d169d052e9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546f1251474a4e249da038b68e089f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71923a1280dc4eb6a270868f9d6b269e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8384f25522614970b228fb6dc4e5c650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99044b5c8a84bb2b115c7855887d3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e511d173342dbb2f78a5ad6b7592f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abac7a5b0214be680e218c0cdd657ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4385b4beb7ee4726907a779cc306513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb858f2075040ce8d67237a92a32945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b4468200794bc283c06a13ebf70a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d8137bd05540ae96c519cff123abc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d5194a1c7446488906fc42321acada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb8da06ccf54b29971472bf3d8c05e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18e7f40cb4746d3b98157c982c42453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea938c12bc914b1eb8ea5365a8dbd4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aa8a35702e4e4596605fe7add9bc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02504db304ff4dc9b75f97083ad7351c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c3537be8d541dba68f9c0694cf71f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b973bc905a44aa9a3ad29f02f102bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76007a7ad72a4373bb053304dedc39f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d581ad317f44b7885d8a4e09cf1c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73059bde0ce84c6ba1a220cf39881536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f3db6d48854f1ea1926499bb732cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f642b7f684c840a8a4f78df04e77f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db1f50fad3b4172be44ec2cd5b94beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d7c4bede2447a99ee89f2b713c245e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdf9d93b7874afe9855e6b8a4359f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45da69a5ab4a47ae8693a5d04cb1e06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5928e86bd24ea2a3fd1ad41303a2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6305ab6c7b8141fd8ed25270bae0cf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59b1ced428d412fb352dcc65f294a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bd3866d03c4933b3a08d5f877627bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ab5e511f8840a5b130e6627dfa5511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44423bed7f4e49838e8a4c3915f4781c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cc63d92d684576a333af3f5fd45481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6d1741735147b692d4861902e9e983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05e45c85f0f4453bc21f507be6467d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eef4bf644c643679db2eb0a7dd580f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f8dd2f1625425faa51410fcc0b8a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28f2f65bad142328a1f8a4890f9f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421ea533c9374d809fef0abfd63c0f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c4d3208b6a43dcab378dfd4b1575a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fca3a7ad91431dbc6528a2c9cdddac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0ac05cab414ba7bf1f098372130b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925f9fbc017e47e6b85cccb7317365f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb284b6cef945cb99f178126f37f3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfca151276104597b5f8c79f661c5ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac66c33952f42a289b0459a96fe6d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e839431eb64c57955ca2de13aa1d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b2a9cdd31748608c19c043f04a4519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : ConvLSTMBidirectionalRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 8}\n",
      "    hidden_dim: 200\n",
      "    num_layers: 1\n",
      "    max_len_y: 2\n",
      "    lr: 0.0001\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    kernel_size: 1\n",
      "    cnn_out_channels: 200\n",
      "    first_drop: 0.3\n",
      "    second_drop: 0.3\n",
      "    third_drop: 0.3\n",
      "    scheduler_name: onecycle\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.001530, MAE: 0.024625 [original units]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    attention_name = \"tanh_attention\",\n",
    "    optimizer_name = \"adamw\",\n",
    "    kernel_size = 1,\n",
    "    cnn_out_channels =200,\n",
    "    first_drop = 0.3,\n",
    "    second_drop = 0.3,\n",
    "    third_drop= 0.3,\n",
    "    scheduler_name = \"onecycle\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    # scheduler_params={\"factor\": 0.2, \"patience\": 5} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features),\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[0],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "\n",
    "    model = ConvLSTMBidirectionalRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        optimizer_name= optimizer_name,\n",
    "        kernel_size = kernel_size,\n",
    "        cnn_out_channels =cnn_out_channels,\n",
    "        first_drop = first_drop,\n",
    "        second_drop = second_drop,\n",
    "        third_drop = third_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        # scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"attention_name\" : attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"kernel_size\" : kernel_size,\n",
    "    \"cnn_out_channels\" :cnn_out_channels,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"second_drop\" : second_drop,\n",
    "    \"third_drop\": third_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    # \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/middle_test.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=400,\n",
    "        save_model= False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e795a99",
   "metadata": {},
   "source": [
    "### Hungarian pure lstm kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f05731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss_fn_reg  | MSELoss       | 0      | train\n",
      "1 | attention    | TanhAttention | 3.7 K  | train\n",
      "2 | fnn          | Sequential    | 4.0 K  | train\n",
      "3 | lstm_kernels | ModuleList    | 12.0 K | train\n",
      "4 | fusion_lstm  | LSTM          | 37.0 K | train\n",
      "5 | regressor    | Sequential    | 1.9 K  | train\n",
      "-------------------------------------------------------\n",
      "58.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.5 K    Total params\n",
      "0.234     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.242173 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.242173]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.3036697 1.3155504 1.1531377 1.2362376]\n",
      " [1.236512  1.3073386 1.2062193 1.2421954]\n",
      " [1.2385321 1.2424706 0.8288991 1.       ]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.114845 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.114845]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.2195877 1.2259089 1.0732266 1.109815 ]\n",
      " [1.1090008 1.1302322 1.0515453 1.114974 ]\n",
      " [1.114974  1.1203835 0.9486662 1.       ]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.120154 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.120154]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.147258   1.1587839  1.0902464  1.099486  ]\n",
      " [1.099486   1.143701   1.0899644  1.1211767 ]\n",
      " [1.1211767  1.1248015  0.97898066 1.        ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "input dim {'main': 4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b501e3ad5df499d8a4bb43ec44c77a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=3). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cada6ee6f3244571ba0b550acc2e3394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ad232385c346ebbfa360c5aa7cd189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e42aa2e351c42d482dec4ba6aebd829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939d76356c6f4c0089a0b9353a60403f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f3f1773e66440388d104e23275d6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4184912d6743c2b32bbd681f14a582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e909def841934e9aa68ee2eead070419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506927ee3a3a4377a2b59fcf55f3782d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9be460aa7740ec82e94df7e6468907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ccc9b228b240efaf13c9737f3827b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48a3a298f0a4d6f888b9f21a7cbf430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7696311c53954eab85e706841d5ef999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dc6774115140688b578f8f3165e00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecf9fb15c6c45eab200ed18f45eabc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b716a1a49d434f87876152486fc0b0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be56a281864540ea8dd5363df41d9fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce30419cca7c4c3faca06a6f69214093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874b69d3c9b24255a656ac5eec9ba5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc01a86a7ac48299de630b151bcb69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca8cb6135be4f2e8d6b829144fa187c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a0128fd09c41349d61513103064940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e6fac226a745a09d437d317bfed0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252b921301814acc8e8336aa517a3326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd99d625e17941d48c30d31fd5f8abcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161bf51bb9f74206b28c03536086d6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516ecef0c9740eca125252a8f4586f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a86910a94f4dda904ada04cb867eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883130896cfe403687eabfc5c7611d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8a2ceb9d3c4e409ec289a815dea4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2b4b256be49c380f43cb1be99ca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a84c525b5d54a93a6d728fd88e2febe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8659256ccd41a682e0b159371e0f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2031f155c7045d4959ee3d5d289a3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2255055d1dc425b8e9496dd121aa7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa14b8641a814d13a81b7efbe2a2c335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9af6f10ca694ffb87bc315683614da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf416810602413dbb4d63f777cbe93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b37b58bf54bfeae955f66f2e332ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6e655d5b3d415aa6e8b8c6a2ae096d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47854963997b44e8a8034e601cc09f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421b50cea2b7435b8bfc16ac3bb37781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1873a297bcb4c29922dac2087a7610d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa384b91899d41ce873bb63a369acfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87181e27c4f24de5bbc7e8217bdb51bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddec543d0684ed4b254ea0d8adab6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7c65b496c34deb919f7d54ae716d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff186b01a1ca48d3beba0f4393bad102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba224b895604f6798f98e6e17d5a483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c386db9f4b64468b6c5393b7cd9b96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b4e6c930604c26979f294d837b3ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182894445451483daa3c49955a6eaf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6750966b12a0485c8e8a4c926b950f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5922c2b1978e4b46b58f158fe078981b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194af8fc7322415fbdc0a69f4e02073e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1414a8afc92c4622be30291fc7a155e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab0ce575af74946a8adb6654cf4dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5e80f289d34316b8fdf271ffa54ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a0f5dc325b4154a17aaee2e407ca73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb530ceaecf144ef856f239cd2f8878f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361369ad6d4a425c8942dcfafc3d5eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3de3e1bc3e4246a1d4d9b3a11b8ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6eb93ae3d7b4d0b85e42283062cff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda9f9f9552946ebb6de4ab420bb721d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acde44c58eb49609f27e04501504d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bf04b572f240f59bce58da8eb12978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f10d6052934ee981e7bc05baf9323d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3937a1a5394492b288f526efedc844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0941a368986f4b0fac03bac8695a7720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8edf84c9b8e44cab1aa56ed6b5a1d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de25fe7d2c7b47128f655da54b48ee10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43df806b37134b3d82fa12052a263d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faddd44cfb1c41789a728d2432855893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb7b665e1a341b29bea0fcd672ca75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1b1dfad45b4b0cb1924e8d3ef27979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c688319cd1db4d988a4e1421e092b615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92db07615d0e406fa125a35b395b65a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051581a527a94adb9b671b1053db09da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3499bcdf279e41caa0ff4c53254cf403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3bb78675e646b484cbdcbd560a1a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e23f9a13e434cc1b4c834dcba4e8ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfd8bc575d240ed80718ec23f3557f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88b02b063984bb587859d847c82cd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d68dc97c4f4b1abb2b09b51f118345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3392fd3c25db46deae2ca6b364799e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46d997a89af4652b388ce87e242a148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667ebd06113844149ba427bde9519581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff6af24382a464fb79a24c5b88c29c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13080b85bc4f43698b2aea5d8c1023a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3b272dd2e4d148c34002115d534e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bdc8146c86437ab980c5063e599f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca3ee53de624c0fb1591b164e2ce191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f9e191e4084e63a447123c9a8cf256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ae0cfa8eed44ce8b6c9f9ae18c428e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e7aa46bae34613b35ed36c6f8bee32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb1cd0bb280487e850a246c2e56af02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6209ee07c1b2460788c558fc01ff21a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218c38a87e0d46738c06525f11722ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3bc6382fb241c191ed772ccef4ab65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e2530456d74014ae7ad22a9d1939f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553d003683f642cb930fe298ae751c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd225075fa06432fa063f6351f4620f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bcb420590a44379d3234a950822df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484423bb581844ec9141eb6867517637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1973c958cb8f4877907a3eb0aa86f32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f9ab82eff34d9aa9c97de36d1d4568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c303a68b941469d9e3bc254f31211fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbf01aa9e234460871ef2d2119853d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1792031b60824e5e9e3bf6c6c6903686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7e577164c74a4caf94a0ca0be0fa6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec36a2efe734dd8af00d26ff2dc48c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc356bd8c46401fad2cb35abb003942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b298a4bb5e154d31bf46550a32dd6b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc66527eb68b4291ba75a12e3e86370c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1b4abba59242889f28a40ba70dc93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527a22099d28481698f67c3eb6d47636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223497a456d746a59839bd49e4e874b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2c4967d3d1444e81d53f5301104927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2b626032a34a8b95188962a0416cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a54fc91529435cb4fc6364d3f9bd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7330c7ee3634e0299b6d7d4a0304a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd7ac13f8f04cd48dd89854b7eadfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57043802fa234126bfe0a7a9ec50bd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fb7237e38d46f6b7d266d290644b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be6249338324cfda99d989d7cad62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9b0e00a27544908ab1408fbb8538ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2420d7c7d29d4db2a7695b3bda4c2fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5049f8671a7a46bcafb57ff3bfdb8174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ab60d3248b4aeeb57c7ff02593314c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd7e277f98d4a299eb4dafa40d39e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be59cf5e9cc449fdb2bc38daae2b9bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b7a1b19532447d9faaa4c13ca34ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21bbfe2dfbe4177b82442206cbe61c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6059e06cf2416180115e4621964148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db98889de4644f0b974e40baf81c693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1aef255e2f144bc844a972d9f1b30c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6ceb5a52794be8be519d97b2d9f634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6bf53b42d245b98d0c7c132a838e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aed1d6e2df241d6a96985e989877b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36f1267af7b4232863efd8b4de7101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8565978f154bd1b6b89cb33e75ffbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414262aa59dc4da583a3e26129ae3e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf218e4d3db43d28c6ec69ccf3bc181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd512827c704d119578126b7f943afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b18f43f51e4c199a72a33b813dc0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b91b4891594bc68a186796e69e8080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91f445f1f2c4a768c1ab8a4b16d9799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342593fa5c36472c8b039c033f429c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801421beb2394e82ada016ab3d34ea4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12c73938e05415abac6d2cf85c9f32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248402074b2f485ab327b648cabeb68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294803e78fff4afbbd8b7e0cc885333c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ea90203a7a49ef98ccfbd7f79e2eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5742e949f394b14b7a07a026bb8f254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c70ef6d495411c80432f2090f4b649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7364d505725473db469c15e7a016e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd2d6d8c5124cfb9cf638bfecf8716f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f72bccdd8434fb0bd0c2ade02104f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67aa16a1a984d8b956dbb3fc77a16c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd561ac091f4407947d40d84bc06a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64ee5c9ed80414bab6167acc8a6ddc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f2a495edca437192f360e3d1783ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa577cb42ea401b9fde506db9f1f051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d61489ddae4a32b8708bd2333ed7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9778e80887c443aeb1713355ed59f7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc668b683f94408af5b26141c177cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db983b241a7f41fe8a1b5ddc34c69141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6830b0dcb9c44dcb8635d96fb4f281d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3a44849f3848bfadca977143431997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6825f4e084394f6887eeb398190c504e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc40b120b0543ec8401b4cb85dafd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6e6c427c944e5aac8adfb654cbe390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128808697b874cd3ad2504124871262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355a4a734a6a4f0fadc89f2c4f907970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fda2a4d5c049a3a01e9674e95b4579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75795829d5f474aa8208969a77f3a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f271db323eb94ae0aa22acba75a82287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4bc2ed5d18457d9ae714b3bb3dfc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dc80406bd04f1aa8a381d0f8662271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b758c4cb98841db8922d2ff12a2a2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b603fed406c7444d97f4569f7f01ac58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc93e8f7fd7640ca88eb8c8eac874e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5aa1e0301b47d58570dafed5c534b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762a121d74cb42a5a51a3a854d496e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4db23af6384d0e8a00e2acec80892e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359bc12ea38f4874bbe38a24fd121fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b4f2bbcf2744b58ae8e86aa3ac0b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cbc1461d744786815d5699f57c0652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02af0915f9b847bd8a9295e9e0bd5122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75811456a3f348b6bf93d55b15891684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a46a22d218043c097a8b929ed2f9a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab965df00ec34cf183711b326bf70a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08d3b43c45d4f8d8ec36069314f8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfccd4f357b142adba072d579657b880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b52d3672cf4439be826e7249696235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1fbd3433bc46ebb89fe5fb64456816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfbbb3ddcfa473488e5190cedfece20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d96102b1854d0495e558f78af8e8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c5e6b6e71c4559ac92e799f95dc38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc38b26b8ca46098834e95dad68f0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b63f5e5c51247c8bf7c6aea43796b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab92c670df5f46c1b1b423990c886c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e786b1d84c419eb05e808d41653355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c69fa5b846e45e498ee019a1e47921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99f86eec018481b82c9e42384247f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd2b5ade689490f8f7c9551180f5da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67c7b7d9d2046ab9e7beb2b83b0367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8f85dcf38f4774b29d955ba3946d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e60780889e411686ba6d37c019270b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d996c42baae94f41980d2c785817e271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d074db98c8ca4c2bac24be30560ddc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20e91dda3064de49f01c1d821d9832b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3b5efe31eb44e8891cc6d020e58902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b376c8a8cc401e8719b3a9f52f2d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a44baa8c9c4488831c5994145b6f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f7365a357e4c64aea479fabd5f7721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6640cc9bf4094aa1b0fb9e2a9dc5459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26432cf178a48dbb76bafdc7fde003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67d5497b86347eb9b88b7e07145c1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca689d741e334272a2ba1e8503ccd641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee0536e0fdd48aa8439cb259560d5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8286b2dcea42489abb465a0bf2fb12f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931ef2557b624645a42925e5e4002b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e257b023fded43659394cc81153ae175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67197ad9a264ba3824e928e37d4dcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a1f15e7c324ee39c4ee9b25868b631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607834e06ab94dc9bf214103e8cd9b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75c306ceebf4d3e95e3b78f0f91bbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199be4a0028b485eabc307e48b3df6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b957b3a88d5a49be98c204977adfa458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe07389a4251460e893e464e3034e34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a297d29bab9443a9b3a0f9325a691d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a0b83c20284589947fbba9ae291cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15202f89223b45f2b754fc0c0ee4a725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3f1f8bd90547baa0749e5528c86916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaed679ca104f21b6210c614c22bf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9049cccf76444a6ea928d66a5955bb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21729d2a72d74dc984ce7f341b667544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a15330f5bc429999917a26f20f76e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7eabdbde43418f83a02165b9db1167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae92b04a370445da05d6e5eac3e3afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4616383b8d145acb3679702573b66f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92803ccdf2e4753bc1d13016ab92656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ce872c2769430dab8351e3bcc09163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c7a99546224bdfaa41a66df18f8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a74363c4b4d29957d71083dcc367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298c09f3d6f64671baa83bf487a76dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2514de31023d40e3a92863bdc0c34d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9010bc6c77064d0ba1c77e5685241752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507e9efd322e492ca40bbb363a835526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900f19e4033246e6abd85f053f7b9ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91962b49df174e9db815ce21eb38b7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08b0257a04049f69fb1acc4fa82210e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82774e6f5ea74de4b619a06a298f38fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23490324d72433ab8d47e9730a58e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a49751ea9249d1a24988cc7fa48b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b351530029864c5ca7b37986e9c123de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc7e66c3a164d5dbd7d354bd85e71ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c84df1b65684ce688e1423bc4e3e304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef07cdeeae94f2d8020884b236f112b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bbf37e38e94139a310e6332d3c296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6faaa2e55d48a485c891367636f333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9be176b854471eaa8cb15408300c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208fdccef6a14c1692cf0c40331df759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a68cc009f54ea2a842cc7d036a2420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1159be51088498989628a9eada1efd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa0c017fab49dba51147545f70f9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb890729d94842dbb04438e1a76bdcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55473a9902ec4f78972cb200ee8c1d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93d43260a1946d891a107557c473b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3177143976024544a696b32f7524e80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edefc3468a04fe1b2c47a5fe0f7b165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dd4f86cb3a4566a361efa90a42bc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39563ccb14ec45f4a34cc22fc40b6cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf9e04b00bc4160897734353b55282f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a93a7baf3c4adab6c8ed4c47b071ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff07a9a36fa417a87c0bcc2d569de66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b039cf93fa764aed8c973642ddfd33f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9dcf34ae847ac95a64d57c7dab24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5756ca18d84262908ccb00444cd0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a6224edaa749f3930d6ec553339836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57556e7c745d45908af1b44e966f1c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a830773b7046259711074c7eb6ece7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4221a972910a48d08b4c25e87eb9688c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaee1457b6354493a099d50d4902c6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc9dac3c8fd4c839781d92e4c0d1ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2620e994bf0c48a688e1dc2b2ceb82ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1297ac5e1a4e9598777124b3651ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d64cc6f5165459a96c691b04f837f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bece0ac58cc94742b298167536dc7c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6613cb65273f46a9a667100f756aee51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d82b0bf99b04f88bf73e6f6f6eb2137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12495bae5334f52871121d5c2cf159c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d646a55f0144dca0ea067f8785550e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2323f57df943508443b45e004d7bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0838890076bf483aa179c6e3b39cc4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b046440ff44981b81a29ab35cdb60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df40041958654ce7ae5e3bbbf051b539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1261d7636564a0bba2e3f1cecf03d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129475ccfd7f4a5682e0bd6fd9ad78c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa7b40bfb284680af9fae87537e85da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935cd95e7c9a4966b68ce6acb1f55152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : LSTMKernelAttentionLSTMMultiRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 4}\n",
      "    hidden_dim: 60\n",
      "    num_layers: 1\n",
      "    max_len_y: 1\n",
      "    lr: 0.0001\n",
      "    kernels: [3]\n",
      "    fusion_out_channels: 10\n",
      "    lstm_out_channels: 32\n",
      "    optimizer_name: adamw\n",
      "    first_drop: 0.3\n",
      "    scheduler_name: reduce_on_plateau\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "    scheduler_params: {'factor': 0.2, 'patience': 3}\n",
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20251004_143254.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20251004_143254.pkl\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.001148, MAE: 0.030838 [original units]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    kernels= [3],\n",
    "    fusion_out_channels = 10,\n",
    "    lstm_out_channels=32,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        # False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = LSTMKernelAttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        kernels= kernels,\n",
    "        fusion_out_channels = fusion_out_channels,\n",
    "        lstm_out_channels= lstm_out_channels,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"kernels\": kernels,\n",
    "    \"fusion_out_channels\" :fusion_out_channels,\n",
    "    \"lstm_out_channels\": lstm_out_channels,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=300\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d72559",
   "metadata": {},
   "source": [
    "### Hungarina lstm kernel + attention lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f923f81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.242173 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.242173]\n",
      "[main] Shape: (3, 8)\n",
      "[main] First few rows:\n",
      " [[ 0.0000000e+00  9.1133006e-03 -1.1546798e-01 -5.1724840e-02\n",
      "   1.3036697e+00  1.3155504e+00  1.1531377e+00  1.2362376e+00]\n",
      " [ 2.2189255e-04  5.7513956e-02 -2.4282021e-02  4.8192986e-03\n",
      "   1.2365119e+00  1.3073386e+00  1.2062193e+00  1.2421954e+00]\n",
      " [-2.9490551e-03  2.2156688e-04 -3.3271441e-01 -1.9497368e-01\n",
      "   1.2385321e+00  1.2424706e+00  8.2889909e-01  1.0000000e+00]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.114845 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.114845]\n",
      "[main] Shape: (3, 8)\n",
      "[main] First few rows:\n",
      " [[-7.9104080e-05  5.1035462e-03 -1.2007821e-01 -9.0079993e-02\n",
      "   1.2195877e+00  1.2259089e+00  1.0732266e+00  1.1098150e+00]\n",
      " [-7.3357683e-04  1.8397052e-02 -5.2503977e-02  4.6485914e-03\n",
      "   1.1090008e+00  1.1302322e+00  1.0515453e+00  1.1149740e+00]\n",
      " [ 0.0000000e+00  4.8516789e-03 -1.4915849e-01 -1.0311810e-01\n",
      "   1.1149740e+00  1.1203835e+00  9.4866621e-01  1.0000000e+00]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.120154 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.120154]\n",
      "[main] Shape: (3, 8)\n",
      "[main] First few rows:\n",
      " [[-1.22937263e-06  1.00452043e-02 -4.96949330e-02 -4.16413099e-02\n",
      "   1.14725804e+00  1.15878391e+00  1.09024644e+00  1.09948599e+00]\n",
      " [ 0.00000000e+00  4.02141735e-02 -8.66011344e-03  1.97280236e-02\n",
      "   1.09948599e+00  1.14370096e+00  1.08996439e+00  1.12117672e+00]\n",
      " [ 0.00000000e+00  3.23298899e-03 -1.26827523e-01 -1.08079955e-01\n",
      "   1.12117672e+00  1.12480152e+00  9.78980660e-01  1.00000000e+00]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "input dim {'main': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-10-05 19:23:07.279805: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-05 19:23:07.291815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759679587.305101  105160 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759679587.308979  105160 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759679587.319934  105160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759679587.319952  105160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759679587.319953  105160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759679587.319954  105160 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-05 19:23:07.323646: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name             | Type          | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_fn_reg      | MSELoss       | 0      | train\n",
      "1 | attention        | TanhAttention | 3.7 K  | train\n",
      "2 | fnn              | Sequential    | 4.2 K  | train\n",
      "3 | lstm_kernels     | ModuleList    | 12.0 K | train\n",
      "4 | fusion_lstm      | LSTM          | 37.0 K | train\n",
      "5 | attention_fusion | TanhAttention | 3.7 K  | train\n",
      "6 | regressor        | Sequential    | 1.9 K  | train\n",
      "-----------------------------------------------------------\n",
      "62.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.5 K    Total params\n",
      "0.250     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138394419bf14b87b71a584ab141fb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=3). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693e2d45c9cc41a9bcb5b50b02c71443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b109da977124a67a77dbda462b26018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9af1afbfce4412934c0f2d6b2b3473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca4343a7dc64602ad1f739f427e009a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfba04c112c04ca68c080e2af62c866f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced3a44129e7496197bce60324d9eedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57f1b82d8344839b82a7e13cddff7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c8a076d7964402bf39849d0044c14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18778d70a6845ffa6f92b6d285face0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0057667cdb749aabc3f2225d7db103e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007d73095e1b42e8ae88a68283b5853c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a49b396c5d3413ea7c58d70ff41a6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72777e3bbf14628a039bcc15b3ad3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686b0bb475a64e919c580b0f40df60d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee7da8bd15a48e8be6cc22e912510d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310cd42f41c043db805b3fc5a4188655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8442173276ce4c25b723f50c44f44cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319826c1bd7e415fb0d3404b21433541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5aadb503c0475d97e54ca45eb9c1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013ce659679b45eda478ce7770385839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be166cb6453b434ca82593501dbe9792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e300e6fcea9548738751208c7af52647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0645612e384d75a396ce9dae0b5a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1fd7928dd74d00a65b47a42191dc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2537d7eb73c42969e537ac421ccc2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504635c9189b4f04a40c179eeec21863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9f44c03bef4c11a0dcde02ad26adb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733515ce5f674b4ab85d97ec751a9a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70b5154ed2144aca208c34f41ba8b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7d6b6f24244a07ab3acfbb294c0544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a856b96665c943a7b1ef0c583877812d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a89c6c9a348a994e94bd62f5dc447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1566a118caf46a595ae681f36c845e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7082fb70ade04f8695357ccddc516105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadaea293247481c911e4f96ffcba5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1787e1efbe43b1820dfd03906d0b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ded98e684f4806a0149e42167d73d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970323a31027410486ebacaded8d59a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccd209f702d4c45b74fb2a3d7ab0b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7753499507b48d188a92ed5eb1d425b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf9ce28fdf64060b4b4aaad6ede4739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d794f09a484d4ebc137d37c0e8539b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e9d614f9e944d694c128d9262cfd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627ba0b2f71f4c73b11cf442cb0b5dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccacc9532c14e80a54cd9ee5bc47631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2f0bd0450f49eea24ee052879d384e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d044eee343da41679d27695dfb8f1e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbec60f88226498ebf2ce8f2133763ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5056f3d599cb4af9bffe1e849638e877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e51921e33db438e83159dca7dea9eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db30e084e7e4465281652a17a76a93cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a048d34977469082a611f4fdbf84b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22600ffdfa2242ecb5efcee5c2788da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513d7fed9ad74a84ab7de3e6493859d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd710da7a07422c9af684b3c3417246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bd7833c1d549cd98c7c5d5d0aa11ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6ed11b3531484891048bf89cce9f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b325fce9eeb4b35b7a3821f47d4b4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d36dd27719149bf8ec6a7a046701829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dbe8a438d84db380bed08a98460566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711268244f0041de9a8e2fc3ca6e51a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e92d84ae3e43b789d747670ce4d8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135b15b88bb54bef8cf2af530098845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e13794c655e4d388c96bc128a4f8202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414771b2b0cd404ea23fddfef9152eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad830fdb2bcb4d13ba2d6cc684d8cbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d3183f790642198a0294163e73c8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2429169257e54a7ea4f89c9c937faa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cd1f7894cc4d5386e1b2bbb3fc1040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3ff6d4ccc9465f84f2bf50f847666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45579f69c86e4cd9a3d4137e313fb2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad18d867e8fe4f009f80ed6db17ce3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f53d5a575f4511b92581377a79886c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef855633a5e4bf9aef4e9e67f690e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fc69e466504be9afb2f53e9de3f001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec08eece74a645ee8e9544b1d3ffabcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974a13ec992a485f990384b8208aa538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0520fb1d444f0dbe1d7475b76216b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab7a80659b745768822f5fa13902a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00b0f3830ec4ee084a50c2fffa622f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e44ec5fc764014a0ace91a612b95b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8632d15c5a34230bfe91130d1eb9092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9558bc392242caa04775363b2a5e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f82244058014465b814ec3dd2c4347a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7584173fa7924a6e817448dce81aad05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70647592b4ce4a3eb5b8719cc9bbefce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381a1cbda89444da85431b79b0b89ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325457eef23d45469a40791809625e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8107fd1b1e4cdd8c53df8387537a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baf3a2d049e40ff9bd05c65435da19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0ec3a8c83c4de180d9163fc3ea75c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf6448a29574cbb9d2815c3b9181b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c3552707c44821ac03426a7f96b244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0f4bf229f8403097ab9b6f03b4b79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97264d98377c4f52909421f08dbcc86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9300d4ed314434a98c944842374c4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466bd211694d4904b334ac8a5fc8236a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966c61c1394b4135be8d5a4be307877f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c19c4f726a4c1b9ddbf1dad07c2e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056d13676174456b9a296f7e98d414f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([50, 1])\n",
      "y_pred shape: torch.Size([50, 1])\n",
      "mask shape: torch.Size([50, 1])\n",
      "y shape: torch.Size([12, 1])\n",
      "y_pred shape: torch.Size([12, 1])\n",
      "mask shape: torch.Size([12, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb9b7787e774c96a631e802a27574c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : LSTMKernelAttentionLSTMMultiRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 8}\n",
      "    hidden_dim: 60\n",
      "    num_layers: 1\n",
      "    max_len_y: 1\n",
      "    lr: 0.0001\n",
      "    kernels: [3]\n",
      "    fusion_out_channels: 10\n",
      "    lstm_out_channels: 32\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    first_drop: 0.3\n",
      "    scheduler_name: reduce_on_plateau\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "    scheduler_params: {'factor': 0.2, 'patience': 3}\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.003209, MAE: 0.052903 [original units]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_lstm_kernel(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    kernels= [3],\n",
    "    fusion_out_channels = 10,\n",
    "    lstm_out_channels=32,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    attention_name = \"tanh_attention\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = LSTMKernelAttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        kernels= kernels,\n",
    "        fusion_out_channels = fusion_out_channels,\n",
    "        lstm_out_channels= lstm_out_channels,\n",
    "        attention_name = attention_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"kernels\": kernels,\n",
    "    \"fusion_out_channels\" :fusion_out_channels,\n",
    "    \"lstm_out_channels\": lstm_out_channels,\n",
    "    \"attention_name\": attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model_lstm_kernel(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True,\n",
    "        scale_labels = False,\n",
    "        max_epochs=100,\n",
    "        save_model = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc34d02",
   "metadata": {},
   "source": [
    "### Hungarian lstm + attention gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8059cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name      | Type          | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | mse_loss  | MSELoss       | 0      | train\n",
      "1 | fnn       | Sequential    | 10.6 K | train\n",
      "2 | lstm      | LSTM          | 161 K  | train\n",
      "3 | attention | TanhAttention | 40.4 K | train\n",
      "4 | regressor | Sequential    | 30.3 K | train\n",
      "----------------------------------------------------\n",
      "242 K     Trainable params\n",
      "0         Non-trainable params\n",
      "242 K     Total params\n",
      "0.972     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.242173 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.242173]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.3036697 1.3155504 1.1531377 1.2362376]\n",
      " [1.236512  1.3073386 1.2062193 1.2421954]\n",
      " [1.2385321 1.2424706 0.8288991 1.       ]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.114845 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.114845]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.2195877 1.2259089 1.0732266 1.109815 ]\n",
      " [1.1090008 1.1302322 1.0515453 1.114974 ]\n",
      " [1.114974  1.1203835 0.9486662 1.       ]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.120154 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.120154]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.147258   1.1587839  1.0902464  1.099486  ]\n",
      " [1.099486   1.143701   1.0899644  1.1211767 ]\n",
      " [1.1211767  1.1248015  0.97898066 1.        ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']} max len y 1\n",
      "input dim {'main': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6806eb61daac4302aff83091b2643d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch (X): {'main': tensor([[[1.0203, 1.0347, 0.9868, 1.0025],\n",
      "         [1.0026, 1.0122, 0.9925, 1.0077],\n",
      "         [1.0077, 1.0081, 0.9961, 1.0000]],\n",
      "\n",
      "        [[1.0365, 1.0574, 0.9994, 1.0265],\n",
      "         [1.0265, 1.0402, 1.0112, 1.0298],\n",
      "         [1.0297, 1.0356, 0.9782, 1.0000]],\n",
      "\n",
      "        [[1.0946, 1.0973, 0.9645, 0.9850],\n",
      "         [0.9852, 1.0200, 0.9791, 1.0021],\n",
      "         [1.0021, 1.0200, 0.9369, 1.0000]],\n",
      "\n",
      "        [[1.1473, 1.1588, 1.0902, 1.0995],\n",
      "         [1.0995, 1.1437, 1.0900, 1.1212],\n",
      "         [1.1212, 1.1248, 0.9790, 1.0000]],\n",
      "\n",
      "        [[1.0425, 1.0601, 1.0177, 1.0328],\n",
      "         [1.0326, 1.0481, 1.0209, 1.0444],\n",
      "         [1.0444, 1.0475, 0.9895, 1.0000]],\n",
      "\n",
      "        [[1.0427, 1.0427, 0.9930, 1.0327],\n",
      "         [1.0327, 1.0539, 1.0201, 1.0374],\n",
      "         [1.0374, 1.0471, 0.9975, 1.0000]],\n",
      "\n",
      "        [[1.0220, 1.0473, 0.9860, 0.9973],\n",
      "         [0.9973, 1.0147, 0.9788, 1.0071],\n",
      "         [1.0071, 1.0106, 0.9780, 1.0000]],\n",
      "\n",
      "        [[1.0029, 1.0268, 0.9431, 0.9982],\n",
      "         [0.9981, 1.0440, 0.9696, 1.0206],\n",
      "         [1.0204, 1.0546, 0.9987, 1.0000]],\n",
      "\n",
      "        [[1.0382, 1.0517, 0.9840, 0.9863],\n",
      "         [0.9861, 1.0157, 0.9776, 1.0067],\n",
      "         [1.0067, 1.0200, 0.9840, 1.0000]],\n",
      "\n",
      "        [[1.1853, 1.2007, 1.1024, 1.1113],\n",
      "         [1.1115, 1.1403, 1.0739, 1.1241],\n",
      "         [1.1229, 1.1512, 0.9726, 1.0000]],\n",
      "\n",
      "        [[1.0540, 1.0643, 1.0312, 1.0530],\n",
      "         [1.0530, 1.0768, 1.0457, 1.0651],\n",
      "         [1.0652, 1.0737, 0.9820, 1.0000]],\n",
      "\n",
      "        [[1.0369, 1.0386, 0.9812, 0.9989],\n",
      "         [0.9989, 1.0184, 0.9924, 1.0116],\n",
      "         [1.0116, 1.0231, 0.9819, 1.0000]],\n",
      "\n",
      "        [[0.9954, 0.9999, 0.9763, 0.9919],\n",
      "         [0.9919, 1.0106, 0.9878, 1.0064],\n",
      "         [1.0064, 1.0247, 0.9892, 1.0000]],\n",
      "\n",
      "        [[1.0403, 1.0526, 1.0065, 1.0206],\n",
      "         [1.0195, 1.0431, 0.9959, 1.0342],\n",
      "         [1.0342, 1.0436, 0.9964, 1.0000]],\n",
      "\n",
      "        [[1.0408, 1.0816, 1.0006, 1.0055],\n",
      "         [1.0054, 1.0432, 0.9910, 1.0276],\n",
      "         [1.0276, 1.0279, 0.9832, 1.0000]],\n",
      "\n",
      "        [[1.0305, 1.0430, 0.9988, 1.0022],\n",
      "         [1.0022, 1.0152, 0.9992, 1.0141],\n",
      "         [1.0141, 1.0297, 0.9931, 1.0000]],\n",
      "\n",
      "        [[1.0115, 1.0159, 1.0004, 1.0049],\n",
      "         [1.0049, 1.0089, 0.9908, 1.0063],\n",
      "         [1.0063, 1.0086, 0.9960, 1.0000]],\n",
      "\n",
      "        [[1.0023, 1.0090, 0.9890, 0.9940],\n",
      "         [0.9940, 1.0114, 0.9746, 1.0015],\n",
      "         [1.0015, 1.0273, 0.9950, 1.0000]],\n",
      "\n",
      "        [[1.1069, 1.1152, 0.9880, 1.0008],\n",
      "         [1.0008, 1.0209, 0.9670, 1.0051],\n",
      "         [1.0051, 1.0098, 0.9852, 1.0000]],\n",
      "\n",
      "        [[1.0565, 1.0644, 1.0161, 1.0177],\n",
      "         [1.0177, 1.0517, 1.0060, 1.0455],\n",
      "         [1.0455, 1.0536, 0.9873, 1.0000]]], device='cuda:0')}\n",
      "Target batch (y): tensor([[1.0072],\n",
      "        [1.0302],\n",
      "        [1.0021],\n",
      "        [1.1202],\n",
      "        [1.0445],\n",
      "        [1.0367],\n",
      "        [1.0065],\n",
      "        [1.0214],\n",
      "        [1.0063],\n",
      "        [1.1241],\n",
      "        [1.0652],\n",
      "        [1.0112],\n",
      "        [1.0060],\n",
      "        [1.0346],\n",
      "        [1.0272],\n",
      "        [1.0143],\n",
      "        [1.0067],\n",
      "        [1.0014],\n",
      "        [1.0044],\n",
      "        [1.0456]], device='cuda:0')\n",
      "Predicted output (y_pred): tensor([[-0.0473],\n",
      "        [-0.0464],\n",
      "        [-0.0452],\n",
      "        [-0.0444],\n",
      "        [-0.0480],\n",
      "        [-0.0442],\n",
      "        [-0.0473],\n",
      "        [-0.0461],\n",
      "        [-0.0457],\n",
      "        [-0.0463],\n",
      "        [-0.0476],\n",
      "        [-0.0474],\n",
      "        [-0.0449],\n",
      "        [-0.0460],\n",
      "        [-0.0453],\n",
      "        [-0.0453],\n",
      "        [-0.0464],\n",
      "        [-0.0475],\n",
      "        [-0.0486],\n",
      "        [-0.0457]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8a8086821944f4af2d2215d5f93586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([20, 1])\n",
      "  First label in batch: tensor([1.0049])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([20, 3, 4])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[1.0042, 1.0115, 0.9696, 0.9938],\n",
      "        [0.9938, 1.0357, 0.9894, 1.0057],\n",
      "        [1.0059, 1.0067, 0.9810, 1.0000]])\n",
      "\n",
      "✅ Combined df_seq shape: (60, 4)\n",
      "✅ Column names in df_seq: ['open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : LSTMAttentionSetRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 4}\n",
      "    hidden_dim: 100\n",
      "    num_layers: 1\n",
      "    max_len_y: 1\n",
      "    lr: 0.0001\n",
      "    bidirectional: True\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    first_drop: 0.2\n",
      "    scheduler_name: onecycle\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 1.180507, MAE: 1.085755 [original units]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_lstm_attention(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=300,\n",
    "    num_layers=2,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    bidirectional=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    attention_name = \"tanh_attention\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"onecycle\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False,\n",
    "    normal_loss = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            # make_step(add_candle_shape_features),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        True, \n",
    "        # False, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns, \"max len y\", max_len_y)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = LSTMAttentionSetRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        normal_loss = normal_loss,\n",
    "        attention_name = attention_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        bidirectional = bidirectional\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"bidirectional\":bidirectional,\n",
    "    \"attention_name\": attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model_lstm_attention(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True,\n",
    "        scale_labels = False,\n",
    "        max_epochs=100,\n",
    "        save_model = False,\n",
    "        hidden_dim=100,\n",
    "        num_layers=1,\n",
    "        lr=0.0001,\n",
    "        batch_size=20,\n",
    "        first_drop=.2,\n",
    "        scheduler_name = \"onecycle\",\n",
    "        optimizer_params={\"weight_decay\": 0.01},\n",
    "        scheduler_params={\"factor\": 0.2, \"patience\": 5} ,\n",
    "        normal_loss = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f636ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [0.       1.05529  0.923251 0.828937 0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.05529  0.923251 0.828937 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[0.44984102 0.45347178 0.41840607 0.43908027]\n",
      " [0.43915114 0.50778055 0.423001   0.4815808 ]\n",
      " [0.48206943 0.50233537 0.4643487  0.48960105]\n",
      " [0.48960105 0.501431   0.45673665 0.49419633]\n",
      " [0.49419695 0.5636583  0.47911596 0.55657494]\n",
      " [0.55657494 0.56257176 0.52542645 0.560165  ]\n",
      " [0.560165   0.5611551  0.5122603  0.52998203]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[0.48206943 0.50233537 0.4643487  0.48960105]\n",
      " [0.48960105 0.501431   0.45673665 0.49419633]\n",
      " [0.49419695 0.5636583  0.47911596 0.55657494]\n",
      " [0.55657494 0.56257176 0.52542645 0.560165  ]\n",
      " [0.560165   0.5611551  0.5122603  0.52998203]\n",
      " [0.5322404  0.53563523 0.42044067 0.4890442 ]\n",
      " [0.4890442  0.50865054 0.4597889  0.47255275]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (6, 4)\n",
      "[main] First few rows:\n",
      " [[0.55657494 0.56257176 0.52542645 0.560165  ]\n",
      " [0.560165   0.5611551  0.5122603  0.52998203]\n",
      " [0.5322404  0.53563523 0.42044067 0.4890442 ]\n",
      " [0.4890442  0.50865054 0.4597889  0.47255275]\n",
      " [0.47258556 0.4907874  0.4309192  0.48919347]\n",
      " [0.49027348 0.49121463 0.37410426 0.43444598]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "input dim {'main': 4}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LSTMKernelAttentionLSTMMultiRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 347\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 179\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, kernels, fusion_out_channels, lstm_out_channels, return_val_accuracy, test_mode, early_stop, optimizer_name, attention_name, first_drop, scheduler_name, optimizer_params, scheduler_params, scale_labels)\u001b[0m\n\u001b[1;32m    177\u001b[0m         input_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]}\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput dim\u001b[39m\u001b[38;5;124m\"\u001b[39m,input_dim)\n\u001b[0;32m--> 179\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTMKernelAttentionLSTMMultiRegressor\u001b[49m(\n\u001b[1;32m    180\u001b[0m         input_dim\u001b[38;5;241m=\u001b[39minput_dim,\n\u001b[1;32m    181\u001b[0m         hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m    182\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[1;32m    183\u001b[0m         max_len_y\u001b[38;5;241m=\u001b[39mmax_len_y,\n\u001b[1;32m    184\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    185\u001b[0m         kernels\u001b[38;5;241m=\u001b[39m kernels,\n\u001b[1;32m    186\u001b[0m         fusion_out_channels \u001b[38;5;241m=\u001b[39m fusion_out_channels,\n\u001b[1;32m    187\u001b[0m         lstm_out_channels\u001b[38;5;241m=\u001b[39m lstm_out_channels,\n\u001b[1;32m    188\u001b[0m         attention_name \u001b[38;5;241m=\u001b[39m attention_name,\n\u001b[1;32m    189\u001b[0m         optimizer_name\u001b[38;5;241m=\u001b[39m optimizer_name,\n\u001b[1;32m    190\u001b[0m         first_drop \u001b[38;5;241m=\u001b[39m first_drop,\n\u001b[1;32m    191\u001b[0m         scheduler_name \u001b[38;5;241m=\u001b[39m scheduler_name,\n\u001b[1;32m    192\u001b[0m         optimizer_params\u001b[38;5;241m=\u001b[39m optimizer_params,\n\u001b[1;32m    193\u001b[0m         scheduler_params\u001b[38;5;241m=\u001b[39m scheduler_params \n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     init_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_dim,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler_params\u001b[39m\u001b[38;5;124m\"\u001b[39m:scheduler_params\n\u001b[1;32m    210\u001b[0m }\n\u001b[1;32m    212\u001b[0m     model_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m ,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m ,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_args\n\u001b[1;32m    216\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTMKernelAttentionLSTMMultiRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    kernels= [3],\n",
    "    fusion_out_channels = 10,\n",
    "    lstm_out_channels=32,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    attention_name = \"tanh_attention\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = LSTMKernelAttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        kernels= kernels,\n",
    "        fusion_out_channels = fusion_out_channels,\n",
    "        lstm_out_channels= lstm_out_channels,\n",
    "        attention_name = attention_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"kernels\": kernels,\n",
    "    \"fusion_out_channels\" :fusion_out_channels,\n",
    "    \"lstm_out_channels\": lstm_out_channels,\n",
    "    \"attention_name\": attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=100,\n",
    "        save_model = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc8746",
   "metadata": {},
   "source": [
    "### Hungarian transfromer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e5a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.242173 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.242173]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.3036697 1.3155504 1.1531377 1.2362376]\n",
      " [1.236512  1.3073386 1.2062193 1.2421954]\n",
      " [1.2385321 1.2424706 0.8288991 1.       ]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.114845 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.114845]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.2195877 1.2259089 1.0732266 1.109815 ]\n",
      " [1.1090008 1.1302322 1.0515453 1.114974 ]\n",
      " [1.114974  1.1203835 0.9486662 1.       ]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.120154 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.120154]\n",
      "[main] Shape: (3, 4)\n",
      "[main] First few rows:\n",
      " [[1.147258   1.1587839  1.0902464  1.099486  ]\n",
      " [1.099486   1.143701   1.0899644  1.1211767 ]\n",
      " [1.1211767  1.1248015  0.97898066 1.        ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "input dim {'main': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name                  | Type                         | Params | Mode \n",
      "-------------------------------------------------------------------------------\n",
      "0 | embedding             | Linear                       | 500    | train\n",
      "1 | positional_encoding   | SinusoidalPositionalEncoding | 0      | train\n",
      "2 | custom_encoder_layers | ModuleList                   | 66.3 K | train\n",
      "3 | regressor             | Sequential                   | 5.1 K  | train\n",
      "  | other params          | n/a                          | 100    | n/a  \n",
      "-------------------------------------------------------------------------------\n",
      "72.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "72.0 K    Total params\n",
      "0.288     Total estimated model params size (MB)\n",
      "22        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c83131c09649deb6d0750ad553deac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fa0accf450484b843a0beb66b50705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([50, 1])\n",
      "  First label in batch: tensor([1.0021])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([50, 3, 4])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[1.0946, 1.0973, 0.9645, 0.9850],\n",
      "        [0.9852, 1.0200, 0.9791, 1.0021],\n",
      "        [1.0021, 1.0200, 0.9369, 1.0000]])\n",
      "\n",
      "✅ Combined df_seq shape: (150, 4)\n",
      "✅ Column names in df_seq: ['open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : TransformerWithPositionalEncoding\n",
      "  init_args:\n",
      "    input_dim: {'main': 4}\n",
      "    hidden_dim: 100\n",
      "    num_heads: 4\n",
      "    num_layers: 1\n",
      "    max_len_y: 1\n",
      "    lr: 0.0001\n",
      "    positional_encoding: sinusoidal\n",
      "    feedforward_dim: 128\n",
      "    optimizer_name: adamw\n",
      "    first_drop: 0.3\n",
      "    scheduler_name: reduce_on_plateau\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "    scheduler_params: {}\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 1.264758, MAE: 1.123840 [original units]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    positional_encoding=\"sinusoidal\", \n",
    "    num_heads=4,\n",
    "    feedforward_dim=128,\n",
    "    hidden_dim = 100,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    first_drop = 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        # False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "    print(\"input dim\",input_dim)\n",
    "    model = TransformerWithPositionalEncoding(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim = hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        positional_encoding = positional_encoding, \n",
    "        num_heads = num_heads,\n",
    "        feedforward_dim = feedforward_dim,\n",
    "        optimizer_name= optimizer_name,\n",
    "        first_drop = first_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_heads\": num_heads,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"positional_encoding\": positional_encoding,\n",
    "    \"feedforward_dim\" :feedforward_dim,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True,\n",
    "        scale_labels = False,\n",
    "        max_epochs=400,\n",
    "        num_heads=4,\n",
    "        feedforward_dim=128,\n",
    "        hidden_dim = 100,\n",
    "        positional_encoding=\"sinusoidal\",\n",
    "        save_model = False,\n",
    "        scheduler_name = \"reduce_on_plateau\",\n",
    "        scheduler_params={},\n",
    "        optimizer_name= \"adamw\",\n",
    "        first_drop = 0.3,\n",
    "        optimizer_params={\"weight_decay\": 0.01},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399de860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "high_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "low_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "close_prop",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "d882cf88-3c2d-455f-9193-5294a02567fe",
       "rows": [
        [
         "0",
         "1.0946264",
         "1.0972793",
         "0.96447265",
         "0.9850137"
        ],
        [
         "1",
         "0.9851636",
         "1.0200473",
         "0.9790629",
         "1.0021199"
        ],
        [
         "2",
         "1.0021199",
         "1.0200146",
         "0.9369444",
         "1.0"
        ],
        [
         "3",
         "1.1852896",
         "1.2007227",
         "1.1023691",
         "1.1112694"
        ],
        [
         "4",
         "1.1114982",
         "1.140259",
         "1.0738727",
         "1.1241392"
        ],
        [
         "5",
         "1.1228728",
         "1.1511936",
         "0.9725997",
         "1.0"
        ],
        [
         "6",
         "1.0114932",
         "1.0158978",
         "1.0003577",
         "1.0048949"
        ],
        [
         "7",
         "1.0048938",
         "1.0089089",
         "0.990802",
         "1.0063332"
        ],
        [
         "8",
         "1.0063332",
         "1.0085773",
         "0.995974",
         "1.0"
        ],
        [
         "9",
         "1.0028834",
         "1.0267755",
         "0.94312054",
         "0.9982481"
        ],
        [
         "10",
         "0.9981472",
         "1.0439754",
         "0.96958923",
         "1.0206116"
        ],
        [
         "11",
         "1.0203662",
         "1.0545676",
         "0.9986785",
         "1.0"
        ],
        [
         "12",
         "1.0295787",
         "1.042734",
         "1.015486",
         "1.0292453"
        ],
        [
         "13",
         "1.0292454",
         "1.0551788",
         "1.0241294",
         "1.0332692"
        ],
        [
         "14",
         "1.0332692",
         "1.0480225",
         "0.9969862",
         "1.0"
        ],
        [
         "15",
         "1.009589",
         "1.0374476",
         "0.9389758",
         "0.977917"
        ],
        [
         "16",
         "0.97792435",
         "1.0260124",
         "0.96215004",
         "1.0248799"
        ],
        [
         "17",
         "1.0248799",
         "1.0373284",
         "0.9727643",
         "1.0"
        ],
        [
         "18",
         "1.1695458",
         "1.1765813",
         "1.0319335",
         "1.0334103"
        ],
        [
         "19",
         "1.0333388",
         "1.1221502",
         "1.0215249",
         "1.0657355"
        ],
        [
         "20",
         "1.0657358",
         "1.1050941",
         "0.95468175",
         "1.0"
        ],
        [
         "21",
         "1.0098583",
         "1.0154507",
         "0.9915112",
         "1.0016719"
        ],
        [
         "22",
         "1.0016719",
         "1.0107921",
         "0.986687",
         "1.0069135"
        ],
        [
         "23",
         "1.0069135",
         "1.013697",
         "0.99858516",
         "1.0"
        ],
        [
         "24",
         "1.02034",
         "1.034664",
         "0.98675966",
         "1.0024605"
        ],
        [
         "25",
         "1.0026021",
         "1.0122323",
         "0.99253446",
         "1.0077221"
        ],
        [
         "26",
         "1.0077473",
         "1.0081077",
         "0.9961095",
         "1.0"
        ],
        [
         "27",
         "1.0424657",
         "1.0601007",
         "1.0176966",
         "1.0328035"
        ],
        [
         "28",
         "1.0326169",
         "1.0481427",
         "1.0208638",
         "1.044387"
        ],
        [
         "29",
         "1.044387",
         "1.0474805",
         "0.98952824",
         "1.0"
        ],
        [
         "30",
         "1.0606343",
         "1.094172",
         "1.014293",
         "1.0500574"
        ],
        [
         "31",
         "1.0500557",
         "1.0661869",
         "1.0237281",
         "1.0594816"
        ],
        [
         "32",
         "1.0594674",
         "1.0760295",
         "0.98457175",
         "1.0"
        ],
        [
         "33",
         "1.0081357",
         "1.0102496",
         "0.9980638",
         "1.003894"
        ],
        [
         "34",
         "1.003894",
         "1.015611",
         "1.0029778",
         "1.0057306"
        ],
        [
         "35",
         "1.0059314",
         "1.0071996",
         "0.996126",
         "1.0"
        ],
        [
         "36",
         "0.9995053",
         "1.0178198",
         "0.9853244",
         "0.9983665"
        ],
        [
         "37",
         "0.9985157",
         "1.0097044",
         "0.9981885",
         "1.0008037"
        ],
        [
         "38",
         "1.0005864",
         "1.005597",
         "0.98751813",
         "1.0"
        ],
        [
         "39",
         "1.0539544",
         "1.057411",
         "1.0263954",
         "1.032172"
        ],
        [
         "40",
         "1.032172",
         "1.0949526",
         "1.0305593",
         "1.0858215"
        ],
        [
         "41",
         "1.0858215",
         "1.090076",
         "0.9731603",
         "1.0"
        ],
        [
         "42",
         "1.0041511",
         "1.0115024",
         "0.9695643",
         "0.99381924"
        ],
        [
         "43",
         "0.99383146",
         "1.0357288",
         "0.9894168",
         "1.0056871"
        ],
        [
         "44",
         "1.0059192",
         "1.0067163",
         "0.98096496",
         "1.0"
        ],
        [
         "45",
         "1.0426732",
         "1.0426732",
         "0.99301636",
         "1.0327234"
        ],
        [
         "46",
         "1.0327431",
         "1.0538812",
         "1.0200928",
         "1.0373737"
        ],
        [
         "47",
         "1.037354",
         "1.0470848",
         "0.99754727",
         "1.0"
        ],
        [
         "48",
         "1.0520571",
         "1.0569746",
         "0.97656786",
         "0.9944799"
        ],
        [
         "49",
         "0.9944799",
         "1.0070086",
         "0.9635298",
         "1.0005529"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 150
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_prop</th>\n",
       "      <th>high_prop</th>\n",
       "      <th>low_prop</th>\n",
       "      <th>close_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.094626</td>\n",
       "      <td>1.097279</td>\n",
       "      <td>0.964473</td>\n",
       "      <td>0.985014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985164</td>\n",
       "      <td>1.020047</td>\n",
       "      <td>0.979063</td>\n",
       "      <td>1.002120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002120</td>\n",
       "      <td>1.020015</td>\n",
       "      <td>0.936944</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.185290</td>\n",
       "      <td>1.200723</td>\n",
       "      <td>1.102369</td>\n",
       "      <td>1.111269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.111498</td>\n",
       "      <td>1.140259</td>\n",
       "      <td>1.073873</td>\n",
       "      <td>1.124139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.000767</td>\n",
       "      <td>1.020895</td>\n",
       "      <td>0.967032</td>\n",
       "      <td>1.005074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.005074</td>\n",
       "      <td>1.009785</td>\n",
       "      <td>0.985172</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.147258</td>\n",
       "      <td>1.158784</td>\n",
       "      <td>1.090246</td>\n",
       "      <td>1.099486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.099486</td>\n",
       "      <td>1.143701</td>\n",
       "      <td>1.089964</td>\n",
       "      <td>1.121177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.121177</td>\n",
       "      <td>1.124802</td>\n",
       "      <td>0.978981</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     open_prop  high_prop  low_prop  close_prop\n",
       "0     1.094626   1.097279  0.964473    0.985014\n",
       "1     0.985164   1.020047  0.979063    1.002120\n",
       "2     1.002120   1.020015  0.936944    1.000000\n",
       "3     1.185290   1.200723  1.102369    1.111269\n",
       "4     1.111498   1.140259  1.073873    1.124139\n",
       "..         ...        ...       ...         ...\n",
       "145   1.000767   1.020895  0.967032    1.005074\n",
       "146   1.005074   1.009785  0.985172    1.000000\n",
       "147   1.147258   1.158784  1.090246    1.099486\n",
       "148   1.099486   1.143701  1.089964    1.121177\n",
       "149   1.121177   1.124802  0.978981    1.000000\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = df_seq.loc[~(df_seq==0).all(axis=1)]\n",
    "df_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc099c49",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754255c5",
   "metadata": {},
   "source": [
    "## MDN server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67861978",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.cnn_lstm_mdn import CNNLSTM_MDN  # <-- your updated \"last-output\" model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg*.pt\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\",FEATURES)\n",
    "# ---------------- Model ----------------\n",
    "# Reconstruct model class\n",
    "#for python file:\n",
    "# model_cls_info = meta[\"model_class_info\"]\n",
    "# ModelClass = import_class(model_cls_info[\"module\"], model_cls_info[\"class\"])\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "ModelClass = cnn_lstm\n",
    "# Initialize model with original args\n",
    "model = ModelClass(**model_cls_info[\"init_args\"])\n",
    "model = cnn_lstm.load_from_checkpoint(state_path)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv( \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"sequential.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        print(\"Returning initial candles:\", candles)\n",
    "\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            print(\"Reached end of data at index:\", next_idx)\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        # ✅ Add to preproc automatically\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # prepare subsequence from current state\n",
    "        seq_dict = preproc.prepare_seq(seq_len)  # returns dict of DataFrames\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mdn_out = model(dict_x)\n",
    "\n",
    "    pi    = mdn_out['pi'][0].cpu().numpy()\n",
    "    mu    = mdn_out['mu'][0].cpu().numpy()\n",
    "    sigma = mdn_out['sigma'][0].cpu().numpy()\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "\n",
    "    return jsonify({\n",
    "        'pred_prices': (last_close * mu).tolist(),\n",
    "        'pred_sigmas': (last_close * sigma).tolist(),\n",
    "        'pi': pi.tolist()\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65996c",
   "metadata": {},
   "source": [
    "## lstm two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = LSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"two_head.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "    print(\"dict\",dict_x)\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred, len_logits = model( dict_x, lengths)\n",
    "\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "    pred_len = model.predict_length(len_logits).item()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices,\n",
    "        \"pred_len\": pred_len\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f38c1",
   "metadata": {},
   "source": [
    "## Hungarian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using latest meta file: /home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_20250929_132333.pkl\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n",
      "init_args {'input_dim': {'main': 4}, 'hidden_dim': 60, 'num_layers': 1, 'max_len_y': 9, 'lr': 0.0001, 'kernels': [3], 'fusion_out_channels': 10, 'lstm_out_channels': 32, 'attention_name': 'tanh_attention', 'optimizer_name': 'adamw', 'first_drop': 0.3, 'scheduler_name': 'reduce_on_plateau', 'optimizer_params': {'weight_decay': 0.01}, 'scheduler_params': {'factor': 0.2, 'patience': 3}}\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:30] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:30] \"GET /get_and_add_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:34] \"GET /get_and_add_data?idx=21 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:34] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:40] \"GET /get_and_add_data?idx=22 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:40] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:43] \"GET /get_and_add_data?idx=23 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:43] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:43] \"GET /get_and_add_data?idx=24 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:44] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:44] \"GET /get_and_add_data?idx=25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:44] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:44] \"GET /get_and_add_data?idx=26 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:44] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"GET /get_and_add_data?idx=27 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"GET /get_and_add_data?idx=28 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"GET /get_and_add_data?idx=29 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"GET /get_and_add_data?idx=30 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"GET /get_and_add_data?idx=31 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"GET /get_and_add_data?idx=32 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"GET /get_and_add_data?idx=33 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"GET /get_and_add_data?idx=34 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"GET /get_and_add_data?idx=35 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"GET /get_and_add_data?idx=36 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Sep/2025 13:25:46] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_files = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")\n",
    "state_files = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")\n",
    "\n",
    "# Pick the newest (last modified)\n",
    "meta_path = max(meta_files, key=os.path.getmtime)\n",
    "state_path = max(state_files, key=os.path.getmtime)\n",
    "print(\"Using latest meta file:\", meta_path)\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_columns']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "print(\"init_args\",init_args)\n",
    "model = LSTMKernelAttentionLSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "pipeline.window_scalers = meta[\"window_scalers\"]\n",
    "pipeline.load_target_scalers(meta[\"target_scalers\"])\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"hungarian.html\")\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # --- Convert dict of DataFrames to dict of tensors ---\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "              for k, v in seq_dict.items()}\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    # --- Predict ---\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(dict_x, lengths)  # (batch, target_dim)\n",
    "\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "\n",
    "    # --- Inverse transform predictions ---\n",
    "    y_pred_inv = None\n",
    "    try:\n",
    "        # Case 1: Regular target scaler (used in pipeline)\n",
    "        if getattr(pipeline, \"target_scaler\", None):\n",
    "            scaler = pipeline.target_scaler\n",
    "            y_pred_inv = scaler.inverse_transform(y_pred_np)\n",
    "\n",
    "        # Case 2: Universal afterburner scaler for labels\n",
    "        elif hasattr(pipeline, \"afterburner_info\") and \"universal_scaler\" in pipeline.afterburner_info:\n",
    "            scaler = pipeline.afterburner_info[\"universal_scaler\"]\n",
    "            y_pred_inv = scaler.inverse_transform(y_pred_np)\n",
    "\n",
    "        # Case 3: No scaler → keep raw\n",
    "        else:\n",
    "            y_pred_inv = y_pred_np\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: inverse-scaling failed ({type(e).__name__}): {e}\")\n",
    "        y_pred_inv = y_pred_np\n",
    "\n",
    "    # --- Convert predictions to final prices ---\n",
    "    pred_prices = y_pred_inv[0].tolist()\n",
    "    last_close = float(preproc.reference_dataset.iloc[-1]['close'])\n",
    "    pred_prices = np.asarray(pred_prices, dtype=np.float32)\n",
    "    scaled_pred_prices = pred_prices * last_close\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": scaled_pred_prices.tolist()\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ec16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[<StreamHandler stderr (NOTSET)>]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"servers.pre_process\")\n",
    "print(logger.handlers)          # list of handlers attached to this logger\n",
    "print(logging.getLogger().handlers)  # root logger handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e43ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:16] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:16] \"GET /get_and_add_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:17] \"GET /validation_samples HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:19] \"POST /validation_test HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validation Test Sample 12 ---\n",
      "seq_len: 112, raw_ts: 1554595200000000000\n",
      "target_y: [0.7261959910392761, 0.7998110055923462, 0.6823400259017944, 0.9392110109329224, 0.6541470289230347, 0.0, 0.0, 0.0, 0.0]\n",
      "Converting reference_dataset index from int64 to datetime...\n",
      "Timestamp 2019-04-07 00:00:00 missing, reindexing...\n",
      "\n",
      "--- prepare_seq_valid debug ---\n",
      "Requested end_idx (raw): 2019-04-07 00:00:00, seq_len: 112\n",
      "Timestamp 2018-12-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-29 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-30 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-31 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-07 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-08 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-09 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-10 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-11 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-12 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-13 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-14 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-15 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-16 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-29 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-30 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-31 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-07 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-08 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-09 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-10 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-11 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-12 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-13 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-14 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-15 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-16 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-07 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-08 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-09 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-10 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-11 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-12 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-13 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-14 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-15 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-16 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-29 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-30 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-31 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-07 00:00:00 missing in dataset → adding candle\n",
      "Sliced 'main' shape: (21, 4)\n",
      "After apply_window 'main' shape: (21, 4)\n",
      "--- prepare_seq_valid end ---\n",
      "\n",
      "main: shape (21, 4), dtype float32\n",
      "lengths tensor: tensor([112])\n",
      "Passing dict_x['main'] to model: shape torch.Size([1, 21, 4])\n",
      "Model forward error: start (21) + length (1) exceeds dimension size (21).\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Current notebook location\n",
    "# notebook_path = Path().resolve()\n",
    "\n",
    "# # Add parent folder (meta/) to sys.path\n",
    "# sys.path.append(str(notebook_path.parent))\n",
    "# from pathlib import Path\n",
    "import pickle\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = CNNAttentionLSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\n",
    "    \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "    parse_dates=['timestamp']\n",
    ")\n",
    "# print(f\"DF loaded, shape: {df.shape}\")\n",
    "\n",
    "# ---------------- Load validation ----------------\n",
    "val_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/val_dataset_*.pkl\")[0]\n",
    "# print(f\"Loading validation dataset from: {val_path}\")\n",
    "\n",
    "with open(val_path, \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "# print(f\"Validation data keys: {list(val_data.keys())}\")\n",
    "# print(f\"Number of validation samples: {len(val_data['y'])}\")\n",
    "\n",
    "VAL_SAMPLES = []\n",
    "for i in range(len(val_data[\"y\"])):\n",
    "    seq_len = int(val_data[\"x_lengths\"][i])\n",
    "    time_indices = val_data[\"time_indices\"][i]  # timestamps, not integer indices\n",
    "    end_ts = pd.to_datetime(time_indices[-1])   # convert last timestamp to pd.Timestamp\n",
    "    \n",
    "    # print(f\"\\nSample {i}:\")\n",
    "    # print(f\"  seq_len: {seq_len}\")\n",
    "    # print(f\"  time_indices: {time_indices}\")\n",
    "    # print(f\"  end_ts: {end_ts}\")\n",
    "    \n",
    "    # find row index in df corresponding to this timestamp\n",
    "    matching_rows = df.index[df['timestamp'] == end_ts].tolist()\n",
    "    # if not matching_rows:\n",
    "    #     print(f\"  WARNING: no matching row in df for timestamp {end_ts}, skipping sample\")\n",
    "    #     continue\n",
    "    \n",
    "    row_idx = matching_rows[0]\n",
    "    end_time = str(df.iloc[row_idx].name)  # timestamp as string\n",
    "    \n",
    "    VAL_SAMPLES.append({\n",
    "        \"idx\": i,\n",
    "        \"seq_len\": seq_len,\n",
    "        \"end_idx\": row_idx,\n",
    "        \"end_time\": end_time\n",
    "    })\n",
    "\n",
    "# print(f\"\\nTotal valid samples loaded: {len(VAL_SAMPLES)}\")\n",
    "\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"hungarian2.html\")\n",
    "\n",
    "@app.route(\"/validation_samples\")\n",
    "def validation_samples():\n",
    "    return jsonify(VAL_SAMPLES)\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "              for k, v in seq_dict.items()}\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(dict_x, lengths)  # only regression head now\n",
    "    print(y_pred)\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices\n",
    "    })\n",
    "\n",
    "@app.route(\"/validation_test\", methods=[\"POST\"])\n",
    "def validation_test():\n",
    "    data = request.get_json(force=True)\n",
    "    sample_idx = data.get(\"sample_idx\")\n",
    "    \n",
    "    if sample_idx is None or not (0 <= sample_idx < len(val_data[\"y\"])):\n",
    "        return jsonify({\"error\": \"Invalid sample_idx\"}), 400\n",
    "\n",
    "    seq_len = int(val_data[\"x_lengths\"][sample_idx])\n",
    "    raw_ts = int(val_data[\"time_indices\"][sample_idx][-1])  # nanoseconds\n",
    "    ts = pd.to_datetime(raw_ts)  # Timestamp\n",
    "\n",
    "    target_y = val_data[\"y\"][sample_idx][:seq_len].tolist()\n",
    "\n",
    "    print(f\"\\n--- Validation Test Sample {sample_idx} ---\")\n",
    "    print(f\"seq_len: {seq_len}, raw_ts: {raw_ts}\")\n",
    "    print(f\"target_y: {target_y}\")\n",
    "\n",
    "    # --- Ensure reference dataset has datetime index ---\n",
    "    ref = preproc.reference_dataset\n",
    "    if np.issubdtype(ref.index.dtype, np.integer):\n",
    "        print(\"Converting reference_dataset index from int64 to datetime...\")\n",
    "        ref.index = pd.to_datetime(ref.index)\n",
    "\n",
    "    # --- Make sure requested timestamp exists ---\n",
    "    if ts not in ref.index:\n",
    "        print(f\"Timestamp {ts} missing, reindexing...\")\n",
    "        freq = pd.infer_freq(ref.index[:10]) or \"D\"  # auto-detect, fallback daily\n",
    "        full_index = pd.date_range(start=ref.index.min(), end=ref.index.max(), freq=freq)\n",
    "        ref = ref.reindex(full_index, method=\"ffill\")\n",
    "        preproc.reference_dataset = ref\n",
    "\n",
    "    # --- Prepare sequence ---\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq_valid(end_idx=ts, seq_len=seq_len)\n",
    "    except ValueError as e:\n",
    "        print(f\"prepare_seq_valid error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert to tensors\n",
    "    dict_x = {}\n",
    "    for k, v in seq_dict.items():\n",
    "        arr = v.values.astype(np.float32)\n",
    "        dict_x[k] = torch.from_numpy(arr).unsqueeze(0)  # add batch dim\n",
    "        print(f\"{k}: shape {arr.shape}, dtype {arr.dtype}\")\n",
    "\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "    print(f\"lengths tensor: {lengths}\")\n",
    "\n",
    "    # Model forward\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            print(f\"Passing dict_x['main'] to model: shape {dict_x['main'].shape}\")\n",
    "            y_pred = model(dict_x, lengths)\n",
    "            print(f\"y_pred shape: {y_pred.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model forward error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "    last_close = preproc.reference_dataset.loc[ts, 'close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "\n",
    "    return jsonify({\n",
    "        \"sample_idx\": sample_idx,\n",
    "        \"end_time\": int(ts.timestamp() * 1000),  # unix ms for frontend\n",
    "        \"seq_len\": seq_len,\n",
    "        \"pred_prices\": pred_prices,\n",
    "        \"target_y\": target_y\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae95b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "caf18009-c014-40df-bd99-518fd835a07c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1514937600",
         "1515456000",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516147200",
         "1516492800",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1519862400",
         "1520121600",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "45",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "48",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "49",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 364
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1514937600</td>\n",
       "      <td>1515456000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1647216000</td>\n",
       "      <td>1648339200</td>\n",
       "      <td>1533</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.889793</td>\n",
       "      <td>0.902754</td>\n",
       "      <td>0.847861</td>\n",
       "      <td>0.840999</td>\n",
       "      <td>0.814315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1629417600</td>\n",
       "      <td>1630108800</td>\n",
       "      <td>1327</td>\n",
       "      <td>1335</td>\n",
       "      <td>1.001120</td>\n",
       "      <td>1.013533</td>\n",
       "      <td>0.976295</td>\n",
       "      <td>1.031057</td>\n",
       "      <td>0.963152</td>\n",
       "      <td>0.958041</td>\n",
       "      <td>0.944168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1612742400</td>\n",
       "      <td>1613174400</td>\n",
       "      <td>1134</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.984341</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>1.021441</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>0.930585</td>\n",
       "      <td>1.035826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1608940800</td>\n",
       "      <td>1609632000</td>\n",
       "      <td>1090</td>\n",
       "      <td>1098</td>\n",
       "      <td>0.795270</td>\n",
       "      <td>0.875328</td>\n",
       "      <td>0.805007</td>\n",
       "      <td>0.861264</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1588636800</td>\n",
       "      <td>1594166400</td>\n",
       "      <td>855</td>\n",
       "      <td>919</td>\n",
       "      <td>1.048390</td>\n",
       "      <td>1.078658</td>\n",
       "      <td>0.957585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919750</td>\n",
       "      <td>0.870564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.108926</td>\n",
       "      <td>0.99542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1514937600  1515456000           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "359  1647216000  1648339200        1533      1546     0.873783     0.889793   \n",
       "360  1629417600  1630108800        1327      1335     1.001120     1.013533   \n",
       "361  1612742400  1613174400        1134      1139     0.984341     1.000241   \n",
       "362  1608940800  1609632000        1090      1098     0.795270     0.875328   \n",
       "363  1588636800  1594166400         855       919     1.048390     1.078658   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "359     0.902754     0.847861     0.840999     0.814315          NaN   \n",
       "360     0.976295     1.031057     0.963152     0.958041     0.944168   \n",
       "361     1.021441     0.949513     0.930585     1.035826          NaN   \n",
       "362     0.805007     0.861264     0.783370          NaN          NaN   \n",
       "363     0.957585          NaN     0.919750     0.870564          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "359          NaN          NaN  \n",
       "360          NaN          NaN  \n",
       "361          NaN          NaN  \n",
       "362          NaN          NaN  \n",
       "363     1.108926      0.99542  \n",
       "\n",
       "[364 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv( \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4c8b3",
   "metadata": {},
   "source": [
    "## xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "from servers.pre_process.multi_reg_dif_seq import ServerPreprocess, build_pipeline_from_config\n",
    "\n",
    "# ---------------- Flask ----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load models + meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_meta_multireg_*.pkl\")[0]\n",
    "model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_multireg_*.pkl\")[0]\n",
    "len_model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_seq_len_*.pkl\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Models\n",
    "model = joblib.load(model_path)       # MultiOutputRegressor with XGBRegressor inside\n",
    "len_model = joblib.load(len_model_path)\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"xgboost_seq.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Use your XGBoost + preproc logic\n",
    "        X_np = preproc.prepare_xgboost_seq(seq_len, model=len_model)\n",
    "        pred_len = int(np.round(len_model.predict(X_np))[0])\n",
    "        y_pred_full = model.predict(X_np)[0]\n",
    "        pred_trunc = np.sort(y_pred_full[:pred_len])\n",
    "        last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "        pred_scaled = (last_close * pred_trunc).tolist()\n",
    "\n",
    "        return jsonify({\n",
    "            'pred_length': pred_len,\n",
    "            'pred_lines': pred_scaled\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # <-- This will print the actual exception in the console\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc07d3a",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09e37c",
   "metadata": {},
   "source": [
    "## tensorboard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06403bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching TensorBoard for: lightning_logs/version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:40:23.482869: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "2025-09-20 22:40:23.713288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758395423.784945   70469 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758395423.810144   70469 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758395423.989054   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758395423.989087   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758395423.989090   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758395423.989091   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-20 22:40:24.009084: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "logdir = \"lightning_logs\"\n",
    "\n",
    "# 1. Find all version folders\n",
    "versions = [d for d in os.listdir(logdir) if d.startswith(\"version_\") and d.split(\"_\")[1].isdigit()]\n",
    "if not versions:\n",
    "    raise ValueError(\"No version folders found in lightning_logs\")\n",
    "\n",
    "# 2. Pick the latest numerically\n",
    "latest_version = max(versions, key=lambda x: int(x.split(\"_\")[1]))\n",
    "latest_logdir = os.path.join(logdir, latest_version)\n",
    "print(f\"Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\"tensorboard\", f\"--logdir={latest_logdir}\", f\"--port={port}\"])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264cbc4",
   "metadata": {},
   "source": [
    "## tensoarboard tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec717ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Launching TensorBoard for: /home/iatell/projects/meta-learning/tune_logs/transformer_tuning_20251005_163143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "2025-10-05 17:22:28.060364: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-05 17:22:28.297932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759672348.376268   71337 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759672348.401753   71337 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759672348.595588   71337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759672348.595682   71337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759672348.595685   71337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759672348.595687   71337 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-05 17:22:28.617325: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "# Base Ray Tune log directory\n",
    "base_logdir = \"/home/iatell/projects/meta-learning/tune_logs\"\n",
    "\n",
    "# 1. Find all experiment folders\n",
    "experiments = [d for d in os.listdir(base_logdir) if os.path.isdir(os.path.join(base_logdir, d))]\n",
    "if not experiments:\n",
    "    raise ValueError(\"No experiment folders found in tune_logs\")\n",
    "\n",
    "# 2. Sort by modification time and get the latest experiment\n",
    "experiments.sort(key=lambda x: os.path.getmtime(os.path.join(base_logdir, x)))\n",
    "latest_experiment = experiments[-1]\n",
    "latest_logdir = os.path.join(base_logdir, latest_experiment)\n",
    "print(f\"🚀 Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\n",
    "    \"tensorboard\",\n",
    "    f\"--logdir={latest_logdir}\",\n",
    "    f\"--port={port}\"\n",
    "])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609a59a",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd2907",
   "metadata": {},
   "source": [
    "## tuning cnn- attention lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c39a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "def resource_usage():\n",
    "    \"\"\"Print current CPU, RAM, and GPU usage.\"\"\"\n",
    "    cpu = psutil.cpu_percent(interval=0.5)\n",
    "    ram = psutil.virtual_memory().percent\n",
    "    usage = f\"💻 CPU: {cpu:.1f}% | 🧠 RAM: {ram:.1f}%\"\n",
    "    try:\n",
    "        import GPUtil\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if gpus:\n",
    "            usage += f\" | 🎮 GPU: {gpus[0].load*100:.1f}% VRAM: {gpus[0].memoryUtil*100:.1f}%\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    print(usage)\n",
    "\n",
    "\n",
    "def train_cnn_lstm_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    Args:\n",
    "        config (dict): hyperparameters for this trial.\n",
    "    \"\"\"\n",
    "    resource_usage()  # Show current hardware usage\n",
    "\n",
    "    # Train using existing train_model function\n",
    "    metrics = train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        # seq_len=config[\"seq_len\"],\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        # num_layers=config[\"num_layers\"],\n",
    "        lr=config[\"lr\"],\n",
    "        # batch_size=config[\"batch_size\"],\n",
    "        # max_epochs=config[\"max_epochs\"],\n",
    "        return_val_accuracy=True,  # Expects dict with \"accuracy\" and optionally \"loss\"\n",
    "        save_model=False  # Never save during search\n",
    "    )\n",
    "\n",
    "    # Report metrics to Ray Tune\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=True):\n",
    "    \"\"\"Hyperparameter tuning for CNN LSTM with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # LSTM / model\n",
    "        \"hidden_dim\": tune.choice([32, 64, 128, 256]),\n",
    "        # \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        # \"attention_name\": tune.choice([\"simple_attention\", \"tanh_attention\"]),\n",
    "\n",
    "        # Learning rate & optimizer\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "\n",
    "        # Scheduler\n",
    "        # \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"cosine\", \"onecycle\"]),\n",
    "        # \"scheduler_params\": {\n",
    "            # \"factor\": tune.loguniform(0.05, 0.5),      # only used for ReduceLROnPlateau\n",
    "            # \"patience\": tune.choice([2, 3, 5, 7]),     # only used for ReduceLROnPlateau\n",
    "            # \"T_max\": tune.choice([10, 20, 50]),        # only used for CosineAnnealingLR\n",
    "            # \"eta_min\": tune.loguniform(1e-6, 1e-4)    # only used for CosineAnnealingLR\n",
    "        # },\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # CNN params\n",
    "        # \"kernels\": tune.choice([[3,5,7,11], [3,5,7], [3,5]]),\n",
    "        \"cnn_out_channels\": tune.choice([ 32, 64]),\n",
    "        # \"first_drop\": tune.uniform(0.1, 0.5),\n",
    "        # \"second_drop\": tune.uniform(0.1, 0.5),\n",
    "        # \"third_drop\": tune.uniform(0.1, 0.5),\n",
    "\n",
    "        # Training\n",
    "        # \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        # \"max_epochs\": tune.choice([50, 100, 150]),\n",
    "    }    \n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",  # must exist in metrics dict from train_model\n",
    "        mode=\"max\",\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        train_cnn_lstm_tune,\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=10\n",
    "        ),\n",
    "    run_config=air.RunConfig(\n",
    "        name=\"cnn_lstm_tuning\",\n",
    "        storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "    ),\n",
    "    # runtime_env=runtime_env\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Best trial\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "    print(\"\\n🏆 Best Config:\", best_result.config)\n",
    "    print(f\"Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # Optional: retrain best model on full data and save\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        # Map scheduler params depending on scheduler type\n",
    "        scheduler_name = best_result.config.get(\"scheduler_name\")\n",
    "        scheduler_params_config = best_result.config.get(\"scheduler_params\", {})\n",
    "\n",
    "        if scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler_params = {\n",
    "                \"factor\": scheduler_params_config.get(\"factor\", 0.2),\n",
    "                \"patience\": scheduler_params_config.get(\"patience\", 3)\n",
    "            }\n",
    "        elif scheduler_name == \"cosine\":\n",
    "            scheduler_params = {\n",
    "                \"T_max\": scheduler_params_config.get(\"T_max\", 10),\n",
    "                \"eta_min\": scheduler_params_config.get(\"eta_min\", 1e-6)\n",
    "            }\n",
    "        else:  # onecycle or others\n",
    "            scheduler_params = {}\n",
    "\n",
    "        # Optimizer params\n",
    "        optimizer_params = best_result.config.get(\"optimizer_params\", {\"weight_decay\": 0.01})\n",
    "\n",
    "        train_model(\n",
    "            data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "            labels_csv=\"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "            do_validation=True,\n",
    "            return_val_accuracy=True,\n",
    "            model_out_dir=\"models/saved_models\",\n",
    "            hidden_dim=best_result.config.get(\"hidden_dim\", 32),\n",
    "            num_layers=best_result.config.get(\"num_layers\", 1),\n",
    "            attention_name=best_result.config.get(\"attention_name\", \"tanh_attention\"),\n",
    "            optimizer_name=best_result.config.get(\"optimizer_name\", \"adamw\"),\n",
    "            lr=best_result.config.get(\"lr\", 1e-3),\n",
    "            batch_size=best_result.config.get(\"batch_size\", 32),\n",
    "            max_epochs=best_result.config.get(\"max_epochs\", 10),\n",
    "            kernels=best_result.config.get(\"kernels\", [3, 5, 7, 11]),\n",
    "            cnn_out_channels=best_result.config.get(\"cnn_out_channels\", 32),\n",
    "            first_drop=best_result.config.get(\"first_drop\", 0.3),\n",
    "            second_drop=best_result.config.get(\"second_drop\", 0.3),\n",
    "            third_drop=best_result.config.get(\"third_drop\", 0.3),\n",
    "            scheduler_name=scheduler_name,\n",
    "            scheduler_params=scheduler_params,\n",
    "            optimizer_params=optimizer_params\n",
    "        )\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "# Fixed arguments for data files and directories\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.json\"\n",
    "\n",
    "\n",
    "def train_cnn_lstm_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    Args:\n",
    "        config (dict): hyperparameters for this trial.\n",
    "    \"\"\"\n",
    "    resource_usage()  # Show current hardware usage\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Start with fixed args\n",
    "    train_args = fixed_args.copy()\n",
    "\n",
    "    # Core hyperparameters from the config\n",
    "    train_args[\"hidden_dim\"] = config[\"hidden_dim\"]\n",
    "    train_args[\"lr\"] = config[\"lr\"]\n",
    "    train_args[\"cnn_out_channels\"] = config[\"cnn_out_channels\"]\n",
    "\n",
    "    # Optimizer configuration\n",
    "    train_args[\"optimizer_name\"] = config[\"optimizer_name\"]\n",
    "    train_args[\"optimizer_params\"] = {\n",
    "        \"weight_decay\": config[\"optimizer_params\"][\"weight_decay\"]\n",
    "    }\n",
    "\n",
    "    # Scheduler configuration\n",
    "    train_args[\"scheduler_name\"] = config[\"scheduler_name\"]\n",
    "    # Scheduler configuration\n",
    "    train_args[\"scheduler_name\"] = config.get(\"scheduler_name\", \"none\")\n",
    "\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        # Safely get nested params, or fallback to defaults\n",
    "        sp = config.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train the model\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for CNN LSTM with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # LSTM / model\n",
    "        \"hidden_dim\": tune.choice([32, 64, 128, 256]),\n",
    "\n",
    "        # Learning rate & optimizer\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "\n",
    "        # Optimizer params\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        # ✅ Optional nested params for reduce_on_plateau\n",
    "        \"scheduler_params\": {\n",
    "            \"factor\": tune.choice([0.1, 0.5]),\n",
    "            \"patience\": tune.choice([3, 5, 10]),\n",
    "        },\n",
    "        # CNN params\n",
    "        \"cnn_out_channels\": tune.choice([32, 64]),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",  # must exist in metrics dict from train_model\n",
    "        mode=\"max\",\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    # Unique run name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"cnn_lstm_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_cnn_lstm_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=10,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Best result\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "    print(\"\\n🏆 Best Config:\", best_result.config)\n",
    "    print(f\"Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # Retrain with best config\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "\n",
    "            # From best config\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"cnn_out_channels\": best_result.config[\"cnn_out_channels\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "\n",
    "            # Nested dicts\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_params\": best_result.config[\"scheduler_params\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc50a3",
   "metadata": {},
   "source": [
    "## Hungarian transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16500ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-06 17:47:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:08:40.72        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  feedforward_dim</th><th style=\"text-align: right;\">  first_drop</th><th style=\"text-align: right;\">         lr</th><th>optimizer_name  </th><th style=\"text-align: right;\">            optimizer_params/wei\n",
       "ght_decay</th><th>positional_encoding  </th><th>scheduler_name   </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_transformer_tune_f1848_00000</td><td>TERMINATED</td><td>172.18.55.78:49781</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">0.000359688</td><td>adamw           </td><td style=\"text-align: right;\">5.62181e-05</td><td>rotary               </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.0514</td><td style=\"text-align: right;\">-0.00664419 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00001</td><td>TERMINATED</td><td>172.18.55.78:49975</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.00360892 </td><td>adam            </td><td style=\"text-align: right;\">0.000855052</td><td>relative             </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.9164</td><td style=\"text-align: right;\">-0.00178589 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00002</td><td>TERMINATED</td><td>172.18.55.78:50154</td><td style=\"text-align: right;\">              256</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.000452029</td><td>adam            </td><td style=\"text-align: right;\">0.00633274 </td><td>learnable            </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.3875</td><td style=\"text-align: right;\">-0.00334822 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00003</td><td>TERMINATED</td><td>172.18.55.78:50354</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">0.00221425 </td><td>adamw           </td><td style=\"text-align: right;\">0.00843959 </td><td>sinusoidal           </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.1542</td><td style=\"text-align: right;\">-0.0134844  </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00004</td><td>TERMINATED</td><td>172.18.55.78:50529</td><td style=\"text-align: right;\">              256</td><td style=\"text-align: right;\">         0.4</td><td style=\"text-align: right;\">0.00167381 </td><td>adamw           </td><td style=\"text-align: right;\">1.08425e-05</td><td>learnable            </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.4272</td><td style=\"text-align: right;\">-0.0224829  </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00005</td><td>TERMINATED</td><td>172.18.55.78:50749</td><td style=\"text-align: right;\">              512</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.000205553</td><td>adam            </td><td style=\"text-align: right;\">0.00910129 </td><td>learnable            </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         34.5792</td><td style=\"text-align: right;\">-0.00183015 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00006</td><td>TERMINATED</td><td>172.18.55.78:50933</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">0.00078554 </td><td>adam            </td><td style=\"text-align: right;\">0.00685279 </td><td>relative             </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.5461</td><td style=\"text-align: right;\">-0.00418836 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00007</td><td>TERMINATED</td><td>172.18.55.78:51092</td><td style=\"text-align: right;\">              256</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">0.00129701 </td><td>adam            </td><td style=\"text-align: right;\">0.00239229 </td><td>learnable            </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         57.24  </td><td style=\"text-align: right;\">-0.00639179 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00008</td><td>TERMINATED</td><td>172.18.55.78:51344</td><td style=\"text-align: right;\">              256</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">0.00168858 </td><td>adam            </td><td style=\"text-align: right;\">0.00862159 </td><td>rotary               </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.0364</td><td style=\"text-align: right;\">-0.00199138 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00009</td><td>TERMINATED</td><td>172.18.55.78:51506</td><td style=\"text-align: right;\">              256</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.00120469 </td><td>adam            </td><td style=\"text-align: right;\">0.00963369 </td><td>relative             </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.4301</td><td style=\"text-align: right;\">-0.00366883 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00010</td><td>TERMINATED</td><td>172.18.55.78:51668</td><td style=\"text-align: right;\">              256</td><td style=\"text-align: right;\">         0.4</td><td style=\"text-align: right;\">0.000447948</td><td>adamw           </td><td style=\"text-align: right;\">1.85389e-05</td><td>relative             </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.2148</td><td style=\"text-align: right;\">-0.00194225 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00011</td><td>TERMINATED</td><td>172.18.55.78:51828</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.000341238</td><td>adam            </td><td style=\"text-align: right;\">0.000753604</td><td>rotary               </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.0789</td><td style=\"text-align: right;\">-0.00159661 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00012</td><td>TERMINATED</td><td>172.18.55.78:51980</td><td style=\"text-align: right;\">              512</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.000630073</td><td>adamw           </td><td style=\"text-align: right;\">4.33521e-05</td><td>sinusoidal           </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         46.3471</td><td style=\"text-align: right;\">-0.000581014</td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00013</td><td>TERMINATED</td><td>172.18.55.78:52201</td><td style=\"text-align: right;\">              512</td><td style=\"text-align: right;\">         0.2</td><td style=\"text-align: right;\">0.00290153 </td><td>adamw           </td><td style=\"text-align: right;\">1.37182e-05</td><td>sinusoidal           </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.0702</td><td style=\"text-align: right;\">-0.00360789 </td></tr>\n",
       "<tr><td>train_transformer_tune_f1848_00014</td><td>TERMINATED</td><td>172.18.55.78:52391</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">         0.4</td><td style=\"text-align: right;\">0.00367104 </td><td>adamw           </td><td style=\"text-align: right;\">0.000116297</td><td>relative             </td><td>onecycle         </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.5546</td><td style=\"text-align: right;\">-0.00522787 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 17:47:14,023\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/iatell/projects/meta-learning/tune_logs/transformer_tuning_20251006_173833' in 0.0033s.\n",
      "2025-10-06 17:47:14,028\tINFO tune.py:1041 -- Total run time: 520.74 seconds (520.71 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Config:\n",
      "{'feedforward_dim': 512, 'first_drop': 0.2, 'lr': 0.0006300725294394885, 'optimizer_name': 'adamw', 'optimizer_params': {'weight_decay': 4.3352130782864506e-05}, 'scheduler_name': 'onecycle', 'positional_encoding': 'sinusoidal'}\n",
      "✅ Best Accuracy: -0.0006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "# labels_csv = \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_transformer_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your Transformer model.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 128,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"num_heads\": 1,\n",
    "        \"feedforward_dim\": 10,\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"positional_encoding\": \"sinusoidal\",\n",
    "        \"max_epochs\": 200,\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        num_heads=config.get(\"num_heads\", default_params[\"num_heads\"]),\n",
    "        feedforward_dim=config.get(\"feedforward_dim\", default_params[\"feedforward_dim\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        positional_encoding=config.get(\"positional_encoding\", default_params[\"positional_encoding\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your Transformer model with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # Transformer / architecture\n",
    "        # \"hidden_dim\": tune.choice([64, 128, 256]),\n",
    "        # \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        # \"num_heads\": tune.choice([2, 4, 8]),\n",
    "        \"feedforward_dim\": tune.choice([128, 256, 512]),\n",
    "\n",
    "        # Dropouts\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "\n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # max_epochs added to the search space\n",
    "        # \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Positional encoding options\n",
    "        \"positional_encoding\": tune.choice([\"sinusoidal\", \"learnable\", \"relative\", \"rotary\"]),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"transformer_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_transformer_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"dropout\": best_result.config[\"dropout\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"num_heads\": best_result.config[\"num_heads\"],\n",
    "            \"feedforward_dim\": best_result.config[\"feedforward_dim\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            # Add positional_encoding and max_epochs for retraining\n",
    "            \"positional_encoding\": best_result.config[\"positional_encoding\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd631b3",
   "metadata": {},
   "source": [
    "## Hungarian lstm + attention gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your Transformer model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 300,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 2,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"bidirectional\": True,\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"attention_name\": \"tanh_attention\",\n",
    "        \"scheduler_name\": \"onecycle\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "        \"normal_loss\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        bidirectional=config.get(\"bidirectional\", default_params[\"bidirectional\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        attention_name=config.get(\"attention_name\", default_params[\"attention_name\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "        normal_loss=config.get(\"normal_loss\", default_params[\"normal_loss\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model_lstm_attention(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your Transformer model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([128, 256, 512]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Attention & Dropouts\n",
    "        \"attention_name\": tune.choice([\"tanh_attention\", \"simple_attention\"]),\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \n",
    "        # Other parameters\n",
    "        \"bidirectional\": tune.choice([True, False]),\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"transformer_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"attention_name\": best_result.config[\"attention_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"bidirectional\": best_result.config[\"bidirectional\"],\n",
    "            \"normal_loss\": best_result.config[\"normal_loss\"],\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "        }\n",
    "\n",
    "        train_model_lstm_attention(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9528db",
   "metadata": {},
   "source": [
    "## Hungarian lstm kernel + attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_lstm_kernel_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your LSTM Kernel model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 60,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"kernels\": [3],\n",
    "        \"fusion_out_channels\": 10,\n",
    "        \"lstm_out_channels\": 32,\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"attention_name\": \"tanh_attention\",\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        kernels=config.get(\"kernels\", default_params[\"kernels\"]),\n",
    "        fusion_out_channels=config.get(\"fusion_out_channels\", default_params[\"fusion_out_channels\"]),\n",
    "        lstm_out_channels=config.get(\"lstm_out_channels\", default_params[\"lstm_out_channels\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        attention_name=config.get(\"attention_name\", default_params[\"attention_name\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model_lstm_kernel(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your LSTM Kernel model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([64, 128, 256]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Kernels and Channels\n",
    "        \"kernels\": tune.choice([[3], [5], [3, 5]]),  # Example of kernel sizes\n",
    "        \"fusion_out_channels\": tune.choice([8, 16, 32]),\n",
    "        \"lstm_out_channels\": tune.choice([16, 32, 64]),\n",
    "\n",
    "        # Attention & Dropouts\n",
    "        \"attention_name\": tune.choice([\"tanh_attention\", \"simple_attention\"]),\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \n",
    "        # Other parameters\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"lstm_kernel_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_lstm_kernel_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"kernels\": best_result.config[\"kernels\"],\n",
    "            \"fusion_out_channels\": best_result.config[\"fusion_out_channels\"],\n",
    "            \"lstm_out_channels\": best_result.config[\"lstm_out_channels\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"attention_name\": best_result.config[\"attention_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"test_mode\": best_result.config[\"test_mode\"],\n",
    "            \"early_stop\": best_result.config[\"early_stop\"],\n",
    "        }\n",
    "\n",
    "        train_model_lstm_kernel(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b18ce8",
   "metadata": {},
   "source": [
    "## Hungarian lstm kernel pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 60,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"kernels\": [3],\n",
    "        \"fusion_out_channels\": 10,\n",
    "        \"lstm_out_channels\": 32,\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        kernels=config.get(\"kernels\", default_params[\"kernels\"]),\n",
    "        fusion_out_channels=config.get(\"fusion_out_channels\", default_params[\"fusion_out_channels\"]),\n",
    "        lstm_out_channels=config.get(\"lstm_out_channels\", default_params[\"lstm_out_channels\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([64, 128, 256]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Kernels and Channels\n",
    "        \"kernels\": tune.choice([[3], [5], [3, 5]]),  # Example of kernel sizes\n",
    "        \"fusion_out_channels\": tune.choice([8, 16, 32]),\n",
    "        \"lstm_out_channels\": tune.choice([16, 32, 64]),\n",
    "\n",
    "        # Dropout and Other Parameters\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"model_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"kernels\": best_result.config[\"kernels\"],\n",
    "            \"fusion_out_channels\": best_result.config[\"fusion_out_channels\"],\n",
    "            \"lstm_out_channels\": best_result.config[\"lstm_out_channels\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"test_mode\": best_result.config[\"test_mode\"],\n",
    "            \"early_stop\": best_result.config[\"early_stop\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56829460",
   "metadata": {},
   "source": [
    "## Hungarian CNN pure lstm 2 bidrectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8798cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 60,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"kernels\": [3],\n",
    "        \"fusion_out_channels\": 10,\n",
    "        \"lstm_out_channels\": 32,\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        kernels=config.get(\"kernels\", default_params[\"kernels\"]),\n",
    "        fusion_out_channels=config.get(\"fusion_out_channels\", default_params[\"fusion_out_channels\"]),\n",
    "        lstm_out_channels=config.get(\"lstm_out_channels\", default_params[\"lstm_out_channels\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([64, 128, 256]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Kernels and Channels\n",
    "        \"kernels\": tune.choice([[3], [5], [3, 5]]),  # Example of kernel sizes\n",
    "        \"fusion_out_channels\": tune.choice([8, 16, 32]),\n",
    "        \"lstm_out_channels\": tune.choice([16, 32, 64]),\n",
    "\n",
    "        # Dropout and Other Parameters\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"model_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"kernels\": best_result.config[\"kernels\"],\n",
    "            \"fusion_out_channels\": best_result.config[\"fusion_out_channels\"],\n",
    "            \"lstm_out_channels\": best_result.config[\"lstm_out_channels\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"test_mode\": best_result.config[\"test_mode\"],\n",
    "            \"early_stop\": best_result.config[\"early_stop\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3947f",
   "metadata": {},
   "source": [
    "## Hungarian CNN attention lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 60,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"second_drop\": 0.3,\n",
    "        \"third_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"attention_name\": \"tanh_attention\",\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"kernels\": [3, 5, 7, 11],\n",
    "        \"cnn_out_channels\": 32,\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 5},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        second_drop=config.get(\"second_drop\", default_params[\"second_drop\"]),\n",
    "        third_drop=config.get(\"third_drop\", default_params[\"third_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        attention_name=config.get(\"attention_name\", default_params[\"attention_name\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        kernels=config.get(\"kernels\", default_params[\"kernels\"]),\n",
    "        cnn_out_channels=config.get(\"cnn_out_channels\", default_params[\"cnn_out_channels\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([128, 256, 512]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # CNN & Attention Layers\n",
    "        \"kernels\": tune.choice([[3], [5], [7], [11], [3, 5], [5, 7]]),\n",
    "        \"cnn_out_channels\": tune.choice([32, 64, 128, 256]),\n",
    "\n",
    "        # Dropout layers\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \"second_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \"third_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \n",
    "        # Other parameters\n",
    "        \"attention_name\": tune.choice([\"tanh_attention\", \"simple_attention\"]),\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"model_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"second_drop\": best_result.config[\"second_drop\"],\n",
    "            \"third_drop\": best_result.config[\"third_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"kernels\": best_result.config[\"kernels\"],\n",
    "            \"cnn_out_channels\": best_result.config[\"cnn_out_channels\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"test_mode\": best_result.config[\"test_mode\"],\n",
    "            \"early_stop\": best_result.config[\"early_stop\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351d8cf",
   "metadata": {},
   "source": [
    "## Hungarian lstm attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 60,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"attention_name\": \"tanh_attention\",\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        attention_name=config.get(\"attention_name\", default_params[\"attention_name\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([128, 256, 512]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Dropout layers\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \n",
    "        # Attention Layers\n",
    "        \"attention_name\": tune.choice([\"tanh_attention\", \"scaled_dot_attention\", \"multihead_attention\"]),\n",
    "\n",
    "        # Other parameters\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"model_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"attention_name\": best_result.config[\"attention_name\"],\n",
    "            \"test_mode\": best_result.config[\"test_mode\"],\n",
    "            \"early_stop\": best_result.config[\"early_stop\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a502e",
   "metadata": {},
   "source": [
    "## Hungaran lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from datetime import datetime\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# Fixed data paths\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_csv = \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"Single Ray Tune trial for your model with tuning.\"\"\"\n",
    "    resource_usage()\n",
    "\n",
    "    # Fixed args for the training process\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_csv=labels_csv,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Default values for the parameters\n",
    "    default_params = {\n",
    "        \"hidden_dim\": 60,\n",
    "        \"lr\": 0.0001,\n",
    "        \"first_drop\": 0.3,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 50,\n",
    "        \"max_epochs\": 200,\n",
    "        \"save_model\": True,\n",
    "        \"return_val_accuracy\": True,\n",
    "        \"test_mode\": False,\n",
    "        \"early_stop\": False,\n",
    "        \"optimizer_name\": \"adamw\",\n",
    "        \"scheduler_name\": \"reduce_on_plateau\",\n",
    "        \"optimizer_params\": {\"weight_decay\": 0.01},\n",
    "        \"scheduler_params\": {\"factor\": 0.2, \"patience\": 3},\n",
    "        \"scale_labels\": False,\n",
    "    }\n",
    "\n",
    "    # Combine fixed and tunable params, using config values if provided, else fallback to defaults\n",
    "    train_args = fixed_args.copy()\n",
    "    train_args.update(\n",
    "        hidden_dim=config.get(\"hidden_dim\", default_params[\"hidden_dim\"]),\n",
    "        lr=config.get(\"lr\", default_params[\"lr\"]),\n",
    "        first_drop=config.get(\"first_drop\", default_params[\"first_drop\"]),\n",
    "        num_layers=config.get(\"num_layers\", default_params[\"num_layers\"]),\n",
    "        batch_size=config.get(\"batch_size\", default_params[\"batch_size\"]),\n",
    "        max_epochs=config.get(\"max_epochs\", default_params[\"max_epochs\"]),\n",
    "        save_model=config.get(\"save_model\", default_params[\"save_model\"]),\n",
    "        return_val_accuracy=config.get(\"return_val_accuracy\", default_params[\"return_val_accuracy\"]),\n",
    "        test_mode=config.get(\"test_mode\", default_params[\"test_mode\"]),\n",
    "        early_stop=config.get(\"early_stop\", default_params[\"early_stop\"]),\n",
    "        optimizer_name=config.get(\"optimizer_name\", default_params[\"optimizer_name\"]),\n",
    "        optimizer_params={\n",
    "            \"weight_decay\": config.get(\"optimizer_params\", default_params[\"optimizer_params\"]).get(\"weight_decay\", default_params[\"optimizer_params\"][\"weight_decay\"])\n",
    "        },\n",
    "        scheduler_name=config.get(\"scheduler_name\", default_params[\"scheduler_name\"]),\n",
    "        scheduler_params=config.get(\"scheduler_params\", default_params[\"scheduler_params\"]),\n",
    "        scale_labels=config.get(\"scale_labels\", default_params[\"scale_labels\"]),\n",
    "    )\n",
    "\n",
    "    # Scheduler configuration\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": sp.get(\"factor\", 0.5),\n",
    "            \"patience\": sp.get(\"patience\", 5),\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"onecycle\":\n",
    "        sp = train_args.get(\"scheduler_params\", {})\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"div_factor\": sp.get(\"div_factor\", 25),\n",
    "            \"final_div_factor\": sp.get(\"final_div_factor\", 1e4),\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train and report results\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for your model with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Architecture\n",
    "        \"hidden_dim\": tune.choice([128, 256, 512]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"batch_size\": tune.choice([32, 50, 64]),\n",
    "        \n",
    "        # Optimizer & LR\n",
    "        \"lr\": tune.loguniform(1e-4, 5e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"onecycle\"]),\n",
    "        \n",
    "        # Max epochs\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Dropout\n",
    "        \"first_drop\": tune.choice([0.2, 0.3, 0.4]),\n",
    "        \n",
    "        # Other parameters\n",
    "        # \"scale_labels\": tune.choice([True, False]),\n",
    "\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        grace_period=2,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"model_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=15,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "\n",
    "    print(\"\\n🏆 Best Config:\")\n",
    "    print(best_result.config)\n",
    "    print(f\"✅ Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_csv\": labels_csv,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"first_drop\": best_result.config[\"first_drop\"],\n",
    "            \"num_layers\": best_result.config[\"num_layers\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"scheduler_params\": best_result.config.get(\"scheduler_params\", {}),\n",
    "            \"scale_labels\": best_result.config[\"scale_labels\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"test_mode\": best_result.config[\"test_mode\"],\n",
    "            \"early_stop\": best_result.config[\"early_stop\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
