{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c93e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "seq_len",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b930cdd8-fd68-4c11-880c-494460928287",
       "rows": [
        [
         "0",
         "1514764800",
         "1515196800",
         "0",
         "5",
         "0.774234",
         "0.941543",
         "1.004005",
         null,
         null,
         null,
         "5"
        ],
        [
         "1",
         "1515283200",
         "1515628800",
         "6",
         "10",
         "1.086008",
         "1.126277",
         "1.165107",
         "0.970955",
         null,
         null,
         "4"
        ],
        [
         "2",
         "1515628800",
         "1516060800",
         "10",
         "15",
         "1.193264",
         "1.336497",
         "1.235186",
         null,
         null,
         null,
         "5"
        ],
        [
         "3",
         "1516060800",
         "1517184000",
         "15",
         "28",
         "0.863277",
         "0.996965",
         "1.088347",
         null,
         null,
         null,
         "13"
        ],
        [
         "4",
         "1517097600",
         "1517875200",
         "27",
         "36",
         "1.351391",
         "1.197126",
         "0.861228",
         null,
         null,
         null,
         "9"
        ],
        [
         "5",
         "1517875200",
         "1519084800",
         "36",
         "50",
         "0.91305",
         "0.749693",
         "0.805304",
         "0.664539",
         null,
         null,
         "14"
        ],
        [
         "6",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.015686",
         "1.058311",
         null,
         null,
         null,
         null,
         "5"
        ],
        [
         "7",
         "1519516800",
         "1520208000",
         "55",
         "63",
         "0.894581",
         "1.005045",
         null,
         null,
         null,
         null,
         "8"
        ],
        [
         "8",
         "1520208000",
         "1521331200",
         "63",
         "76",
         "1.134643",
         "0.949258",
         "1.011053",
         null,
         null,
         null,
         "13"
        ],
        [
         "9",
         "1521590400",
         "1522540800",
         "79",
         "90",
         "0.952544",
         "1.223968",
         null,
         null,
         null,
         null,
         "11"
        ],
        [
         "10",
         "1523232000",
         "1525478400",
         "98",
         "124",
         "0.888803",
         "0.981552",
         "0.827628",
         null,
         null,
         null,
         "26"
        ],
        [
         "11",
         "1525478400",
         "1527465600",
         "124",
         "147",
         "1.193822",
         "1.31115",
         "1.114156",
         "1.041731",
         null,
         null,
         "23"
        ],
        [
         "12",
         "1527465600",
         "1528329600",
         "147",
         "157",
         "0.969558",
         null,
         null,
         null,
         null,
         null,
         "10"
        ],
        [
         "13",
         "1528329600",
         "1529798400",
         "157",
         "174",
         "1.022398",
         "1.099473",
         "1.049206",
         null,
         null,
         null,
         "17"
        ],
        [
         "14",
         "1530230400",
         "1532476800",
         "179",
         "205",
         "0.899944",
         "0.931975",
         "0.778048",
         "0.810079",
         "1.037855",
         null,
         "26"
        ],
        [
         "15",
         "1532476800",
         "1534204800",
         "205",
         "225",
         "1.271149",
         "1.335279",
         "1.32027",
         "1.145617",
         "0.988702",
         "1.056926",
         "20"
        ],
        [
         "16",
         "1536364800",
         "1537574400",
         "250",
         "264",
         "0.960264",
         "0.913796",
         null,
         null,
         null,
         null,
         "14"
        ],
        [
         "17",
         "1537574400",
         "1539216000",
         "264",
         "283",
         "1.023049",
         "1.078415",
         null,
         null,
         null,
         null,
         "19"
        ],
        [
         "18",
         "1539561600",
         "1542240000",
         "287",
         "318",
         "1.126735",
         "1.179985",
         "1.087177",
         null,
         null,
         null,
         "31"
        ],
        [
         "19",
         "1542153600",
         "1544832000",
         "317",
         "348",
         "1.200769",
         "1.391551",
         "1.263454",
         "1.347943",
         "1.042692",
         "0.999085",
         "31"
        ],
        [
         "20",
         "1544918400",
         "1546905600",
         "349",
         "372",
         "0.930514",
         "0.983124",
         "1.020145",
         "0.901287",
         "0.948051",
         null,
         "23"
        ],
        [
         "21",
         "1546905600",
         "1549584000",
         "372",
         "403",
         "0.974219",
         "1.005812",
         "0.921565",
         "1.085846",
         null,
         null,
         "31"
        ],
        [
         "22",
         "1549584000",
         "1550966400",
         "403",
         "419",
         "0.974868",
         "0.956341",
         "1.040744",
         "1.079858",
         "1.110737",
         null,
         "16"
        ],
        [
         "23",
         "1550966400",
         "1554163200",
         "419",
         "456",
         "0.797801",
         "0.848962",
         "0.827036",
         null,
         null,
         null,
         "37"
        ],
        [
         "24",
         "1554163200",
         "1557446400",
         "456",
         "494",
         "0.804541",
         "0.786374",
         "0.837573",
         "0.883817",
         "0.916848",
         null,
         "38"
        ],
        [
         "25",
         "1557187200",
         "1559174400",
         "491",
         "514",
         "0.959915",
         "0.822445",
         "1.059199",
         "0.898818",
         null,
         null,
         "23"
        ],
        [
         "26",
         "1559174400",
         "1560124800",
         "514",
         "525",
         "0.97726",
         "1.076155",
         "0.933746",
         null,
         null,
         null,
         "11"
        ],
        [
         "27",
         "1560038400",
         "1561507200",
         "524",
         "541",
         "0.711745",
         "0.681577",
         null,
         null,
         null,
         null,
         "17"
        ],
        [
         "28",
         "1561507200",
         "1564272000",
         "541",
         "573",
         "1.298719",
         "1.21132",
         "1.065656",
         "1.140788",
         "1.008923",
         null,
         "32"
        ],
        [
         "29",
         "1564272000",
         "1565136000",
         "573",
         "583",
         "0.960277",
         null,
         null,
         null,
         null,
         null,
         "10"
        ],
        [
         "30",
         "1565136000",
         "1567123200",
         "583",
         "606",
         "1.250152",
         "1.17841",
         "1.088351",
         "1.02882",
         "1.140249",
         null,
         "23"
        ],
        [
         "31",
         "1567036800",
         "1567728000",
         "605",
         "613",
         "1.019979",
         "0.927642",
         null,
         null,
         null,
         null,
         "8"
        ],
        [
         "32",
         "1567728000",
         "1571875200",
         "613",
         "661",
         "1.387543",
         "1.318462",
         "1.105299",
         "1.06385",
         null,
         null,
         "48"
        ],
        [
         "33",
         "1571875200",
         "1572220800",
         "661",
         "665",
         "0.804214",
         "1.036258",
         null,
         null,
         null,
         null,
         "4"
        ],
        [
         "34",
         "1572048000",
         "1574640000",
         "663",
         "693",
         "1.286138",
         "1.343756",
         "1.21823",
         "1.024796",
         null,
         null,
         "30"
        ],
        [
         "35",
         "1574640000",
         "1578441600",
         "693",
         "737",
         "0.904404",
         "0.946173",
         "0.871715",
         "0.799072",
         null,
         null,
         "44"
        ],
        [
         "36",
         "1578614400",
         "1581552000",
         "739",
         "773",
         "0.800902",
         "0.850958",
         "0.911025",
         "0.996835",
         null,
         null,
         "34"
        ],
        [
         "37",
         "1581552000",
         "1584057600",
         "773",
         "802",
         "1.424052",
         "1.591895",
         "1.510596",
         "1.738757",
         "1.859395",
         null,
         "29"
        ],
        [
         "38",
         "1584057600",
         "1588809600",
         "802",
         "857",
         "0.682698",
         "0.616772",
         "0.503967",
         "0.558172",
         "0.773528",
         "0.887799",
         "55"
        ],
        [
         "39",
         "1588809600",
         "1591056000",
         "857",
         "883",
         "1.026785",
         "0.966838",
         "0.917651",
         "0.936097",
         null,
         null,
         "26"
        ],
        [
         "40",
         "1591056000",
         "1593907200",
         "883",
         "916",
         "1.063058",
         "0.99692",
         null,
         null,
         null,
         null,
         "33"
        ],
        [
         "41",
         "1593907200",
         "1595808000",
         "916",
         "938",
         "0.836963",
         "0.868797",
         "0.823699",
         null,
         null,
         null,
         "22"
        ],
        [
         "42",
         "1595721600",
         "1598918400",
         "937",
         "974",
         "0.98554",
         "0.888977",
         "0.935274",
         null,
         null,
         null,
         "37"
        ],
        [
         "43",
         "1599004800",
         "1602115200",
         "975",
         "1011",
         "0.948399",
         "0.993145",
         "1.02057",
         "0.97005",
         null,
         null,
         "36"
        ],
        [
         "44",
         "1602115200",
         "1604534400",
         "1011",
         "1039",
         "0.739499",
         "0.724325",
         "0.878082",
         null,
         null,
         null,
         "28"
        ],
        [
         "45",
         "1604534400",
         "1606176000",
         "1039",
         "1058",
         "0.809127",
         "0.771266",
         "0.848635",
         "0.973743",
         null,
         null,
         "19"
        ],
        [
         "46",
         "1606262400",
         "1608076800",
         "1059",
         "1080",
         "0.901803",
         "0.923977",
         "0.86928",
         "0.844149",
         "0.803495",
         null,
         "21"
        ],
        [
         "47",
         "1608076800",
         "1609632000",
         "1080",
         "1098",
         "0.733311",
         "0.719861",
         "0.684744",
         "0.792338",
         "0.861079",
         null,
         "18"
        ],
        [
         "48",
         "1609632000",
         "1612310400",
         "1098",
         "1129",
         "1.086558",
         "0.945543",
         "0.853577",
         "0.781026",
         null,
         null,
         "31"
        ],
        [
         "49",
         "1612396800",
         "1613865600",
         "1130",
         "1147",
         "0.669818",
         "0.809765",
         "0.841906",
         "0.891456",
         "0.912883",
         "0.970469",
         "17"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 73
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515196800</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.774234</td>\n",
       "      <td>0.941543</td>\n",
       "      <td>1.004005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1515283200</td>\n",
       "      <td>1515628800</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.086008</td>\n",
       "      <td>1.126277</td>\n",
       "      <td>1.165107</td>\n",
       "      <td>0.970955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515628800</td>\n",
       "      <td>1516060800</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1.193264</td>\n",
       "      <td>1.336497</td>\n",
       "      <td>1.235186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1516060800</td>\n",
       "      <td>1517184000</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>1.088347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1517097600</td>\n",
       "      <td>1517875200</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>1.351391</td>\n",
       "      <td>1.197126</td>\n",
       "      <td>0.861228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1644451200</td>\n",
       "      <td>1645660800</td>\n",
       "      <td>1501</td>\n",
       "      <td>1515</td>\n",
       "      <td>0.996103</td>\n",
       "      <td>0.955050</td>\n",
       "      <td>1.165443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1645660800</td>\n",
       "      <td>1648512000</td>\n",
       "      <td>1515</td>\n",
       "      <td>1548</td>\n",
       "      <td>0.833872</td>\n",
       "      <td>0.898831</td>\n",
       "      <td>0.785499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1648512000</td>\n",
       "      <td>1651622400</td>\n",
       "      <td>1548</td>\n",
       "      <td>1584</td>\n",
       "      <td>1.046141</td>\n",
       "      <td>1.174980</td>\n",
       "      <td>1.118819</td>\n",
       "      <td>0.980070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1651708800</td>\n",
       "      <td>1652313600</td>\n",
       "      <td>1585</td>\n",
       "      <td>1592</td>\n",
       "      <td>1.071227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1652313600</td>\n",
       "      <td>1653264000</td>\n",
       "      <td>1592</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.009742</td>\n",
       "      <td>0.949503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0   1514764800  1515196800           0         5     0.774234     0.941543   \n",
       "1   1515283200  1515628800           6        10     1.086008     1.126277   \n",
       "2   1515628800  1516060800          10        15     1.193264     1.336497   \n",
       "3   1516060800  1517184000          15        28     0.863277     0.996965   \n",
       "4   1517097600  1517875200          27        36     1.351391     1.197126   \n",
       "..         ...         ...         ...       ...          ...          ...   \n",
       "68  1644451200  1645660800        1501      1515     0.996103     0.955050   \n",
       "69  1645660800  1648512000        1515      1548     0.833872     0.898831   \n",
       "70  1648512000  1651622400        1548      1584     1.046141     1.174980   \n",
       "71  1651708800  1652313600        1585      1592     1.071227          NaN   \n",
       "72  1652313600  1653264000        1592      1603     1.009742     0.949503   \n",
       "\n",
       "    linePrice_3  linePrice_4  linePrice_5  linePrice_6  seq_len  \n",
       "0      1.004005          NaN          NaN          NaN        5  \n",
       "1      1.165107     0.970955          NaN          NaN        4  \n",
       "2      1.235186          NaN          NaN          NaN        5  \n",
       "3      1.088347          NaN          NaN          NaN       13  \n",
       "4      0.861228          NaN          NaN          NaN        9  \n",
       "..          ...          ...          ...          ...      ...  \n",
       "68     1.165443          NaN          NaN          NaN       14  \n",
       "69     0.785499          NaN          NaN          NaN       33  \n",
       "70     1.118819     0.980070          NaN          NaN       36  \n",
       "71          NaN          NaN          NaN          NaN        7  \n",
       "72          NaN          NaN          NaN          NaN       11  \n",
       "\n",
       "[73 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv(\"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\")\n",
    "label[\"seq_len\"] = label[\"endIndex\"] - label[\"startIndex\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e027af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "276b5b3c-e85b-4fb2-8da6-147dc065c148",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "235bdf69-4062-412b-b007-7297a3902ae0",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles_prop.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b8d98",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ccb9c",
   "metadata": {},
   "source": [
    "## Hungarian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159560e2",
   "metadata": {},
   "source": [
    "### Hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16033bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Predict max_len_y candidate values\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # per-element loss\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss.\n",
    "        y_pred: (B, max_len_y)\n",
    "        y_true: (B, max_len_y)\n",
    "        mask:   (B, max_len_y), 1 where valid target, 0 where padding\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            preds = y_pred[i]                 # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Build cost matrix (L x max_len_y)\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)  # squared error\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Compute loss only for assigned pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52405383",
   "metadata": {},
   "source": [
    "### Hungarian lstm order weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6785b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Predict max_len_y candidate values\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # per-element loss\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss with position-based weighting.\n",
    "        Earlier ground-truth positions in y_true get higher weight.\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            # Extract ground-truth values and their positions\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)  # positions in y_true\n",
    "\n",
    "            preds = y_pred[i]  # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Cost matrix (L x max_len_y) using squared error\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Matched pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            # --- weighting logic ---\n",
    "            # Lower index = higher weight (inverse rank)\n",
    "            gt_pos = gt_indices[row_ind]  # actual positions of matched gts\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())  # e.g. pos=0 -> 1.0, pos=2 -> 0.33\n",
    "\n",
    "            # Compute weighted MSE\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "    \n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Same Hungarian matching but without weights (baseline).\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d451064",
   "metadata": {},
   "source": [
    "### CNN -attention lstm hungarian - concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d25a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# --- Sinusoidal positional encoding ---\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "\n",
    "class LearnablePositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        # nn.Embedding is a perfect layer for this.\n",
    "        # It's a lookup table that stores embeddings of a fixed size.\n",
    "        self.embedding = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Create a tensor of positions [0, 1, 2, ..., T-1]\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0) # (1, T)\n",
    "        \n",
    "        # Look up the embeddings for these positions\n",
    "        positional_encodings = self.embedding(positions) # (1, T, d_model)\n",
    "        \n",
    "        # Add to the input tensor\n",
    "        return x + positional_encodings\n",
    "\n",
    "class RotaryPositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim, base=10000):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        self.seq_len_cached = None\n",
    "        self.cos_cached = None\n",
    "        self.sin_cached = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.shape[1]\n",
    "        if seq_len != self.seq_len_cached:\n",
    "            self.seq_len_cached = seq_len\n",
    "            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)\n",
    "            freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1)\n",
    "            self.cos_cached = emb.cos()[:, None, None, :]\n",
    "            self.sin_cached = emb.sin()[:, None, None, :]\n",
    "        return self.cos_cached, self.sin_cached\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=x1.ndim - 1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin):\n",
    "    # q, k have shape (B, H, T, head_dim)\n",
    "    # cos, sin have shape (T, 1, 1, head_dim)\n",
    "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)\n",
    "\n",
    "# --- How to use it in your Transformer ---\n",
    "# self.rope = RotaryPositionalEncoding(dim=head_dim)\n",
    "#\n",
    "# def forward(self, x):\n",
    "#     q, k, v = self.to_qkv(x)\n",
    "#     cos, sin = self.rope(q)\n",
    "#     q, k = apply_rotary_pos_emb(q, k, cos, sin)\n",
    "#     # ... proceed with attention calculation using the new q and k\n",
    "\n",
    "# --- CNN + Transformer Regressor ---\n",
    "class CNNAttentionTransformerRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, nhead=4, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Multi-branch CNN ---\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ) for k in [3, 5, 7, 11]\n",
    "        ])\n",
    "\n",
    "        # --- Conv2d fusion ---\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # --- Positional encoding ---\n",
    "        self.positional_encoding = SinusoidalPositionalEncoding(d_model=32)\n",
    "\n",
    "        # --- Transformer encoder ---\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=32,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=0.3,\n",
    "            activation=\"relu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # --- Regressor ---\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "\n",
    "    # --- Forward ---\n",
    "    def forward(self, x, lengths):\n",
    "        # x[\"main\"]: (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "\n",
    "        # Multi-branch CNN\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)               # (B, 4, 32, T)\n",
    "\n",
    "        # Conv2d fusion\n",
    "        fused = self.fusion_conv2d(stacked)                        # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)                                   # (B, 32, T)\n",
    "        fused = fused.transpose(1, 2)                               # (B, T, 32)\n",
    "\n",
    "        # Positional encoding\n",
    "        fused = self.positional_encoding(fused)                    # (B, T, 32)\n",
    "\n",
    "        # Padding mask for transformer\n",
    "        max_len = fused.size(1)\n",
    "        mask = torch.arange(max_len, device=lengths.device)[None, :] >= lengths[:, None]  # True=masked\n",
    "\n",
    "        # Transformer encoder\n",
    "        transformer_out = self.transformer(fused, src_key_padding_mask=mask)  # (B, T, 32)\n",
    "\n",
    "        # Masked mean pooling over sequence\n",
    "        seq_mask = ~mask\n",
    "        pooled = (transformer_out * seq_mask.unsqueeze(-1)).sum(1) / seq_mask.sum(1, keepdim=True)  # (B, 32)\n",
    "\n",
    "        # Regression\n",
    "        y_pred = self.regressor(pooled)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    # --- Hungarian weighted loss ---\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            gt_pos = gt_indices[row_ind]\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())\n",
    "\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "\n",
    "    # --- Hungarian unweighted loss ---\n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "\n",
    "    # --- Training step ---\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5ef5c",
   "metadata": {},
   "source": [
    "depricated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import  load_attention\n",
    "from importlib import import_module\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_layer = nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.v_context = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_outputs, lengths):\n",
    "        energy = torch.tanh(self.attn_layer(lstm_outputs))\n",
    "        attn_scores = self.v_context(energy).squeeze(2)\n",
    "        mask = torch.arange(\n",
    "            lstm_outputs.size(1), device=lstm_outputs.device\n",
    "        )[None, :] < lengths[:, None]\n",
    "        attn_scores = attn_scores.masked_fill(mask == 0, -1e10)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        context_vector = torch.bmm(attn_weights.unsqueeze(1), lstm_outputs).squeeze(1)\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Multi-branch 1D convolutions\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ) for k in [3, 5, 7, 11]\n",
    "        ])\n",
    "\n",
    "        # Fusion with Conv2d over (branches × seq)\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # LSTM takes feature_dim = 32 after fusion\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(hidden_dim)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Input: x[\"main\"] → (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "\n",
    "        # Branch outputs\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)  # (B, 4, 32, T)\n",
    "\n",
    "        # Fusion conv2d\n",
    "        fused = self.fusion_conv2d(stacked)  # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)             # (B, 32, T)\n",
    "\n",
    "        # Prepare for LSTM\n",
    "        lstm_input = fused.transpose(1, 2)   # (B, T, 32)\n",
    "\n",
    "        # LSTM with packing\n",
    "        packed_input = pack_padded_sequence(lstm_input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)  # (B, T, H)\n",
    "\n",
    "        # Attention\n",
    "        context_vector = self.attention(lstm_outputs, lengths)  # (B, H)\n",
    "\n",
    "        # Regression\n",
    "        y_pred = self.regressor(context_vector)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss with position-based weighting.\n",
    "        Earlier ground-truth positions in y_true get higher weight.\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            # Extract ground-truth values and their positions\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)  # positions in y_true\n",
    "\n",
    "            preds = y_pred[i]  # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Cost matrix (L x max_len_y) using squared error\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Matched pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            # --- weighting logic ---\n",
    "            # Lower index = higher weight (inverse rank)\n",
    "            gt_pos = gt_indices[row_ind]  # actual positions of matched gts\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())  # e.g. pos=0 -> 1.0, pos=2 -> 0.33\n",
    "\n",
    "            # Compute weighted MSE\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "    \n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Same Hungarian matching but without weights (baseline).\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Import optimizer dynamically\n",
    "        opt_module = import_module(f\"model.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr)\n",
    "\n",
    "        # No scheduler\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "\n",
    "        # Import scheduler dynamically\n",
    "        sch_module = import_module(f\"model.schedulers.{self.scheduler_name}\")\n",
    "        # OneCycle needs trainer\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer)\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer)\n",
    "\n",
    "        # Lightning accepts dict or list depending on scheduler type\n",
    "        if isinstance(scheduler, dict):\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler._LRScheduler):\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler return type: {type(scheduler)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541ef27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import  load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, attention_name=\"tanh_attention\",optimizer_name=\"adamw\",kernels= [3, 5, 7, 11],\n",
    "    cnn_out_channels=32,first_drop= 0.3, second_drop=0.3, third_drop= 0.3,scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.kernels = kernels\n",
    "        # Multi-branch 1D convolutions\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim[\"main\"], out_channels=cnn_out_channels, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(cnn_out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(first_drop)\n",
    "            ) for k in self.kernels\n",
    "        ])\n",
    "        # Fusion with Conv2d over (branches × seq)\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(second_drop)\n",
    "        )\n",
    "        \n",
    "        # LSTM takes feature_dim = 32 after fusion\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_out_channels,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(third_drop),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # Input: x[\"main\"] → (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "        # Branch outputs\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)  # (B, 4, 32, T)\n",
    "        # Fusion conv2d\n",
    "        fused = self.fusion_conv2d(stacked)  # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)             # (B, 32, T)\n",
    "        # Prepare for LSTM\n",
    "        lstm_input = fused.transpose(1, 2)   # (B, T, 32)\n",
    "        # LSTM with packing\n",
    "        packed_input = pack_padded_sequence(lstm_input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)  # (B, T, H)\n",
    "        # Attention\n",
    "        context_vector = self.attention(lstm_outputs, lengths)  # (B, H)\n",
    "        # Regression\n",
    "        y_pred = self.regressor(context_vector)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Import optimizer dynamically\n",
    "        opt_module = import_module(f\"models.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr)\n",
    "\n",
    "        # No scheduler\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "\n",
    "        # Import scheduler dynamically\n",
    "        sch_module = import_module(f\"models.schedulers.{self.scheduler_name}\")\n",
    "        # OneCycle needs trainer\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer)\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer)\n",
    "\n",
    "        # Lightning accepts dict or list depending on scheduler type\n",
    "        if isinstance(scheduler, dict):\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler._LRScheduler):\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler return type: {type(scheduler)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0236de84",
   "metadata": {},
   "source": [
    "### CNN simple attention lstm weightening`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c47cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from utils.load_attention import load_attention\n",
    "from utils.load_class import load_class\n",
    "from importlib import import_module\n",
    "from models.losses.hungarian_loss import hungarian_loss_weighted\n",
    "from models.losses.hungarian_loss_unweighted import hungarian_loss_unweighted\n",
    "from typing import Optional\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, attention_name=\"tanh_attention\",optimizer_name=\"adamw\",kernels= [3, 5, 7, 11],fusion_out_channels = 10,\n",
    "    cnn_out_channels=32,first_drop= 0.3, second_drop=0.3, third_drop= 0.3,scheduler_name=None, scheduler_params=None, optimizer_params=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.input_dim = input_dim[\"candle_shape\"]\n",
    "        self.cnn_out_channels = cnn_out_channels\n",
    "        self.kernels = kernels\n",
    "        self.num_branches = len(kernels)\n",
    "        self.fusion_out_channels = fusion_out_channels\n",
    "        self.main_feat_dim = input_dim['main']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.max_len_y = max_len_y\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "        self.attention = load_class(f\"models.attention.{attention_name}\", hidden_dim=hidden_dim)\n",
    "        self.hungarian_loss = hungarian_loss_weighted\n",
    "        self.hungarian_loss_unweighted = hungarian_loss_unweighted\n",
    "        # ----- Branches: multiple Conv1d with different kernel sizes -----\n",
    "        branches = []\n",
    "        for k in kernels:\n",
    "            pad = (k - 1) // 2  # 'same' padding for odd kernels; for even kernels behavior approximated\n",
    "            branches.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=self.input_dim , out_channels=cnn_out_channels, kernel_size=k, padding=pad),\n",
    "                    nn.BatchNorm1d(cnn_out_channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(first_drop)\n",
    "                )\n",
    "            )\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "\n",
    "        # ----- Fusion Conv2d: we will stack branch outputs into shape (B, num_branches, C, T)\n",
    "        # in_channels should equal number of branches.\n",
    "        # Kernel height must be cnn_out_channels to cover \"full feature height\".\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.num_branches,\n",
    "                out_channels=self.fusion_out_channels,\n",
    "                kernel_size=(self.cnn_out_channels, 1),\n",
    "                padding=(0, 0)\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.fusion_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(second_drop)\n",
    "        )\n",
    "\n",
    "        # After fusion we will have (B, fusion_out_channels, 1, T) -> squeeze -> (B, fusion_out_channels, T)\n",
    "\n",
    "        # ----- LSTM: input_size should be fusion_out_channels + main_feat_dim -----\n",
    "        lstm_input_size = self.fusion_out_channels + self.main_feat_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=third_drop if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Regressor (maps attention context to target length)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(third_drop),\n",
    "            nn.Linear(hidden_dim, max(4, hidden_dim // 2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(max(4, hidden_dim // 2), max_len_y)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: dict, lengths):\n",
    "        \"\"\"\n",
    "        x is a dict with at least:\n",
    "          - x[\"candle_shape\"]: Tensor shape (B, input_dim, T)\n",
    "          - x[\"main\"]: Tensor shape (B, main_feat_dim, T)\n",
    "\n",
    "        Returns:\n",
    "          - out: (B, max_len_y)\n",
    "          - optionally attention weights if you want them (we return both)\n",
    "        \"\"\"\n",
    "        candle = x[\"candle_shape\"]\n",
    "        candle = candle.permute(0, 2, 1) \n",
    "        main = x[\"main\"]\n",
    "        main = main.permute(0, 2, 1)\n",
    "        # ---- Validate shapes ----\n",
    "        B, _, T = candle.shape\n",
    "        assert main.shape[0] == B and main.shape[2] == T, \\\n",
    "            f\"main must match batch and time dims, got {main.shape} vs candle {candle.shape}\"\n",
    "        # ---- Branches: each branch returns (B, C, T) ----\n",
    "        branch_feats = [branch(candle) for branch in self.branches]  # list of (B, C, T)\n",
    "        # stack into (B, num_branches, C, T)\n",
    "        stacked = torch.stack(branch_feats, dim=1)\n",
    "\n",
    "        # ---- Fusion Conv2d expects (B, in_channels=num_branches, height=C, width=T) ----\n",
    "        fused = self.fusion_conv2d(stacked)  # -> (B, fusion_out_channels, 1, T)\n",
    "        fused = fused.squeeze(2)  # -> (B, fusion_out_channels, T)\n",
    "\n",
    "        # ---- Concatenate with main features along channel dimension -> (B, fusion_out + m, T) ----\n",
    "        combined = torch.cat([fused, main], dim=1)\n",
    "\n",
    "        # ---- Prepare for LSTM: LSTM batch_first expects (B, T, feat) ----\n",
    "        combined_t = combined.permute(0, 2, 1)  # (B, T, feat_dim)\n",
    "        packed_input = pack_padded_sequence(combined_t, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        # LSTM\n",
    "        packed_output, _ = self.lstm(packed_input)  # lstm_out: (B, T, hidden_dim)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # Attention over LSTM outputs\n",
    "        context= self.attention(lstm_outputs,lengths)  # context: (B, hidden_dim)\n",
    "\n",
    "        # Regressor -> (B, max_len_y)\n",
    "        y_pred = self.regressor(context)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    # ---------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        self.log(\"val_loss\", loss_reg, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Import optimizer dynamically\n",
    "        opt_module = import_module(f\"models.optimizer.{self.optimizer_name}\")\n",
    "        optimizer = opt_module.build(self, self.lr)\n",
    "\n",
    "        # No scheduler\n",
    "        if self.scheduler_name is None:\n",
    "            return optimizer\n",
    "\n",
    "        # Import scheduler dynamically\n",
    "        sch_module = import_module(f\"models.schedulers.{self.scheduler_name}\")\n",
    "        # OneCycle needs trainer\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = sch_module.build(optimizer, self.lr, self.trainer)\n",
    "        else:\n",
    "            scheduler = sch_module.build(optimizer)\n",
    "\n",
    "        # Lightning accepts dict or list depending on scheduler type\n",
    "        if isinstance(scheduler, dict):\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        elif isinstance(scheduler, torch.optim.lr_scheduler._LRScheduler):\n",
    "            return [optimizer], [scheduler]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler return type: {type(scheduler)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567ad84",
   "metadata": {},
   "source": [
    "### CNN LSTM Hungarian weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f191e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class CNNLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Conv1d branches\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=k // 2),\n",
    "                nn.BatchNorm1d(32),      # normalize per branch\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)          # regularize per branch\n",
    "            )\n",
    "            for k in [1, 3, 7, 10]\n",
    "        ])\n",
    "\n",
    "        # Conv2d fuse across branch dimension\n",
    "        self.conv2d = nn.Conv2d(\n",
    "            in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)\n",
    "        )\n",
    "        self.bn2d = nn.BatchNorm2d(1)   # normalize conv2d output\n",
    "        self.dropout2d = nn.Dropout(0.3)\n",
    "\n",
    "        self.lstm_input_dim = 32  # after conv2d → (B, 32, T)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0   # built-in LSTM dropout\n",
    "        )\n",
    "\n",
    "        self.dropout_fc = nn.Dropout(0.3)\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]  # (B, T, F)\n",
    "        B, T, F = x.shape\n",
    "\n",
    "        # Conv1d branches\n",
    "        feats = [branch(x.transpose(1, 2)) for branch in self.branches]  # (B, 32, T) each\n",
    "        fusion = torch.stack(feats, dim=1)                               # (B, 4, 32, T)\n",
    "\n",
    "        # Conv2d fusion\n",
    "        fusion2d = self.conv2d(fusion)                                   # (B, 1, 32, T)\n",
    "        fusion2d = self.bn2d(fusion2d)\n",
    "        fusion2d = F.relu(fusion2d)\n",
    "        fusion2d = self.dropout2d(fusion2d)\n",
    "        fusion2d = fusion2d.squeeze(1)                                   # (B, 32, T)\n",
    "\n",
    "        # LSTM\n",
    "        fusion2d = fusion2d.transpose(1, 2)                              # (B, T, 32)\n",
    "        packed = pack_padded_sequence(fusion2d, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        # Fully connected with dropout\n",
    "        last_h = self.dropout_fc(last_h)\n",
    "        y_pred = self.fc_reg(last_h)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------- Hungarian Losses (same as your code) -------------------\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)\n",
    "\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            gt_pos = gt_indices[row_ind]\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())\n",
    "\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "\n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b0b0f",
   "metadata": {},
   "source": [
    "### transformer Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31244e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Injects position information into the input sequence.\"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (Sequence Length, Batch Size, Feature Dim)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x\n",
    "\n",
    "class TransformerRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 1. CNN Feature Extractor (same as before)\n",
    "        self.branches = nn.ModuleList([...]) # Your Conv1D branches\n",
    "        self.fusion_conv = nn.Sequential([...]) # Your 1x1 fusion conv\n",
    "        \n",
    "        # We need to ensure the output dim of fusion_conv matches model_dim\n",
    "        # Let's assume fusion_conv outputs `model_dim` channels\n",
    "\n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model=model_dim)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "\n",
    "        # 4. Final Regressor Head\n",
    "        self.regressor = nn.Linear(model_dim, max_len_y)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"].transpose(1, 2)\n",
    "        \n",
    "        # --- CNN Part ---\n",
    "        branch_outputs = [branch(x) for branch in self.branches]\n",
    "        fused_features = torch.cat(branch_outputs, dim=1)\n",
    "        fused_features = self.fusion_conv(fused_features) # (B, model_dim, T)\n",
    "        \n",
    "        # --- Transformer Part ---\n",
    "        # Reshape for Transformer: (B, T, F)\n",
    "        transformer_input = fused_features.transpose(1, 2)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        # Note: Pytorch's default Transformer expects (T, B, F) or batch_first=True\n",
    "        # We used batch_first=True, so shape is (B, T, F)\n",
    "        transformer_input = self.pos_encoder(transformer_input.transpose(0, 1)).transpose(0, 1)\n",
    "\n",
    "        # Create padding mask for the Transformer\n",
    "        # (B, T) -> True for positions that should be ignored\n",
    "        padding_mask = (torch.arange(x.size(2), device=x.device)[None, :] >= lengths[:, None])\n",
    "\n",
    "        # Pass through Transformer Encoder\n",
    "        transformer_output = self.transformer_encoder(transformer_input, src_key_padding_mask=padding_mask) # (B, T, F)\n",
    "\n",
    "        # Aggregate the output sequence into a single vector for prediction.\n",
    "        # Simple averaging is a common and effective method.\n",
    "        aggregated_output = transformer_output.mean(dim=1)\n",
    "        \n",
    "        y_pred = self.regressor(aggregated_output)\n",
    "        return y_pred\n",
    "\n",
    "    # ... (training_step, loss functions, etc. would remain the same) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab1e7f",
   "metadata": {},
   "source": [
    "## two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        print(\"x\",x)\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_loss_reg\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_len\", loss_len, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702411e",
   "metadata": {},
   "source": [
    "## two head lstm greedy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def match_and_loss(y_pred, y_true, mask, loss_fn):\n",
    "    \"\"\"\n",
    "    y_pred: (B, max_len_y)\n",
    "    y_true: (B, max_len_y)\n",
    "    mask: (B, max_len_y)  1 if real, 0 if padding\n",
    "    loss_fn: pointwise loss, e.g. MSELoss(reduction=\"none\")\n",
    "    for each target find closest line\n",
    "    \"\"\"\n",
    "    B, max_len = y_true.shape\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for i in range(B):\n",
    "        gt_vals = y_true[i][mask[i] > 0]  # real targets\n",
    "        preds = y_pred[i]\n",
    "\n",
    "        if len(gt_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        # greedy matching: for each gt, find closest prediction\n",
    "        used = set()\n",
    "        for gt in gt_vals:\n",
    "            dists = torch.abs(preds - gt)\n",
    "            for u in used:\n",
    "                dists[u] = float(\"inf\")  # prevent reuse\n",
    "            j = torch.argmin(dists)     # index of closest prediction\n",
    "            used.add(j.item())\n",
    "\n",
    "            total_loss += loss_fn(preds[j], gt)\n",
    "            total_count += 1\n",
    "\n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        # --- New greedy-matching regression loss ---\n",
    "        loss_reg = match_and_loss(y_pred, y, mask, nn.MSELoss())\n",
    "\n",
    "        # --- Length loss (unchanged) ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb2dd1",
   "metadata": {},
   "source": [
    "## two head lstm sum of logits loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models.losses.two_head_logit_sum import sum_of_logits\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # masked regression\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # multi-label classification\n",
    "        self.compute_loss = sum_of_logits()\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)\n",
    "        len_logits = self.fc_len(last_h)\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        loss, loss_reg, loss_len = self.compute_loss(y_pred, len_logits, y, lengths)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"loss_reg\", loss_reg, prog_bar=False)\n",
    "        self.log(\"loss_len\", loss_len, prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b88b10",
   "metadata": {},
   "source": [
    "## two head lstm soft thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "from models.losses.soft_thresholding_two_head import soft_thresholding_loss\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5, k_soft=20.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "        self.k_soft = k_soft\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()\n",
    "        self.compute_loss = soft_thresholding_loss\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)\n",
    "        len_logits = self.fc_len(last_h)\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        loss, loss_reg, loss_len = self.compute_loss(y_pred, len_logits, y, lengths)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"loss_reg\", loss_reg, prog_bar=False)\n",
    "        self.log(\"loss_len\", loss_len, prog_bar=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b75a48",
   "metadata": {},
   "source": [
    "## FNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c70fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b1d4",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    B = y_true.shape[0]\n",
    "\n",
    "    # Keep track if any valid lines are found\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]  # (B,1)\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "\n",
    "        mask = (y_target != 0).squeeze()\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        valid_line_found = True\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_loss = -log_likelihood.mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        # Avoid returning a Python float; create a tensor with requires_grad\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a057d",
   "metadata": {},
   "source": [
    "## LSTM weightening with pi order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15,hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base network\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        \n",
    "        if lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3*n_components)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f1d12",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class cnn_lstm(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base feature projection\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "\n",
    "        # Parallel conv1d branches\n",
    "        self.k1 = nn.Conv1d(feature_eng, feature_eng, kernel_size=1, padding=0)\n",
    "        self.k3 = nn.Conv1d(feature_eng, feature_eng, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fusion via conv2d\n",
    "        # Input channels = 2 (from k1 + k3), Output = 1, kernel size (1,1) to fuse\n",
    "        self.fusion_conv2d = nn.Conv2d(2, 1, kernel_size=(1, 1))\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: dict with key \"main\", value shape (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]  # (B, T, input_dim)\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # Fully connected projection\n",
    "        x = F.relu(self.ln1(self.fc1(x)))  # (B, T, F)\n",
    "\n",
    "        # Conv1d expects (B, F, T)\n",
    "        x_cnn = x.transpose(1, 2)  # (B, F, T)\n",
    "\n",
    "        # Parallel convs\n",
    "        x1 = self.k1(x_cnn)  # (B, F, T)\n",
    "        x3 = self.k3(x_cnn)  # (B, F, T)\n",
    "\n",
    "        # Stack into 2-channel feature map\n",
    "        stacked = torch.stack([x1, x3], dim=1)  # (B, 2, F, T)\n",
    "\n",
    "        # Fuse with conv2d → (B, 1, F, T)\n",
    "        fused = self.fusion_conv2d(stacked).squeeze(1)  # (B, F, T)\n",
    "\n",
    "        # Back to (B, T, F)\n",
    "        fused = fused.transpose(1, 2)\n",
    "\n",
    "        # LSTM with packed sequence\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(fused, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(packed)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(fused)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3 * n_components)\n",
    "\n",
    "        # Assume you have mdn_split_params(pi, mu, sigma)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e7f3",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening with sigma confidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll_with_sigma_penalty(y_true, mdn_params, weights, lambda_sigma=0.01):\n",
    "    \"\"\"\n",
    "    Calculates weighted MDN NLL and adds a penalty for large sigmas.\n",
    "    \n",
    "    Args:\n",
    "        lambda_sigma (float): The strength of the sigma penalty.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "        mask = (y_target != -1).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # --- 1. NLL Loss Calculation (same as before) ---\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_nll_loss = -log_likelihood.mean()\n",
    "\n",
    "        # --- 2. NEW: Sigma Penalty Calculation ---\n",
    "        # We penalize the mean of the sigmas for the most likely component\n",
    "        # This focuses the penalty on the component the model actually uses\n",
    "        most_likely_idx = torch.argmax(pi_masked, dim=1)\n",
    "        most_likely_sigma = sigma_masked.gather(1, most_likely_idx.unsqueeze(1)).squeeze()\n",
    "        sigma_penalty = torch.mean(most_likely_sigma)\n",
    "        \n",
    "        # --- 3. Combine and Weight ---\n",
    "        combined_line_loss = line_nll_loss + (lambda_sigma * sigma_penalty)\n",
    "        total_loss += weights[i] * combined_line_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# In your training_step, you would call this new function:\n",
    "# loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights, lambda_sigma=0.01)\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6484b7d",
   "metadata": {},
   "source": [
    "## CNNlSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2139f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # Inside your CNNLSTM_MDN class\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 50% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e8361",
   "metadata": {},
   "source": [
    "## CNNLSTM scalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a359387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components, mu_scale=10, mu_bias=.9, sigma_scale=10.0):\n",
    "    \"\"\"\n",
    "    Split raw MDN parameters into (pi, mu, sigma).\n",
    "\n",
    "    Args:\n",
    "        raw_params: (B, 3 * K) from the network\n",
    "        n_components: number of mixture components\n",
    "        mu_scale: scaling factor for mu (default 1.0 = no scaling)\n",
    "        mu_bias: shift/bias applied after scaling\n",
    "        sigma_scale: scaling factor for sigma (default 10.0)\n",
    "    \"\"\"\n",
    "    B = raw_params.size(0)\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi_raw = raw[..., 0]\n",
    "    mu_raw = raw[..., 1]\n",
    "    sigma_raw = raw[..., 2]\n",
    "\n",
    "    pi = F.softmax(pi_raw, dim=-1)\n",
    "    mu = mu_raw / mu_scale + mu_bias\n",
    "    sigma = F.softplus(sigma_raw / sigma_scale) + 1e-4\n",
    "\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] \n",
    "\n",
    "        # --- Debug print first candle ---\n",
    "        # if x.ndim == 3:  # batched: (B, T, F)\n",
    "        #     first_candle = x[0, 0, :]   # first sample, first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # elif x.ndim == 2:  # single sequence: (T, F)\n",
    "        #     first_candle = x[0, :]      # first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # else:\n",
    "        #     print(\"Unexpected shape for x:\", x.shape)\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # # Inside your CNNLSTM_MDN class\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 80% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    # def configure_optimizers(self):\n",
    "    #     return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccc1c2",
   "metadata": {},
   "source": [
    "## CNNtransformer wheightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "\n",
    "# --- Helper Functions and Modules ---\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma).\n",
    "    This function is used by each individual MDN head.\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-6 # Added a small epsilon for stability\n",
    "    return pi, mu, sigma\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Injects positional information into the input sequence for the Transformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- Weighted Loss Function for Multi-Head Architecture ---\n",
    "\n",
    "def weighted_mdn_nll_multihead(y_true, mdn_params_list, weights, padding_value=-1):\n",
    "    \"\"\"\n",
    "    Calculates the weighted negative log-likelihood for a multi-headed MDN.\n",
    "    This version correctly handles multiple heads and calculates the full NLL for each.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensor): Padded target values, shape (B, num_lines).\n",
    "        mdn_params_list (list): A list of dicts, one for each head.\n",
    "        weights (Tensor): A 1D tensor of importance weights, shape (num_lines,).\n",
    "        padding_value (int): Value used for padding in y_true.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    \n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params_list[i]['pi'], mdn_params_list[i]['mu'], mdn_params_list[i]['sigma']\n",
    "\n",
    "        # Create a mask for valid (non-padded) targets for this line\n",
    "        mask = (y_target != padding_value).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:  # Skip if no valid targets for this line in the batch\n",
    "            continue\n",
    "\n",
    "        # Select only the valid data for this line's loss calculation\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # Use torch.distributions for a clean and stable calculation\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        \n",
    "        # Calculate log probabilities of the target values in each Gaussian component\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        \n",
    "        # Mix the probabilities using the mixture weights (pi)\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        \n",
    "        # Use logsumexp for numerical stability to get the log-likelihood\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        \n",
    "        # Calculate the mean negative log-likelihood for this line\n",
    "        line_loss = -log_likelihood.mean()\n",
    "\n",
    "        # Apply the importance weight and add to total loss\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    # If no valid lines were found in the entire batch, return a zero tensor\n",
    "    if not isinstance(total_loss, torch.Tensor):\n",
    "        return torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "# --- The CNN-Transformer Model ---\n",
    "\n",
    "class cnn_transformer(pl.LightningModule):\n",
    "    def __init__(self, input_dim, cnn_out_channels=64, d_model=128, nhead=4, num_encoder_layers=2,\n",
    "                 n_components=9, num_lines=9, lr=1e-4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "        \n",
    "        # 1. CNN Feature Extractor Block\n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, cnn_out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(cnn_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(cnn_out_channels, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # 4. Multi-Head MDN Output\n",
    "        self.mdn_heads = nn.ModuleList([\n",
    "            nn.Linear(d_model, 3 * n_components) for _ in range(num_lines)\n",
    "        ])\n",
    "        \n",
    "        # Importance weights for lines (exponential decay)\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, X, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        src_key_padding_mask: (B, T) boolean mask for padded elements in X\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        \n",
    "        # 1. CNN Feature Extraction\n",
    "        # Input for Conv1d needs to be (B, C_in, L), so we permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn_extractor(x)\n",
    "        # Permute back to (B, T, C_out) for Transformer\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 2. Add Positional Encoding\n",
    "        # Transformer expects (T, B, C), so permute again\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.pos_encoder(x)\n",
    "        # Permute back to (B, T, C) for batch_first=True\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        # The mask should indicate which key values are NOT to be attended to\n",
    "        encoded_seq = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # We use the representation of the last valid timestep for prediction\n",
    "        # (A common strategy, alternatively you could use mean pooling)\n",
    "        # For simplicity, we'll take the last hidden state of the sequence.\n",
    "        sequence_summary = encoded_seq[:, -1, :] # (B, d_model)\n",
    "        \n",
    "        # 4. Get parameters from all MDN heads\n",
    "        mdn_params_list = []\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](sequence_summary)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            mdn_params_list.append({\"pi\": pi, \"mu\": mu, \"sigma\": sigma})\n",
    "\n",
    "        return mdn_params_list\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        # Create the padding mask for the transformer\n",
    "        # True values indicate positions that should be ignored.\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "\n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        # Use a padding value of -1 for the loss function\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "        \n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefa26",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95badad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6d37502b-8844-4574-b3cd-d3f9d9cfeb6c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1515456000",
         "1514937600",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516492800",
         "1516147200",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1520121600",
         "1519862400",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "46",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "49",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "50",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 320
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1515456000</td>\n",
       "      <td>1514937600</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1651795200</td>\n",
       "      <td>1649116800</td>\n",
       "      <td>1555</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.873150</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.938913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1652054400</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1589</td>\n",
       "      <td>1591</td>\n",
       "      <td>1.063729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1652572800</td>\n",
       "      <td>1651881600</td>\n",
       "      <td>1587</td>\n",
       "      <td>1595</td>\n",
       "      <td>0.813907</td>\n",
       "      <td>0.870793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788406</td>\n",
       "      <td>0.904141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1653264000</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1591</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.042211</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.958532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1648598400</td>\n",
       "      <td>1640304000</td>\n",
       "      <td>1453</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.884394</td>\n",
       "      <td>0.71872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1515456000  1514937600           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "328  1651795200  1649116800        1555      1586     0.873150     0.825739   \n",
       "330  1652054400  1652227200        1589      1591     1.063729          NaN   \n",
       "331  1652572800  1651881600        1587      1595     0.813907     0.870793   \n",
       "332  1653264000  1652227200        1591      1603     1.042211     1.075683   \n",
       "333  1648598400  1640304000        1453      1549     0.781703     0.741996   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "328     0.905267     0.938913          NaN          NaN          NaN   \n",
       "330          NaN     1.023085          NaN          NaN          NaN   \n",
       "331          NaN          NaN          NaN          NaN          NaN   \n",
       "332     0.992004     0.958532          NaN          NaN          NaN   \n",
       "333     0.993930     0.847425     0.884394      0.71872          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "328     0.955736          NaN  \n",
       "330          NaN          NaN  \n",
       "331     0.788406     0.904141  \n",
       "332          NaN          NaN  \n",
       "333          NaN     0.647521  \n",
       "\n",
       "[320 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_labels = pd.read_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\")\n",
    "cols = [f'price_line{i}' for i in range(1, 10)]\n",
    "df_labels = df_labels.dropna(subset=cols, how='all')\n",
    "df_labels = df_labels.rename(columns={c: c.replace('price_line', 'linePrice_') \n",
    "                        for c in df_labels.columns if c.startswith('price_line')})\n",
    "df_labels.to_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\", index=False)      \n",
    "#     # overwrites the old file\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4dd53",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677dbff",
   "metadata": {},
   "source": [
    "## simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e281d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# ---------------- Evaluation ---------------- #\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, zero_idx=0, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (last-output version).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    zero_idx : which mixture component is considered \"no-line\" (usually 0)\n",
    "    threshold : if pi[:,zero_idx] > threshold → predict invalid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            if isinstance(X_batch, dict):\n",
    "                X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            else:\n",
    "                X_batch = X_batch.to(device)\n",
    "\n",
    "            y_batch = y_batch.to(device)\n",
    "            mdn = model(X_batch, lengths)\n",
    "            pi, mu, sigma = mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"]  # (B,K)\n",
    "\n",
    "            # regression expectation\n",
    "            y_pred = (pi * mu).sum(dim=-1)  # (B,)\n",
    "            B = y_batch.size(0)\n",
    "            y_len = (y_batch > 0).sum(dim=1)                # (B,)\n",
    "            idx = torch.clamp(y_len - 1, min=0)             # last valid index\n",
    "            y_true = y_batch[torch.arange(B, device=y_batch.device), idx]  # (B,)\n",
    "            # only last step\n",
    "            # print(\"lengths(features):\", lengths[:10])\n",
    "            # print(\"lengths(labels):\", y_len[:10])\n",
    "\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "            # validity classification\n",
    "            pi_zero = pi[:, zero_idx]  # (B,)\n",
    "            pred_valid = (pi_zero < (1 - threshold)).long()\n",
    "            true_valid = torch.ones_like(pred_valid)  # last step always valid\n",
    "\n",
    "            all_preds_len.extend(pred_valid.cpu().numpy().tolist())\n",
    "            all_labels_len.extend(true_valid.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "        # ----- Regression metrics -----\n",
    "    all_preds_reg = np.concatenate(all_preds_reg)  # (N,)\n",
    "    all_labels_reg = np.concatenate(all_labels_reg)\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "    # ----- Validity metrics -----\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (MDN, last-output):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Validity   → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=1000,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNLSTM_MDN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44de2e9",
   "metadata": {},
   "source": [
    "### hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression only\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per batch ---\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg)\n",
    "    all_labels_reg = np.array(all_labels_reg)\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=300,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return metrics\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a7940",
   "metadata": {},
   "source": [
    "## ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb16e4",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.235186 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.235186 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (3, 12)\n",
      "[main] First few rows:\n",
      " [[ 0.0334583  -0.0164952  -0.08295181 -0.05172484  0.0091133   0.06722008\n",
      "   0.05172484  0.3         1.3036697   1.3155504   1.1531377   1.2362376 ]\n",
      " [-0.05151443 -0.0062422   0.04603237  0.0048193   0.05244192  0.02449848\n",
      "   0.00457536  0.7         1.236512    1.3073386   1.2062193   1.2421954 ]\n",
      " [ 0.00163378 -0.04961828 -0.31281227 -0.19497368  0.00318     0.17110091\n",
      "   0.19259259  0.3         1.2385321   1.2424706   0.8288991   1.        ]]\n",
      "==========================\n",
      "\n",
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([2, 9])\n",
      "  First label in batch: tensor([1.2352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([2, 3, 12])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[ 0.0335, -0.0165, -0.0830, -0.0517,  0.0091,  0.0672,  0.0517,  0.3000,\n",
      "          1.3037,  1.3156,  1.1531,  1.2362],\n",
      "        [-0.0515, -0.0062,  0.0460,  0.0048,  0.0524,  0.0245,  0.0046,  0.7000,\n",
      "          1.2365,  1.3073,  1.2062,  1.2422],\n",
      "        [ 0.0016, -0.0496, -0.3128, -0.1950,  0.0032,  0.1711,  0.1926,  0.3000,\n",
      "          1.2385,  1.2425,  0.8289,  1.0000]])\n",
      "\n",
      "✅ Combined df_seq shape: (6, 12)\n",
      "✅ Column names in df_seq: ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type      | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | fc1           | Linear    | 195    | train\n",
      "1 | ln1           | LayerNorm | 30     | train\n",
      "2 | k1            | Conv1d    | 240    | train\n",
      "3 | k3            | Conv1d    | 690    | train\n",
      "4 | fusion_conv2d | Conv2d    | 3      | train\n",
      "5 | lstm          | LSTM      | 6.3 K  | train\n",
      "6 | mdn_head      | Linear    | 891    | train\n",
      "----------------------------------------------------\n",
      "8.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.3 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4a0ac5bd0e4c7a834a906ea7f5a3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=False,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    feature_eng=15,\n",
    "    n_components=9,\n",
    "    dropout = 0.1,\n",
    "    batch_size=2,\n",
    "    max_epochs=600,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(add_candle_shape_features),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"standard\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         # \"open_dif\":\"standard\",\"close_dif\":\"standard\",\"high_dif\":\"standard\",\"low_dif\":\"standard\"\n",
    "        #         # \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         # \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "          True,\n",
    "          True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_cols)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_lstm(input_dim=input_dim, feature_eng= feature_eng, hidden_dim=hidden_dim, \n",
    "                     n_components=n_components,  lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    init_args = get_init_args(model, input_dim=input_dim,feature_eng= feature_eng\n",
    "                              ,hidden_dim=hidden_dim, n_components=n_components,\n",
    "                              lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/debug_test_seq.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=False,\n",
    "        test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fd2dc",
   "metadata": {},
   "source": [
    "### cnn transforemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948aa8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (5, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      " [ 0.00938704  0.12409948  0.04899828  0.12622231]\n",
      " [ 0.12622082 -0.00192766  0.09665822  0.00645032]\n",
      " [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnn_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 304\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 190\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, early_stop)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# single tensor\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     input_dim \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 190\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_transformer\u001b[49m(input_dim, feature_eng\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, num_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m init_args \u001b[38;5;241m=\u001b[39m get_init_args(model, input_dim\u001b[38;5;241m=\u001b[39minput_dim,num_lines\u001b[38;5;241m=\u001b[39m max_len_y )\n\u001b[1;32m    194\u001b[0m model_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_args\n\u001b[1;32m    198\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=500,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_transformer(input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim,num_lines= max_len_y )\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3023ae",
   "metadata": {},
   "source": [
    "### two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91951ca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm        | LSTM              | 68.6 K | train\n",
      "1 | fc_reg      | Linear            | 774    | train\n",
      "2 | fc_len      | Linear            | 774    | train\n",
      "3 | loss_fn_reg | MSELoss           | 0      | train\n",
      "4 | loss_fn_len | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "70.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 K    Total params\n",
      "0.281     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.086008 1.126277 1.165107 0.970955 0.       0.      ] Encoded (padded): [1.086008 1.126277 1.165107 0.970955 0.       0.      ]\n",
      "[main] Shape: (5, 4)\n",
      "[main] First few rows:\n",
      " [[ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]\n",
      " [-0.08115927 -0.05037893  0.09358804 -0.03372177]\n",
      " [-0.03365467 -0.03511871 -0.06278902  0.03521458]\n",
      " [ 0.03742796  0.00087057 -0.13184595 -0.11191386]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6b9bc314ea4e17b85c57d428d1d2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250913_143827.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250913_143827.pkl\n",
      "\n",
      "📊 Validation Metrics:\n",
      "  Regression → MSE: 0.454865, MAE: 0.510467\n",
      "  Length     → Acc: 0.0667, F1: 0.0096\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            # Send to same device as model\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression + length logits\n",
    "            y_pred, len_logits = model(X_batch, lengths)\n",
    "\n",
    "            # Regression targets\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_batch.cpu().numpy())\n",
    "\n",
    "            # Length targets\n",
    "            true_lengths = lengths.cpu().numpy()\n",
    "            pred_lengths = model.predict_length(len_logits).cpu().numpy()\n",
    "\n",
    "            all_labels_len.extend(true_lengths.tolist())\n",
    "            all_preds_len.extend(pred_lengths.tolist())\n",
    "\n",
    "    # ----- Regression metrics -----\n",
    "    all_preds_reg = np.vstack(all_preds_reg)\n",
    "    all_labels_reg = np.vstack(all_labels_reg)\n",
    "\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    # ----- Length metrics -----\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics:\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Length     → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=50,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838866e",
   "metadata": {},
   "source": [
    "### xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439210d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_main shape: (362, 4, 146)\n",
      "\n",
      "=== DEBUG SAMPLE CHECK (XGBoost mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.139775] Encoded (padded): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (7, 4)\n",
      "First few rows of sequence:\n",
      " [[ 1.01464312e-03  4.30967808e-02 -3.57823558e-02  1.66540481e-02]\n",
      " [ 0.00000000e+00  2.41623223e-02 -6.71248585e-02  9.38569661e-03]\n",
      " [ 1.32806178e-06  1.40555426e-01 -3.05148754e-02  1.26222312e-01]\n",
      " [ 0.00000000e+00  1.07745165e-02 -5.59645146e-02  6.45032339e-03]\n",
      " [ 0.00000000e+00  1.76745001e-03 -8.55189189e-02 -5.38823269e-02]\n",
      " [ 4.26129252e-03  1.06668528e-02 -2.06688777e-01 -7.72438198e-02]\n",
      " [ 0.00000000e+00  4.00911532e-02 -5.98213449e-02 -3.37217674e-02]]\n",
      "ROCKET feature vector (X_rocket): [ 1.          1.026216    0.         ... -0.04845506  0.9931507\n",
      "  0.2994692 ]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.086008 1.126277 1.290228] Encoded (padded): [1.086008 1.126277 1.290228 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (6, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.00000000e+00  1.07745165e-02 -5.59645146e-02  6.45032339e-03]\n",
      " [ 0.00000000e+00  1.76745001e-03 -8.55189189e-02 -5.38823269e-02]\n",
      " [ 4.26129252e-03  1.06668528e-02 -2.06688777e-01 -7.72438198e-02]\n",
      " [ 0.00000000e+00  4.00911532e-02 -5.98213449e-02 -3.37217674e-02]\n",
      " [ 6.94444461e-05  3.85874994e-02 -8.81034732e-02  3.52145843e-02]\n",
      " [ 2.20767432e-03  4.13159095e-03 -2.35263214e-01 -1.11913860e-01]]\n",
      "ROCKET feature vector (X_rocket): [1.         0.92223585 0.         ... 0.03938796 0.9726027  0.23223244]\n",
      "\n",
      "📊 Validation Report (Multi-Regression with variable-length sequences):\n",
      "\n",
      "Sample 0:\n",
      "  Predicted length: 6, True length: 4\n",
      "  MSE: 0.003819, MAE: 0.059365, R²: 0.621011\n",
      "  Predicted lines: [0.7306001  0.7586334  0.789453   0.84672207]\n",
      "  True lines     : [0.659905 0.701181 0.7572   0.923782]\n",
      "\n",
      "Sample 1:\n",
      "  Predicted length: 3, True length: 1\n",
      "  MSE: 0.000367, MAE: 0.019159, R²: nan\n",
      "  Predicted lines: [0.85665256]\n",
      "  True lines     : [0.875812]\n",
      "\n",
      "Sample 2:\n",
      "  Predicted length: 3, True length: 2\n",
      "  MSE: 0.026267, MAE: 0.143602, R²: -46.460762\n",
      "  Predicted lines: [0.844773  1.0420995]\n",
      "  True lines     : [0.776309 0.82336 ]\n",
      "\n",
      "Sample 3:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.000131, MAE: 0.011361, R²: 0.929404\n",
      "  Predicted lines: [1.0109115 1.0742604]\n",
      "  True lines     : [0.998254 1.084324]\n",
      "\n",
      "Sample 4:\n",
      "  Predicted length: 4, True length: 4\n",
      "  MSE: 0.007307, MAE: 0.059826, R²: -2.553568\n",
      "  Predicted lines: [0.7488622  0.9276502  0.97641087 0.9904293 ]\n",
      "  True lines     : [0.913391 0.942228 0.9983   1.028739]\n",
      "\n",
      "Sample 5:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.017921, MAE: 0.093847, R²: -6.833525\n",
      "  Predicted lines: [0.612103   0.87950265 0.9236883 ]\n",
      "  True lines     : [0.840672 0.898335 0.957828]\n",
      "\n",
      "Sample 6:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.105437, MAE: 0.243680, R²: -345.698059\n",
      "  Predicted lines: [0.6243688 1.0884682]\n",
      "  True lines     : [1.082659 1.117537]\n",
      "\n",
      "Sample 7:\n",
      "  Predicted length: 1, True length: 1\n",
      "  MSE: 0.000096, MAE: 0.009822, R²: nan\n",
      "  Predicted lines: [0.99798113]\n",
      "  True lines     : [0.988159]\n",
      "\n",
      "Sample 8:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.062383, MAE: 0.235909, R²: -16.746914\n",
      "  Predicted lines: [1.014916  1.1722956 1.3563795]\n",
      "  True lines     : [1.356097 1.3978   1.497422]\n",
      "\n",
      "Sample 9:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.059909, MAE: 0.243062, R²: -3.164996\n",
      "  Predicted lines: [0.76109445 0.94335276]\n",
      "  True lines     : [0.975353 1.215219]\n",
      "\n",
      "Sample 10:\n",
      "  Predicted length: 4, True length: 6\n",
      "  MSE: 0.003342, MAE: 0.049893, R²: -6.206861\n",
      "  Predicted lines: [0.76336735 0.83922344 0.8831807  0.8990667 ]\n",
      "  True lines     : [0.766538 0.791976 0.808164 0.82493 ]\n",
      "\n",
      "Sample 11:\n",
      "  Predicted length: 3, True length: 1\n",
      "  MSE: 0.008981, MAE: 0.094766, R²: nan\n",
      "  Predicted lines: [1.0637021]\n",
      "  True lines     : [1.158468]\n",
      "\n",
      "Sample 12:\n",
      "  Predicted length: 2, True length: 1\n",
      "  MSE: 0.001788, MAE: 0.042286, R²: nan\n",
      "  Predicted lines: [0.9782339]\n",
      "  True lines     : [0.935948]\n",
      "\n",
      "Sample 13:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.021336, MAE: 0.111127, R²: -13.863990\n",
      "  Predicted lines: [0.69580895 0.92493325 1.0086406 ]\n",
      "  True lines     : [0.938085 0.994583 1.030095]\n",
      "\n",
      "Sample 14:\n",
      "  Predicted length: 2, True length: 1\n",
      "  MSE: 0.001805, MAE: 0.042484, R²: nan\n",
      "  Predicted lines: [1.0056537]\n",
      "  True lines     : [1.048138]\n",
      "\n",
      "Sample 15:\n",
      "  Predicted length: 1, True length: 2\n",
      "  MSE: 0.000027, MAE: 0.005171, R²: nan\n",
      "  Predicted lines: [1.1226981]\n",
      "  True lines     : [1.117527]\n",
      "\n",
      "Sample 16:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.004751, MAE: 0.068878, R²: -9.358092\n",
      "  Predicted lines: [0.92182904 0.96999305]\n",
      "  True lines     : [0.993372 1.036207]\n",
      "\n",
      "Sample 17:\n",
      "  Predicted length: 1, True length: 1\n",
      "  MSE: 0.000020, MAE: 0.004417, R²: nan\n",
      "  Predicted lines: [0.85811025]\n",
      "  True lines     : [0.862527]\n",
      "\n",
      "Sample 18:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.016994, MAE: 0.099001, R²: -46.987663\n",
      "  Predicted lines: [0.89525974 1.102519  ]\n",
      "  True lines     : [1.079072 1.116709]\n",
      "\n",
      "Sample 19:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.019814, MAE: 0.095662, R²: -25.937252\n",
      "  Predicted lines: [0.7485344  0.99263984 1.0561528 ]\n",
      "  True lines     : [0.98843  1.035966 1.052388]\n",
      "\n",
      "Sample 20:\n",
      "  Predicted length: 6, True length: 5\n",
      "  MSE: 0.045400, MAE: 0.207525, R²: -2.498033\n",
      "  Predicted lines: [0.75635314 0.9108957  1.0254605  1.1142099  1.2023455 ]\n",
      "  True lines     : [1.042605 1.143742 1.218046 1.259327 1.383168]\n",
      "\n",
      "Sample 21:\n",
      "  Predicted length: 3, True length: 1\n",
      "  MSE: 0.000357, MAE: 0.018883, R²: nan\n",
      "  Predicted lines: [1.0239918]\n",
      "  True lines     : [1.042875]\n",
      "\n",
      "Sample 22:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.020842, MAE: 0.098240, R²: -3.178410\n",
      "  Predicted lines: [0.7658189 1.0516785 1.1304669]\n",
      "  True lines     : [1.011354 1.053575 1.177756]\n",
      "\n",
      "Sample 23:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.001913, MAE: 0.043664, R²: -0.960265\n",
      "  Predicted lines: [0.9628294 1.1126364]\n",
      "  True lines     : [1.003966 1.066444]\n",
      "\n",
      "Sample 24:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.000015, MAE: 0.003693, R²: 0.911474\n",
      "  Predicted lines: [0.9510035  0.96060795 0.9846519 ]\n",
      "  True lines     : [0.948224 0.957645 0.979314]\n",
      "\n",
      "Sample 25:\n",
      "  Predicted length: 4, True length: 3\n",
      "  MSE: 0.007102, MAE: 0.083874, R²: -7.049133\n",
      "  Predicted lines: [0.8719143  0.92574584 0.96416444]\n",
      "  True lines     : [0.966787 1.007275 1.039386]\n",
      "\n",
      "Sample 26:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.010795, MAE: 0.087127, R²: -8.224894\n",
      "  Predicted lines: [0.6951343  0.85625756 0.8826722 ]\n",
      "  True lines     : [0.860858 0.890957 0.94363 ]\n",
      "\n",
      "Sample 27:\n",
      "  Predicted length: 3, True length: 5\n",
      "  MSE: 0.003435, MAE: 0.050284, R²: -0.094365\n",
      "  Predicted lines: [0.6731774  0.8528071  0.86101055]\n",
      "  True lines     : [0.736604 0.774024 0.869654]\n",
      "\n",
      "Sample 28:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.352181, MAE: 0.420548, R²: -6245.808105\n",
      "  Predicted lines: [0.14602177 0.9984647 ]\n",
      "  True lines     : [0.985283 1.0003  ]\n",
      "\n",
      "Sample 29:\n",
      "  Predicted length: 4, True length: 7\n",
      "  MSE: 0.013860, MAE: 0.088143, R²: -103.746117\n",
      "  Predicted lines: [0.7417819  0.84111714 0.9352474  0.981652  ]\n",
      "  True lines     : [0.944168 0.958041 0.963152 0.976295]\n",
      "\n",
      "Sample 30:\n",
      "  Predicted length: 1, True length: 1\n",
      "  MSE: 0.003720, MAE: 0.060996, R²: nan\n",
      "  Predicted lines: [0.9595799]\n",
      "  True lines     : [0.898584]\n",
      "\n",
      "Sample 31:\n",
      "  Predicted length: 2, True length: 1\n",
      "  MSE: 0.016312, MAE: 0.127717, R²: nan\n",
      "  Predicted lines: [1.0223927]\n",
      "  True lines     : [1.15011]\n",
      "\n",
      "Sample 32:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.000300, MAE: 0.016111, R²: 0.801454\n",
      "  Predicted lines: [1.0330176 1.0785081]\n",
      "  True lines     : [1.010566 1.088278]\n",
      "\n",
      "Sample 33:\n",
      "  Predicted length: 2, True length: 1\n",
      "  MSE: 0.002913, MAE: 0.053975, R²: nan\n",
      "  Predicted lines: [1.0677632]\n",
      "  True lines     : [1.121738]\n",
      "\n",
      "Sample 34:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.009349, MAE: 0.073369, R²: -244.109375\n",
      "  Predicted lines: [0.867827  1.0269178]\n",
      "  True lines     : [1.004175 1.016527]\n",
      "\n",
      "Sample 35:\n",
      "  Predicted length: 4, True length: 4\n",
      "  MSE: 0.018815, MAE: 0.103789, R²: -31.488483\n",
      "  Predicted lines: [0.69725615 0.91055876 0.9515563  0.97300804]\n",
      "  True lines     : [0.955937 0.973722 0.998622 1.019253]\n",
      "\n",
      "Sample 36:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.054956, MAE: 0.174764, R²: -72.381935\n",
      "  Predicted lines: [0.6044965  0.96682394 1.0064126 ]\n",
      "  True lines     : [1.000194 1.034612 1.067219]\n",
      "\n",
      "Sample 37:\n",
      "  Predicted length: 3, True length: 2\n",
      "  MSE: 0.000768, MAE: 0.026889, R²: -0.357610\n",
      "  Predicted lines: [0.82147574 0.8824257 ]\n",
      "  True lines     : [0.855058 0.902621]\n",
      "\n",
      "Sample 38:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.011898, MAE: 0.090877, R²: -24.833355\n",
      "  Predicted lines: [0.8046891 0.9682692]\n",
      "  True lines     : [0.955895 0.998817]\n",
      "\n",
      "Sample 39:\n",
      "  Predicted length: 3, True length: 2\n",
      "  MSE: 0.000165, MAE: 0.012859, R²: 0.618120\n",
      "  Predicted lines: [0.88643986 0.9281643 ]\n",
      "  True lines     : [0.873634 0.915252]\n",
      "\n",
      "Sample 40:\n",
      "  Predicted length: 4, True length: 6\n",
      "  MSE: 0.001284, MAE: 0.028889, R²: -0.624571\n",
      "  Predicted lines: [0.93116057 0.97770953 1.0351317  1.0497075 ]\n",
      "  True lines     : [0.990753 1.013251 1.032416 1.067412]\n",
      "\n",
      "Sample 41:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.000002, MAE: 0.001246, R²: 0.980895\n",
      "  Predicted lines: [1.0196933 1.0341375 1.0434607]\n",
      "  True lines     : [1.018789 1.033092 1.041673]\n",
      "\n",
      "Sample 42:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.125377, MAE: 0.277232, R²: -55.542725\n",
      "  Predicted lines: [0.43513945 0.9735097  0.9898302 ]\n",
      "  True lines     : [1.022507 1.070346 1.137321]\n",
      "\n",
      "Sample 43:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.048808, MAE: 0.181002, R²: -285.773651\n",
      "  Predicted lines: [0.58750576 0.9756011 ]\n",
      "  True lines     : [0.895183 0.921275]\n",
      "\n",
      "Sample 44:\n",
      "  Predicted length: 2, True length: 1\n",
      "  MSE: 0.000658, MAE: 0.025650, R²: nan\n",
      "  Predicted lines: [1.0193837]\n",
      "  True lines     : [1.045034]\n",
      "\n",
      "Sample 45:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.092724, MAE: 0.220940, R²: -6444.072754\n",
      "  Predicted lines: [0.5279962  0.95467603]\n",
      "  True lines     : [0.958483 0.966069]\n",
      "\n",
      "Sample 46:\n",
      "  Predicted length: 1, True length: 2\n",
      "  MSE: 0.000000, MAE: 0.000620, R²: nan\n",
      "  Predicted lines: [0.88107777]\n",
      "  True lines     : [0.880458]\n",
      "\n",
      "Sample 47:\n",
      "  Predicted length: 3, True length: 1\n",
      "  MSE: 0.000149, MAE: 0.012187, R²: nan\n",
      "  Predicted lines: [1.0076443]\n",
      "  True lines     : [0.995457]\n",
      "\n",
      "Sample 48:\n",
      "  Predicted length: 4, True length: 5\n",
      "  MSE: 0.148516, MAE: 0.237200, R²: -16.986940\n",
      "  Predicted lines: [0.2923807 1.1001406 1.1453593 1.2811334]\n",
      "  True lines     : [1.053524 1.177543 1.236932 1.299815]\n",
      "\n",
      "Sample 49:\n",
      "  Predicted length: 4, True length: 4\n",
      "  MSE: 0.001792, MAE: 0.037451, R²: 0.382007\n",
      "  Predicted lines: [0.92539287 0.9318829  0.9863761  1.0547888 ]\n",
      "  True lines     : [0.937739 0.987649 1.044069 1.078789]\n",
      "\n",
      "Sample 50:\n",
      "  Predicted length: 1, True length: 1\n",
      "  MSE: 0.000125, MAE: 0.011197, R²: nan\n",
      "  Predicted lines: [0.87662214]\n",
      "  True lines     : [0.887819]\n",
      "\n",
      "Sample 51:\n",
      "  Predicted length: 4, True length: 4\n",
      "  MSE: 0.011983, MAE: 0.094166, R²: -8.449877\n",
      "  Predicted lines: [0.80116326 0.93390423 0.94024414 1.0550009 ]\n",
      "  True lines     : [0.972674 1.021095 1.043691 1.069515]\n",
      "\n",
      "Sample 52:\n",
      "  Predicted length: 4, True length: 5\n",
      "  MSE: 0.009011, MAE: 0.055538, R²: -20.707993\n",
      "  Predicted lines: [0.7088561 0.8892341 0.9322882 0.9450871]\n",
      "  True lines     : [0.89694  0.914011 0.930077 0.952168]\n",
      "\n",
      "Sample 53:\n",
      "  Predicted length: 4, True length: 5\n",
      "  MSE: 0.008342, MAE: 0.078056, R²: -0.367879\n",
      "  Predicted lines: [0.92379093 0.94028723 0.95711625 1.019257  ]\n",
      "  True lines     : [0.771981 0.852797 0.922465 0.980986]\n",
      "\n",
      "Sample 54:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.059132, MAE: 0.214149, R²: -74.711937\n",
      "  Predicted lines: [0.68162495 0.9669175  0.9954565 ]\n",
      "  True lines     : [1.058688 1.101383 1.126376]\n",
      "\n",
      "Sample 55:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.166225, MAE: 0.294451, R²: -161.365036\n",
      "  Predicted lines: [0.34209114 0.99498546]\n",
      "  True lines     : [0.918542 0.982535]\n",
      "\n",
      "Sample 56:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.095338, MAE: 0.195009, R²: -141.227234\n",
      "  Predicted lines: [0.48082978 1.0303086  1.0525709 ]\n",
      "  True lines     : [1.014382 1.058436 1.075917]\n",
      "\n",
      "Sample 57:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.001513, MAE: 0.035455, R²: -2.731435\n",
      "  Predicted lines: [1.0345639 1.1068105]\n",
      "  True lines     : [1.086008 1.126277]\n",
      "\n",
      "Sample 58:\n",
      "  Predicted length: 2, True length: 1\n",
      "  MSE: 0.000537, MAE: 0.023166, R²: nan\n",
      "  Predicted lines: [0.9712452]\n",
      "  True lines     : [0.948079]\n",
      "\n",
      "Sample 59:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.011603, MAE: 0.106965, R²: -2.395761\n",
      "  Predicted lines: [0.88906604 0.9805309 ]\n",
      "  True lines     : [0.983308 1.100218]\n",
      "\n",
      "Sample 60:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.113266, MAE: 0.240875, R²: -2216.135986\n",
      "  Predicted lines: [0.46915394 0.9535355 ]\n",
      "  True lines     : [0.945072 0.959367]\n",
      "\n",
      "Sample 61:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.024746, MAE: 0.132650, R²: -90.426353\n",
      "  Predicted lines: [0.7483113 0.9503335]\n",
      "  True lines     : [0.96552  0.998424]\n",
      "\n",
      "Sample 62:\n",
      "  Predicted length: 2, True length: 3\n",
      "  MSE: 0.001671, MAE: 0.036360, R²: -44.596348\n",
      "  Predicted lines: [0.88802177 0.9728482 ]\n",
      "  True lines     : [0.943051 0.955157]\n",
      "\n",
      "Sample 63:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.020673, MAE: 0.114699, R²: -141.715195\n",
      "  Predicted lines: [0.7464134  0.94388634]\n",
      "  True lines     : [0.947813 0.971884]\n",
      "\n",
      "Sample 64:\n",
      "  Predicted length: 7, True length: 6\n",
      "  MSE: 0.011643, MAE: 0.106652, R²: -0.012864\n",
      "  Predicted lines: [0.77565575 0.8054658  0.84655243 0.8931465  0.9782692  1.0499047 ]\n",
      "  True lines     : [0.855668 0.904321 0.946023 1.022477 1.101249 1.159169]\n",
      "\n",
      "Sample 65:\n",
      "  Predicted length: 4, True length: 4\n",
      "  MSE: 0.000578, MAE: 0.018132, R²: 0.534536\n",
      "  Predicted lines: [0.87832934 0.9318775  0.97396827 1.0086256 ]\n",
      "  True lines     : [0.923158 0.946344 0.979124 1.016702]\n",
      "\n",
      "Sample 66:\n",
      "  Predicted length: 5, True length: 5\n",
      "  MSE: 0.095130, MAE: 0.211568, R²: -69.960686\n",
      "  Predicted lines: [0.30515236 0.9043752  0.9069564  0.9251792  0.9638211 ]\n",
      "  True lines     : [0.965057 0.985966 1.005266 1.04065  1.066384]\n",
      "\n",
      "Sample 67:\n",
      "  Predicted length: 2, True length: 2\n",
      "  MSE: 0.130352, MAE: 0.292339, R²: -21.907595\n",
      "  Predicted lines: [0.4929524 1.0675693]\n",
      "  True lines     : [0.997165 1.148034]\n",
      "\n",
      "Sample 68:\n",
      "  Predicted length: 4, True length: 6\n",
      "  MSE: 0.007505, MAE: 0.086490, R²: -11.878461\n",
      "  Predicted lines: [0.85002416 0.865207   0.88552713 0.9014709 ]\n",
      "  True lines     : [0.928763 0.950952 0.976645 0.991828]\n",
      "\n",
      "Sample 69:\n",
      "  Predicted length: 3, True length: 4\n",
      "  MSE: 0.055254, MAE: 0.202940, R²: -127.758316\n",
      "  Predicted lines: [0.62179565 0.72457695 0.9538682 ]\n",
      "  True lines     : [0.944451 0.969418 0.995191]\n",
      "\n",
      "Sample 70:\n",
      "  Predicted length: 3, True length: 3\n",
      "  MSE: 0.019043, MAE: 0.122247, R²: -25.662302\n",
      "  Predicted lines: [0.9203455 1.0523334 1.1401603]\n",
      "  True lines     : [1.123357 1.169629 1.186595]\n",
      "\n",
      "Sample 71:\n",
      "  Predicted length: 1, True length: 4\n",
      "  MSE: 0.000416, MAE: 0.020392, R²: nan\n",
      "  Predicted lines: [1.1223089]\n",
      "  True lines     : [1.101917]\n",
      "\n",
      "Sample 72:\n",
      "  Predicted length: 5, True length: 6\n",
      "  MSE: 0.038834, MAE: 0.188527, R²: -6.251622\n",
      "  Predicted lines: [0.4928488 1.0364187 1.042693  1.0998    1.1576513]\n",
      "  True lines     : [0.790804 0.844171 0.900874 0.950906 0.995934]\n",
      "\n",
      "--- Global Scores ---\n",
      "Mean MSE: 0.030682\n",
      "Mean MAE: 0.102481\n",
      "Mean R²: -307.750471\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "# ---------------- Evaluation ---------------- #\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def evaluate_model(model, length_model, X_val, y_val, true_lengths, return_sequences=False):\n",
    "    \"\"\"\n",
    "    Evaluate multi-output regression with predicted sequence lengths.\n",
    "    Permutation-invariant: sorts both predictions and true values before computing metrics.\n",
    "    Can optionally return the predicted vs true sequences for inspection.\n",
    "    \"\"\"\n",
    "    y_pred_full = model.predict(X_val)\n",
    "    pred_lengths = np.round(length_model.predict(X_val)).astype(int)\n",
    "\n",
    "    print(\"\\n📊 Validation Report (Multi-Regression with variable-length sequences):\")\n",
    "    mse_list, mae_list, r2_list = [], [], []\n",
    "\n",
    "    pred_vs_true_list = []  # store predicted vs true sequences if needed\n",
    "\n",
    "    for i, (pred, pred_len, true_y, true_len) in enumerate(zip(y_pred_full, pred_lengths, y_val, true_lengths)):\n",
    "        L = min(pred_len, true_len)\n",
    "        pred_trunc = np.sort(pred[:L])       # sort predictions for permutation-invariant metrics\n",
    "        true_trunc = np.sort(true_y[:L])     # sort true values\n",
    "\n",
    "        mse = mean_squared_error(true_trunc, pred_trunc)\n",
    "        mae = mean_absolute_error(true_trunc, pred_trunc)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            try:\n",
    "                r2 = r2_score(true_trunc, pred_trunc)\n",
    "            except ValueError:\n",
    "                r2 = np.nan\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  Predicted length: {pred_len}, True length: {true_len}\")\n",
    "        print(f\"  MSE: {mse:.6f}, MAE: {mae:.6f}, R²: {r2:.6f}\")\n",
    "        print(f\"  Predicted lines: {pred_trunc}\")\n",
    "        print(f\"  True lines     : {true_trunc}\")\n",
    "\n",
    "        if return_sequences:\n",
    "            pred_vs_true_list.append((pred_trunc, true_trunc))\n",
    "\n",
    "    print(\"\\n--- Global Scores ---\")\n",
    "    print(f\"Mean MSE: {np.mean(mse_list):.6f}\")\n",
    "    print(f\"Mean MAE: {np.mean(mae_list):.6f}\")\n",
    "    print(f\"Mean R²: {np.nanmean(r2_list):.6f}\")\n",
    "\n",
    "    results = {\"mse\": np.mean(mse_list), \"mae\": np.mean(mae_list), \"r2\": np.nanmean(r2_list)}\n",
    "    \n",
    "    if return_sequences:\n",
    "        results[\"pred_vs_true\"] = pred_vs_true_list\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=1000,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    num_kernels = 100,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor with a linked sequence-length predictor.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.pkl\"\n",
    "    length_model_out = f\"{model_out_dir}/xgb_model_seq_len_{timestamp}.pkl\"\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # --- Preprocess data ---\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, df, feature_cols, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[1,3],\n",
    "            feature_pipeline=pipeline,\n",
    "            num_kernels = num_kernels,\n",
    "            preserve_order= False\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, df, feature_cols, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    # --- Train max-line regression ---\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "\n",
    "    model = MultiOutputRegressor(xgb_model, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Train length predictor ---\n",
    "    xgb_len_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "    xgb_len_model.fit(X_train, train_lengths)\n",
    "\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Save trained models\n",
    "        joblib.dump(model, model_out)\n",
    "        joblib.dump(xgb_len_model, length_model_out)\n",
    "        \n",
    "        # Save full metadata\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"multioutput_wrapper\": {\n",
    "                \"class\": model.__class__.__name__,\n",
    "                \"module\": model.__class__.__module__,\n",
    "            }\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Length predictor saved to {length_model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, xgb_len_model, X_val, y_val, val_lengths, return_sequences=True)\n",
    "\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        num_kernels = 2000,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed65845",
   "metadata": {},
   "source": [
    "### XG boost 1 head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dacf956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_main shape: (362, 4, 146)\n",
      "\n",
      "=== DEBUG SAMPLE CHECK (XGBoost mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [1.139775] Encoded (padded): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (7, 4)\n",
      "First few rows of sequence:\n",
      " [[ 1.01464312e-03  4.30967808e-02 -3.57823558e-02  1.66540481e-02]\n",
      " [ 0.00000000e+00  2.41623223e-02 -6.71248585e-02  9.38569661e-03]\n",
      " [ 1.32806178e-06  1.40555426e-01 -3.05148754e-02  1.26222312e-01]\n",
      " [ 0.00000000e+00  1.07745165e-02 -5.59645146e-02  6.45032339e-03]\n",
      " [ 0.00000000e+00  1.76745001e-03 -8.55189189e-02 -5.38823269e-02]\n",
      " [ 4.26129252e-03  1.06668528e-02 -2.06688777e-01 -7.72438198e-02]\n",
      " [ 0.00000000e+00  4.00911532e-02 -5.98213449e-02 -3.37217674e-02]]\n",
      "ROCKET feature vector (X_rocket): [9.53488350e-01 8.61878967e+00 9.31506872e-01 1.66629562e+01\n",
      " 9.81132090e-01 1.05033360e+01 2.83018872e-02 2.99045048e+01\n",
      " 2.14285720e-02 8.80680847e+00 6.84931502e-02 1.54439392e+01\n",
      " 1.11111112e-01 8.12637424e+00 1.00000000e+00 3.08411961e+01\n",
      " 1.47058824e-02 2.14829063e+01 9.72602725e-01 1.46254225e+01]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.086008 1.126277 1.290228] Encoded (padded): [1.086008 1.126277 1.290228 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (6, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.00000000e+00  1.07745165e-02 -5.59645146e-02  6.45032339e-03]\n",
      " [ 0.00000000e+00  1.76745001e-03 -8.55189189e-02 -5.38823269e-02]\n",
      " [ 4.26129252e-03  1.06668528e-02 -2.06688777e-01 -7.72438198e-02]\n",
      " [ 0.00000000e+00  4.00911532e-02 -5.98213449e-02 -3.37217674e-02]\n",
      " [ 6.94444461e-05  3.85874994e-02 -8.81034732e-02  3.52145843e-02]\n",
      " [ 2.20767432e-03  4.13159095e-03 -2.35263214e-01 -1.11913860e-01]]\n",
      "ROCKET feature vector (X_rocket): [ 1.          7.265891    0.9520548   8.4715185   1.          7.5793633\n",
      "  0.         -0.1044336   0.02142857 10.029431    0.0890411  14.154301\n",
      "  0.1388889   6.331827    0.9512195  13.902936    0.02205882 20.669838\n",
      "  0.8767123  10.760459  ]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.053524 1.177543 1.236932 1.299815 1.364445] Encoded (padded): [1.053524 1.177543 1.236932 1.299815 1.364445 0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (9, 4)\n",
      "First few rows of sequence:\n",
      " [[ 4.2612925e-03  1.0666853e-02 -2.0668878e-01 -7.7243820e-02]\n",
      " [ 0.0000000e+00  4.0091153e-02 -5.9821345e-02 -3.3721767e-02]\n",
      " [ 6.9444446e-05  3.8587499e-02 -8.8103473e-02  3.5214584e-02]\n",
      " [ 2.2076743e-03  4.1315909e-03 -2.3526321e-01 -1.1191386e-01]\n",
      " [-1.5107132e-06  6.5791562e-02 -5.5804234e-02  3.7860740e-02]\n",
      " [ 7.2343467e-04  6.1134599e-02 -2.4643359e-03  3.4205943e-02]\n",
      " [ 0.0000000e+00  9.1133006e-03 -1.1546798e-01 -5.1724840e-02]\n",
      " [ 2.2189255e-04  5.7513956e-02 -2.4282021e-02  4.8192986e-03]\n",
      " [-2.9490551e-03  2.2156688e-04 -3.3271441e-01 -1.9497368e-01]]\n",
      "ROCKET feature vector (X_rocket): [ 0.9883721   5.7916045   0.89041096  6.889959    0.9811321   5.6106834\n",
      "  0.         -0.10443363  0.05       10.655044    0.3561644  12.144565\n",
      "  0.22222222  9.852006    1.         20.163492    0.04411765  9.762816\n",
      "  0.89041096  9.404309  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/projects/meta-learning/models/losses/soft_assignment_xg_boost.py:78: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_logits = np.exp(logits - row_max)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 233\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# ---------------- Main ---------------- #\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 233\u001b[0m     \u001b[43mtrain_model_xgb_multireg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_kernels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 191\u001b[0m, in \u001b[0;36mtrain_model_xgb_multireg\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, n_estimators, max_depth, learning_rate, subsample, colsample_bytree, save_model, return_val_metrics, num_kernels, scale_label, normalise, **model_params)\u001b[0m\n\u001b[1;32m    180\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\n\u001b[1;32m    181\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[1;32m    182\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params\n\u001b[1;32m    188\u001b[0m )\n\u001b[1;32m    190\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputRegressor(xgb_model, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 191\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# --- Save models ---\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_model:\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/sklearn/multioutput.py:278\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from models.losses.soft_assignment_xg_boost import soft_assignment_loss_objective\n",
    "# ---------------- Evaluation ---------------- #\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# ----------------- Evaluation Function for XGBoost ---------------- #\n",
    "def evaluate_model_xgb(model, X_val, y_val, pipeline=None, scale_labels=False):\n",
    "    \"\"\"\n",
    "    Evaluates an XGBoost model using Hungarian matching for performance metrics.\n",
    "\n",
    "    Args:\n",
    "        model (MultiOutputRegressor): The trained XGBoost model wrapped in MultiOutputRegressor.\n",
    "        X_val (np.ndarray): The validation features.\n",
    "        y_val (np.ndarray): The validation labels with padded zeros.\n",
    "        pipeline (object, optional): The scikit-learn pipeline for inverse transformations.\n",
    "        scale_labels (bool, optional): Whether to inverse-transform the labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the computed MSE and MAE.\n",
    "    \"\"\"\n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Ensure y_pred and y_val have the correct shape\n",
    "    n_samples, n_preds = y_pred.shape\n",
    "    n_samples_val, n_labels = y_val.shape\n",
    "    \n",
    "    if n_samples != n_samples_val:\n",
    "        raise ValueError(\"Shape mismatch between predictions and true labels.\")\n",
    "\n",
    "    # --- Inverse-transform back to original scale if requested ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        # Reshape for the scaler, which expects a 2D array\n",
    "        y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(n_samples, n_preds)\n",
    "        y_val = scaler.inverse_transform(y_val.reshape(-1, 1)).reshape(n_samples, n_labels)\n",
    "        \n",
    "    all_preds_matched = []\n",
    "    all_labels_matched = []\n",
    "\n",
    "    # Loop through each sample to perform Hungarian matching\n",
    "    for i in range(n_samples):\n",
    "        preds = y_pred[i, :]\n",
    "        true_labels = y_val[i, :]\n",
    "        \n",
    "        # Filter out padded zeros from true labels\n",
    "        gt_vals = true_labels[true_labels != 0]\n",
    "\n",
    "        if gt_vals.size == 0:\n",
    "            # If a sample has no true targets, skip it\n",
    "            continue\n",
    "\n",
    "        # Compute cost matrix (squared differences)\n",
    "        # Using broadcasting to create the cost matrix\n",
    "        cost = (preds[None, :] - gt_vals[:, None]) ** 2\n",
    "        \n",
    "        # Perform Hungarian assignment to find the optimal one-to-one matching\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "        # Get the matched predictions and true labels\n",
    "        matched_preds = preds[col_ind]\n",
    "        matched_labels = gt_vals[row_ind]\n",
    "\n",
    "        all_preds_matched.extend(matched_preds.tolist())\n",
    "        all_labels_matched.extend(matched_labels.tolist())\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    all_preds_matched = np.array(all_preds_matched, dtype=np.float32)\n",
    "    all_labels_matched = np.array(all_labels_matched, dtype=np.float32)\n",
    "\n",
    "    # Calculate regression metrics on the matched pairs\n",
    "    mse = mean_squared_error(all_labels_matched, all_preds_matched)\n",
    "    mae = mean_absolute_error(all_labels_matched, all_preds_matched)\n",
    "    \n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression -> MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=1000,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    num_kernels = 100,\n",
    "    scale_label = False,\n",
    "    normalise = True,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor with a linked sequence-length predictor.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.pkl\"\n",
    "    length_model_out = f\"{model_out_dir}/xgb_model_seq_len_{timestamp}.pkl\"\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # --- Preprocess data ---\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, df, feature_cols, max_len_y, train_lengths,val_lengths = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            num_kernels = num_kernels,\n",
    "            preserve_order= False,\n",
    "            normalise = True\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, df, feature_cols, max_len_y, seq_lengths_true = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    # --- Train max-line regression ---\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=soft_assignment_loss_objective,\n",
    "        **model_params\n",
    "    )\n",
    "\n",
    "    model = MultiOutputRegressor(xgb_model, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Save trained models\n",
    "        joblib.dump(model, model_out)\n",
    "        \n",
    "        # Save full metadata\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"multioutput_wrapper\": {\n",
    "                \"class\": model.__class__.__name__,\n",
    "                \"module\": model.__class__.__module__,\n",
    "            }\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Length predictor saved to {length_model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model_xgb(model, X_val, y_val,scale_labels = scale_label)\n",
    "\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        num_kernels = 10,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e330df",
   "metadata": {},
   "source": [
    "### Hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377d5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (5, 4)\n",
      "[main] First few rows:\n",
      " [[ 0.00000000e+00  2.41623223e-02 -6.71248585e-02  9.38569661e-03]\n",
      " [ 1.32806178e-06  1.40555426e-01 -3.05148754e-02  1.26222312e-01]\n",
      " [ 0.00000000e+00  1.07745165e-02 -5.59645146e-02  6.45032339e-03]\n",
      " [ 0.00000000e+00  1.76745001e-03 -8.55189189e-02 -5.38823269e-02]\n",
      " [ 4.26129252e-03  1.06668528e-02 -2.06688777e-01 -7.72438198e-02]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LSTMMultiRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 284\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 154\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, early_stop)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# single tensor\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         input_dim \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 154\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTMMultiRegressor\u001b[49m(\n\u001b[1;32m    155\u001b[0m         input_dim\u001b[38;5;241m=\u001b[39minput_dim,\n\u001b[1;32m    156\u001b[0m         hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m    157\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[1;32m    158\u001b[0m         max_len_y\u001b[38;5;241m=\u001b[39mmax_len_y,\n\u001b[1;32m    159\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     init_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_dim,\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr\n\u001b[1;32m    167\u001b[0m }\n\u001b[1;32m    169\u001b[0m     model_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m,\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_args\n\u001b[1;32m    173\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTMMultiRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression only\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per batch ---\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "            #y_batch.shape[0] is batch actually\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg)\n",
    "    all_labels_reg = np.array(all_labels_reg)\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=30,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=100,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return metrics\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8d4ec",
   "metadata": {},
   "source": [
    "### Hungarian CNN-attention lstm weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1000a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [0.       1.05529  0.923251 0.828937 0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [0.       1.05529  0.923251 0.828937 0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[0.8487854  0.8556362  0.7894722  0.82848144]\n",
      " [0.8286152  0.9581091  0.79814214 0.9086739 ]\n",
      " [0.90959585 0.94783473 0.87615937 0.9238069 ]\n",
      " [0.9238069  0.94612825 0.86179656 0.93247753]\n",
      " [0.9324787  1.0635422  0.90402305 1.050177  ]\n",
      " [1.050177   1.0614922  0.99140435 1.0569509 ]\n",
      " [1.0569509  1.0588192  0.9665617  1.        ]]\n",
      "[candle_shape] Shape: (7, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.00807125 0.0470852  0.02392123 0.3       ]\n",
      " [0.05440368 0.03677583 0.08810496 0.7       ]\n",
      " [0.02600957 0.0367597  0.01538321 0.7       ]\n",
      " [0.01463923 0.06712486 0.00929843 0.7       ]\n",
      " [0.01272671 0.03051616 0.11207467 0.7       ]\n",
      " [0.00429648 0.05596451 0.00640898 0.7       ]\n",
      " [0.00176745 0.03343833 0.05388233 0.3       ]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[1.0201389  1.063025   0.9826389  1.036077  ]\n",
      " [1.036077   1.0611111  0.96653056 1.0458014 ]\n",
      " [1.0458027  1.1927944  1.0138888  1.177805  ]\n",
      " [1.177805   1.1904953  1.1118896  1.185402  ]\n",
      " [1.185402   1.1874973  1.0840278  1.1215299 ]\n",
      " [1.126309   1.1334931  0.8897222  1.0348986 ]\n",
      " [1.0348986  1.0763888  0.97298956 1.        ]]\n",
      "[candle_shape] Shape: (7, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.02600957 0.0367597  0.01538321 0.7       ]\n",
      " [0.01463923 0.06712486 0.00929843 0.7       ]\n",
      " [0.01272671 0.03051616 0.11207467 0.7       ]\n",
      " [0.00429648 0.05596451 0.00640898 0.7       ]\n",
      " [0.00176745 0.03343833 0.05388233 0.3       ]\n",
      " [0.00637838 0.14028078 0.08115927 0.3       ]\n",
      " [0.04009115 0.02701042 0.03372177 0.3       ]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (6, 4)\n",
      "[main] First few rows:\n",
      " [[1.2811143  1.2949177  1.2094173  1.2893778 ]\n",
      " [1.2893778  1.2916569  1.1791116  1.2199032 ]\n",
      " [1.2251015  1.2329156  0.9677629  1.1256732 ]\n",
      " [1.1256732  1.1708027  1.0583339  1.0877135 ]\n",
      " [1.087789   1.1296856  0.99188215 1.1260169 ]\n",
      " [1.1285027  1.1306691  0.8611065  1.        ]]\n",
      "[candle_shape] Shape: (6, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.00429648 0.05596451 0.00640898 0.7       ]\n",
      " [0.00176745 0.03343833 0.05388233 0.3       ]\n",
      " [0.00637838 0.14028078 0.08115927 0.3       ]\n",
      " [0.04009115 0.02701042 0.03372177 0.3       ]\n",
      " [0.00325818 0.0881668  0.03394962 0.7       ]\n",
      " [0.00191968 0.13889347 0.11387014 0.3       ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop'], 'candle_shape': ['upper_shadow', 'lower_shadow', 'body', 'color']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 12:34:48.205608: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-21 12:34:48.444767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758445488.524386     945 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758445488.548197     945 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758445488.750025     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758445488.750057     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758445488.750058     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758445488.750059     945 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-21 12:34:48.772236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss_fn_reg   | MSELoss       | 0      | train\n",
      "1 | attention     | TanhAttention | 3.7 K  | train\n",
      "2 | branches      | ModuleList    | 3.7 K  | train\n",
      "3 | fusion_conv2d | Sequential    | 1.3 K  | train\n",
      "4 | lstm          | LSTM          | 18.2 K | train\n",
      "5 | regressor     | Sequential    | 2.1 K  | train\n",
      "--------------------------------------------------------\n",
      "29.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.1 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036b6b09a1eb4cb7ab60c6292ec37df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e544401940a424bb741378b4d50aede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c972cffa5cdc42dbae610b7ef72cac90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325311ad738c45b4bb3e176ff0ee23f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5042f17c257948ae8832a7c9805f91af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dbd2e773a64a31a17f7d67f06fc6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645308cb191540a8abff0a860e740544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e203c3207242609878083d1c6df18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a720a534154510aeb945ee1e0fabcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b287f8a83ca443c795b4c81ac3273e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6045892a774765a6fc56670f9ff22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966069ec5f2941f6a032ba127f38a8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ed5c059e044dd9ad5538eacde59ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff56253012a64d728445a5a9ed9ba497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2113dc1062be48b4a8ff0b8b194418a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5361fd383a7f4cd6b4461c92acd1cd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe89baff8f7450c85d082e24caffd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cda747632e34209a4464cc247f0cb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bc2543e2e742e595441acbed70ee44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d3a055376d4d9cb8c93bbc41f31452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c084df27792d40fca041da0a8c6f31fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acfe17d99604ffdb2b12b4693371c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddf44b280e6462a8cb0f5ee09396368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e487678473f47bd9d2f86c6a292ba07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6df603653ba49209d8cc06671a8ebf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8198c5f849b347ecb40317f38121f02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c8fdb51617479ba88b8cc6b86b1f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7f2ef78ed848f4b00a50f06807b83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fde6010e57c4bb6b6745edca3198a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0eb51729ce4a91850ba09b109e3373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa046dd74b4442beb88afd30f46f1d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e05a94d6224b14a20f48b010737844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d05e893afc47bcb01b1ae2ac5afe9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd00ba7d3194e3e8a46e4c09277ac26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91053c400609417a86088fa990222950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b7caf156fe4a088210a77ea4afec19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8215cb6dc946e582f1274926365068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d44a0a282448a28662aa27ebe9daf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8709eaea3a3649a385f3a0f3d9042c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26808fde7544ceb944a63b6e208a9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56d07ff73604885965d2738788d9807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e57b8b9ce934edda6790c342c45868f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfeec1ff6f3499687e1c4cf32a1dcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0374fd0c293c4ea1bd3ce8ff051ff1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ced1c3051294fd2be0b12bb9e7e8a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605f30a0efb64eeeb073493a9cdc95a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c692e2800a4ef4aff727fa6772e8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3fed1b80c04f10ac2c89ab95079ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17e04c420344fb0be7bd82701c2f26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8dc2b3df084d45a107fd5b7dd58b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d105c28b8b344fa1b3a85eb3ffbbc47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fee4d428f1a4d32aa278c0e50368451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c4740a2f764f0daa09606e4f5cb7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06271b05d5744b48a94ec134d1761287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405085fc398a4b30a820573ef67f5df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d7efd2ed4144d98cd6fd93710bf77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8780b3de8fa44af5855f157d1ba2bbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d888d159956465d9f155a9c067c7cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e057ea6b41e4a629b2518758b73d9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82576a845f304e73a8153a56fb4b9e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df4255ce6f4cd2818e24e2be8f7b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11200d963164dda8f5e3515ee800570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c774b8436d447a8b9833aadeb3c6706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487e63db88504a3593ad5dbdef19473b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c8f687e3634189b58145624cecc3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c4c1699233429ba27a14fc4ef4b7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb0fec5385b45dc800afef00b4abe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a71bf0c60b4182ae8c97fba886fcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baaa6a4edec43848e7e35b8fdf80bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47adddf4f42e493da9b21b85c1caf069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90512b95bc2d497c820c65b10762e431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4208124a93884065951573e1a548b143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1959af1db36b490bae0989b409b3f136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437418a0f98d468a873f4a2427e2fd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5790f38ecc4f1f8e9b0a173b3dfcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4aa286c1a34a04b77bb55c3c74fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6daea4de32074ab1a2276df1b91941a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c914379d3f541de9c768299849b62c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf45ac5194494f9ba5893ec419a6d9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da81b2048a0d4c409b403b3569c6992a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e8d09b5b814019b91079cf6e04880d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a352dacbdef141d39b42bb6ee1351546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d87c3fbb514446afcc62aa03036104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aafe697ac44f1f87887505f2130299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173c701283a743798c5999a64c488966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc29d56252e452185b05bf8fd6afc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6dfef86e87464ea5001417b16d7ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0ce4ccb0564d22b240ec31bf93504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122a95fb51d54c73965f6c92db9a1f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4605659a5548ccb11db81ad4697e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07ac70247aa433f8fe2192adc727e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caf3986f7784c52b282647ec179f02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6254fac51c4340bba965bd1d0b19acdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f7e8a4a0be40dfbae38cb7a2390102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33d0f9edbcd4fada55c33be70948301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6859d77e4864071ad625b45fa18dc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eb6df249e24e28a1b3a2bc9a0a8ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d533d9d4c54f7d94d4bde7cca6327b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0f15adbdc244a0a190eeed02f1c12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4752f0d2906846528c71ccbf3dda1d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd106c8bf0a4dad9fec30061678bf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64c47422d57479c92c603d9a51b0586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : CNNAttentionLSTMMultiRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 4, 'candle_shape': 4}\n",
      "    hidden_dim: 60\n",
      "    num_layers: 1\n",
      "    max_len_y: 9\n",
      "    lr: 0.0001\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    kernels: [3, 5, 7, 11]\n",
      "    cnn_out_channels: 32\n",
      "    first_drop: 0.3\n",
      "    second_drop: 0.3\n",
      "    third_drop: 0.3\n",
      "    scheduler_name: reduce_on_plateau\n",
      "    optimizer_params: {'weight_decay': 0.01}\n",
      "    scheduler_params: {'factor': 0.2, 'patience': 3}\n",
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250921_123446.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250921_123446.pkl\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.006634, MAE: 0.057623 [original units]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "from utils.print_scalers import print_scaler_dict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, pipeline=None, scale_labels=False):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per sample ---\n",
    "            batch_preds, batch_labels = [], []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg, dtype=np.float32)\n",
    "    all_labels_reg = np.array(all_labels_reg, dtype=np.float32)\n",
    "\n",
    "    # --- Optionally inverse-transform back to original scale ---\n",
    "    if scale_labels and pipeline is not None and hasattr(pipeline, \"target_scaler\"):\n",
    "        scaler = pipeline.target_scaler\n",
    "        all_preds_reg = scaler.inverse_transform(all_preds_reg.reshape(-1, 1)).ravel()\n",
    "        all_labels_reg = scaler.inverse_transform(all_labels_reg.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f} \"\n",
    "          f\"[{'scaled' if scale_labels else 'original'} units]\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=60,\n",
    "    num_layers=1,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    attention_name = \"tanh_attention\",\n",
    "    optimizer_name= \"adamw\",\n",
    "    kernels = [3,5,7,11],\n",
    "    cnn_out_channels =32,\n",
    "    first_drop = 0.3,\n",
    "    second_drop = 0.3,\n",
    "    third_drop= 0.3,\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    scale_labels = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features, seperatable = \"complete\", dict_name = \"candle_shape\"),\n",
    "            # make_step(add_candle_rocp),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        True, \n",
    "        True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=[1,3,5],\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_columns, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "            scale_labels = scale_labels\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_columns)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):\n",
    "        # build a dict of input_dims for all feature groups\n",
    "        input_dim = {k: v.shape[1] for k, v in sample.items()}\n",
    "    else:\n",
    "        # single tensor → wrap into dict with a default key\n",
    "        input_dim = {\"main\": sample.shape[1]}\n",
    "\n",
    "    model = CNNAttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr,\n",
    "        attention_name = attention_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        kernels = kernels,\n",
    "        cnn_out_channels =cnn_out_channels,\n",
    "        first_drop = first_drop,\n",
    "        second_drop = second_drop,\n",
    "        third_drop = third_drop,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params \n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr,\n",
    "    \"attention_name\" : attention_name,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"kernels\" : kernels,\n",
    "    \"cnn_out_channels\" :cnn_out_channels,\n",
    "    \"first_drop\" : first_drop,\n",
    "    \"second_drop\" : second_drop,\n",
    "    \"third_drop\": third_drop,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name in feature_columns:\n",
    "                feature_names_dict[name] = feature_columns[name]\n",
    "            else:\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # Print feature scalers\n",
    "    print_scaler_dict(\"pipeline.scalers\", pipeline.scalers)\n",
    "\n",
    "    # Print window scalers\n",
    "    print_scaler_dict(\"pipeline.window_scalers\", pipeline.window_scalers)\n",
    "\n",
    "    # Print target scaler\n",
    "    target_scaler = pipeline.export_target_scalers()\n",
    "    print(\"\\n🎯 Target scaler:\")\n",
    "    if hasattr(target_scaler, \"mean_\") and hasattr(target_scaler, \"var_\"):\n",
    "        print(f\"  mean={np.round(target_scaler.mean_, 4)}, var={np.round(target_scaler.var_, 4)}\")\n",
    "    else:\n",
    "        print(f\"  (no mean_/var_ found) -> {target_scaler}\")\n",
    "\n",
    "    # Print model_class_info and init_args\n",
    "    print(\"\\n📦 model_class_info:\")\n",
    "    print(f\"  module: {model_class_info['module']}\")\n",
    "    print(f\"  class : {model_class_info['class']}\")\n",
    "    print(f\"  init_args:\")\n",
    "    for k, v in model_class_info[\"init_args\"].items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"target_scalers\": pipeline.export_target_scalers(),\n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader,pipeline, scale_labels)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False,\n",
    "        scale_labels = False,\n",
    "        max_epochs=100\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399de860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "high_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "low_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "close_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "color",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "5eed4cfd-9907-4d9d-b9b7-3e91afa7e322",
       "rows": [
        [
         "0",
         "3.1119325",
         "3.4781706",
         "3.4061303",
         "3.4276407",
         "3.6520383",
         "0.8363725",
         "-0.4499542",
         "0.0"
        ],
        [
         "1",
         "3.1279716",
         "2.9642682",
         "0.11395626",
         "1.3453131",
         "-0.49563015",
         "10.862902",
         "6.025596",
         "-1.0"
        ],
        [
         "2",
         "1.2341014",
         "1.6109802",
         "0.116310015",
         "1.415349",
         "4.5402703",
         "10.844402",
         "-0.32921672",
         "0.0"
        ],
        [
         "3",
         "1.2869838",
         "1.7547662",
         "1.2348816",
         "1.3941935",
         "6.1904225",
         "2.4466078",
         "-0.57420075",
         "-1.0"
        ],
        [
         "4",
         "1.2778133",
         "1.6938448",
         "1.1745819",
         "1.7988474",
         "1.5847327",
         "2.90498",
         "0.9381372",
         "0.0"
        ],
        [
         "5",
         "1.6529298",
         "2.6416125",
         "2.017039",
         "2.8439512",
         "1.2038012",
         "-0.46645483",
         "2.9575825",
         "0.0"
        ],
        [
         "6",
         "2.6179397",
         "2.424149",
         "1.6588677",
         "1.8422452",
         "-0.76337415",
         "2.5122745",
         "2.8091989",
         "-1.0"
        ],
        [
         "7",
         "1.6930059",
         "1.789311",
         "0.806557",
         "1.2349231",
         "2.1309168",
         "4.6259503",
         "1.6923822",
         "-1.0"
        ],
        [
         "8",
         "1.1321678",
         "1.4060249",
         "0.8103667",
         "1.2657881",
         "3.9131463",
         "4.5956955",
         "-0.48273998",
         "0.0"
        ],
        [
         "9",
         "1.1606416",
         "1.5306603",
         "1.2866476",
         "1.7002573",
         "0.8722596",
         "1.0553573",
         "1.0640053",
         "0.0"
        ],
        [
         "10",
         "1.5618633",
         "1.6931535",
         "1.6470284",
         "1.5624406",
         "2.5309727",
         "0.5382239",
         "-0.07744142",
         "-1.0"
        ],
        [
         "11",
         "1.4414867",
         "1.5833688",
         "1.1354791",
         "1.4943928",
         "2.6866186",
         "3.9583337",
         "-0.3128444",
         "-1.0"
        ],
        [
         "12",
         "1.3717779",
         "1.5884559",
         "1.5609623",
         "1.8114834",
         "0.40164202",
         "0.6800013",
         "0.59735435",
         "0.0"
        ],
        [
         "13",
         "1.6711396",
         "2.020185",
         "2.0134768",
         "2.1182802",
         "1.8167411",
         "-0.29212007",
         "0.49403894",
         "0.0"
        ],
        [
         "14",
         "1.9479133",
         "1.8246856",
         "1.7985896",
         "1.6221755",
         "-0.08958885",
         "-0.16166031",
         "1.2158589",
         "-1.0"
        ],
        [
         "15",
         "1.4891323",
         "1.3401905",
         "0.80636424",
         "0.8227535",
         "-0.32697996",
         "1.415624",
         "2.492454",
         "-1.0"
        ],
        [
         "16",
         "0.74607456",
         "0.69872344",
         "0.6462701",
         "0.8602912",
         "0.3888383",
         "2.704171",
         "-0.4230243",
         "0.0"
        ],
        [
         "17",
         "0.78620994",
         "0.63269246",
         "-0.113385886",
         "0.02372521",
         "-0.35488108",
         "2.6717138",
         "2.9439821",
         "-1.0"
        ],
        [
         "97",
         "1.1270775",
         "0.9447718",
         "0.9220812",
         "0.7722085",
         "-0.6747617",
         "0.02720682",
         "1.2489815",
         "-1.0"
        ],
        [
         "98",
         "0.7094123",
         "0.5335009",
         "0.70824677",
         "0.64105856",
         "-0.60740423",
         "0.73096174",
         "-0.02388771",
         "-1.0"
        ],
        [
         "99",
         "0.5794438",
         "0.49472648",
         "0.7353396",
         "0.5591924",
         "0.44837418",
         "-0.20308349",
         "-0.27051294",
         "-1.0"
        ],
        [
         "100",
         "0.508157",
         "0.33264738",
         "0.5528108",
         "0.44819957",
         "-0.6035003",
         "0.41775525",
         "-0.11817226",
         "-1.0"
        ],
        [
         "101",
         "0.3994197",
         "0.28942516",
         "0.17734659",
         "0.02372521",
         "0.17420061",
         "-0.02114459",
         "1.2623639",
         "-1.0"
        ],
        [
         "194",
         "-0.34134802",
         "-0.5154765",
         "-0.3859573",
         "-0.443129",
         "-0.5884766",
         "0.92105496",
         "-0.19570743",
         "-1.0"
        ],
        [
         "195",
         "-0.4174476",
         "-0.28729883",
         "-0.2141771",
         "-0.15161742",
         "-0.1368049",
         "-0.7791175",
         "0.8063944",
         "0.0"
        ],
        [
         "196",
         "-0.14824808",
         "-0.12646532",
         "0.050338376",
         "-0.0133293625",
         "0.27293167",
         "-0.4843567",
         "0.050396472",
         "0.0"
        ],
        [
         "197",
         "-0.020544458",
         "-0.14803287",
         "0.1610151",
         "0.02372521",
         "-0.43197376",
         "-0.21499538",
         "-0.43214038",
         "0.0"
        ],
        [
         "291",
         "-0.3831967",
         "-0.23344669",
         "-0.18380184",
         "-0.19378608",
         "1.0670503",
         "-0.7079398",
         "0.42811665",
         "0.0"
        ],
        [
         "292",
         "-0.1861587",
         "-0.32294622",
         "-0.11097052",
         "-0.23052579",
         "-0.10493648",
         "0.29926202",
         "-0.42285568",
         "-1.0"
        ],
        [
         "293",
         "-0.21702659",
         "-0.07465285",
         "-0.087855466",
         "0.054996945",
         "0.12386127",
         "0.119950764",
         "0.71731484",
         "0.0"
        ],
        [
         "294",
         "0.042552214",
         "-0.080403395",
         "0.12669154",
         "-0.057044998",
         "0.051950745",
         "-0.30524078",
         "-0.079459056",
         "-1.0"
        ],
        [
         "295",
         "-0.063821346",
         "0.027049925",
         "0.1021417",
         "0.02372521",
         "1.7667388",
         "-0.10490292",
         "-0.21031186",
         "0.0"
        ],
        [
         "388",
         "0.84738415",
         "0.78582245",
         "0.15392786",
         "0.31102046",
         "0.6706319",
         "2.7543352",
         "1.9843782",
         "-1.0"
        ],
        [
         "389",
         "0.2789799",
         "0.22321913",
         "-0.1011299",
         "-0.17618343",
         "0.8423865",
         "0.7220283",
         "1.611024",
         "-1.0"
        ],
        [
         "390",
         "-0.1741542",
         "-0.26132384",
         "-0.6673064",
         "-0.21025291",
         "0.5352205",
         "5.8170395",
         "-0.45861423",
         "-1.0"
        ],
        [
         "391",
         "-0.20028102",
         "-0.2050632",
         "-0.40546292",
         "-0.55887246",
         "1.6083506",
         "-0.034750484",
         "1.1081097",
         "-1.0"
        ],
        [
         "392",
         "-0.52433217",
         "-0.029249495",
         "-0.5735888",
         "0.02372521",
         "1.0597235",
         "1.6580225",
         "2.1501658",
         "0.0"
        ],
        [
         "485",
         "-0.7205808",
         "-0.7947969",
         "-0.77715135",
         "-0.8965223",
         "0.81956524",
         "0.31583267",
         "0.057457216",
         "-1.0"
        ],
        [
         "486",
         "-0.83613855",
         "-0.5908239",
         "-0.67818224",
         "-0.4341091",
         "-0.6901269",
         "-0.7335685",
         "1.7282552",
         "0.0"
        ],
        [
         "487",
         "-0.4091181",
         "-0.40506917",
         "-0.33421162",
         "-0.33602682",
         "0.56890124",
         "0.49773374",
         "-0.11911933",
         "0.0"
        ],
        [
         "488",
         "-0.31854293",
         "-0.42112356",
         "-0.24092664",
         "-0.34092274",
         "0.35680082",
         "0.49221578",
         "-0.58315605",
         "-1.0"
        ],
        [
         "489",
         "-0.32306173",
         "-0.21034458",
         "-0.22732434",
         "-0.11071514",
         "0.36198437",
         "0.35960546",
         "0.5026432",
         "0.0"
        ],
        [
         "490",
         "-0.11047722",
         "-0.10048596",
         "0.058291767",
         "0.026963148",
         "0.12726623",
         "-0.16974673",
         "0.04387351",
         "0.0"
        ],
        [
         "491",
         "0.016664097",
         "-0.05116152",
         "0.020271648",
         "0.0262172",
         "0.7464134",
         "1.4563668",
         "-0.60400593",
         "-1.0"
        ],
        [
         "492",
         "0.015850289",
         "-0.086555965",
         "0.1669501",
         "0.02372521",
         "0.31243828",
         "0.07514732",
         "-0.5963831",
         "-1.0"
        ],
        [
         "582",
         "0.55198175",
         "0.5010469",
         "0.78594095",
         "0.60374033",
         "0.84503657",
         "-0.25296098",
         "-0.59478545",
         "-1.0"
        ],
        [
         "583",
         "0.54929286",
         "0.4079216",
         "0.74795866",
         "0.53876036",
         "-0.20630713",
         "-0.48993132",
         "-0.32267305",
         "-1.0"
        ],
        [
         "584",
         "0.48929042",
         "0.42555127",
         "0.6333869",
         "0.5968594",
         "0.07320749",
         "0.50113076",
         "-0.35261473",
         "0.0"
        ],
        [
         "585",
         "0.54293936",
         "0.54064614",
         "0.79607075",
         "0.58541256",
         "1.413055",
         "-0.49861962",
         "-0.5573135",
         "-1.0"
        ],
        [
         "586",
         "0.53237027",
         "0.34351146",
         "0.30410042",
         "0.097270556",
         "-0.75903994",
         "-0.5072334",
         "1.5374762",
         "-1.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 547
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_prop</th>\n",
       "      <th>high_prop</th>\n",
       "      <th>low_prop</th>\n",
       "      <th>close_prop</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.111933</td>\n",
       "      <td>3.478171</td>\n",
       "      <td>3.406130</td>\n",
       "      <td>3.427641</td>\n",
       "      <td>3.652038</td>\n",
       "      <td>0.836372</td>\n",
       "      <td>-0.449954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.127972</td>\n",
       "      <td>2.964268</td>\n",
       "      <td>0.113956</td>\n",
       "      <td>1.345313</td>\n",
       "      <td>-0.495630</td>\n",
       "      <td>10.862902</td>\n",
       "      <td>6.025596</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.234101</td>\n",
       "      <td>1.610980</td>\n",
       "      <td>0.116310</td>\n",
       "      <td>1.415349</td>\n",
       "      <td>4.540270</td>\n",
       "      <td>10.844402</td>\n",
       "      <td>-0.329217</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.286984</td>\n",
       "      <td>1.754766</td>\n",
       "      <td>1.234882</td>\n",
       "      <td>1.394194</td>\n",
       "      <td>6.190423</td>\n",
       "      <td>2.446608</td>\n",
       "      <td>-0.574201</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.277813</td>\n",
       "      <td>1.693845</td>\n",
       "      <td>1.174582</td>\n",
       "      <td>1.798847</td>\n",
       "      <td>1.584733</td>\n",
       "      <td>2.904980</td>\n",
       "      <td>0.938137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>-0.113037</td>\n",
       "      <td>0.063968</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>0.014550</td>\n",
       "      <td>2.340452</td>\n",
       "      <td>-0.068158</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>0.006337</td>\n",
       "      <td>-0.147091</td>\n",
       "      <td>0.178038</td>\n",
       "      <td>-0.010626</td>\n",
       "      <td>-0.327740</td>\n",
       "      <td>-0.348123</td>\n",
       "      <td>-0.482406</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>-0.018048</td>\n",
       "      <td>-0.150242</td>\n",
       "      <td>0.180550</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>-0.248125</td>\n",
       "      <td>-0.371499</td>\n",
       "      <td>-0.530769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.160322</td>\n",
       "      <td>0.068586</td>\n",
       "      <td>-0.089325</td>\n",
       "      <td>-0.411513</td>\n",
       "      <td>-0.064361</td>\n",
       "      <td>-0.142659</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4760</th>\n",
       "      <td>-0.090723</td>\n",
       "      <td>-0.150267</td>\n",
       "      <td>0.087113</td>\n",
       "      <td>0.023725</td>\n",
       "      <td>-0.460029</td>\n",
       "      <td>-0.238667</td>\n",
       "      <td>-0.072418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      open_prop  high_prop  low_prop  close_prop  upper_shadow  lower_shadow  \\\n",
       "0      3.111933   3.478171  3.406130    3.427641      3.652038      0.836372   \n",
       "1      3.127972   2.964268  0.113956    1.345313     -0.495630     10.862902   \n",
       "2      1.234101   1.610980  0.116310    1.415349      4.540270     10.844402   \n",
       "3      1.286984   1.754766  1.234882    1.394194      6.190423      2.446608   \n",
       "4      1.277813   1.693845  1.174582    1.798847      1.584733      2.904980   \n",
       "...         ...        ...       ...         ...           ...           ...   \n",
       "4756  -0.113037   0.063968  0.044745    0.014550      2.340452     -0.068158   \n",
       "4757   0.006337  -0.147091  0.178038   -0.010626     -0.327740     -0.348123   \n",
       "4758  -0.018048  -0.150242  0.180550    0.005551     -0.248125     -0.371499   \n",
       "4759  -0.000217  -0.160322  0.068586   -0.089325     -0.411513     -0.064361   \n",
       "4760  -0.090723  -0.150267  0.087113    0.023725     -0.460029     -0.238667   \n",
       "\n",
       "          body  color  \n",
       "0    -0.449954    0.0  \n",
       "1     6.025596   -1.0  \n",
       "2    -0.329217    0.0  \n",
       "3    -0.574201   -1.0  \n",
       "4     0.938137    0.0  \n",
       "...        ...    ...  \n",
       "4756 -0.000709    0.0  \n",
       "4757 -0.482406   -1.0  \n",
       "4758 -0.530769    0.0  \n",
       "4759 -0.142659   -1.0  \n",
       "4760 -0.072418    0.0  \n",
       "\n",
       "[547 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = df_seq.loc[~(df_seq==0).all(axis=1)]\n",
    "df_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc099c49",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754255c5",
   "metadata": {},
   "source": [
    "## MDN server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67861978",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.cnn_lstm_mdn import CNNLSTM_MDN  # <-- your updated \"last-output\" model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg*.pt\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\",FEATURES)\n",
    "# ---------------- Model ----------------\n",
    "# Reconstruct model class\n",
    "#for python file:\n",
    "# model_cls_info = meta[\"model_class_info\"]\n",
    "# ModelClass = import_class(model_cls_info[\"module\"], model_cls_info[\"class\"])\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "ModelClass = cnn_lstm\n",
    "# Initialize model with original args\n",
    "model = ModelClass(**model_cls_info[\"init_args\"])\n",
    "model = cnn_lstm.load_from_checkpoint(state_path)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv( \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"sequential.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        print(\"Returning initial candles:\", candles)\n",
    "\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            print(\"Reached end of data at index:\", next_idx)\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        # ✅ Add to preproc automatically\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # prepare subsequence from current state\n",
    "        seq_dict = preproc.prepare_seq(seq_len)  # returns dict of DataFrames\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mdn_out = model(dict_x)\n",
    "\n",
    "    pi    = mdn_out['pi'][0].cpu().numpy()\n",
    "    mu    = mdn_out['mu'][0].cpu().numpy()\n",
    "    sigma = mdn_out['sigma'][0].cpu().numpy()\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "\n",
    "    return jsonify({\n",
    "        'pred_prices': (last_close * mu).tolist(),\n",
    "        'pred_sigmas': (last_close * sigma).tolist(),\n",
    "        'pi': pi.tolist()\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65996c",
   "metadata": {},
   "source": [
    "## lstm two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = LSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"two_head.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "    print(\"dict\",dict_x)\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred, len_logits = model( dict_x, lengths)\n",
    "\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "    pred_len = model.predict_length(len_logits).item()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices,\n",
    "        \"pred_len\": pred_len\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f38c1",
   "metadata": {},
   "source": [
    "## Hungarian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f3016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using latest meta file: /home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_20250921_123446.pkl\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop'], 'candle_shape': ['upper_shadow', 'lower_shadow', 'body', 'color']}\n",
      "init_args {'input_dim': {'main': 4, 'candle_shape': 4}, 'hidden_dim': 60, 'num_layers': 1, 'max_len_y': 9, 'lr': 0.0001, 'attention_name': 'tanh_attention', 'optimizer_name': 'adamw', 'kernels': [3, 5, 7, 11], 'cnn_out_channels': 32, 'first_drop': 0.3, 'second_drop': 0.3, 'third_drop': 0.3, 'scheduler_name': 'reduce_on_plateau', 'optimizer_params': {'weight_decay': 0.01}, 'scheduler_params': {'factor': 0.2, 'patience': 3}}\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:12] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:12] \"GET /get_and_add_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:16] \"GET /get_and_add_data?idx=21 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:16] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Raw slice values (candle_color):\n",
      "candle_shape: [0.7 0.3 0.3]\n",
      "{'main': tensor([[[1.0664, 1.2174, 1.0606, 1.1896],\n",
      "         [1.1896, 1.1896, 1.0190, 1.0716],\n",
      "         [1.0716, 1.1084, 0.9201, 1.0000]]]), 'candle_shape': tensor([[[0.0234, 0.0054, 0.1035, 0.7000],\n",
      "         [0.0000, 0.0490, 0.0992, 0.3000],\n",
      "         [0.0344, 0.0799, 0.0668, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:21] \"GET /get_and_add_data?idx=22 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:21] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1853, 1.1853, 1.0154, 1.0677],\n",
      "         [1.0677, 1.1044, 0.9168, 0.9964],\n",
      "         [0.9964, 1.0555, 0.9172, 1.0000]]]), 'candle_shape': tensor([[[0.0000, 0.0490, 0.0992, 0.3000],\n",
      "         [0.0344, 0.0799, 0.0668, 0.3000],\n",
      "         [0.0555, 0.0795, 0.0036, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:23] \"GET /get_and_add_data?idx=23 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:23] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.0159, 1.0508, 0.8723, 0.9480],\n",
      "         [0.9480, 1.0043, 0.8727, 0.9515],\n",
      "         [0.9515, 1.0194, 0.9251, 1.0000]]]), 'candle_shape': tensor([[[0.0344, 0.0799, 0.0668, 0.3000],\n",
      "         [0.0555, 0.0795, 0.0036, 0.7000],\n",
      "         [0.0194, 0.0277, 0.0485, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:27] \"GET /get_and_add_data?idx=24 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9628, 1.0200, 0.8863, 0.9663],\n",
      "         [0.9663, 1.0354, 0.9396, 1.0156],\n",
      "         [1.0156, 1.0554, 0.9799, 1.0000]]]), 'candle_shape': tensor([[[0.0555, 0.0795, 0.0036, 0.7000],\n",
      "         [0.0194, 0.0277, 0.0485, 0.7000],\n",
      "         [0.0391, 0.0201, 0.0154, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:29] \"GET /get_and_add_data?idx=25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9739, 1.0434, 0.9469, 1.0235],\n",
      "         [1.0235, 1.0636, 0.9875, 1.0078],\n",
      "         [1.0086, 1.0500, 0.9299, 1.0000]]]), 'candle_shape': tensor([[[0.0194, 0.0277, 0.0485, 0.7000],\n",
      "         [0.0391, 0.0201, 0.0154, 0.3000],\n",
      "         [0.0410, 0.0701, 0.0086, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:29] \"GET /get_and_add_data?idx=26 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9877, 1.0264, 0.9529, 0.9725],\n",
      "         [0.9733, 1.0132, 0.8973, 0.9650],\n",
      "         [0.9650, 1.0138, 0.9436, 1.0000]]]), 'candle_shape': tensor([[[0.0391, 0.0201, 0.0154, 0.3000],\n",
      "         [0.0410, 0.0701, 0.0086, 0.3000],\n",
      "         [0.0138, 0.0222, 0.0350, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:30] \"GET /get_and_add_data?idx=27 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9415, 0.9801, 0.8679, 0.9334],\n",
      "         [0.9334, 0.9806, 0.9127, 0.9673],\n",
      "         [0.9680, 1.0306, 0.9603, 1.0000]]]), 'candle_shape': tensor([[[0.0410, 0.0701, 0.0086, 0.3000],\n",
      "         [0.0138, 0.0222, 0.0350, 0.7000],\n",
      "         [0.0306, 0.0080, 0.0320, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:30] \"GET /get_and_add_data?idx=28 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9856, 1.0355, 0.9637, 1.0213],\n",
      "         [1.0221, 1.0883, 1.0140, 1.0559],\n",
      "         [1.0559, 1.0644, 0.9901, 1.0000]]]), 'candle_shape': tensor([[[0.0138, 0.0222, 0.0350, 0.7000],\n",
      "         [0.0306, 0.0080, 0.0320, 0.7000],\n",
      "         [0.0080, 0.0099, 0.0529, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:31] \"GET /get_and_add_data?idx=29 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:31] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1233, 1.1960, 1.1143, 1.1604],\n",
      "         [1.1604, 1.1697, 1.0881, 1.0990],\n",
      "         [1.0989, 1.1046, 0.9670, 1.0000]]]), 'candle_shape': tensor([[[0.0306, 0.0080, 0.0320, 0.7000],\n",
      "         [0.0080, 0.0099, 0.0529, 0.3000],\n",
      "         [0.0052, 0.0330, 0.0900, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:31] \"GET /get_and_add_data?idx=30 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:31] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1551, 1.1643, 1.0831, 1.0939],\n",
      "         [1.0938, 1.0995, 0.9626, 0.9954],\n",
      "         [0.9946, 1.0137, 0.9431, 1.0000]]]), 'candle_shape': tensor([[[0.0080, 0.0099, 0.0529, 0.3000],\n",
      "         [0.0052, 0.0330, 0.0900, 0.3000],\n",
      "         [0.0137, 0.0518, 0.0054, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:32] \"GET /get_and_add_data?idx=31 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.2196, 1.2259, 1.0732, 1.1098],\n",
      "         [1.1090, 1.1302, 1.0515, 1.1150],\n",
      "         [1.1150, 1.1204, 0.9487, 1.0000]]]), 'candle_shape': tensor([[[0.0052, 0.0330, 0.0900, 0.3000],\n",
      "         [0.0137, 0.0518, 0.0054, 0.7000],\n",
      "         [0.0049, 0.0513, 0.1031, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:33] \"GET /get_and_add_data?idx=32 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:33] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1529, 1.1750, 1.0932, 1.1591],\n",
      "         [1.1591, 1.1648, 0.9862, 1.0396],\n",
      "         [1.0396, 1.0425, 0.9027, 1.0000]]]), 'candle_shape': tensor([[[0.0137, 0.0518, 0.0054, 0.7000],\n",
      "         [0.0049, 0.0513, 0.1031, 0.3000],\n",
      "         [0.0028, 0.0973, 0.0381, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:33] \"GET /get_and_add_data?idx=33 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:33] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1180, 1.1234, 0.9512, 1.0027],\n",
      "         [1.0027, 1.0054, 0.8707, 0.9645],\n",
      "         [0.9645, 1.0297, 0.8945, 1.0000]]]), 'candle_shape': tensor([[[0.0049, 0.0513, 0.1031, 0.3000],\n",
      "         [0.0028, 0.0973, 0.0381, 0.3000],\n",
      "         [0.0297, 0.0726, 0.0355, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:34] \"GET /get_and_add_data?idx=34 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:34] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1270, 1.1301, 0.9786, 1.0841],\n",
      "         [1.0841, 1.1574, 1.0054, 1.1240],\n",
      "         [1.1240, 1.1446, 0.9689, 1.0000]]]), 'candle_shape': tensor([[[0.0028, 0.0973, 0.0381, 0.3000],\n",
      "         [0.0297, 0.0726, 0.0355, 0.7000],\n",
      "         [0.0183, 0.0311, 0.1103, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:34] \"GET /get_and_add_data?idx=35 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:34] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.2785, 1.3650, 1.1857, 1.3256],\n",
      "         [1.3256, 1.3499, 1.1427, 1.1794],\n",
      "         [1.1787, 1.2079, 0.9546, 1.0000]]]), 'candle_shape': tensor([[[0.0297, 0.0726, 0.0355, 0.7000],\n",
      "         [0.0183, 0.0311, 0.1103, 0.3000],\n",
      "         [0.0248, 0.0454, 0.1516, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:35] \"GET /get_and_add_data?idx=36 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:35] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.2023, 1.2242, 1.0363, 1.0696],\n",
      "         [1.0690, 1.0955, 0.8658, 0.9069],\n",
      "         [0.9069, 1.0295, 0.7841, 1.0000]]]), 'candle_shape': tensor([[[0.0183, 0.0311, 0.1103, 0.3000],\n",
      "         [0.0248, 0.0454, 0.1516, 0.3000],\n",
      "         [0.0295, 0.1354, 0.0931, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:35] \"GET /get_and_add_data?idx=37 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:35] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.0765, 1.1031, 0.8718, 0.9133],\n",
      "         [0.9132, 1.0367, 0.7896, 1.0070],\n",
      "         [1.0074, 1.1154, 0.9409, 1.0000]]]), 'candle_shape': tensor([[[0.0248, 0.0454, 0.1516, 0.3000],\n",
      "         [0.0295, 0.1354, 0.0931, 0.7000],\n",
      "         [0.1072, 0.0591, 0.0073, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:35] \"GET /get_and_add_data?idx=38 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:35] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.8392, 0.9527, 0.7256, 0.9254],\n",
      "         [0.9257, 1.0250, 0.8646, 0.9189],\n",
      "         [0.9189, 1.0013, 0.9157, 1.0000]]]), 'candle_shape': tensor([[[0.0295, 0.1354, 0.0931, 0.7000],\n",
      "         [0.1072, 0.0591, 0.0073, 0.3000],\n",
      "         [0.0013, 0.0035, 0.0811, 0.7000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:36] \"GET /get_and_add_data?idx=39 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:36] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.8734, 0.9671, 0.8158, 0.8670],\n",
      "         [0.8670, 0.9447, 0.8639, 0.9435],\n",
      "         [0.9414, 1.0012, 0.9410, 1.0000]]]), 'candle_shape': tensor([[[1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:39] \"GET /get_and_add_data?idx=40 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.8904, 0.9703, 0.8873, 0.9690],\n",
      "         [0.9668, 1.0283, 0.9664, 1.0270],\n",
      "         [1.0219, 1.0623, 0.9515, 1.0000]]]), 'candle_shape': tensor([[[1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:40] \"GET /get_and_add_data?idx=41 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:40] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.0232, 1.0883, 1.0228, 1.0869],\n",
      "         [1.0814, 1.1242, 1.0070, 1.0583],\n",
      "         [1.0583, 1.0602, 0.9582, 1.0000]]]), 'candle_shape': tensor([[[1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:50] \"GET /get_and_add_data?idx=42 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:50] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.2130, 1.2996, 1.1794, 1.2749],\n",
      "         [1.2748, 1.3247, 1.2299, 1.2552],\n",
      "         [1.2563, 1.3078, 1.1582, 1.2455],\n",
      "         [1.2455, 1.3085, 1.2179, 1.2907],\n",
      "         [1.2917, 1.3753, 1.2814, 1.3344],\n",
      "         [1.3344, 1.3451, 1.2512, 1.2637],\n",
      "         [1.2636, 1.2702, 1.1120, 1.1499],\n",
      "         [1.1491, 1.1710, 1.0895, 1.1552],\n",
      "         [1.1552, 1.1608, 0.9829, 1.0361],\n",
      "         [1.0361, 1.0390, 0.8997, 0.9966],\n",
      "         [0.9966, 1.0640, 0.9243, 1.0334],\n",
      "         [1.0334, 1.0522, 0.8907, 0.9193],\n",
      "         [0.9188, 0.9416, 0.7441, 0.7795],\n",
      "         [0.7795, 0.8849, 0.6739, 0.8595],\n",
      "         [0.8598, 0.9520, 0.8031, 0.8535],\n",
      "         [0.8535, 0.9301, 0.8505, 0.9288],\n",
      "         [0.9268, 0.9857, 0.9264, 0.9845],\n",
      "         [0.9795, 1.0183, 0.9121, 0.9586],\n",
      "         [0.9586, 0.9602, 0.8679, 0.9057],\n",
      "         [0.9057, 1.0097, 0.9045, 1.0000]]]), 'candle_shape': tensor([[[1.9426e-02, 2.7700e-02, 4.8533e-02, 7.0000e-01],\n",
      "         [3.9127e-02, 2.0139e-02, 1.5391e-02, 3.0000e-01],\n",
      "         [4.0976e-02, 7.0146e-02, 8.5563e-03, 3.0000e-01],\n",
      "         [1.3837e-02, 2.2212e-02, 3.4984e-02, 7.0000e-01],\n",
      "         [3.0644e-02, 7.9983e-03, 3.1984e-02, 7.0000e-01],\n",
      "         [8.0026e-03, 9.9058e-03, 5.2942e-02, 3.0000e-01],\n",
      "         [5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:55] \"GET /get_and_add_data?idx=43 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:55] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.3291, 1.3811, 1.2822, 1.3086],\n",
      "         [1.3097, 1.3634, 1.2074, 1.2985],\n",
      "         [1.2985, 1.3642, 1.2697, 1.3456],\n",
      "         [1.3466, 1.4337, 1.3358, 1.3911],\n",
      "         [1.3911, 1.4022, 1.3044, 1.3175],\n",
      "         [1.3174, 1.3242, 1.1593, 1.1988],\n",
      "         [1.1979, 1.2208, 1.1358, 1.2044],\n",
      "         [1.2044, 1.2102, 1.0247, 1.0802],\n",
      "         [1.0802, 1.0832, 0.9380, 1.0390],\n",
      "         [1.0390, 1.1093, 0.9636, 1.0773],\n",
      "         [1.0773, 1.0970, 0.9286, 0.9584],\n",
      "         [0.9579, 0.9816, 0.7758, 0.8127],\n",
      "         [0.8126, 0.9225, 0.7026, 0.8960],\n",
      "         [0.8964, 0.9925, 0.8372, 0.8898],\n",
      "         [0.8898, 0.9696, 0.8867, 0.9683],\n",
      "         [0.9662, 1.0276, 0.9657, 1.0263],\n",
      "         [1.0212, 1.0616, 0.9508, 0.9993],\n",
      "         [0.9993, 1.0011, 0.9048, 0.9443],\n",
      "         [0.9443, 1.0526, 0.9430, 1.0425],\n",
      "         [1.0425, 1.0480, 0.9779, 1.0000]]]), 'candle_shape': tensor([[[3.9127e-02, 2.0139e-02, 1.5391e-02, 3.0000e-01],\n",
      "         [4.0976e-02, 7.0146e-02, 8.5563e-03, 3.0000e-01],\n",
      "         [1.3837e-02, 2.2212e-02, 3.4984e-02, 7.0000e-01],\n",
      "         [3.0644e-02, 7.9983e-03, 3.1984e-02, 7.0000e-01],\n",
      "         [8.0026e-03, 9.9058e-03, 5.2942e-02, 3.0000e-01],\n",
      "         [5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:55] \"GET /get_and_add_data?idx=44 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:55] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1836, 1.2321, 1.0911, 1.1734],\n",
      "         [1.1734, 1.2328, 1.1474, 1.2160],\n",
      "         [1.2169, 1.2957, 1.2072, 1.2571],\n",
      "         [1.2571, 1.2672, 1.1788, 1.1906],\n",
      "         [1.1905, 1.1967, 1.0476, 1.0833],\n",
      "         [1.0825, 1.1033, 1.0265, 1.0884],\n",
      "         [1.0884, 1.0937, 0.9260, 0.9761],\n",
      "         [0.9761, 0.9788, 0.8476, 0.9389],\n",
      "         [0.9389, 1.0024, 0.8708, 0.9735],\n",
      "         [0.9735, 0.9913, 0.8392, 0.8661],\n",
      "         [0.8656, 0.8871, 0.7011, 0.7344],\n",
      "         [0.7344, 0.8337, 0.6349, 0.8098],\n",
      "         [0.8101, 0.8969, 0.7566, 0.8041],\n",
      "         [0.8041, 0.8762, 0.8013, 0.8751],\n",
      "         [0.8731, 0.9286, 0.8727, 0.9275],\n",
      "         [0.9228, 0.9593, 0.8593, 0.9031],\n",
      "         [0.9031, 0.9047, 0.8176, 0.8533],\n",
      "         [0.8533, 0.9512, 0.8522, 0.9421],\n",
      "         [0.9421, 0.9471, 0.8837, 0.9037],\n",
      "         [0.9032, 1.0042, 0.9030, 1.0000]]]), 'candle_shape': tensor([[[4.0976e-02, 7.0146e-02, 8.5563e-03, 3.0000e-01],\n",
      "         [1.3837e-02, 2.2212e-02, 3.4984e-02, 7.0000e-01],\n",
      "         [3.0644e-02, 7.9983e-03, 3.1984e-02, 7.0000e-01],\n",
      "         [8.0026e-03, 9.9058e-03, 5.2942e-02, 3.0000e-01],\n",
      "         [5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:56] \"GET /get_and_add_data?idx=45 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:56] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1089, 1.1650, 1.0843, 1.1491],\n",
      "         [1.1500, 1.2244, 1.1408, 1.1880],\n",
      "         [1.1880, 1.1975, 1.1139, 1.1251],\n",
      "         [1.1250, 1.1308, 0.9900, 1.0237],\n",
      "         [1.0230, 1.0426, 0.9700, 1.0285],\n",
      "         [1.0285, 1.0335, 0.8751, 0.9224],\n",
      "         [0.9224, 0.9250, 0.8010, 0.8873],\n",
      "         [0.8873, 0.9473, 0.8229, 0.9200],\n",
      "         [0.9200, 0.9368, 0.7930, 0.8185],\n",
      "         [0.8180, 0.8383, 0.6625, 0.6940],\n",
      "         [0.6940, 0.7878, 0.6000, 0.7652],\n",
      "         [0.7655, 0.8476, 0.7150, 0.7599],\n",
      "         [0.7599, 0.8280, 0.7572, 0.8269],\n",
      "         [0.8251, 0.8776, 0.8247, 0.8765],\n",
      "         [0.8721, 0.9066, 0.8120, 0.8534],\n",
      "         [0.8534, 0.8549, 0.7726, 0.8064],\n",
      "         [0.8064, 0.8989, 0.8053, 0.8903],\n",
      "         [0.8903, 0.8950, 0.8351, 0.8540],\n",
      "         [0.8535, 0.9490, 0.8533, 0.9450],\n",
      "         [0.9450, 1.0219, 0.9301, 1.0000]]]), 'candle_shape': tensor([[[1.3837e-02, 2.2212e-02, 3.4984e-02, 7.0000e-01],\n",
      "         [3.0644e-02, 7.9983e-03, 3.1984e-02, 7.0000e-01],\n",
      "         [8.0026e-03, 9.9058e-03, 5.2942e-02, 3.0000e-01],\n",
      "         [5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:57] \"GET /get_and_add_data?idx=46 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:57] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.1319, 1.2051, 1.1228, 1.1693],\n",
      "         [1.1693, 1.1786, 1.0964, 1.1074],\n",
      "         [1.1073, 1.1130, 0.9744, 1.0076],\n",
      "         [1.0069, 1.0262, 0.9547, 1.0123],\n",
      "         [1.0123, 1.0172, 0.8613, 0.9079],\n",
      "         [0.9079, 0.9104, 0.7884, 0.8733],\n",
      "         [0.8733, 0.9324, 0.8099, 0.9055],\n",
      "         [0.9055, 0.9220, 0.7805, 0.8056],\n",
      "         [0.8051, 0.8251, 0.6521, 0.6831],\n",
      "         [0.6830, 0.7754, 0.5906, 0.7532],\n",
      "         [0.7534, 0.8343, 0.7037, 0.7479],\n",
      "         [0.7479, 0.8150, 0.7453, 0.8139],\n",
      "         [0.8121, 0.8637, 0.8117, 0.8627],\n",
      "         [0.8583, 0.8923, 0.7992, 0.8400],\n",
      "         [0.8400, 0.8414, 0.7605, 0.7937],\n",
      "         [0.7937, 0.8847, 0.7926, 0.8763],\n",
      "         [0.8763, 0.8809, 0.8220, 0.8405],\n",
      "         [0.8401, 0.9340, 0.8399, 0.9301],\n",
      "         [0.9301, 1.0059, 0.9155, 0.9843],\n",
      "         [0.9843, 1.0161, 0.9514, 1.0000]]]), 'candle_shape': tensor([[[3.0644e-02, 7.9983e-03, 3.1984e-02, 7.0000e-01],\n",
      "         [8.0026e-03, 9.9058e-03, 5.2942e-02, 3.0000e-01],\n",
      "         [5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:57] \"GET /get_and_add_data?idx=47 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:57] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.0761, 1.0847, 1.0091, 1.0192],\n",
      "         [1.0191, 1.0244, 0.8968, 0.9273],\n",
      "         [0.9267, 0.9444, 0.8787, 0.9317],\n",
      "         [0.9317, 0.9362, 0.7927, 0.8356],\n",
      "         [0.8356, 0.8379, 0.7256, 0.8037],\n",
      "         [0.8037, 0.8581, 0.7454, 0.8334],\n",
      "         [0.8334, 0.8486, 0.7183, 0.7414],\n",
      "         [0.7410, 0.7593, 0.6001, 0.6286],\n",
      "         [0.6286, 0.7136, 0.5435, 0.6932],\n",
      "         [0.6934, 0.7678, 0.6477, 0.6883],\n",
      "         [0.6883, 0.7501, 0.6859, 0.7491],\n",
      "         [0.7474, 0.7949, 0.7471, 0.7939],\n",
      "         [0.7899, 0.8212, 0.7355, 0.7730],\n",
      "         [0.7730, 0.7744, 0.6999, 0.7305],\n",
      "         [0.7304, 0.8143, 0.7295, 0.8065],\n",
      "         [0.8065, 0.8107, 0.7565, 0.7736],\n",
      "         [0.7731, 0.8596, 0.7729, 0.8560],\n",
      "         [0.8560, 0.9257, 0.8426, 0.9058],\n",
      "         [0.9059, 0.9351, 0.8756, 0.9203],\n",
      "         [0.9200, 1.0032, 0.9104, 1.0000]]]), 'candle_shape': tensor([[[8.0026e-03, 9.9058e-03, 5.2942e-02, 3.0000e-01],\n",
      "         [5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:57] \"GET /get_and_add_data?idx=48 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:57] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.0835, 1.0891, 0.9534, 0.9859],\n",
      "         [0.9852, 1.0041, 0.9342, 0.9905],\n",
      "         [0.9905, 0.9953, 0.8428, 0.8884],\n",
      "         [0.8884, 0.8908, 0.7714, 0.8545],\n",
      "         [0.8545, 0.9123, 0.7925, 0.8860],\n",
      "         [0.8860, 0.9022, 0.7637, 0.7883],\n",
      "         [0.7878, 0.8073, 0.6380, 0.6684],\n",
      "         [0.6683, 0.7587, 0.5778, 0.7370],\n",
      "         [0.7372, 0.8163, 0.6886, 0.7318],\n",
      "         [0.7318, 0.7975, 0.7292, 0.7964],\n",
      "         [0.7946, 0.8452, 0.7943, 0.8441],\n",
      "         [0.8399, 0.8731, 0.7820, 0.8219],\n",
      "         [0.8219, 0.8233, 0.7441, 0.7766],\n",
      "         [0.7766, 0.8657, 0.7756, 0.8574],\n",
      "         [0.8574, 0.8620, 0.8043, 0.8225],\n",
      "         [0.8220, 0.9139, 0.8218, 0.9101],\n",
      "         [0.9101, 0.9842, 0.8958, 0.9631],\n",
      "         [0.9632, 0.9942, 0.9309, 0.9785],\n",
      "         [0.9781, 1.0666, 0.9679, 1.0632],\n",
      "         [1.0632, 1.0858, 0.9708, 1.0000]]]), 'candle_shape': tensor([[[5.1831e-03, 3.2968e-02, 9.0008e-02, 3.0000e-01],\n",
      "         [1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:58] \"GET /get_and_add_data?idx=49 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9172, 0.9348, 0.8697, 0.9222],\n",
      "         [0.9222, 0.9267, 0.7846, 0.8271],\n",
      "         [0.8271, 0.8294, 0.7182, 0.7956],\n",
      "         [0.7956, 0.8494, 0.7378, 0.8249],\n",
      "         [0.8249, 0.8400, 0.7110, 0.7339],\n",
      "         [0.7334, 0.7516, 0.5940, 0.6223],\n",
      "         [0.6222, 0.7064, 0.5380, 0.6861],\n",
      "         [0.6864, 0.7600, 0.6411, 0.6813],\n",
      "         [0.6813, 0.7424, 0.6789, 0.7415],\n",
      "         [0.7398, 0.7868, 0.7395, 0.7859],\n",
      "         [0.7819, 0.8129, 0.7281, 0.7652],\n",
      "         [0.7652, 0.7665, 0.6928, 0.7230],\n",
      "         [0.7230, 0.8060, 0.7220, 0.7983],\n",
      "         [0.7983, 0.8025, 0.7488, 0.7657],\n",
      "         [0.7653, 0.8509, 0.7651, 0.8473],\n",
      "         [0.8473, 0.9163, 0.8340, 0.8966],\n",
      "         [0.8967, 0.9256, 0.8667, 0.9110],\n",
      "         [0.9106, 0.9930, 0.9011, 0.9898],\n",
      "         [0.9898, 1.0108, 0.9038, 0.9310],\n",
      "         [0.9302, 1.0087, 0.9209, 1.0000]]]), 'candle_shape': tensor([[[1.3685e-02, 5.1808e-02, 5.3573e-03, 7.0000e-01],\n",
      "         [4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:58] \"GET /get_and_add_data?idx=50 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9182, 0.9227, 0.7813, 0.8235],\n",
      "         [0.8235, 0.8258, 0.7151, 0.7922],\n",
      "         [0.7922, 0.8457, 0.7347, 0.8214],\n",
      "         [0.8214, 0.8364, 0.7080, 0.7307],\n",
      "         [0.7303, 0.7484, 0.5915, 0.6196],\n",
      "         [0.6196, 0.7033, 0.5357, 0.6832],\n",
      "         [0.6834, 0.7567, 0.6383, 0.6784],\n",
      "         [0.6784, 0.7392, 0.6760, 0.7383],\n",
      "         [0.7366, 0.7835, 0.7363, 0.7825],\n",
      "         [0.7786, 0.8094, 0.7249, 0.7619],\n",
      "         [0.7619, 0.7632, 0.6898, 0.7199],\n",
      "         [0.7199, 0.8025, 0.7190, 0.7948],\n",
      "         [0.7948, 0.7990, 0.7456, 0.7624],\n",
      "         [0.7620, 0.8472, 0.7618, 0.8437],\n",
      "         [0.8437, 0.9124, 0.8304, 0.8928],\n",
      "         [0.8929, 0.9216, 0.8630, 0.9071],\n",
      "         [0.9067, 0.9888, 0.8972, 0.9856],\n",
      "         [0.9856, 1.0065, 0.8999, 0.9270],\n",
      "         [0.9263, 1.0044, 0.9169, 0.9957],\n",
      "         [0.9952, 1.0522, 0.9910, 1.0000]]]), 'candle_shape': tensor([[[4.8517e-03, 5.1334e-02, 1.0312e-01, 3.0000e-01],\n",
      "         [2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:58] \"GET /get_and_add_data?idx=51 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.8838, 0.8862, 0.7674, 0.8501],\n",
      "         [0.8501, 0.9076, 0.7884, 0.8814],\n",
      "         [0.8814, 0.8975, 0.7598, 0.7842],\n",
      "         [0.7837, 0.8031, 0.6347, 0.6649],\n",
      "         [0.6649, 0.7548, 0.5748, 0.7331],\n",
      "         [0.7334, 0.8121, 0.6850, 0.7280],\n",
      "         [0.7280, 0.7933, 0.7255, 0.7923],\n",
      "         [0.7905, 0.8408, 0.7902, 0.8397],\n",
      "         [0.8355, 0.8686, 0.7780, 0.8176],\n",
      "         [0.8176, 0.8191, 0.7403, 0.7726],\n",
      "         [0.7726, 0.8612, 0.7715, 0.8530],\n",
      "         [0.8530, 0.8575, 0.8001, 0.8182],\n",
      "         [0.8177, 0.9092, 0.8175, 0.9054],\n",
      "         [0.9054, 0.9791, 0.8912, 0.9581],\n",
      "         [0.9582, 0.9891, 0.9261, 0.9734],\n",
      "         [0.9730, 1.0611, 0.9629, 1.0577],\n",
      "         [1.0577, 1.0801, 0.9657, 0.9948],\n",
      "         [0.9940, 1.0778, 0.9840, 1.0685],\n",
      "         [1.0680, 1.1292, 1.0635, 1.0731],\n",
      "         [1.0726, 1.0830, 0.9772, 1.0000]]]), 'candle_shape': tensor([[[2.7622e-03, 9.7262e-02, 3.8104e-02, 3.0000e-01],\n",
      "         [2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:59] \"GET /get_and_add_data?idx=52 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:59] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9044, 0.9655, 0.8387, 0.9377],\n",
      "         [0.9377, 0.9548, 0.8083, 0.8342],\n",
      "         [0.8338, 0.8544, 0.6753, 0.7074],\n",
      "         [0.7073, 0.8030, 0.6116, 0.7800],\n",
      "         [0.7802, 0.8639, 0.7288, 0.7745],\n",
      "         [0.7745, 0.8440, 0.7718, 0.8429],\n",
      "         [0.8410, 0.8945, 0.8406, 0.8934],\n",
      "         [0.8889, 0.9240, 0.8276, 0.8698],\n",
      "         [0.8698, 0.8714, 0.7875, 0.8219],\n",
      "         [0.8219, 0.9162, 0.8208, 0.9074],\n",
      "         [0.9074, 0.9122, 0.8512, 0.8704],\n",
      "         [0.8700, 0.9672, 0.8697, 0.9632],\n",
      "         [0.9632, 1.0416, 0.9481, 1.0193],\n",
      "         [1.0194, 1.0522, 0.9852, 1.0356],\n",
      "         [1.0352, 1.1288, 1.0244, 1.1252],\n",
      "         [1.1252, 1.1491, 1.0274, 1.0583],\n",
      "         [1.0575, 1.1467, 1.0468, 1.1368],\n",
      "         [1.1362, 1.2013, 1.1314, 1.1417],\n",
      "         [1.1411, 1.1522, 1.0396, 1.0639],\n",
      "         [1.0640, 1.1144, 0.9865, 1.0000]]]), 'candle_shape': tensor([[[2.9679e-02, 7.2583e-02, 3.5536e-02, 7.0000e-01],\n",
      "         [1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:59] \"GET /get_and_add_data?idx=53 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:59] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.9081, 0.9247, 0.7827, 0.8079],\n",
      "         [0.8074, 0.8274, 0.6539, 0.6850],\n",
      "         [0.6850, 0.7776, 0.5922, 0.7553],\n",
      "         [0.7556, 0.8366, 0.7058, 0.7501],\n",
      "         [0.7501, 0.8173, 0.7474, 0.8162],\n",
      "         [0.8144, 0.8662, 0.8141, 0.8651],\n",
      "         [0.8608, 0.8949, 0.8015, 0.8424],\n",
      "         [0.8424, 0.8438, 0.7627, 0.7960],\n",
      "         [0.7960, 0.8873, 0.7949, 0.8788],\n",
      "         [0.8788, 0.8834, 0.8243, 0.8429],\n",
      "         [0.8425, 0.9367, 0.8423, 0.9328],\n",
      "         [0.9328, 1.0087, 0.9181, 0.9871],\n",
      "         [0.9872, 1.0190, 0.9541, 1.0029],\n",
      "         [1.0025, 1.0932, 0.9920, 1.0897],\n",
      "         [1.0897, 1.1128, 0.9950, 1.0249],\n",
      "         [1.0241, 1.1104, 1.0137, 1.1009],\n",
      "         [1.1003, 1.1634, 1.0957, 1.1056],\n",
      "         [1.1050, 1.1158, 1.0068, 1.0303],\n",
      "         [1.0304, 1.0792, 0.9554, 0.9684],\n",
      "         [0.9689, 1.0300, 0.9446, 1.0000]]]), 'candle_shape': tensor([[[1.8265e-02, 3.1132e-02, 1.1034e-01, 3.0000e-01],\n",
      "         [2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:54:59] \"GET /get_and_add_data?idx=54 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:54:59] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.8438, 0.8647, 0.6834, 0.7159],\n",
      "         [0.7158, 0.8126, 0.6189, 0.7893],\n",
      "         [0.7896, 0.8743, 0.7375, 0.7838],\n",
      "         [0.7838, 0.8541, 0.7811, 0.8530],\n",
      "         [0.8511, 0.9052, 0.8507, 0.9041],\n",
      "         [0.8995, 0.9351, 0.8376, 0.8803],\n",
      "         [0.8803, 0.8818, 0.7970, 0.8318],\n",
      "         [0.8318, 0.9272, 0.8307, 0.9184],\n",
      "         [0.9184, 0.9232, 0.8614, 0.8809],\n",
      "         [0.8804, 0.9789, 0.8802, 0.9748],\n",
      "         [0.9748, 1.0542, 0.9595, 1.0315],\n",
      "         [1.0316, 1.0649, 0.9971, 1.0480],\n",
      "         [1.0476, 1.1424, 1.0367, 1.1387],\n",
      "         [1.1387, 1.1629, 1.0398, 1.0711],\n",
      "         [1.0702, 1.1605, 1.0594, 1.1504],\n",
      "         [1.1498, 1.2157, 1.1450, 1.1554],\n",
      "         [1.1548, 1.1660, 1.0521, 1.0767],\n",
      "         [1.0768, 1.1278, 0.9984, 1.0120],\n",
      "         [1.0125, 1.0764, 0.9872, 1.0450],\n",
      "         [1.0450, 1.0828, 0.9647, 1.0000]]]), 'candle_shape': tensor([[[2.4793e-02, 4.5388e-02, 1.5159e-01, 3.0000e-01],\n",
      "         [2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:00] \"GET /get_and_add_data?idx=55 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:00] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7236, 0.8215, 0.6257, 0.7979],\n",
      "         [0.7982, 0.8838, 0.7456, 0.7924],\n",
      "         [0.7924, 0.8634, 0.7896, 0.8623],\n",
      "         [0.8604, 0.9151, 0.8600, 0.9139],\n",
      "         [0.9093, 0.9453, 0.8467, 0.8899],\n",
      "         [0.8899, 0.8914, 0.8057, 0.8409],\n",
      "         [0.8409, 0.9373, 0.8397, 0.9284],\n",
      "         [0.9284, 0.9333, 0.8708, 0.8905],\n",
      "         [0.8900, 0.9895, 0.8898, 0.9854],\n",
      "         [0.9854, 1.0656, 0.9699, 1.0428],\n",
      "         [1.0428, 1.0765, 1.0079, 1.0594],\n",
      "         [1.0590, 1.1549, 1.0480, 1.1512],\n",
      "         [1.1512, 1.1756, 1.0511, 1.0827],\n",
      "         [1.0819, 1.1731, 1.0709, 1.1630],\n",
      "         [1.1624, 1.2290, 1.1575, 1.1680],\n",
      "         [1.1674, 1.1787, 1.0636, 1.0884],\n",
      "         [1.0885, 1.1401, 1.0093, 1.0230],\n",
      "         [1.0235, 1.0881, 0.9979, 1.0564],\n",
      "         [1.0564, 1.0946, 0.9752, 1.0109],\n",
      "         [1.0109, 1.0268, 0.9671, 1.0000]]]), 'candle_shape': tensor([[[2.9516e-02, 1.3540e-01, 9.3113e-02, 7.0000e-01],\n",
      "         [1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:00] \"GET /get_and_add_data?idx=56 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:00] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7415, 0.8210, 0.6926, 0.7361],\n",
      "         [0.7361, 0.8020, 0.7334, 0.8010],\n",
      "         [0.7992, 0.8500, 0.7989, 0.8490],\n",
      "         [0.8447, 0.8781, 0.7865, 0.8266],\n",
      "         [0.8266, 0.8281, 0.7484, 0.7811],\n",
      "         [0.7811, 0.8707, 0.7800, 0.8624],\n",
      "         [0.8624, 0.8669, 0.8089, 0.8272],\n",
      "         [0.8267, 0.9192, 0.8265, 0.9153],\n",
      "         [0.9153, 0.9899, 0.9010, 0.9686],\n",
      "         [0.9687, 0.9999, 0.9363, 0.9841],\n",
      "         [0.9837, 1.0727, 0.9735, 1.0693],\n",
      "         [1.0693, 1.0920, 0.9764, 1.0058],\n",
      "         [1.0049, 1.0897, 0.9948, 1.0803],\n",
      "         [1.0797, 1.1416, 1.0752, 1.0849],\n",
      "         [1.0844, 1.0949, 0.9880, 1.0110],\n",
      "         [1.0111, 1.0590, 0.9375, 0.9503],\n",
      "         [0.9508, 1.0108, 0.9270, 0.9813],\n",
      "         [0.9813, 1.0168, 0.9059, 0.9390],\n",
      "         [0.9390, 0.9538, 0.8984, 0.9289],\n",
      "         [0.9289, 1.0117, 0.9057, 1.0000]]]), 'candle_shape': tensor([[[1.0725e-01, 5.9085e-02, 7.3181e-03, 3.0000e-01],\n",
      "         [1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:00] \"GET /get_and_add_data?idx=57 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7190, 0.7834, 0.7164, 0.7824],\n",
      "         [0.7807, 0.8303, 0.7803, 0.8293],\n",
      "         [0.8251, 0.8578, 0.7683, 0.8075],\n",
      "         [0.8075, 0.8089, 0.7311, 0.7630],\n",
      "         [0.7630, 0.8505, 0.7619, 0.8424],\n",
      "         [0.8424, 0.8468, 0.7901, 0.8080],\n",
      "         [0.8076, 0.8979, 0.8074, 0.8941],\n",
      "         [0.8941, 0.9669, 0.8801, 0.9462],\n",
      "         [0.9462, 0.9768, 0.9146, 0.9613],\n",
      "         [0.9609, 1.0479, 0.9509, 1.0445],\n",
      "         [1.0445, 1.0667, 0.9537, 0.9824],\n",
      "         [0.9816, 1.0644, 0.9717, 1.0553],\n",
      "         [1.0547, 1.1151, 1.0503, 1.0598],\n",
      "         [1.0592, 1.0695, 0.9651, 0.9876],\n",
      "         [0.9877, 1.0345, 0.9158, 0.9283],\n",
      "         [0.9287, 0.9873, 0.9055, 0.9586],\n",
      "         [0.9586, 0.9932, 0.8848, 0.9173],\n",
      "         [0.9173, 0.9317, 0.8775, 0.9074],\n",
      "         [0.9074, 0.9882, 0.8847, 0.9768],\n",
      "         [0.9765, 1.0285, 0.9576, 1.0000]]]), 'candle_shape': tensor([[[1.3170e-03, 3.5413e-03, 8.1069e-02, 7.0000e-01],\n",
      "         [1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"GET /get_and_add_data?idx=58 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7990, 0.8498, 0.7986, 0.8487],\n",
      "         [0.8445, 0.8779, 0.7863, 0.8264],\n",
      "         [0.8264, 0.8278, 0.7482, 0.7809],\n",
      "         [0.7809, 0.8705, 0.7798, 0.8621],\n",
      "         [0.8621, 0.8667, 0.8087, 0.8270],\n",
      "         [0.8265, 0.9189, 0.8263, 0.9151],\n",
      "         [0.9151, 0.9896, 0.9007, 0.9684],\n",
      "         [0.9684, 0.9997, 0.9360, 0.9838],\n",
      "         [0.9835, 1.0725, 0.9732, 1.0690],\n",
      "         [1.0690, 1.0917, 0.9761, 1.0055],\n",
      "         [1.0047, 1.0894, 0.9945, 1.0800],\n",
      "         [1.0794, 1.1413, 1.0749, 1.0847],\n",
      "         [1.0841, 1.0946, 0.9877, 1.0107],\n",
      "         [1.0109, 1.0587, 0.9373, 0.9501],\n",
      "         [0.9505, 1.0105, 0.9267, 0.9810],\n",
      "         [0.9810, 1.0165, 0.9056, 0.9388],\n",
      "         [0.9388, 0.9535, 0.8981, 0.9287],\n",
      "         [0.9287, 1.0114, 0.9054, 0.9997],\n",
      "         [0.9994, 1.0526, 0.9801, 1.0235],\n",
      "         [1.0249, 1.0747, 0.9974, 1.0000]]]), 'candle_shape': tensor([[[1.2426e-03, 4.2723e-04, 5.8630e-02, 7.0000e-01],\n",
      "         [3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01],\n",
      "         [4.8531e-02, 2.5913e-03, 2.4335e-02, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"GET /get_and_add_data?idx=59 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7986, 0.8302, 0.7436, 0.7815],\n",
      "         [0.7815, 0.7829, 0.7076, 0.7385],\n",
      "         [0.7384, 0.8232, 0.7375, 0.8153],\n",
      "         [0.8153, 0.8196, 0.7647, 0.7820],\n",
      "         [0.7816, 0.8690, 0.7814, 0.8654],\n",
      "         [0.8654, 0.9359, 0.8518, 0.9158],\n",
      "         [0.9158, 0.9454, 0.8852, 0.9304],\n",
      "         [0.9300, 1.0142, 0.9203, 1.0109],\n",
      "         [1.0109, 1.0324, 0.9231, 0.9509],\n",
      "         [0.9501, 1.0302, 0.9405, 1.0213],\n",
      "         [1.0208, 1.0793, 1.0165, 1.0257],\n",
      "         [1.0252, 1.0352, 0.9341, 0.9558],\n",
      "         [0.9560, 1.0012, 0.8864, 0.8984],\n",
      "         [0.8989, 0.9556, 0.8764, 0.9278],\n",
      "         [0.9278, 0.9613, 0.8564, 0.8878],\n",
      "         [0.8878, 0.9017, 0.8493, 0.8782],\n",
      "         [0.8782, 0.9564, 0.8562, 0.9454],\n",
      "         [0.9451, 0.9954, 0.9268, 0.9679],\n",
      "         [0.9693, 1.0163, 0.9432, 0.9457],\n",
      "         [0.9456, 1.0129, 0.9377, 1.0000]]]), 'candle_shape': tensor([[[3.9574e-02, 4.8510e-02, 2.1407e-02, 3.0000e-01],\n",
      "         [1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01],\n",
      "         [4.8531e-02, 2.5913e-03, 2.4335e-02, 3.0000e-01],\n",
      "         [1.2858e-02, 8.2939e-03, 5.4429e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"GET /get_and_add_data?idx=60 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"GET /get_and_add_data?idx=61 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:01] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7731, 0.7744, 0.6999, 0.7305],\n",
      "         [0.7305, 0.8143, 0.7295, 0.8065],\n",
      "         [0.8065, 0.8108, 0.7565, 0.7736],\n",
      "         [0.7732, 0.8596, 0.7730, 0.8561],\n",
      "         [0.8561, 0.9258, 0.8426, 0.9059],\n",
      "         [0.9060, 0.9352, 0.8756, 0.9204],\n",
      "         [0.9200, 1.0033, 0.9104, 1.0000],\n",
      "         [1.0000, 1.0213, 0.9131, 0.9406],\n",
      "         [0.9399, 1.0191, 0.9304, 1.0103],\n",
      "         [1.0098, 1.0677, 1.0056, 1.0147],\n",
      "         [1.0141, 1.0240, 0.9240, 0.9455],\n",
      "         [0.9456, 0.9904, 0.8768, 0.8888],\n",
      "         [0.8892, 0.9453, 0.8669, 0.9177],\n",
      "         [0.9177, 0.9509, 0.8472, 0.8782],\n",
      "         [0.8782, 0.8920, 0.8402, 0.8687],\n",
      "         [0.8687, 0.9461, 0.8470, 0.9352],\n",
      "         [0.9350, 0.9847, 0.9168, 0.9574],\n",
      "         [0.9588, 1.0053, 0.9331, 0.9355],\n",
      "         [0.9354, 1.0019, 0.9276, 0.9892],\n",
      "         [0.9895, 1.0146, 0.9756, 1.0000]]]), 'candle_shape': tensor([[[1.7588e-03, 4.1835e-02, 5.5087e-02, 3.0000e-01],\n",
      "         [9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01],\n",
      "         [4.8531e-02, 2.5913e-03, 2.4335e-02, 3.0000e-01],\n",
      "         [1.2858e-02, 8.2939e-03, 5.4429e-02, 7.0000e-01],\n",
      "         [1.4585e-02, 1.4040e-02, 1.0476e-02, 7.0000e-01]]])}\n",
      "{'main': tensor([[[0.7034, 0.7841, 0.7024, 0.7766],\n",
      "         [0.7766, 0.7807, 0.7284, 0.7449],\n",
      "         [0.7445, 0.8277, 0.7443, 0.8243],\n",
      "         [0.8243, 0.8914, 0.8113, 0.8723],\n",
      "         [0.8723, 0.9005, 0.8431, 0.8862],\n",
      "         [0.8859, 0.9660, 0.8766, 0.9629],\n",
      "         [0.9629, 0.9834, 0.8792, 0.9057],\n",
      "         [0.9050, 0.9813, 0.8958, 0.9728],\n",
      "         [0.9723, 1.0280, 0.9683, 0.9770],\n",
      "         [0.9765, 0.9860, 0.8897, 0.9104],\n",
      "         [0.9106, 0.9537, 0.8443, 0.8558],\n",
      "         [0.8562, 0.9102, 0.8348, 0.8837],\n",
      "         [0.8837, 0.9156, 0.8157, 0.8456],\n",
      "         [0.8456, 0.8589, 0.8090, 0.8365],\n",
      "         [0.8365, 0.9110, 0.8156, 0.9005],\n",
      "         [0.9003, 0.9481, 0.8828, 0.9219],\n",
      "         [0.9232, 0.9680, 0.8984, 0.9008],\n",
      "         [0.9007, 0.9648, 0.8932, 0.9525],\n",
      "         [0.9528, 0.9769, 0.9394, 0.9629],\n",
      "         [0.9629, 1.0069, 0.9608, 1.0000]]]), 'candle_shape': tensor([[[9.6597e-03, 1.3418e-03, 9.4258e-02, 7.0000e-01],\n",
      "         [5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01],\n",
      "         [4.8531e-02, 2.5913e-03, 2.4335e-02, 3.0000e-01],\n",
      "         [1.2858e-02, 8.2939e-03, 5.4429e-02, 7.0000e-01],\n",
      "         [1.4585e-02, 1.4040e-02, 1.0476e-02, 7.0000e-01],\n",
      "         [6.9362e-03, 2.1723e-03, 3.7114e-02, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"GET /get_and_add_data?idx=62 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7732, 0.7772, 0.7252, 0.7416],\n",
      "         [0.7412, 0.8241, 0.7410, 0.8207],\n",
      "         [0.8207, 0.8875, 0.8078, 0.8684],\n",
      "         [0.8685, 0.8965, 0.8394, 0.8823],\n",
      "         [0.8820, 0.9618, 0.8728, 0.9587],\n",
      "         [0.9587, 0.9791, 0.8754, 0.9017],\n",
      "         [0.9010, 0.9770, 0.8919, 0.9686],\n",
      "         [0.9681, 1.0235, 0.9640, 0.9727],\n",
      "         [0.9722, 0.9817, 0.8858, 0.9064],\n",
      "         [0.9066, 0.9495, 0.8406, 0.8520],\n",
      "         [0.8524, 0.9062, 0.8311, 0.8798],\n",
      "         [0.8798, 0.9116, 0.8122, 0.8419],\n",
      "         [0.8419, 0.8551, 0.8055, 0.8328],\n",
      "         [0.8328, 0.9070, 0.8120, 0.8966],\n",
      "         [0.8963, 0.9440, 0.8789, 0.9178],\n",
      "         [0.9192, 0.9638, 0.8945, 0.8968],\n",
      "         [0.8967, 0.9605, 0.8893, 0.9483],\n",
      "         [0.9486, 0.9726, 0.9353, 0.9587],\n",
      "         [0.9587, 1.0025, 0.9566, 0.9956],\n",
      "         [0.9956, 1.0043, 0.9596, 1.0000]]]), 'candle_shape': tensor([[[5.2791e-03, 2.2120e-02, 4.0784e-02, 3.0000e-01],\n",
      "         [4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01],\n",
      "         [4.8531e-02, 2.5913e-03, 2.4335e-02, 3.0000e-01],\n",
      "         [1.2858e-02, 8.2939e-03, 5.4429e-02, 7.0000e-01],\n",
      "         [1.4585e-02, 1.4040e-02, 1.0476e-02, 7.0000e-01],\n",
      "         [6.9362e-03, 2.1723e-03, 3.7114e-02, 7.0000e-01],\n",
      "         [4.3422e-03, 3.6151e-02, 4.3882e-03, 7.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"GET /get_and_add_data?idx=63 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.7452, 0.8285, 0.7450, 0.8250],\n",
      "         [0.8250, 0.8922, 0.8121, 0.8731],\n",
      "         [0.8731, 0.9013, 0.8439, 0.8870],\n",
      "         [0.8867, 0.9669, 0.8774, 0.9638],\n",
      "         [0.9638, 0.9843, 0.8800, 0.9065],\n",
      "         [0.9058, 0.9822, 0.8967, 0.9737],\n",
      "         [0.9732, 1.0290, 0.9691, 0.9779],\n",
      "         [0.9774, 0.9869, 0.8905, 0.9113],\n",
      "         [0.9114, 0.9546, 0.8450, 0.8566],\n",
      "         [0.8570, 0.9110, 0.8355, 0.8845],\n",
      "         [0.8845, 0.9164, 0.8165, 0.8464],\n",
      "         [0.8464, 0.8597, 0.8097, 0.8373],\n",
      "         [0.8373, 0.9118, 0.8163, 0.9013],\n",
      "         [0.9011, 0.9490, 0.8836, 0.9227],\n",
      "         [0.9241, 0.9689, 0.8992, 0.9016],\n",
      "         [0.9015, 0.9656, 0.8940, 0.9534],\n",
      "         [0.9537, 0.9778, 0.9403, 0.9638],\n",
      "         [0.9638, 1.0079, 0.9617, 1.0009],\n",
      "         [1.0009, 1.0097, 0.9647, 1.0053],\n",
      "         [1.0053, 1.0224, 0.9966, 1.0000]]]), 'candle_shape': tensor([[[4.1915e-03, 2.5424e-04, 9.6806e-02, 7.0000e-01],\n",
      "         [2.1941e-02, 1.5712e-02, 5.5011e-02, 7.0000e-01],\n",
      "         [1.6082e-02, 3.3486e-02, 1.5658e-02, 7.0000e-01],\n",
      "         [3.2175e-03, 1.0444e-02, 8.0029e-02, 7.0000e-01],\n",
      "         [2.1237e-02, 2.9223e-02, 5.9434e-02, 3.0000e-01],\n",
      "         [8.6972e-03, 1.0090e-02, 6.9756e-02, 7.0000e-01],\n",
      "         [5.2229e-02, 4.1733e-03, 4.8103e-03, 7.0000e-01],\n",
      "         [9.7329e-03, 2.2764e-02, 6.7661e-02, 3.0000e-01],\n",
      "         [4.7363e-02, 1.3458e-02, 6.0157e-02, 3.0000e-01],\n",
      "         [3.0003e-02, 2.4997e-02, 3.1141e-02, 7.0000e-01],\n",
      "         [3.6120e-02, 3.5330e-02, 4.3088e-02, 3.0000e-01],\n",
      "         [1.5730e-02, 3.2868e-02, 1.0780e-02, 3.0000e-01],\n",
      "         [1.1654e-02, 2.5026e-02, 7.1096e-02, 7.0000e-01],\n",
      "         [2.8476e-02, 1.9378e-02, 2.3469e-02, 7.0000e-01],\n",
      "         [4.8531e-02, 2.5913e-03, 2.4335e-02, 3.0000e-01],\n",
      "         [1.2858e-02, 8.2939e-03, 5.4429e-02, 7.0000e-01],\n",
      "         [1.4585e-02, 1.4040e-02, 1.0476e-02, 7.0000e-01],\n",
      "         [6.9362e-03, 2.1723e-03, 3.7114e-02, 7.0000e-01],\n",
      "         [4.3422e-03, 3.6151e-02, 4.3882e-03, 7.0000e-01],\n",
      "         [1.6934e-02, 3.4041e-03, 5.2974e-03, 3.0000e-01]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"GET /get_and_add_data?idx=64 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[0.8818, 0.9536, 0.8680, 0.9332],\n",
      "         [0.9332, 0.9633, 0.9020, 0.9481],\n",
      "         [0.9477, 1.0335, 0.9378, 1.0301],\n",
      "         [1.0301, 1.0520, 0.9406, 0.9689],\n",
      "         [0.9681, 1.0498, 0.9584, 1.0407],\n",
      "         [1.0402, 1.0998, 1.0358, 1.0452],\n",
      "         [1.0447, 1.0548, 0.9518, 0.9740],\n",
      "         [0.9741, 1.0202, 0.9032, 0.9155],\n",
      "         [0.9159, 0.9737, 0.8930, 0.9454],\n",
      "         [0.9454, 0.9795, 0.8727, 0.9046],\n",
      "         [0.9046, 0.9189, 0.8655, 0.8949],\n",
      "         [0.8949, 0.9746, 0.8725, 0.9634],\n",
      "         [0.9631, 1.0143, 0.9444, 0.9862],\n",
      "         [0.9877, 1.0356, 0.9611, 0.9636],\n",
      "         [0.9635, 1.0321, 0.9555, 1.0190],\n",
      "         [1.0193, 1.0451, 1.0050, 1.0301],\n",
      "         [1.0301, 1.0772, 1.0279, 1.0698],\n",
      "         [1.0698, 1.0792, 1.0311, 1.0745],\n",
      "         [1.0745, 1.0927, 1.0652, 1.0688],\n",
      "         [1.0689, 1.0689, 0.9850, 1.0000]]]), 'candle_shape': tensor([[[0.0219, 0.0157, 0.0550, 0.7000],\n",
      "         [0.0161, 0.0335, 0.0157, 0.7000],\n",
      "         [0.0032, 0.0104, 0.0800, 0.7000],\n",
      "         [0.0212, 0.0292, 0.0594, 0.3000],\n",
      "         [0.0087, 0.0101, 0.0698, 0.7000],\n",
      "         [0.0522, 0.0042, 0.0048, 0.7000],\n",
      "         [0.0097, 0.0228, 0.0677, 0.3000],\n",
      "         [0.0474, 0.0135, 0.0602, 0.3000],\n",
      "         [0.0300, 0.0250, 0.0311, 0.7000],\n",
      "         [0.0361, 0.0353, 0.0431, 0.3000],\n",
      "         [0.0157, 0.0329, 0.0108, 0.3000],\n",
      "         [0.0117, 0.0250, 0.0711, 0.7000],\n",
      "         [0.0285, 0.0194, 0.0235, 0.7000],\n",
      "         [0.0485, 0.0026, 0.0243, 0.3000],\n",
      "         [0.0129, 0.0083, 0.0544, 0.7000],\n",
      "         [0.0146, 0.0140, 0.0105, 0.7000],\n",
      "         [0.0069, 0.0022, 0.0371, 0.7000],\n",
      "         [0.0043, 0.0362, 0.0044, 0.7000],\n",
      "         [0.0169, 0.0034, 0.0053, 0.3000],\n",
      "         [0.0000, 0.0150, 0.0645, 0.3000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"GET /get_and_add_data?idx=65 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2025 12:55:02] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': tensor([[[1.0092, 1.0417, 0.9754, 1.0252],\n",
      "         [1.0248, 1.1176, 1.0141, 1.1140],\n",
      "         [1.1140, 1.1376, 1.0172, 1.0478],\n",
      "         [1.0469, 1.1352, 1.0364, 1.1254],\n",
      "         [1.1248, 1.1893, 1.1201, 1.1303],\n",
      "         [1.1297, 1.1407, 1.0293, 1.0532],\n",
      "         [1.0534, 1.1033, 0.9767, 0.9900],\n",
      "         [0.9905, 1.0530, 0.9657, 1.0223],\n",
      "         [1.0223, 1.0592, 0.9437, 0.9783],\n",
      "         [0.9783, 0.9936, 0.9359, 0.9677],\n",
      "         [0.9677, 1.0539, 0.9435, 1.0418],\n",
      "         [1.0415, 1.0969, 1.0213, 1.0665],\n",
      "         [1.0680, 1.1199, 1.0394, 1.0421],\n",
      "         [1.0419, 1.1161, 1.0333, 1.1019],\n",
      "         [1.1023, 1.1302, 1.0868, 1.1139],\n",
      "         [1.1139, 1.1649, 1.1115, 1.1569],\n",
      "         [1.1569, 1.1670, 1.1150, 1.1620],\n",
      "         [1.1620, 1.1816, 1.1519, 1.1558],\n",
      "         [1.1559, 1.1559, 1.0651, 1.0814],\n",
      "         [1.0814, 1.0998, 0.9475, 1.0000]]]), 'candle_shape': tensor([[[0.0161, 0.0335, 0.0157, 0.7000],\n",
      "         [0.0032, 0.0104, 0.0800, 0.7000],\n",
      "         [0.0212, 0.0292, 0.0594, 0.3000],\n",
      "         [0.0087, 0.0101, 0.0698, 0.7000],\n",
      "         [0.0522, 0.0042, 0.0048, 0.7000],\n",
      "         [0.0097, 0.0228, 0.0677, 0.3000],\n",
      "         [0.0474, 0.0135, 0.0602, 0.3000],\n",
      "         [0.0300, 0.0250, 0.0311, 0.7000],\n",
      "         [0.0361, 0.0353, 0.0431, 0.3000],\n",
      "         [0.0157, 0.0329, 0.0108, 0.3000],\n",
      "         [0.0117, 0.0250, 0.0711, 0.7000],\n",
      "         [0.0285, 0.0194, 0.0235, 0.7000],\n",
      "         [0.0485, 0.0026, 0.0243, 0.3000],\n",
      "         [0.0129, 0.0083, 0.0544, 0.7000],\n",
      "         [0.0146, 0.0140, 0.0105, 0.7000],\n",
      "         [0.0069, 0.0022, 0.0371, 0.7000],\n",
      "         [0.0043, 0.0362, 0.0044, 0.7000],\n",
      "         [0.0169, 0.0034, 0.0053, 0.3000],\n",
      "         [0.0000, 0.0150, 0.0645, 0.3000],\n",
      "         [0.0170, 0.0525, 0.0753, 0.3000]]])}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_files = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")\n",
    "state_files = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")\n",
    "\n",
    "# Pick the newest (last modified)\n",
    "meta_path = max(meta_files, key=os.path.getmtime)\n",
    "state_path = max(state_files, key=os.path.getmtime)\n",
    "print(\"Using latest meta file:\", meta_path)\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_columns']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "print(\"init_args\",init_args)\n",
    "model = CNNAttentionLSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "pipeline.window_scalers = meta[\"window_scalers\"]\n",
    "pipeline.load_target_scalers(meta[\"target_scalers\"])\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"hungarian.html\")\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "              for k, v in seq_dict.items()}\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(dict_x, lengths)  # (batch, target_dim)\n",
    "\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "\n",
    "    # Example: assume you only care about the \"close\" target\n",
    "    if pipeline.target_scaler:\n",
    "        scaler = pipeline.load_target_scalers(meta[\"target_scalers\"])\n",
    "        y_pred_inv = scaler.inverse_transform(y_pred_np)\n",
    "        pred_prices = y_pred_inv[0].tolist()\n",
    "    else:\n",
    "        # fallback: use raw predictions\n",
    "        pred_prices = y_pred_np[0].tolist()\n",
    "\n",
    "\n",
    "    last_close = float(preproc.reference_dataset.iloc[-1]['close'])\n",
    "\n",
    "    # ✅ Ensure pred_prices is a NumPy array before multiplying\n",
    "    pred_prices = np.asarray(pred_prices, dtype=np.float32)\n",
    "\n",
    "    scaled_pred_prices = pred_prices * last_close\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": scaled_pred_prices.tolist()\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ec16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[<StreamHandler stderr (NOTSET)>]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"servers.pre_process\")\n",
    "print(logger.handlers)          # list of handlers attached to this logger\n",
    "print(logging.getLogger().handlers)  # root logger handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e43ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:16] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:16] \"GET /get_and_add_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:17] \"GET /validation_samples HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Sep/2025 01:38:19] \"POST /validation_test HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validation Test Sample 12 ---\n",
      "seq_len: 112, raw_ts: 1554595200000000000\n",
      "target_y: [0.7261959910392761, 0.7998110055923462, 0.6823400259017944, 0.9392110109329224, 0.6541470289230347, 0.0, 0.0, 0.0, 0.0]\n",
      "Converting reference_dataset index from int64 to datetime...\n",
      "Timestamp 2019-04-07 00:00:00 missing, reindexing...\n",
      "\n",
      "--- prepare_seq_valid debug ---\n",
      "Requested end_idx (raw): 2019-04-07 00:00:00, seq_len: 112\n",
      "Timestamp 2018-12-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-29 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-30 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2018-12-31 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-07 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-08 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-09 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-10 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-11 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-12 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-13 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-14 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-15 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-16 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-29 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-30 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-01-31 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-07 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-08 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-09 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-10 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-11 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-12 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-13 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-14 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-15 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-16 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-02-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-07 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-08 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-09 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-10 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-11 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-12 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-13 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-14 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-15 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-16 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-17 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-18 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-19 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-20 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-21 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-22 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-23 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-24 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-25 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-26 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-27 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-28 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-29 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-30 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-03-31 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-01 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-02 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-03 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-04 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-05 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-06 00:00:00 missing in dataset → adding candle\n",
      "Timestamp 2019-04-07 00:00:00 missing in dataset → adding candle\n",
      "Sliced 'main' shape: (21, 4)\n",
      "After apply_window 'main' shape: (21, 4)\n",
      "--- prepare_seq_valid end ---\n",
      "\n",
      "main: shape (21, 4), dtype float32\n",
      "lengths tensor: tensor([112])\n",
      "Passing dict_x['main'] to model: shape torch.Size([1, 21, 4])\n",
      "Model forward error: start (21) + length (1) exceeds dimension size (21).\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Current notebook location\n",
    "# notebook_path = Path().resolve()\n",
    "\n",
    "# # Add parent folder (meta/) to sys.path\n",
    "# sys.path.append(str(notebook_path.parent))\n",
    "# from pathlib import Path\n",
    "import pickle\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = CNNAttentionLSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\n",
    "    \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "    parse_dates=['timestamp']\n",
    ")\n",
    "# print(f\"DF loaded, shape: {df.shape}\")\n",
    "\n",
    "# ---------------- Load validation ----------------\n",
    "val_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/val_dataset_*.pkl\")[0]\n",
    "# print(f\"Loading validation dataset from: {val_path}\")\n",
    "\n",
    "with open(val_path, \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "# print(f\"Validation data keys: {list(val_data.keys())}\")\n",
    "# print(f\"Number of validation samples: {len(val_data['y'])}\")\n",
    "\n",
    "VAL_SAMPLES = []\n",
    "for i in range(len(val_data[\"y\"])):\n",
    "    seq_len = int(val_data[\"x_lengths\"][i])\n",
    "    time_indices = val_data[\"time_indices\"][i]  # timestamps, not integer indices\n",
    "    end_ts = pd.to_datetime(time_indices[-1])   # convert last timestamp to pd.Timestamp\n",
    "    \n",
    "    # print(f\"\\nSample {i}:\")\n",
    "    # print(f\"  seq_len: {seq_len}\")\n",
    "    # print(f\"  time_indices: {time_indices}\")\n",
    "    # print(f\"  end_ts: {end_ts}\")\n",
    "    \n",
    "    # find row index in df corresponding to this timestamp\n",
    "    matching_rows = df.index[df['timestamp'] == end_ts].tolist()\n",
    "    # if not matching_rows:\n",
    "    #     print(f\"  WARNING: no matching row in df for timestamp {end_ts}, skipping sample\")\n",
    "    #     continue\n",
    "    \n",
    "    row_idx = matching_rows[0]\n",
    "    end_time = str(df.iloc[row_idx].name)  # timestamp as string\n",
    "    \n",
    "    VAL_SAMPLES.append({\n",
    "        \"idx\": i,\n",
    "        \"seq_len\": seq_len,\n",
    "        \"end_idx\": row_idx,\n",
    "        \"end_time\": end_time\n",
    "    })\n",
    "\n",
    "# print(f\"\\nTotal valid samples loaded: {len(VAL_SAMPLES)}\")\n",
    "\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"hungarian2.html\")\n",
    "\n",
    "@app.route(\"/validation_samples\")\n",
    "def validation_samples():\n",
    "    return jsonify(VAL_SAMPLES)\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "              for k, v in seq_dict.items()}\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(dict_x, lengths)  # only regression head now\n",
    "    print(y_pred)\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices\n",
    "    })\n",
    "\n",
    "@app.route(\"/validation_test\", methods=[\"POST\"])\n",
    "def validation_test():\n",
    "    data = request.get_json(force=True)\n",
    "    sample_idx = data.get(\"sample_idx\")\n",
    "    \n",
    "    if sample_idx is None or not (0 <= sample_idx < len(val_data[\"y\"])):\n",
    "        return jsonify({\"error\": \"Invalid sample_idx\"}), 400\n",
    "\n",
    "    seq_len = int(val_data[\"x_lengths\"][sample_idx])\n",
    "    raw_ts = int(val_data[\"time_indices\"][sample_idx][-1])  # nanoseconds\n",
    "    ts = pd.to_datetime(raw_ts)  # Timestamp\n",
    "\n",
    "    target_y = val_data[\"y\"][sample_idx][:seq_len].tolist()\n",
    "\n",
    "    print(f\"\\n--- Validation Test Sample {sample_idx} ---\")\n",
    "    print(f\"seq_len: {seq_len}, raw_ts: {raw_ts}\")\n",
    "    print(f\"target_y: {target_y}\")\n",
    "\n",
    "    # --- Ensure reference dataset has datetime index ---\n",
    "    ref = preproc.reference_dataset\n",
    "    if np.issubdtype(ref.index.dtype, np.integer):\n",
    "        print(\"Converting reference_dataset index from int64 to datetime...\")\n",
    "        ref.index = pd.to_datetime(ref.index)\n",
    "\n",
    "    # --- Make sure requested timestamp exists ---\n",
    "    if ts not in ref.index:\n",
    "        print(f\"Timestamp {ts} missing, reindexing...\")\n",
    "        freq = pd.infer_freq(ref.index[:10]) or \"D\"  # auto-detect, fallback daily\n",
    "        full_index = pd.date_range(start=ref.index.min(), end=ref.index.max(), freq=freq)\n",
    "        ref = ref.reindex(full_index, method=\"ffill\")\n",
    "        preproc.reference_dataset = ref\n",
    "\n",
    "    # --- Prepare sequence ---\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq_valid(end_idx=ts, seq_len=seq_len)\n",
    "    except ValueError as e:\n",
    "        print(f\"prepare_seq_valid error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert to tensors\n",
    "    dict_x = {}\n",
    "    for k, v in seq_dict.items():\n",
    "        arr = v.values.astype(np.float32)\n",
    "        dict_x[k] = torch.from_numpy(arr).unsqueeze(0)  # add batch dim\n",
    "        print(f\"{k}: shape {arr.shape}, dtype {arr.dtype}\")\n",
    "\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "    print(f\"lengths tensor: {lengths}\")\n",
    "\n",
    "    # Model forward\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            print(f\"Passing dict_x['main'] to model: shape {dict_x['main'].shape}\")\n",
    "            y_pred = model(dict_x, lengths)\n",
    "            print(f\"y_pred shape: {y_pred.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model forward error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "    last_close = preproc.reference_dataset.loc[ts, 'close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "\n",
    "    return jsonify({\n",
    "        \"sample_idx\": sample_idx,\n",
    "        \"end_time\": int(ts.timestamp() * 1000),  # unix ms for frontend\n",
    "        \"seq_len\": seq_len,\n",
    "        \"pred_prices\": pred_prices,\n",
    "        \"target_y\": target_y\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae95b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "caf18009-c014-40df-bd99-518fd835a07c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1514937600",
         "1515456000",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516147200",
         "1516492800",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1519862400",
         "1520121600",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "45",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "48",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "49",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 364
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1514937600</td>\n",
       "      <td>1515456000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1647216000</td>\n",
       "      <td>1648339200</td>\n",
       "      <td>1533</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.889793</td>\n",
       "      <td>0.902754</td>\n",
       "      <td>0.847861</td>\n",
       "      <td>0.840999</td>\n",
       "      <td>0.814315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1629417600</td>\n",
       "      <td>1630108800</td>\n",
       "      <td>1327</td>\n",
       "      <td>1335</td>\n",
       "      <td>1.001120</td>\n",
       "      <td>1.013533</td>\n",
       "      <td>0.976295</td>\n",
       "      <td>1.031057</td>\n",
       "      <td>0.963152</td>\n",
       "      <td>0.958041</td>\n",
       "      <td>0.944168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1612742400</td>\n",
       "      <td>1613174400</td>\n",
       "      <td>1134</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.984341</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>1.021441</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>0.930585</td>\n",
       "      <td>1.035826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1608940800</td>\n",
       "      <td>1609632000</td>\n",
       "      <td>1090</td>\n",
       "      <td>1098</td>\n",
       "      <td>0.795270</td>\n",
       "      <td>0.875328</td>\n",
       "      <td>0.805007</td>\n",
       "      <td>0.861264</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1588636800</td>\n",
       "      <td>1594166400</td>\n",
       "      <td>855</td>\n",
       "      <td>919</td>\n",
       "      <td>1.048390</td>\n",
       "      <td>1.078658</td>\n",
       "      <td>0.957585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919750</td>\n",
       "      <td>0.870564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.108926</td>\n",
       "      <td>0.99542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1514937600  1515456000           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "359  1647216000  1648339200        1533      1546     0.873783     0.889793   \n",
       "360  1629417600  1630108800        1327      1335     1.001120     1.013533   \n",
       "361  1612742400  1613174400        1134      1139     0.984341     1.000241   \n",
       "362  1608940800  1609632000        1090      1098     0.795270     0.875328   \n",
       "363  1588636800  1594166400         855       919     1.048390     1.078658   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "359     0.902754     0.847861     0.840999     0.814315          NaN   \n",
       "360     0.976295     1.031057     0.963152     0.958041     0.944168   \n",
       "361     1.021441     0.949513     0.930585     1.035826          NaN   \n",
       "362     0.805007     0.861264     0.783370          NaN          NaN   \n",
       "363     0.957585          NaN     0.919750     0.870564          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "359          NaN          NaN  \n",
       "360          NaN          NaN  \n",
       "361          NaN          NaN  \n",
       "362          NaN          NaN  \n",
       "363     1.108926      0.99542  \n",
       "\n",
       "[364 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv( \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4c8b3",
   "metadata": {},
   "source": [
    "## xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "from servers.pre_process.multi_reg_dif_seq import ServerPreprocess, build_pipeline_from_config\n",
    "\n",
    "# ---------------- Flask ----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load models + meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_meta_multireg_*.pkl\")[0]\n",
    "model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_multireg_*.pkl\")[0]\n",
    "len_model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_seq_len_*.pkl\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Models\n",
    "model = joblib.load(model_path)       # MultiOutputRegressor with XGBRegressor inside\n",
    "len_model = joblib.load(len_model_path)\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"xgboost_seq.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Use your XGBoost + preproc logic\n",
    "        X_np = preproc.prepare_xgboost_seq(seq_len, model=len_model)\n",
    "        pred_len = int(np.round(len_model.predict(X_np))[0])\n",
    "        y_pred_full = model.predict(X_np)[0]\n",
    "        pred_trunc = np.sort(y_pred_full[:pred_len])\n",
    "        last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "        pred_scaled = (last_close * pred_trunc).tolist()\n",
    "\n",
    "        return jsonify({\n",
    "            'pred_length': pred_len,\n",
    "            'pred_lines': pred_scaled\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # <-- This will print the actual exception in the console\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc07d3a",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09e37c",
   "metadata": {},
   "source": [
    "## tensorboard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06403bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching TensorBoard for: lightning_logs/version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:40:23.482869: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "2025-09-20 22:40:23.713288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758395423.784945   70469 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758395423.810144   70469 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758395423.989054   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758395423.989087   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758395423.989090   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758395423.989091   70469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-20 22:40:24.009084: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "logdir = \"lightning_logs\"\n",
    "\n",
    "# 1. Find all version folders\n",
    "versions = [d for d in os.listdir(logdir) if d.startswith(\"version_\") and d.split(\"_\")[1].isdigit()]\n",
    "if not versions:\n",
    "    raise ValueError(\"No version folders found in lightning_logs\")\n",
    "\n",
    "# 2. Pick the latest numerically\n",
    "latest_version = max(versions, key=lambda x: int(x.split(\"_\")[1]))\n",
    "latest_logdir = os.path.join(logdir, latest_version)\n",
    "print(f\"Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\"tensorboard\", f\"--logdir={latest_logdir}\", f\"--port={port}\"])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264cbc4",
   "metadata": {},
   "source": [
    "## tensoarboard tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec717ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Launching TensorBoard for: /home/iatell/projects/meta-learning/tune_logs/cnn_lstm_tuning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 13:22:26.075205: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-21 13:22:26.085246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758448346.098199   17034 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758448346.102121   17034 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758448346.112870   17034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758448346.112907   17034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758448346.112910   17034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758448346.112911   17034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-21 13:22:26.116275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0921 13:22:28.635366 135418193121408 program.py:300] TensorBoard could not bind to port 6006, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6006, it was already in use\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "# Base Ray Tune log directory\n",
    "base_logdir = \"/home/iatell/projects/meta-learning/tune_logs\"\n",
    "\n",
    "# 1. Find all experiment folders\n",
    "experiments = [d for d in os.listdir(base_logdir) if os.path.isdir(os.path.join(base_logdir, d))]\n",
    "if not experiments:\n",
    "    raise ValueError(\"No experiment folders found in tune_logs\")\n",
    "\n",
    "# 2. Sort by modification time and get the latest experiment\n",
    "experiments.sort(key=lambda x: os.path.getmtime(os.path.join(base_logdir, x)))\n",
    "latest_experiment = experiments[-1]\n",
    "latest_logdir = os.path.join(base_logdir, latest_experiment)\n",
    "print(f\"🚀 Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\n",
    "    \"tensorboard\",\n",
    "    f\"--logdir={latest_logdir}\",\n",
    "    f\"--port={port}\"\n",
    "])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609a59a",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd2907",
   "metadata": {},
   "source": [
    "## tuning cnn- attention lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c39a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-09-21 13:20:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:46.79        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.003843875601887703<br>Logical resource usage: 1.0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  cnn_out_channels</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">         lr</th><th>optimizer_name  </th><th style=\"text-align: right;\">            optimizer_params/wei\n",
       "ght_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00000</td><td>TERMINATED</td><td>172.18.55.78:15018</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000124993</td><td>adam            </td><td style=\"text-align: right;\">2.68816e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         126.297</td><td style=\"text-align: right;\">-0.0114773 </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00001</td><td>TERMINATED</td><td>172.18.55.78:15010</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000885102</td><td>adamw           </td><td style=\"text-align: right;\">7.67892e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         128.646</td><td style=\"text-align: right;\">-0.00219728</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00002</td><td>TERMINATED</td><td>172.18.55.78:15016</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000538188</td><td>adam            </td><td style=\"text-align: right;\">0.00735574 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         126.157</td><td style=\"text-align: right;\">-0.00301658</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00003</td><td>TERMINATED</td><td>172.18.55.78:15011</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000111802</td><td>adam            </td><td style=\"text-align: right;\">6.4462e-05 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         219.646</td><td style=\"text-align: right;\">-0.00487337</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00004</td><td>TERMINATED</td><td>172.18.55.78:15014</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.000632836</td><td>adamw           </td><td style=\"text-align: right;\">0.00834247 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         153.249</td><td style=\"text-align: right;\">-0.00314877</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00005</td><td>TERMINATED</td><td>172.18.55.78:15013</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000488824</td><td>adam            </td><td style=\"text-align: right;\">0.00935971 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         221.403</td><td style=\"text-align: right;\">-0.00366801</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00006</td><td>TERMINATED</td><td>172.18.55.78:15012</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.000137027</td><td>adamw           </td><td style=\"text-align: right;\">8.8031e-05 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         153.261</td><td style=\"text-align: right;\">-0.00401974</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00007</td><td>TERMINATED</td><td>172.18.55.78:15019</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000223933</td><td>adam            </td><td style=\"text-align: right;\">0.000172903</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         127.04 </td><td style=\"text-align: right;\">-0.00363007</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00008</td><td>TERMINATED</td><td>172.18.55.78:15017</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000158767</td><td>adam            </td><td style=\"text-align: right;\">0.00552943 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         219.978</td><td style=\"text-align: right;\">-0.00592373</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_dbd46_00009</td><td>TERMINATED</td><td>172.18.55.78:15015</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000167255</td><td>adam            </td><td style=\"text-align: right;\">0.000151493</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         113.484</td><td style=\"text-align: right;\">-0.0073531 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 13:20:20,694\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/iatell/projects/meta-learning/tune_logs/cnn_lstm_tuning' in 0.0062s.\n",
      "2025-09-21 13:20:20,699\tINFO tune.py:1041 -- Total run time: 226.81 seconds (226.78 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Config: {'hidden_dim': 64, 'lr': 0.0008851020580787064, 'optimizer_name': 'adamw', 'optimizer_params': {'weight_decay': 7.678916759507008e-05}, 'cnn_out_channels': 32}\n",
      "Best Accuracy: -0.0022\n",
      "\n",
      "🔁 Retraining best model on full dataset for saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | loss_fn_reg   | MSELoss       | 0      | train\n",
      "1 | attention     | TanhAttention | 4.2 K  | train\n",
      "2 | branches      | ModuleList    | 3.7 K  | train\n",
      "3 | fusion_conv2d | Sequential    | 1.3 K  | train\n",
      "4 | lstm          | LSTM          | 20.5 K | train\n",
      "5 | regressor     | Sequential    | 2.4 K  | train\n",
      "--------------------------------------------------------\n",
      "32.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.1 K    Total params\n",
      "0.128     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Label: [0.       1.05529  0.923251 0.828937 0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [0.       1.05529  0.923251 0.828937 0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[0.8487854  0.8556362  0.7894722  0.82848144]\n",
      " [0.8286152  0.9581091  0.79814214 0.9086739 ]\n",
      " [0.90959585 0.94783473 0.87615937 0.9238069 ]\n",
      " [0.9238069  0.94612825 0.86179656 0.93247753]\n",
      " [0.9324787  1.0635422  0.90402305 1.050177  ]\n",
      " [1.050177   1.0614922  0.99140435 1.0569509 ]\n",
      " [1.0569509  1.0588192  0.9665617  1.        ]]\n",
      "[candle_shape] Shape: (7, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.00807125 0.0470852  0.02392123 0.3       ]\n",
      " [0.05440368 0.03677583 0.08810496 0.7       ]\n",
      " [0.02600957 0.0367597  0.01538321 0.7       ]\n",
      " [0.01463923 0.06712486 0.00929843 0.7       ]\n",
      " [0.01272671 0.03051616 0.11207467 0.7       ]\n",
      " [0.00429648 0.05596451 0.00640898 0.7       ]\n",
      " [0.00176745 0.03343833 0.05388233 0.3       ]]\n",
      "\n",
      "--- Sequence 3 ---\n",
      "Label: [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.139775 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (7, 4)\n",
      "[main] First few rows:\n",
      " [[1.0201389  1.063025   0.9826389  1.036077  ]\n",
      " [1.036077   1.0611111  0.96653056 1.0458014 ]\n",
      " [1.0458027  1.1927944  1.0138888  1.177805  ]\n",
      " [1.177805   1.1904953  1.1118896  1.185402  ]\n",
      " [1.185402   1.1874973  1.0840278  1.1215299 ]\n",
      " [1.126309   1.1334931  0.8897222  1.0348986 ]\n",
      " [1.0348986  1.0763888  0.97298956 1.        ]]\n",
      "[candle_shape] Shape: (7, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.02600957 0.0367597  0.01538321 0.7       ]\n",
      " [0.01463923 0.06712486 0.00929843 0.7       ]\n",
      " [0.01272671 0.03051616 0.11207467 0.7       ]\n",
      " [0.00429648 0.05596451 0.00640898 0.7       ]\n",
      " [0.00176745 0.03343833 0.05388233 0.3       ]\n",
      " [0.00637838 0.14028078 0.08115927 0.3       ]\n",
      " [0.04009115 0.02701042 0.03372177 0.3       ]]\n",
      "\n",
      "--- Sequence 5 ---\n",
      "Label: [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.290228 1.126277 1.086008 0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (6, 4)\n",
      "[main] First few rows:\n",
      " [[1.2811143  1.2949177  1.2094173  1.2893778 ]\n",
      " [1.2893778  1.2916569  1.1791116  1.2199032 ]\n",
      " [1.2251015  1.2329156  0.9677629  1.1256732 ]\n",
      " [1.1256732  1.1708027  1.0583339  1.0877135 ]\n",
      " [1.087789   1.1296856  0.99188215 1.1260169 ]\n",
      " [1.1285027  1.1306691  0.8611065  1.        ]]\n",
      "[candle_shape] Shape: (6, 4)\n",
      "[candle_shape] First few rows:\n",
      " [[0.00429648 0.05596451 0.00640898 0.7       ]\n",
      " [0.00176745 0.03343833 0.05388233 0.3       ]\n",
      " [0.00637838 0.14028078 0.08115927 0.3       ]\n",
      " [0.04009115 0.02701042 0.03372177 0.3       ]\n",
      " [0.00325818 0.0881668  0.03394962 0.7       ]\n",
      " [0.00191968 0.13889347 0.11387014 0.3       ]]\n",
      "==========================\n",
      "\n",
      "features {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop'], 'candle_shape': ['upper_shadow', 'lower_shadow', 'body', 'color']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c727e675dd8463289c04acbf0b3a90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494b598bf432439a8916b01e45256b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b370861f665448109ce094cdc2321c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273c6cf094c74ece981117016b698adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb127536e3e4021a802bd072cadf8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833cb1c4064c4caf9fb9838e5f75081b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39df297cc0244658cd916dccc067177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f48e2841a4143e28e2519357eb8d215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527ec1623304f568cc89ebfef3dce37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912570a1b4d743ad8603e98d4959db8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b9185d0e454fd39d7cab51f93bf086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1c3e8d884c44afa9dadcd3ce00b22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 pipeline.scalers:\n",
      "\n",
      "🔹 pipeline.window_scalers:\n",
      "\n",
      "🎯 Target scaler:\n",
      "  (no mean_/var_ found) -> {}\n",
      "\n",
      "📦 model_class_info:\n",
      "  module: __main__\n",
      "  class : CNNAttentionLSTMMultiRegressor\n",
      "  init_args:\n",
      "    input_dim: {'main': 4, 'candle_shape': 4}\n",
      "    hidden_dim: 64\n",
      "    num_layers: 1\n",
      "    max_len_y: 9\n",
      "    lr: 0.0008851020580787064\n",
      "    attention_name: tanh_attention\n",
      "    optimizer_name: adamw\n",
      "    kernels: [3, 5, 7, 11]\n",
      "    cnn_out_channels: 32\n",
      "    first_drop: 0.3\n",
      "    second_drop: 0.3\n",
      "    third_drop: 0.3\n",
      "    scheduler_name: None\n",
      "    optimizer_params: {'weight_decay': 7.678916759507008e-05}\n",
      "    scheduler_params: {}\n",
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250921_132020.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250921_132020.pkl\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.005542, MAE: 0.055367 [original units]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "def resource_usage():\n",
    "    \"\"\"Print current CPU, RAM, and GPU usage.\"\"\"\n",
    "    cpu = psutil.cpu_percent(interval=0.5)\n",
    "    ram = psutil.virtual_memory().percent\n",
    "    usage = f\"💻 CPU: {cpu:.1f}% | 🧠 RAM: {ram:.1f}%\"\n",
    "    try:\n",
    "        import GPUtil\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if gpus:\n",
    "            usage += f\" | 🎮 GPU: {gpus[0].load*100:.1f}% VRAM: {gpus[0].memoryUtil*100:.1f}%\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    print(usage)\n",
    "\n",
    "\n",
    "def train_cnn_lstm_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    Args:\n",
    "        config (dict): hyperparameters for this trial.\n",
    "    \"\"\"\n",
    "    resource_usage()  # Show current hardware usage\n",
    "\n",
    "    # Train using existing train_model function\n",
    "    metrics = train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        # seq_len=config[\"seq_len\"],\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        # num_layers=config[\"num_layers\"],\n",
    "        lr=config[\"lr\"],\n",
    "        # batch_size=config[\"batch_size\"],\n",
    "        # max_epochs=config[\"max_epochs\"],\n",
    "        return_val_accuracy=True,  # Expects dict with \"accuracy\" and optionally \"loss\"\n",
    "        save_model=False  # Never save during search\n",
    "    )\n",
    "\n",
    "    # Report metrics to Ray Tune\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=True):\n",
    "    \"\"\"Hyperparameter tuning for CNN LSTM with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # LSTM / model\n",
    "        \"hidden_dim\": tune.choice([32, 64, 128, 256]),\n",
    "        # \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        # \"attention_name\": tune.choice([\"simple_attention\", \"tanh_attention\"]),\n",
    "\n",
    "        # Learning rate & optimizer\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-3),\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "\n",
    "        # Scheduler\n",
    "        # \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"cosine\", \"onecycle\"]),\n",
    "        # \"scheduler_params\": {\n",
    "            # \"factor\": tune.loguniform(0.05, 0.5),      # only used for ReduceLROnPlateau\n",
    "            # \"patience\": tune.choice([2, 3, 5, 7]),     # only used for ReduceLROnPlateau\n",
    "            # \"T_max\": tune.choice([10, 20, 50]),        # only used for CosineAnnealingLR\n",
    "            # \"eta_min\": tune.loguniform(1e-6, 1e-4)    # only used for CosineAnnealingLR\n",
    "        # },\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2)\n",
    "        },\n",
    "\n",
    "        # CNN params\n",
    "        # \"kernels\": tune.choice([[3,5,7,11], [3,5,7], [3,5]]),\n",
    "        \"cnn_out_channels\": tune.choice([ 32, 64]),\n",
    "        # \"first_drop\": tune.uniform(0.1, 0.5),\n",
    "        # \"second_drop\": tune.uniform(0.1, 0.5),\n",
    "        # \"third_drop\": tune.uniform(0.1, 0.5),\n",
    "\n",
    "        # Training\n",
    "        # \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        # \"max_epochs\": tune.choice([50, 100, 150]),\n",
    "    }    \n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",  # must exist in metrics dict from train_model\n",
    "        mode=\"max\",\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        train_cnn_lstm_tune,\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=10\n",
    "        ),\n",
    "    run_config=air.RunConfig(\n",
    "        name=\"cnn_lstm_tuning\",\n",
    "        storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "    ),\n",
    "    # runtime_env=runtime_env\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Best trial\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "    print(\"\\n🏆 Best Config:\", best_result.config)\n",
    "    print(f\"Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # Optional: retrain best model on full data and save\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        # Map scheduler params depending on scheduler type\n",
    "        scheduler_name = best_result.config.get(\"scheduler_name\")\n",
    "        scheduler_params_config = best_result.config.get(\"scheduler_params\", {})\n",
    "\n",
    "        if scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler_params = {\n",
    "                \"factor\": scheduler_params_config.get(\"factor\", 0.2),\n",
    "                \"patience\": scheduler_params_config.get(\"patience\", 3)\n",
    "            }\n",
    "        elif scheduler_name == \"cosine\":\n",
    "            scheduler_params = {\n",
    "                \"T_max\": scheduler_params_config.get(\"T_max\", 10),\n",
    "                \"eta_min\": scheduler_params_config.get(\"eta_min\", 1e-6)\n",
    "            }\n",
    "        else:  # onecycle or others\n",
    "            scheduler_params = {}\n",
    "\n",
    "        # Optimizer params\n",
    "        optimizer_params = best_result.config.get(\"optimizer_params\", {\"weight_decay\": 0.01})\n",
    "\n",
    "        train_model(\n",
    "            data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "            labels_csv=\"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "            do_validation=True,\n",
    "            return_val_accuracy=True,\n",
    "            model_out_dir=\"models/saved_models\",\n",
    "            hidden_dim=best_result.config.get(\"hidden_dim\", 32),\n",
    "            num_layers=best_result.config.get(\"num_layers\", 1),\n",
    "            attention_name=best_result.config.get(\"attention_name\", \"tanh_attention\"),\n",
    "            optimizer_name=best_result.config.get(\"optimizer_name\", \"adamw\"),\n",
    "            lr=best_result.config.get(\"lr\", 1e-3),\n",
    "            batch_size=best_result.config.get(\"batch_size\", 32),\n",
    "            max_epochs=best_result.config.get(\"max_epochs\", 10),\n",
    "            kernels=best_result.config.get(\"kernels\", [3, 5, 7, 11]),\n",
    "            cnn_out_channels=best_result.config.get(\"cnn_out_channels\", 32),\n",
    "            first_drop=best_result.config.get(\"first_drop\", 0.3),\n",
    "            second_drop=best_result.config.get(\"second_drop\", 0.3),\n",
    "            third_drop=best_result.config.get(\"third_drop\", 0.3),\n",
    "            scheduler_name=scheduler_name,\n",
    "            scheduler_params=scheduler_params,\n",
    "            optimizer_params=optimizer_params\n",
    "        )\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
