{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv(\"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\")\n",
    "label[\"seq_len\"] = label[\"endIndex\"] - label[\"startIndex\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e027af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "276b5b3c-e85b-4fb2-8da6-147dc065c148",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles_prop.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b8d98",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ccb9c",
   "metadata": {},
   "source": [
    "## Hungarian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159560e2",
   "metadata": {},
   "source": [
    "### Hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16033bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Predict max_len_y candidate values\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # per-element loss\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss.\n",
    "        y_pred: (B, max_len_y)\n",
    "        y_true: (B, max_len_y)\n",
    "        mask:   (B, max_len_y), 1 where valid target, 0 where padding\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            preds = y_pred[i]                 # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Build cost matrix (L x max_len_y)\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)  # squared error\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Compute loss only for assigned pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52405383",
   "metadata": {},
   "source": [
    "### Hungarian lstm order weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6785b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Predict max_len_y candidate values\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # per-element loss\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss with position-based weighting.\n",
    "        Earlier ground-truth positions in y_true get higher weight.\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            # Extract ground-truth values and their positions\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)  # positions in y_true\n",
    "\n",
    "            preds = y_pred[i]  # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Cost matrix (L x max_len_y) using squared error\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Matched pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            # --- weighting logic ---\n",
    "            # Lower index = higher weight (inverse rank)\n",
    "            gt_pos = gt_indices[row_ind]  # actual positions of matched gts\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())  # e.g. pos=0 -> 1.0, pos=2 -> 0.33\n",
    "\n",
    "            # Compute weighted MSE\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "    \n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Same Hungarian matching but without weights (baseline).\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d451064",
   "metadata": {},
   "source": [
    "### CNN -attention lstm hungarian - concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d25a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# --- Sinusoidal positional encoding ---\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "# --- CNN + Transformer Regressor ---\n",
    "class CNNAttentionTransformerRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, nhead=4, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Multi-branch CNN ---\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ) for k in [3, 5, 7, 11]\n",
    "        ])\n",
    "\n",
    "        # --- Conv2d fusion ---\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # --- Positional encoding ---\n",
    "        self.positional_encoding = SinusoidalPositionalEncoding(d_model=32)\n",
    "\n",
    "        # --- Transformer encoder ---\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=32,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=0.3,\n",
    "            activation=\"relu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # --- Regressor ---\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "\n",
    "    # --- Forward ---\n",
    "    def forward(self, x, lengths):\n",
    "        # x[\"main\"]: (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "\n",
    "        # Multi-branch CNN\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)               # (B, 4, 32, T)\n",
    "\n",
    "        # Conv2d fusion\n",
    "        fused = self.fusion_conv2d(stacked)                        # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)                                   # (B, 32, T)\n",
    "        fused = fused.transpose(1, 2)                               # (B, T, 32)\n",
    "\n",
    "        # Positional encoding\n",
    "        fused = self.positional_encoding(fused)                    # (B, T, 32)\n",
    "\n",
    "        # Padding mask for transformer\n",
    "        max_len = fused.size(1)\n",
    "        mask = torch.arange(max_len, device=lengths.device)[None, :] >= lengths[:, None]  # True=masked\n",
    "\n",
    "        # Transformer encoder\n",
    "        transformer_out = self.transformer(fused, src_key_padding_mask=mask)  # (B, T, 32)\n",
    "\n",
    "        # Masked mean pooling over sequence\n",
    "        seq_mask = ~mask\n",
    "        pooled = (transformer_out * seq_mask.unsqueeze(-1)).sum(1) / seq_mask.sum(1, keepdim=True)  # (B, 32)\n",
    "\n",
    "        # Regression\n",
    "        y_pred = self.regressor(pooled)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    # --- Hungarian weighted loss ---\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            gt_pos = gt_indices[row_ind]\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())\n",
    "\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "\n",
    "    # --- Hungarian unweighted loss ---\n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "\n",
    "    # --- Training step ---\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5ef5c",
   "metadata": {},
   "source": [
    "### CNN simple attention lstm weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01c1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Assuming you already have this\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_outputs, lengths):\n",
    "        # lstm_outputs: (B, T, H)\n",
    "        mask = torch.arange(lstm_outputs.size(1), device=lengths.device)[None, :] < lengths[:, None]\n",
    "        attn_scores = self.attn(lstm_outputs).squeeze(-1)  # (B, T)\n",
    "        attn_scores = attn_scores.masked_fill(~mask, float('-inf'))\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)  # (B, T)\n",
    "        context = torch.sum(lstm_outputs * attn_weights.unsqueeze(-1), dim=1)  # (B, H)\n",
    "        return context\n",
    "\n",
    "\n",
    "class CNNAttentionLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Multi-branch 1D convolutions\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=\"same\"),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ) for k in [3, 5, 7, 11]\n",
    "        ])\n",
    "\n",
    "        # Fusion with Conv2d over (branches × seq)\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # LSTM takes feature_dim = 32 after fusion\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(hidden_dim)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, max_len_y)\n",
    "        )\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Input: x[\"main\"] → (B, T, input_dim)\n",
    "        x = x[\"main\"].transpose(1, 2)  # (B, input_dim, T)\n",
    "\n",
    "        # Branch outputs\n",
    "        branch_outputs = [branch(x) for branch in self.branches]  # list of (B, 32, T)\n",
    "        stacked = torch.stack(branch_outputs, dim=1)  # (B, 4, 32, T)\n",
    "\n",
    "        # Fusion conv2d\n",
    "        fused = self.fusion_conv2d(stacked)  # (B, 1, 32, T)\n",
    "        fused = fused.squeeze(1)             # (B, 32, T)\n",
    "\n",
    "        # Prepare for LSTM\n",
    "        lstm_input = fused.transpose(1, 2)   # (B, T, 32)\n",
    "\n",
    "        # LSTM with packing\n",
    "        packed_input = pack_padded_sequence(lstm_input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_outputs, _ = pad_packed_sequence(packed_output, batch_first=True)  # (B, T, H)\n",
    "\n",
    "        # Attention\n",
    "        context_vector = self.attention(lstm_outputs, lengths)  # (B, H)\n",
    "\n",
    "        # Regression\n",
    "        y_pred = self.regressor(context_vector)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Hungarian matching loss with position-based weighting.\n",
    "        Earlier ground-truth positions in y_true get higher weight.\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            # Extract ground-truth values and their positions\n",
    "            gt_vals = y_true[i][mask[i] > 0]  # (L,)\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)  # positions in y_true\n",
    "\n",
    "            preds = y_pred[i]  # (max_len_y,)\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Cost matrix (L x max_len_y) using squared error\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            # Hungarian assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            # Matched pairs\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            # --- weighting logic ---\n",
    "            # Lower index = higher weight (inverse rank)\n",
    "            gt_pos = gt_indices[row_ind]  # actual positions of matched gts\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())  # e.g. pos=0 -> 1.0, pos=2 -> 0.33\n",
    "\n",
    "            # Compute weighted MSE\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "    \n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        \"\"\"\n",
    "        Same Hungarian matching but without weights (baseline).\n",
    "        \"\"\"\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "\n",
    "        # Hungarian matching loss (weighted)\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "\n",
    "        # Log both weighted and unweighted (for comparison/debug)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)              # weighted\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)           # reference\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567ad84",
   "metadata": {},
   "source": [
    "### CNN LSTM Hungarian weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f191e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "class CNNLSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Conv1d branches\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=k, padding=k // 2),\n",
    "                nn.BatchNorm1d(32),      # normalize per branch\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)          # regularize per branch\n",
    "            )\n",
    "            for k in [1, 3, 7, 10]\n",
    "        ])\n",
    "\n",
    "        # Conv2d fuse across branch dimension\n",
    "        self.conv2d = nn.Conv2d(\n",
    "            in_channels=4, out_channels=1, kernel_size=(1, 3), padding=(0, 1)\n",
    "        )\n",
    "        self.bn2d = nn.BatchNorm2d(1)   # normalize conv2d output\n",
    "        self.dropout2d = nn.Dropout(0.3)\n",
    "\n",
    "        self.lstm_input_dim = 32  # after conv2d → (B, 32, T)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0.0   # built-in LSTM dropout\n",
    "        )\n",
    "\n",
    "        self.dropout_fc = nn.Dropout(0.3)\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"]  # (B, T, F)\n",
    "        B, T, F = x.shape\n",
    "\n",
    "        # Conv1d branches\n",
    "        feats = [branch(x.transpose(1, 2)) for branch in self.branches]  # (B, 32, T) each\n",
    "        fusion = torch.stack(feats, dim=1)                               # (B, 4, 32, T)\n",
    "\n",
    "        # Conv2d fusion\n",
    "        fusion2d = self.conv2d(fusion)                                   # (B, 1, 32, T)\n",
    "        fusion2d = self.bn2d(fusion2d)\n",
    "        fusion2d = F.relu(fusion2d)\n",
    "        fusion2d = self.dropout2d(fusion2d)\n",
    "        fusion2d = fusion2d.squeeze(1)                                   # (B, 32, T)\n",
    "\n",
    "        # LSTM\n",
    "        fusion2d = fusion2d.transpose(1, 2)                              # (B, T, 32)\n",
    "        packed = pack_padded_sequence(fusion2d, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        # Fully connected with dropout\n",
    "        last_h = self.dropout_fc(last_h)\n",
    "        y_pred = self.fc_reg(last_h)  # (B, max_len_y)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------- Hungarian Losses (same as your code) -------------------\n",
    "    def hungarian_loss(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            gt_indices = torch.nonzero(mask[i] > 0, as_tuple=False).squeeze(1)\n",
    "\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            gt_pos = gt_indices[row_ind]\n",
    "            weights = 1.0 / (1.0 + gt_pos.float())\n",
    "\n",
    "            loss = (weights * self.loss_fn_reg(matched_preds, matched_gts)).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += weights.sum().item()\n",
    "\n",
    "        return total_loss / max(total_count, 1.0)\n",
    "\n",
    "    def hungarian_loss_unweighted(self, y_pred, y_true, mask):\n",
    "        B, max_len = y_true.shape\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        for i in range(B):\n",
    "            gt_vals = y_true[i][mask[i] > 0]\n",
    "            preds = y_pred[i]\n",
    "\n",
    "            if len(gt_vals) == 0:\n",
    "                continue\n",
    "\n",
    "            cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "            cost = cost.detach().cpu().numpy()\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(cost)\n",
    "\n",
    "            matched_preds = preds[col_ind]\n",
    "            matched_gts = gt_vals[row_ind]\n",
    "\n",
    "            loss = self.loss_fn_reg(matched_preds, matched_gts).sum()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_count += len(gt_vals)\n",
    "\n",
    "        return total_loss / max(total_count, 1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred = self(X, lengths)\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        loss_reg = self.hungarian_loss(y_pred, y, mask)\n",
    "        unweighted_loss = self.hungarian_loss_unweighted(y_pred, y, mask)\n",
    "\n",
    "        self.log(\"train_loss\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_unweighted\", unweighted_loss)\n",
    "        return loss_reg\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b0b0f",
   "metadata": {},
   "source": [
    "### transformer Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31244e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Injects position information into the input sequence.\"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (Sequence Length, Batch Size, Feature Dim)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x\n",
    "\n",
    "class TransformerRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, max_len_y, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # 1. CNN Feature Extractor (same as before)\n",
    "        self.branches = nn.ModuleList([...]) # Your Conv1D branches\n",
    "        self.fusion_conv = nn.Sequential([...]) # Your 1x1 fusion conv\n",
    "        \n",
    "        # We need to ensure the output dim of fusion_conv matches model_dim\n",
    "        # Let's assume fusion_conv outputs `model_dim` channels\n",
    "\n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model=model_dim)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "\n",
    "        # 4. Final Regressor Head\n",
    "        self.regressor = nn.Linear(model_dim, max_len_y)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"].transpose(1, 2)\n",
    "        \n",
    "        # --- CNN Part ---\n",
    "        branch_outputs = [branch(x) for branch in self.branches]\n",
    "        fused_features = torch.cat(branch_outputs, dim=1)\n",
    "        fused_features = self.fusion_conv(fused_features) # (B, model_dim, T)\n",
    "        \n",
    "        # --- Transformer Part ---\n",
    "        # Reshape for Transformer: (B, T, F)\n",
    "        transformer_input = fused_features.transpose(1, 2)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        # Note: Pytorch's default Transformer expects (T, B, F) or batch_first=True\n",
    "        # We used batch_first=True, so shape is (B, T, F)\n",
    "        transformer_input = self.pos_encoder(transformer_input.transpose(0, 1)).transpose(0, 1)\n",
    "\n",
    "        # Create padding mask for the Transformer\n",
    "        # (B, T) -> True for positions that should be ignored\n",
    "        padding_mask = (torch.arange(x.size(2), device=x.device)[None, :] >= lengths[:, None])\n",
    "\n",
    "        # Pass through Transformer Encoder\n",
    "        transformer_output = self.transformer_encoder(transformer_input, src_key_padding_mask=padding_mask) # (B, T, F)\n",
    "\n",
    "        # Aggregate the output sequence into a single vector for prediction.\n",
    "        # Simple averaging is a common and effective method.\n",
    "        aggregated_output = transformer_output.mean(dim=1)\n",
    "        \n",
    "        y_pred = self.regressor(aggregated_output)\n",
    "        return y_pred\n",
    "\n",
    "    # ... (training_step, loss functions, etc. would remain the same) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab1e7f",
   "metadata": {},
   "source": [
    "## two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ccb5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        print(\"x\",x)\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_loss_reg\", loss_reg, prog_bar=True)\n",
    "        self.log(\"train_loss_len\", loss_len, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702411e",
   "metadata": {},
   "source": [
    "## two head lstm greedy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def match_and_loss(y_pred, y_true, mask, loss_fn):\n",
    "    \"\"\"\n",
    "    y_pred: (B, max_len_y)\n",
    "    y_true: (B, max_len_y)\n",
    "    mask: (B, max_len_y)  1 if real, 0 if padding\n",
    "    loss_fn: pointwise loss, e.g. MSELoss(reduction=\"none\")\n",
    "    \"\"\"\n",
    "    B, max_len = y_true.shape\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for i in range(B):\n",
    "        gt_vals = y_true[i][mask[i] > 0]  # real targets\n",
    "        preds = y_pred[i]\n",
    "\n",
    "        if len(gt_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        # greedy matching: for each gt, find closest prediction\n",
    "        used = set()\n",
    "        for gt in gt_vals:\n",
    "            dists = torch.abs(preds - gt)\n",
    "            for u in used:\n",
    "                dists[u] = float(\"inf\")  # prevent reuse\n",
    "            j = torch.argmin(dists)     # index of closest prediction\n",
    "            used.add(j.item())\n",
    "\n",
    "            total_loss += loss_fn(preds[j], gt)\n",
    "            total_count += 1\n",
    "\n",
    "    return total_loss / max(total_count, 1)\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        mask = (y != 0).float()\n",
    "\n",
    "        # --- New greedy-matching regression loss ---\n",
    "        loss_reg = match_and_loss(y_pred, y, mask, nn.MSELoss())\n",
    "\n",
    "        # --- Length loss (unchanged) ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb2dd1",
   "metadata": {},
   "source": [
    "## two head lstm sum of logits loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b88b10",
   "metadata": {},
   "source": [
    "## two head lstm soft thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5, k_soft=20.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "        self.k_soft = k_soft  # slope for soft thresholding\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Soft threshold length loss ---\n",
    "        # Convert logits into soft 0-1 mask around threshold\n",
    "        soft_mask = torch.sigmoid(self.k_soft * (len_logits - self.threshold))\n",
    "        # Compute soft expected length per sample\n",
    "        soft_len = soft_mask.sum(dim=1)\n",
    "        # True length\n",
    "        true_len = lengths.float()\n",
    "        # MSE loss on soft expected length\n",
    "        loss_len = F.mse_loss(soft_len, true_len)\n",
    "\n",
    "        # Combine losses\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b75a48",
   "metadata": {},
   "source": [
    "## FNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c70fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b1d4",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368a03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    B = y_true.shape[0]\n",
    "\n",
    "    # Keep track if any valid lines are found\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]  # (B,1)\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "\n",
    "        mask = (y_target != 0).squeeze()\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        valid_line_found = True\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_loss = -log_likelihood.mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        # Avoid returning a Python float; create a tensor with requires_grad\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a057d",
   "metadata": {},
   "source": [
    "## LSTM weightening with pi order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce6729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15,hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base network\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        \n",
    "        if lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3*n_components)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f1d12",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb7ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.distributions import Normal\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class cnn_lstm(pl.LightningModule):\n",
    "    def __init__(self, input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base feature projection\n",
    "        self.fc1 = nn.Linear(input_dim, feature_eng)\n",
    "        self.ln1 = nn.LayerNorm(feature_eng)\n",
    "\n",
    "        # Parallel conv1d branches\n",
    "        self.k1 = nn.Conv1d(feature_eng, feature_eng, kernel_size=1, padding=0)\n",
    "        self.k3 = nn.Conv1d(feature_eng, feature_eng, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fusion via conv2d\n",
    "        # Input channels = 2 (from k1 + k3), Output = 1, kernel size (1,1) to fuse\n",
    "        self.fusion_conv2d = nn.Conv2d(2, 1, kernel_size=(1, 1))\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(feature_eng, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: dict with key \"main\", value shape (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]  # (B, T, input_dim)\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # Fully connected projection\n",
    "        x = F.relu(self.ln1(self.fc1(x)))  # (B, T, F)\n",
    "\n",
    "        # Conv1d expects (B, F, T)\n",
    "        x_cnn = x.transpose(1, 2)  # (B, F, T)\n",
    "\n",
    "        # Parallel convs\n",
    "        x1 = self.k1(x_cnn)  # (B, F, T)\n",
    "        x3 = self.k3(x_cnn)  # (B, F, T)\n",
    "\n",
    "        # Stack into 2-channel feature map\n",
    "        stacked = torch.stack([x1, x3], dim=1)  # (B, 2, F, T)\n",
    "\n",
    "        # Fuse with conv2d → (B, 1, F, T)\n",
    "        fused = self.fusion_conv2d(stacked).squeeze(1)  # (B, F, T)\n",
    "\n",
    "        # Back to (B, T, F)\n",
    "        fused = fused.transpose(1, 2)\n",
    "\n",
    "        # LSTM with packed sequence\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(fused, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(packed)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(fused)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3 * n_components)\n",
    "\n",
    "        # Assume you have mdn_split_params(pi, mu, sigma)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e7f3",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening with sigma confidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e3bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll_with_sigma_penalty(y_true, mdn_params, weights, lambda_sigma=0.01):\n",
    "    \"\"\"\n",
    "    Calculates weighted MDN NLL and adds a penalty for large sigmas.\n",
    "    \n",
    "    Args:\n",
    "        lambda_sigma (float): The strength of the sigma penalty.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "        mask = (y_target != -1).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # --- 1. NLL Loss Calculation (same as before) ---\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_nll_loss = -log_likelihood.mean()\n",
    "\n",
    "        # --- 2. NEW: Sigma Penalty Calculation ---\n",
    "        # We penalize the mean of the sigmas for the most likely component\n",
    "        # This focuses the penalty on the component the model actually uses\n",
    "        most_likely_idx = torch.argmax(pi_masked, dim=1)\n",
    "        most_likely_sigma = sigma_masked.gather(1, most_likely_idx.unsqueeze(1)).squeeze()\n",
    "        sigma_penalty = torch.mean(most_likely_sigma)\n",
    "        \n",
    "        # --- 3. Combine and Weight ---\n",
    "        combined_line_loss = line_nll_loss + (lambda_sigma * sigma_penalty)\n",
    "        total_loss += weights[i] * combined_line_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# In your training_step, you would call this new function:\n",
    "# loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights, lambda_sigma=0.01)\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6484b7d",
   "metadata": {},
   "source": [
    "## CNNlSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2139f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # Inside your CNNLSTM_MDN class\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 50% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e8361",
   "metadata": {},
   "source": [
    "## CNNLSTM scalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a359387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components, mu_scale=10, mu_bias=.9, sigma_scale=10.0):\n",
    "    \"\"\"\n",
    "    Split raw MDN parameters into (pi, mu, sigma).\n",
    "\n",
    "    Args:\n",
    "        raw_params: (B, 3 * K) from the network\n",
    "        n_components: number of mixture components\n",
    "        mu_scale: scaling factor for mu (default 1.0 = no scaling)\n",
    "        mu_bias: shift/bias applied after scaling\n",
    "        sigma_scale: scaling factor for sigma (default 10.0)\n",
    "    \"\"\"\n",
    "    B = raw_params.size(0)\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi_raw = raw[..., 0]\n",
    "    mu_raw = raw[..., 1]\n",
    "    sigma_raw = raw[..., 2]\n",
    "\n",
    "    pi = F.softmax(pi_raw, dim=-1)\n",
    "    mu = mu_raw / mu_scale + mu_bias\n",
    "    sigma = F.softplus(sigma_raw / sigma_scale) + 1e-4\n",
    "\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] \n",
    "\n",
    "        # --- Debug print first candle ---\n",
    "        # if x.ndim == 3:  # batched: (B, T, F)\n",
    "        #     first_candle = x[0, 0, :]   # first sample, first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # elif x.ndim == 2:  # single sequence: (T, F)\n",
    "        #     first_candle = x[0, :]      # first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # else:\n",
    "        #     print(\"Unexpected shape for x:\", x.shape)\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # # Inside your CNNLSTM_MDN class\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 80% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    # def configure_optimizers(self):\n",
    "    #     return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccc1c2",
   "metadata": {},
   "source": [
    "## CNNtransformer wheightening order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9609ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "\n",
    "# --- Helper Functions and Modules ---\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma).\n",
    "    This function is used by each individual MDN head.\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-6 # Added a small epsilon for stability\n",
    "    return pi, mu, sigma\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Injects positional information into the input sequence for the Transformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- Weighted Loss Function for Multi-Head Architecture ---\n",
    "\n",
    "def weighted_mdn_nll_multihead(y_true, mdn_params_list, weights, padding_value=-1):\n",
    "    \"\"\"\n",
    "    Calculates the weighted negative log-likelihood for a multi-headed MDN.\n",
    "    This version correctly handles multiple heads and calculates the full NLL for each.\n",
    "\n",
    "    Args:\n",
    "        y_true (Tensor): Padded target values, shape (B, num_lines).\n",
    "        mdn_params_list (list): A list of dicts, one for each head.\n",
    "        weights (Tensor): A 1D tensor of importance weights, shape (num_lines,).\n",
    "        padding_value (int): Value used for padding in y_true.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    \n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params_list[i]['pi'], mdn_params_list[i]['mu'], mdn_params_list[i]['sigma']\n",
    "\n",
    "        # Create a mask for valid (non-padded) targets for this line\n",
    "        mask = (y_target != padding_value).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:  # Skip if no valid targets for this line in the batch\n",
    "            continue\n",
    "\n",
    "        # Select only the valid data for this line's loss calculation\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # Use torch.distributions for a clean and stable calculation\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        \n",
    "        # Calculate log probabilities of the target values in each Gaussian component\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        \n",
    "        # Mix the probabilities using the mixture weights (pi)\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        \n",
    "        # Use logsumexp for numerical stability to get the log-likelihood\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        \n",
    "        # Calculate the mean negative log-likelihood for this line\n",
    "        line_loss = -log_likelihood.mean()\n",
    "\n",
    "        # Apply the importance weight and add to total loss\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    # If no valid lines were found in the entire batch, return a zero tensor\n",
    "    if not isinstance(total_loss, torch.Tensor):\n",
    "        return torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "# --- The CNN-Transformer Model ---\n",
    "\n",
    "class cnn_transformer(pl.LightningModule):\n",
    "    def __init__(self, input_dim, cnn_out_channels=64, d_model=128, nhead=4, num_encoder_layers=2,\n",
    "                 n_components=9, num_lines=9, lr=1e-4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "        \n",
    "        # 1. CNN Feature Extractor Block\n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, cnn_out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(cnn_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(cnn_out_channels, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # 4. Multi-Head MDN Output\n",
    "        self.mdn_heads = nn.ModuleList([\n",
    "            nn.Linear(d_model, 3 * n_components) for _ in range(num_lines)\n",
    "        ])\n",
    "        \n",
    "        # Importance weights for lines (exponential decay)\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, X, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        src_key_padding_mask: (B, T) boolean mask for padded elements in X\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        \n",
    "        # 1. CNN Feature Extraction\n",
    "        # Input for Conv1d needs to be (B, C_in, L), so we permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn_extractor(x)\n",
    "        # Permute back to (B, T, C_out) for Transformer\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 2. Add Positional Encoding\n",
    "        # Transformer expects (T, B, C), so permute again\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.pos_encoder(x)\n",
    "        # Permute back to (B, T, C) for batch_first=True\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        # The mask should indicate which key values are NOT to be attended to\n",
    "        encoded_seq = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # We use the representation of the last valid timestep for prediction\n",
    "        # (A common strategy, alternatively you could use mean pooling)\n",
    "        # For simplicity, we'll take the last hidden state of the sequence.\n",
    "        sequence_summary = encoded_seq[:, -1, :] # (B, d_model)\n",
    "        \n",
    "        # 4. Get parameters from all MDN heads\n",
    "        mdn_params_list = []\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](sequence_summary)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            mdn_params_list.append({\"pi\": pi, \"mu\": mu, \"sigma\": sigma})\n",
    "\n",
    "        return mdn_params_list\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        # Create the padding mask for the transformer\n",
    "        # True values indicate positions that should be ignored.\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "\n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        # Use a padding value of -1 for the loss function\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        max_len = X['main'].shape[1]\n",
    "        mask = torch.arange(max_len, device=self.device)[None, :] >= lengths[:, None]\n",
    "        \n",
    "        mdn_params = self(X, src_key_padding_mask=mask)\n",
    "        loss = weighted_mdn_nll_multihead(y, mdn_params, self.loss_weights, padding_value=-1)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefa26",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95badad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6d37502b-8844-4574-b3cd-d3f9d9cfeb6c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1515456000",
         "1514937600",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516492800",
         "1516147200",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1520121600",
         "1519862400",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "46",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "49",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "50",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 320
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1515456000</td>\n",
       "      <td>1514937600</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1651795200</td>\n",
       "      <td>1649116800</td>\n",
       "      <td>1555</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.873150</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.938913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1652054400</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1589</td>\n",
       "      <td>1591</td>\n",
       "      <td>1.063729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1652572800</td>\n",
       "      <td>1651881600</td>\n",
       "      <td>1587</td>\n",
       "      <td>1595</td>\n",
       "      <td>0.813907</td>\n",
       "      <td>0.870793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788406</td>\n",
       "      <td>0.904141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1653264000</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1591</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.042211</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.958532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1648598400</td>\n",
       "      <td>1640304000</td>\n",
       "      <td>1453</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.884394</td>\n",
       "      <td>0.71872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1515456000  1514937600           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "328  1651795200  1649116800        1555      1586     0.873150     0.825739   \n",
       "330  1652054400  1652227200        1589      1591     1.063729          NaN   \n",
       "331  1652572800  1651881600        1587      1595     0.813907     0.870793   \n",
       "332  1653264000  1652227200        1591      1603     1.042211     1.075683   \n",
       "333  1648598400  1640304000        1453      1549     0.781703     0.741996   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "328     0.905267     0.938913          NaN          NaN          NaN   \n",
       "330          NaN     1.023085          NaN          NaN          NaN   \n",
       "331          NaN          NaN          NaN          NaN          NaN   \n",
       "332     0.992004     0.958532          NaN          NaN          NaN   \n",
       "333     0.993930     0.847425     0.884394      0.71872          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "328     0.955736          NaN  \n",
       "330          NaN          NaN  \n",
       "331     0.788406     0.904141  \n",
       "332          NaN          NaN  \n",
       "333          NaN     0.647521  \n",
       "\n",
       "[320 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_labels = pd.read_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\")\n",
    "cols = [f'price_line{i}' for i in range(1, 10)]\n",
    "df_labels = df_labels.dropna(subset=cols, how='all')\n",
    "df_labels = df_labels.rename(columns={c: c.replace('price_line', 'linePrice_') \n",
    "                        for c in df_labels.columns if c.startswith('price_line')})\n",
    "df_labels.to_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\", index=False)      \n",
    "#     # overwrites the old file\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4dd53",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677dbff",
   "metadata": {},
   "source": [
    "## simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e281d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# ---------------- Evaluation ---------------- #\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, zero_idx=0, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (last-output version).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    zero_idx : which mixture component is considered \"no-line\" (usually 0)\n",
    "    threshold : if pi[:,zero_idx] > threshold → predict invalid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            if isinstance(X_batch, dict):\n",
    "                X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            else:\n",
    "                X_batch = X_batch.to(device)\n",
    "\n",
    "            y_batch = y_batch.to(device)\n",
    "            mdn = model(X_batch, lengths)\n",
    "            pi, mu, sigma = mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"]  # (B,K)\n",
    "\n",
    "            # regression expectation\n",
    "            y_pred = (pi * mu).sum(dim=-1)  # (B,)\n",
    "            B = y_batch.size(0)\n",
    "            y_len = (y_batch > 0).sum(dim=1)                # (B,)\n",
    "            idx = torch.clamp(y_len - 1, min=0)             # last valid index\n",
    "            y_true = y_batch[torch.arange(B, device=y_batch.device), idx]  # (B,)\n",
    "            # only last step\n",
    "            # print(\"lengths(features):\", lengths[:10])\n",
    "            # print(\"lengths(labels):\", y_len[:10])\n",
    "\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "            # validity classification\n",
    "            pi_zero = pi[:, zero_idx]  # (B,)\n",
    "            pred_valid = (pi_zero < (1 - threshold)).long()\n",
    "            true_valid = torch.ones_like(pred_valid)  # last step always valid\n",
    "\n",
    "            all_preds_len.extend(pred_valid.cpu().numpy().tolist())\n",
    "            all_labels_len.extend(true_valid.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "        # ----- Regression metrics -----\n",
    "    all_preds_reg = np.concatenate(all_preds_reg)  # (N,)\n",
    "    all_labels_reg = np.concatenate(all_labels_reg)\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "    # ----- Validity metrics -----\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (MDN, last-output):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Validity   → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=1000,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNLSTM_MDN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44de2e9",
   "metadata": {},
   "source": [
    "### hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression only\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per batch ---\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg)\n",
    "    all_labels_reg = np.array(all_labels_reg)\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=300,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return metrics\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a7940",
   "metadata": {},
   "source": [
    "## ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb16e4",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d529c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.235186 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.235186 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (3, 12)\n",
      "[main] First few rows:\n",
      " [[ 0.0334583  -0.0164952  -0.08295181 -0.05172484  0.0091133   0.06722008\n",
      "   0.05172484  0.3         1.3036697   1.3155504   1.1531377   1.2362376 ]\n",
      " [-0.05151443 -0.0062422   0.04603237  0.0048193   0.05244192  0.02449848\n",
      "   0.00457536  0.7         1.236512    1.3073386   1.2062193   1.2421954 ]\n",
      " [ 0.00163378 -0.04961828 -0.31281227 -0.19497368  0.00318     0.17110091\n",
      "   0.19259259  0.3         1.2385321   1.2424706   0.8288991   1.        ]]\n",
      "==========================\n",
      "\n",
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([2, 9])\n",
      "  First label in batch: tensor([1.2352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([2, 3, 12])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[ 0.0335, -0.0165, -0.0830, -0.0517,  0.0091,  0.0672,  0.0517,  0.3000,\n",
      "          1.3037,  1.3156,  1.1531,  1.2362],\n",
      "        [-0.0515, -0.0062,  0.0460,  0.0048,  0.0524,  0.0245,  0.0046,  0.7000,\n",
      "          1.2365,  1.3073,  1.2062,  1.2422],\n",
      "        [ 0.0016, -0.0496, -0.3128, -0.1950,  0.0032,  0.1711,  0.1926,  0.3000,\n",
      "          1.2385,  1.2425,  0.8289,  1.0000]])\n",
      "\n",
      "✅ Combined df_seq shape: (6, 12)\n",
      "✅ Column names in df_seq: ['open_dif', 'high_dif', 'low_dif', 'close_dif', 'upper_shadow', 'lower_shadow', 'body', 'color', 'open_prop', 'high_prop', 'low_prop', 'close_prop']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type      | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | fc1           | Linear    | 195    | train\n",
      "1 | ln1           | LayerNorm | 30     | train\n",
      "2 | k1            | Conv1d    | 240    | train\n",
      "3 | k3            | Conv1d    | 690    | train\n",
      "4 | fusion_conv2d | Conv2d    | 3      | train\n",
      "5 | lstm          | LSTM      | 6.3 K  | train\n",
      "6 | mdn_head      | Linear    | 891    | train\n",
      "----------------------------------------------------\n",
      "8.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.3 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4a0ac5bd0e4c7a834a906ea7f5a3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=False,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    feature_eng=15,\n",
    "    n_components=9,\n",
    "    dropout = 0.1,\n",
    "    batch_size=2,\n",
    "    max_epochs=600,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(add_candle_shape_features),\n",
    "            make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"standard\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         # \"open_dif\":\"standard\",\"close_dif\":\"standard\",\"high_dif\":\"standard\",\"low_dif\":\"standard\"\n",
    "        #         # \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         # \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "          True,\n",
    "          True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True,\n",
    "        )\n",
    "        val_ds = None\n",
    "    print(\"features\",feature_cols)\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_lstm(input_dim=input_dim, feature_eng= feature_eng, hidden_dim=hidden_dim, \n",
    "                     n_components=n_components,  lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    init_args = get_init_args(model, input_dim=input_dim,feature_eng= feature_eng\n",
    "                              ,hidden_dim=hidden_dim, n_components=n_components,\n",
    "                              lr=lr, dropout=dropout,num_lines=max_len_y)\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/debug_test_seq.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=False,\n",
    "        test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fd2dc",
   "metadata": {},
   "source": [
    "### cnn transforemer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948aa8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "Shape: (5, 4)\n",
      "First few rows of sequence:\n",
      " [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      " [ 0.00938704  0.12409948  0.04899828  0.12622231]\n",
      " [ 0.12622082 -0.00192766  0.09665822  0.00645032]\n",
      " [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnn_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 304\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 190\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_csv, model_out_dir, do_validation, hidden_dim, num_layers, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, early_stop)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# single tensor\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     input_dim \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 190\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_transformer\u001b[49m(input_dim, feature_eng\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, num_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m init_args \u001b[38;5;241m=\u001b[39m get_init_args(model, input_dim\u001b[38;5;241m=\u001b[39minput_dim,num_lines\u001b[38;5;241m=\u001b[39m max_len_y )\n\u001b[1;32m    194\u001b[0m model_class_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_args\n\u001b[1;32m    198\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNN–LSTM–MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=500,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = cnn_transformer(input_dim, feature_eng=15, hidden_dim=32, n_components=9, num_lines=9, lr=1e-3, dropout=0.1\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim,num_lines= max_len_y )\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # ✅ save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3023ae",
   "metadata": {},
   "source": [
    "### two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91951ca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm        | LSTM              | 68.6 K | train\n",
      "1 | fc_reg      | Linear            | 774    | train\n",
      "2 | fc_len      | Linear            | 774    | train\n",
      "3 | loss_fn_reg | MSELoss           | 0      | train\n",
      "4 | loss_fn_len | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "70.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 K    Total params\n",
      "0.281     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.086008 1.126277 1.165107 0.970955 0.       0.      ] Encoded (padded): [1.086008 1.126277 1.165107 0.970955 0.       0.      ]\n",
      "[main] Shape: (5, 4)\n",
      "[main] First few rows:\n",
      " [[ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]\n",
      " [-0.08115927 -0.05037893  0.09358804 -0.03372177]\n",
      " [-0.03365467 -0.03511871 -0.06278902  0.03521458]\n",
      " [ 0.03742796  0.00087057 -0.13184595 -0.11191386]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6b9bc314ea4e17b85c57d428d1d2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250913_143827.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250913_143827.pkl\n",
      "\n",
      "📊 Validation Metrics:\n",
      "  Regression → MSE: 0.454865, MAE: 0.510467\n",
      "  Length     → Acc: 0.0667, F1: 0.0096\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            # Send to same device as model\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression + length logits\n",
    "            y_pred, len_logits = model(X_batch, lengths)\n",
    "\n",
    "            # Regression targets\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_batch.cpu().numpy())\n",
    "\n",
    "            # Length targets\n",
    "            true_lengths = lengths.cpu().numpy()\n",
    "            pred_lengths = model.predict_length(len_logits).cpu().numpy()\n",
    "\n",
    "            all_labels_len.extend(true_lengths.tolist())\n",
    "            all_preds_len.extend(pred_lengths.tolist())\n",
    "\n",
    "    # ----- Regression metrics -----\n",
    "    all_preds_reg = np.vstack(all_preds_reg)\n",
    "    all_labels_reg = np.vstack(all_labels_reg)\n",
    "\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    # ----- Length metrics -----\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics:\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Length     → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=50,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838866e",
   "metadata": {},
   "source": [
    "### xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439210d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.make_step import make_step\n",
    "from preprocess.multi_regression_seq_dif2 import preprocess_sequences_csv_multilines\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.feature_pipeline4 import FeaturePipeline\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "# ---------------- Evaluation ---------------- #\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def evaluate_model(model, length_model, X_val, y_val, true_lengths, return_sequences=False):\n",
    "    \"\"\"\n",
    "    Evaluate multi-output regression with predicted sequence lengths.\n",
    "    Permutation-invariant: sorts both predictions and true values before computing metrics.\n",
    "    Can optionally return the predicted vs true sequences for inspection.\n",
    "    \"\"\"\n",
    "    y_pred_full = model.predict(X_val)\n",
    "    pred_lengths = np.round(length_model.predict(X_val)).astype(int)\n",
    "\n",
    "    print(\"\\n📊 Validation Report (Multi-Regression with variable-length sequences):\")\n",
    "    mse_list, mae_list, r2_list = [], [], []\n",
    "\n",
    "    pred_vs_true_list = []  # store predicted vs true sequences if needed\n",
    "\n",
    "    for i, (pred, pred_len, true_y, true_len) in enumerate(zip(y_pred_full, pred_lengths, y_val, true_lengths)):\n",
    "        L = min(pred_len, true_len)\n",
    "        pred_trunc = np.sort(pred[:L])       # sort predictions for permutation-invariant metrics\n",
    "        true_trunc = np.sort(true_y[:L])     # sort true values\n",
    "\n",
    "        mse = mean_squared_error(true_trunc, pred_trunc)\n",
    "        mae = mean_absolute_error(true_trunc, pred_trunc)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            try:\n",
    "                r2 = r2_score(true_trunc, pred_trunc)\n",
    "            except ValueError:\n",
    "                r2 = np.nan\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        print(f\"  Predicted length: {pred_len}, True length: {true_len}\")\n",
    "        print(f\"  MSE: {mse:.6f}, MAE: {mae:.6f}, R²: {r2:.6f}\")\n",
    "        print(f\"  Predicted lines: {pred_trunc}\")\n",
    "        print(f\"  True lines     : {true_trunc}\")\n",
    "\n",
    "        if return_sequences:\n",
    "            pred_vs_true_list.append((pred_trunc, true_trunc))\n",
    "\n",
    "    print(\"\\n--- Global Scores ---\")\n",
    "    print(f\"Mean MSE: {np.mean(mse_list):.6f}\")\n",
    "    print(f\"Mean MAE: {np.mean(mae_list):.6f}\")\n",
    "    print(f\"Mean R²: {np.nanmean(r2_list):.6f}\")\n",
    "\n",
    "    results = {\"mse\": np.mean(mse_list), \"mae\": np.mean(mae_list), \"r2\": np.nanmean(r2_list)}\n",
    "    \n",
    "    if return_sequences:\n",
    "        results[\"pred_vs_true\"] = pred_vs_true_list\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model_xgb_multireg(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    n_estimators=1000,\n",
    "    max_depth=16,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_metrics=True,\n",
    "    **model_params\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-output XGBoost regressor with a linked sequence-length predictor.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multireg_{timestamp}.pkl\"\n",
    "    length_model_out = f\"{model_out_dir}/xgb_model_seq_len_{timestamp}.pkl\"\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # --- Preprocess data ---\n",
    "    if do_validation:\n",
    "        X_train, y_train, X_val, y_val, df, feature_cols, max_len_y, seq_lengths_true = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, df, feature_cols, max_len_y, seq_lengths_true = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "\n",
    "    # --- Sequence length targets ---\n",
    "    if do_validation:\n",
    "        idx_train, idx_val = train_test_split(\n",
    "            np.arange(len(seq_lengths_true)),\n",
    "            test_size=0.2,  # match your preprocess split\n",
    "            random_state=42\n",
    "        )\n",
    "        train_lengths = np.array(seq_lengths_true)[idx_train]\n",
    "        val_lengths   = np.array(seq_lengths_true)[idx_val]\n",
    "    else:\n",
    "        train_lengths = np.array(seq_lengths_true)\n",
    "\n",
    "    # --- Train max-line regression ---\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "    model = MultiOutputRegressor(xgb_model, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Train length predictor ---\n",
    "    xgb_len_model = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective=\"reg:squarederror\",\n",
    "        **model_params\n",
    "    )\n",
    "    xgb_len_model.fit(X_train, train_lengths)\n",
    "\n",
    "\n",
    "    # --- Save models ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Save trained models\n",
    "        joblib.dump(model, model_out)\n",
    "        joblib.dump(xgb_len_model, length_model_out)\n",
    "        \n",
    "        # Save full metadata\n",
    "        meta_dict = {\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"target_dim\": max_len_y,\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"model_params\": model_params,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"multioutput_wrapper\": {\n",
    "                \"class\": model.__class__.__name__,\n",
    "                \"module\": model.__class__.__module__,\n",
    "            }\n",
    "        }\n",
    "        joblib.dump(meta_dict, meta_out)\n",
    "        \n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Length predictor saved to {length_model_out}\")\n",
    "        print(f\"✅ Metadata saved to {meta_out}\")\n",
    "    # --- Evaluate ---\n",
    "    val_metrics = None\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, xgb_len_model, X_val, y_val, val_lengths, return_sequences=True)\n",
    "\n",
    "\n",
    "    if return_val_metrics:\n",
    "        return val_metrics\n",
    "\n",
    "# ---------------- Main ---------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multireg(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        save_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e330df",
   "metadata": {},
   "source": [
    "### Hungarian lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression only\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per batch ---\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "            #y_batch.shape[0] is batch actually\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg)\n",
    "    all_labels_reg = np.array(all_labels_reg)\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=30,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=100,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return metrics\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8d4ec",
   "metadata": {},
   "source": [
    "### Hungarian CNN-attention lstm weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1000a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.      ]\n",
      "[main] Shape: (5, 4)\n",
      "[main] First few rows:\n",
      " [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      " [ 0.00938704  0.12409948  0.04899828  0.12622231]\n",
      " [ 0.12622082 -0.00192766  0.09665822  0.00645032]\n",
      " [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      " [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type       | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | branches      | ModuleList | 3.7 K  | train\n",
      "1 | fusion_conv2d | Sequential | 15     | train\n",
      "2 | lstm          | LSTM       | 7.7 K  | train\n",
      "3 | attention     | Attention  | 31     | train\n",
      "4 | regressor     | Sequential | 609    | train\n",
      "5 | loss_fn_reg   | MSELoss    | 0      | train\n",
      "-----------------------------------------------------\n",
      "12.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.0 K    Total params\n",
      "0.048     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3212b4d0e6742d7a1ef0472fb71f334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([50, 9])\n",
      "  First label in batch: tensor([0.9730, 0.0000, 0.0000, 0.9495, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([50, 39, 4])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[ 3.0652e-02, -1.6475e-02, -4.0506e-02, -5.4798e-02],\n",
      "        [-5.4728e-02, -4.7273e-02, -1.3351e-02,  6.1068e-03],\n",
      "        [ 5.9055e-03,  3.6256e-03,  2.9371e-02, -5.5269e-04],\n",
      "        [ 8.9162e-05,  1.0588e-02, -7.9936e-04,  1.7062e-02],\n",
      "        [ 1.6608e-02,  2.7926e-03, -1.0000e-02, -2.0726e-02],\n",
      "        [-2.0722e-02,  5.8714e-03,  1.0897e-02,  2.9606e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "\n",
      "✅ Combined df_seq shape: (1950, 4)\n",
      "✅ Column names in df_seq: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "\n",
      "📊 Validation Metrics (Hungarian matched):\n",
      "  Regression → MSE: 0.560149, MAE: 0.740157\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Current notebook location\n",
    "# notebook_path = Path().resolve()\n",
    "\n",
    "# # Add parent folder (meta/) to sys.path\n",
    "# sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif3 import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "from models.LSTM.cnn_attention_lstm_multireg import CNNAttentionLSTMMultiRegressor\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression only\n",
    "            y_pred = model(X_batch, lengths)\n",
    "\n",
    "            mask = (y_batch != 0).float()\n",
    "\n",
    "            # --- Hungarian assignment per batch ---\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "            #y_batch.shape[0] is batch actually\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                gt_vals = y_batch[i][mask[i] > 0]  # true targets\n",
    "                preds = y_pred[i]\n",
    "\n",
    "                if len(gt_vals) == 0:\n",
    "                    continue\n",
    "\n",
    "                cost = torch.cdist(gt_vals.unsqueeze(1), preds.unsqueeze(1), p=2).pow(2)\n",
    "                row_ind, col_ind = linear_sum_assignment(cost.cpu().numpy())\n",
    "\n",
    "                matched_preds = preds[col_ind].cpu().numpy()\n",
    "                matched_labels = gt_vals[row_ind].cpu().numpy()\n",
    "\n",
    "                batch_preds.extend(matched_preds.tolist())\n",
    "                batch_labels.extend(matched_labels.tolist())\n",
    "\n",
    "            all_preds_reg.extend(batch_preds)\n",
    "            all_labels_reg.extend(batch_labels)\n",
    "\n",
    "    # Convert to arrays\n",
    "    all_preds_reg = np.array(all_preds_reg)\n",
    "    all_labels_reg = np.array(all_labels_reg)\n",
    "\n",
    "    # Regression metrics\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    print(\"\\n📊 Validation Metrics (Hungarian matched):\")\n",
    "    print(f\"  Regression → MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=30,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=50,\n",
    "    max_epochs=100,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_multihead_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_multihead_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            preserve_order= True,\n",
    "            feature_pipeline=pipeline,\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNAttentionLSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"🔍 Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\n✅ Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"✅ Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"✅ Model saved to {model_out}\")\n",
    "        print(f\"✅ Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399de860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "high_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "low_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "close_dif",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "15454e37-3886-4259-8b24-c81142a08884",
       "rows": [
        [
         "0",
         "0.030652428",
         "-0.01647547",
         "-0.04050633",
         "-0.05479772"
        ],
        [
         "1",
         "-0.05472827",
         "-0.047272753",
         "-0.013350924",
         "0.006106785"
        ],
        [
         "2",
         "0.0059054843",
         "0.0036255703",
         "0.029371228",
         "-0.00055269303"
        ],
        [
         "3",
         "8.916188e-05",
         "0.010588351",
         "-0.0007993605",
         "0.017061694"
        ],
        [
         "4",
         "0.016608387",
         "0.0027925535",
         "-0.01",
         "-0.020725742"
        ],
        [
         "5",
         "-0.020721925",
         "0.0058714473",
         "0.01089697",
         "0.029606264"
        ],
        [
         "39",
         "-0.015807793",
         "-0.048349876",
         "-0.28994116",
         "-0.1437508"
        ],
        [
         "40",
         "-0.14419094",
         "-0.026000518",
         "0.16166666",
         "0.10456638"
        ],
        [
         "41",
         "0.10510037",
         "-0.005928389",
         "-0.03908178",
         "-0.08080191"
        ],
        [
         "42",
         "-0.08049373",
         "-0.07988152",
         "0.051141303",
         "0.005307633"
        ],
        [
         "43",
         "0.0052373176",
         "-0.0143799735",
         "-0.116180055",
         "-0.074619494"
        ],
        [
         "44",
         "-0.074137226",
         "0.04309727",
         "0.093857124",
         "0.11949243"
        ],
        [
         "45",
         "0.119070895",
         "-0.0032121744",
         "0.070189536",
         "-0.012155028"
        ],
        [
         "46",
         "-0.012529183",
         "0.026368015",
         "0.03791418",
         "0.023932073"
        ],
        [
         "47",
         "0.023932334",
         "-0.010525208",
         "-0.01762334",
         "-0.018142084"
        ],
        [
         "48",
         "-0.018142078",
         "-0.037942756",
         "-0.06598406",
         "-0.07439635"
        ],
        [
         "49",
         "-0.07444072",
         "-0.03959197",
         "-0.030309075",
         "-0.029675728"
        ],
        [
         "50",
         "-0.029629473",
         "-0.022780191",
         "-0.0075450246",
         "0.029941209"
        ],
        [
         "51",
         "0.02994092",
         "0.027707739",
         "0.023213398",
         "0.045243617"
        ],
        [
         "52",
         "0.04524419",
         "0.010555215",
         "0.044274963",
         "-0.015051346"
        ],
        [
         "53",
         "-0.015004368",
         "0.00871333",
         "0.0071216286",
         "0.023862531"
        ],
        [
         "54",
         "0.023813423",
         "0.03272727",
         "0.034799553",
         "0.04466779"
        ],
        [
         "55",
         "0.044667527",
         "-0.004735282",
         "-0.043444984",
         "-0.061604783"
        ],
        [
         "56",
         "-0.061600722",
         "-0.034718815",
         "-0.021238836",
         "-0.03572728"
        ],
        [
         "57",
         "-0.03565328",
         "-0.038101517",
         "0.012126436",
         "0.007971966"
        ],
        [
         "58",
         "0.007890512",
         "0.011513158",
         "-0.054568168",
         "-0.06267462"
        ],
        [
         "59",
         "-0.06255812",
         "-0.07674769",
         "-0.06906907",
         "-0.0051256544"
        ],
        [
         "60",
         "-0.0052495818",
         "0.101760566",
         "0.04505871",
         "0.12004622"
        ],
        [
         "61",
         "0.120046556",
         "0.025475299",
         "0.10449112",
         "-0.019052343"
        ],
        [
         "62",
         "-0.018995909",
         "-0.021059468",
         "0.004325359",
         "0.017893583"
        ],
        [
         "63",
         "0.017835025",
         "-0.0057528582",
         "-0.037187815",
         "-0.047837537"
        ],
        [
         "64",
         "-0.04783727",
         "0.05115281",
         "0.0045271204",
         "0.09774516"
        ],
        [
         "65",
         "0.09774456",
         "0.042764094",
         "0.11430791",
         "0.038331576"
        ],
        [
         "66",
         "0.038331587",
         "0.006476468",
         "0.020046476",
         "-0.009187663"
        ],
        [
         "78",
         "0.023825772",
         "0.12697656",
         "0.027690155",
         "0.11059916"
        ],
        [
         "79",
         "0.11059916",
         "-0.013394636",
         "0.065319784",
         "-0.011214003"
        ],
        [
         "80",
         "-0.011214003",
         "0.008947513",
         "0.023379082",
         "0.017811773"
        ],
        [
         "81",
         "0.017810855",
         "-0.01523607",
         "0.0017573067",
         "-8.287893e-05"
        ],
        [
         "82",
         "-6.576269e-05",
         "0.024529992",
         "0.011910258",
         "0.021248495"
        ],
        [
         "83",
         "0.021231933",
         "0.03643831",
         "0.023722628",
         "0.04108435"
        ],
        [
         "84",
         "0.04108435",
         "0.022127982",
         "-0.062522285",
         "-0.06184302"
        ],
        [
         "117",
         "-0.09092764",
         "-0.07749881",
         "0.0073639923",
         "0.0225347"
        ],
        [
         "118",
         "0.022673605",
         "-0.008043567",
         "0.009893049",
         "-0.004882547"
        ],
        [
         "119",
         "-0.0049968134",
         "-0.00069243606",
         "-0.02643103",
         "0.002320679"
        ],
        [
         "120",
         "0.0022917537",
         "0.012803313",
         "0.023577914",
         "-0.0011471765"
        ],
        [
         "121",
         "-0.0009900368",
         "-0.007973251",
         "0.013055711",
         "0.0024412053"
        ],
        [
         "122",
         "0.0020737967",
         "-0.0040679285",
         "-0.010689718",
         "-0.0008030343"
        ],
        [
         "123",
         "-0.00057558925",
         "-0.0016426687",
         "0.0024044006",
         "-0.00318854"
        ],
        [
         "124",
         "-0.0033115444",
         "-0.0013037809",
         "-0.029256979",
         "-0.02427943"
        ],
        [
         "125",
         "-0.02395911",
         "0.01229765",
         "0.0089519955",
         "0.03833607"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 548
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_dif</th>\n",
       "      <th>high_dif</th>\n",
       "      <th>low_dif</th>\n",
       "      <th>close_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030652</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>-0.040506</td>\n",
       "      <td>-0.054798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054728</td>\n",
       "      <td>-0.047273</td>\n",
       "      <td>-0.013351</td>\n",
       "      <td>0.006107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>-0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>-0.000799</td>\n",
       "      <td>0.017062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016608</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.020726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.012030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.012856</td>\n",
       "      <td>0.020954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>0.020772</td>\n",
       "      <td>-0.011087</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>-0.006201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>-0.006023</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.001502</td>\n",
       "      <td>-0.001486</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.006951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      open_dif  high_dif   low_dif  close_dif\n",
       "0     0.030652 -0.016475 -0.040506  -0.054798\n",
       "1    -0.054728 -0.047273 -0.013351   0.006107\n",
       "2     0.005905  0.003626  0.029371  -0.000553\n",
       "3     0.000089  0.010588 -0.000799   0.017062\n",
       "4     0.016608  0.002793 -0.010000  -0.020726\n",
       "...        ...       ...       ...        ...\n",
       "1912  0.002876  0.004903  0.016211   0.012030\n",
       "1913  0.012210  0.029894  0.012856   0.020954\n",
       "1914  0.020772 -0.011087  0.007147  -0.006201\n",
       "1915 -0.006023  0.006231  0.000841   0.001675\n",
       "1916  0.001502 -0.001486  0.004217   0.006951\n",
       "\n",
       "[548 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = df_seq.loc[~(df_seq==0).all(axis=1)]\n",
    "df_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc099c49",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754255c5",
   "metadata": {},
   "source": [
    "## MDN server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67861978",
   "metadata": {},
   "source": [
    "### cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.cnn_lstm_mdn import CNNLSTM_MDN  # <-- your updated \"last-output\" model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg*.pt\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\",FEATURES)\n",
    "# ---------------- Model ----------------\n",
    "# Reconstruct model class\n",
    "#for python file:\n",
    "# model_cls_info = meta[\"model_class_info\"]\n",
    "# ModelClass = import_class(model_cls_info[\"module\"], model_cls_info[\"class\"])\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "ModelClass = cnn_lstm\n",
    "# Initialize model with original args\n",
    "model = ModelClass(**model_cls_info[\"init_args\"])\n",
    "model = cnn_lstm.load_from_checkpoint(state_path)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv( \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"sequential.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        print(\"Returning initial candles:\", candles)\n",
    "\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            print(\"Reached end of data at index:\", next_idx)\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        # ✅ Add to preproc automatically\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # prepare subsequence from current state\n",
    "        seq_dict = preproc.prepare_seq(seq_len)  # returns dict of DataFrames\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mdn_out = model(dict_x)\n",
    "\n",
    "    pi    = mdn_out['pi'][0].cpu().numpy()\n",
    "    mu    = mdn_out['mu'][0].cpu().numpy()\n",
    "    sigma = mdn_out['sigma'][0].cpu().numpy()\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "\n",
    "    return jsonify({\n",
    "        'pred_prices': (last_close * mu).tolist(),\n",
    "        'pred_sigmas': (last_close * sigma).tolist(),\n",
    "        'pi': pi.tolist()\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65996c",
   "metadata": {},
   "source": [
    "## lstm two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = LSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"two_head.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "            for k, v in seq_dict.items()}\n",
    "    print(\"dict\",dict_x)\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred, len_logits = model( dict_x, lengths)\n",
    "\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "    pred_len = model.predict_length(len_logits).item()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices,\n",
    "        \"pred_len\": pred_len\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f38c1",
   "metadata": {},
   "source": [
    "## Hungarian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f3016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:08] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:08] \"GET /get_and_add_data HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:08] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:09] \"GET /get_and_add_data?idx=21 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:09] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0425, 1.2005, 0.8164, 1.0097, 0.9321, 1.1899, 0.8403, 1.3358, 0.9156]])\n",
      "tensor([[1.0277, 1.1864, 0.8158, 1.0041, 0.9325, 1.1776, 0.8238, 1.3283, 0.9120]])\n",
      "tensor([[1.0651, 1.2377, 0.8508, 1.0316, 0.9703, 1.2312, 0.8612, 1.4033, 0.9415]])\n",
      "tensor([[1.0704, 1.2450, 0.8595, 1.0376, 0.9730, 1.2304, 0.8555, 1.4157, 0.9422]])\n",
      "tensor([[1.0783, 1.2486, 0.8725, 1.0540, 0.9852, 1.2432, 0.8601, 1.4212, 0.9535]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:22] \"GET /get_and_add_data?idx=22 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0204, 1.1738, 0.8026, 0.9993, 0.9208, 1.1722, 0.8387, 1.3179, 0.8971]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:18] \"GET /get_and_add_data?idx=23 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:18] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9905, 1.1329, 0.7682, 0.9545, 0.8824, 1.1177, 0.8056, 1.2665, 0.8563]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:19] \"GET /get_and_add_data?idx=24 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:19] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9028, 1.0197, 0.6897, 0.8700, 0.8090, 1.0037, 0.7164, 1.1122, 0.7760]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"GET /get_and_add_data?idx=25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9445, 1.0676, 0.7308, 0.9197, 0.8604, 1.0712, 0.7560, 1.1812, 0.8306]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:19] \"GET /get_and_add_data?idx=26 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:19] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9219, 1.0413, 0.7158, 0.9027, 0.8434, 1.0479, 0.7416, 1.1539, 0.8111]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:20] \"GET /get_and_add_data?idx=27 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:20] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9252, 1.0437, 0.7149, 0.8989, 0.8386, 1.0416, 0.7393, 1.1514, 0.8046]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:20] \"GET /get_and_add_data?idx=28 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:20] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9527, 1.0808, 0.7398, 0.9287, 0.8663, 1.0856, 0.7684, 1.1937, 0.8374]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:21] \"GET /get_and_add_data?idx=29 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:21] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0705, 1.2262, 0.8481, 1.0483, 0.9687, 1.2435, 0.8781, 1.3686, 0.9385]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:21] \"GET /get_and_add_data?idx=30 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:21] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0596, 1.2218, 0.8346, 1.0374, 0.9556, 1.2338, 0.8807, 1.3747, 0.9266]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:21] \"GET /get_and_add_data?idx=31 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:21] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0893, 1.2589, 0.8723, 1.0680, 0.9878, 1.2813, 0.9098, 1.4268, 0.9530]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:22] \"GET /get_and_add_data?idx=32 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1075, 1.2832, 0.8782, 1.0677, 0.9953, 1.2888, 0.9153, 1.4480, 0.9567]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:22] \"GET /get_and_add_data?idx=33 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0567, 1.2157, 0.8333, 1.0195, 0.9513, 1.2222, 0.8780, 1.3694, 0.9174]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:23] \"GET /get_and_add_data?idx=34 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:23] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0132, 1.1652, 0.7990, 0.9809, 0.9141, 1.1645, 0.8273, 1.3052, 0.8852]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:23] \"GET /get_and_add_data?idx=35 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:23] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1381, 1.3184, 0.9038, 1.0952, 1.0258, 1.3354, 0.9409, 1.4881, 0.9916]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:23] \"GET /get_and_add_data?idx=36 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:23] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1560, 1.3570, 0.9112, 1.1123, 1.0257, 1.3592, 0.9787, 1.5322, 0.9973]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"GET /get_and_add_data?idx=37 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0410, 1.2073, 0.8005, 0.9614, 0.9050, 1.1652, 0.8480, 1.3425, 0.8721]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"GET /get_and_add_data?idx=38 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9651, 1.0950, 0.7298, 0.8950, 0.8387, 1.0404, 0.7450, 1.2026, 0.8024]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:32] \"GET /get_and_add_data?idx=39 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9333, 1.0660, 0.7165, 0.8894, 0.8367, 1.0392, 0.7377, 1.1686, 0.8038]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"GET /get_and_add_data?idx=40 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9648, 1.0962, 0.7483, 0.9319, 0.8697, 1.0885, 0.7729, 1.2128, 0.8435]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:24] \"GET /get_and_add_data?idx=41 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9893, 1.1275, 0.7761, 0.9688, 0.8960, 1.1264, 0.7969, 1.2463, 0.8678]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"GET /get_and_add_data?idx=42 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9709, 1.0997, 0.7563, 0.9446, 0.8797, 1.1055, 0.7863, 1.2244, 0.8457]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"GET /get_and_add_data?idx=43 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9464, 1.0748, 0.7262, 0.9062, 0.8420, 1.0544, 0.7516, 1.1772, 0.8187]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"GET /get_and_add_data?idx=44 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9666, 1.1007, 0.7526, 0.9402, 0.8651, 1.0862, 0.7685, 1.2237, 0.8403]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:26] \"GET /get_and_add_data?idx=45 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:26] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9346, 1.0602, 0.7148, 0.8984, 0.8330, 1.0433, 0.7453, 1.1582, 0.8073]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:26] \"GET /get_and_add_data?idx=46 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:26] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9546, 1.0787, 0.7379, 0.9238, 0.8552, 1.0674, 0.7581, 1.1885, 0.8260]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:26] \"GET /get_and_add_data?idx=47 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:26] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9292, 1.0536, 0.7230, 0.9081, 0.8431, 1.0508, 0.7412, 1.1578, 0.8138]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"GET /get_and_add_data?idx=48 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9611, 1.0926, 0.7470, 0.9341, 0.8661, 1.0903, 0.7750, 1.1978, 0.8407]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"GET /get_and_add_data?idx=49 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9641, 1.0978, 0.7540, 0.9459, 0.8693, 1.0925, 0.7732, 1.2159, 0.8456]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"GET /get_and_add_data?idx=50 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9342, 1.0590, 0.7194, 0.8998, 0.8407, 1.0482, 0.7459, 1.1608, 0.8133]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"GET /get_and_add_data?idx=51 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0105, 1.1482, 0.7880, 0.9740, 0.9117, 1.1498, 0.8107, 1.2829, 0.8792]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:28] \"GET /get_and_add_data?idx=52 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:28] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0356, 1.1836, 0.8191, 1.0120, 0.9415, 1.1960, 0.8433, 1.3166, 0.9099]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:28] \"GET /get_and_add_data?idx=53 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:28] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0192, 1.1657, 0.8042, 1.0029, 0.9261, 1.1841, 0.8456, 1.3100, 0.8956]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:29] \"GET /get_and_add_data?idx=54 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0127, 1.1567, 0.7987, 0.9940, 0.9194, 1.1699, 0.8318, 1.2979, 0.8872]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:29] \"GET /get_and_add_data?idx=55 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9845, 1.1198, 0.7655, 0.9588, 0.8901, 1.1228, 0.7973, 1.2437, 0.8572]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:29] \"GET /get_and_add_data?idx=56 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:29] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9482, 1.0721, 0.7351, 0.9245, 0.8595, 1.0753, 0.7668, 1.1891, 0.8277]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:30] \"GET /get_and_add_data?idx=57 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9277, 1.0513, 0.7084, 0.8903, 0.8258, 1.0282, 0.7353, 1.1510, 0.8006]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:37] \"GET /get_and_add_data?idx=58 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:37] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9451, 1.0662, 0.7347, 0.9225, 0.8542, 1.0646, 0.7521, 1.1761, 0.8234]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:39] \"GET /get_and_add_data?idx=59 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9249, 1.0488, 0.7195, 0.9080, 0.8398, 1.0473, 0.7405, 1.1515, 0.8113]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:39] \"GET /get_and_add_data?idx=60 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9075, 1.0234, 0.6963, 0.8801, 0.8199, 1.0189, 0.7247, 1.1210, 0.7874]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:48] \"GET /get_and_add_data?idx=61 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9314, 1.0511, 0.7267, 0.9152, 0.8444, 1.0517, 0.7463, 1.1610, 0.8104]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:39] \"GET /get_and_add_data?idx=62 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:40] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8918, 1.0084, 0.6837, 0.8703, 0.8064, 1.0039, 0.7137, 1.0983, 0.7777]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:40] \"GET /get_and_add_data?idx=63 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:40] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8690, 0.9752, 0.6651, 0.8473, 0.7885, 0.9729, 0.6892, 1.0632, 0.7502]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:40] \"GET /get_and_add_data?idx=64 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0003, 1.1340, 0.7864, 0.9856, 0.9123, 1.1551, 0.8170, 1.2656, 0.8802]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"GET /get_and_add_data?idx=65 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1051, 1.2731, 0.8799, 1.0821, 0.9985, 1.2982, 0.9210, 1.4300, 0.9711]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"GET /get_and_add_data?idx=66 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0874, 1.2565, 0.8664, 1.0695, 0.9903, 1.2819, 0.9105, 1.4209, 0.9583]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"GET /get_and_add_data?idx=67 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2025 01:28:41] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0921, 1.2655, 0.8714, 1.0680, 0.9913, 1.2856, 0.9180, 1.4304, 0.9563]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq2 import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.two_head_lstm import LSTMMultiRegressor  # your new model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_multihead_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg_multihead_*.pt\")[0]\n",
    "\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Initialize model class\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = CNNAttentionLSTMMultiRegressor.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"hungarian.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [{'time': int(ts.timestamp()),\n",
    "                    'open': float(row.open),\n",
    "                    'high': float(row.high),\n",
    "                    'low': float(row.low),\n",
    "                    'close': float(row.close)}\n",
    "                   for ts, row in dense.iloc[:initial_seq_len].iterrows()]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {'time': int(row.name.timestamp()),\n",
    "                  'open': float(row.open),\n",
    "                  'high': float(row.high),\n",
    "                  'low': float(row.low),\n",
    "                  'close': float(row.close)}\n",
    "        preproc.add_candle(row)\n",
    "        return jsonify({\"next_idx\": next_idx + 1, \"candle\": candle})\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames to dict of tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "              for k, v in seq_dict.items()}\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(dict_x, lengths)  # only regression head now\n",
    "    print(y_pred)\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    pred_prices = (last_close * y_pred[0]).tolist()\n",
    "\n",
    "    return jsonify({\n",
    "        \"pred_prices\": pred_prices\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edae95b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "caf18009-c014-40df-bd99-518fd835a07c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1514937600",
         "1515456000",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516147200",
         "1516492800",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1519862400",
         "1520121600",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "45",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "48",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "49",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 364
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1514937600</td>\n",
       "      <td>1515456000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1647216000</td>\n",
       "      <td>1648339200</td>\n",
       "      <td>1533</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.873783</td>\n",
       "      <td>0.889793</td>\n",
       "      <td>0.902754</td>\n",
       "      <td>0.847861</td>\n",
       "      <td>0.840999</td>\n",
       "      <td>0.814315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1629417600</td>\n",
       "      <td>1630108800</td>\n",
       "      <td>1327</td>\n",
       "      <td>1335</td>\n",
       "      <td>1.001120</td>\n",
       "      <td>1.013533</td>\n",
       "      <td>0.976295</td>\n",
       "      <td>1.031057</td>\n",
       "      <td>0.963152</td>\n",
       "      <td>0.958041</td>\n",
       "      <td>0.944168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1612742400</td>\n",
       "      <td>1613174400</td>\n",
       "      <td>1134</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.984341</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>1.021441</td>\n",
       "      <td>0.949513</td>\n",
       "      <td>0.930585</td>\n",
       "      <td>1.035826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1608940800</td>\n",
       "      <td>1609632000</td>\n",
       "      <td>1090</td>\n",
       "      <td>1098</td>\n",
       "      <td>0.795270</td>\n",
       "      <td>0.875328</td>\n",
       "      <td>0.805007</td>\n",
       "      <td>0.861264</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1588636800</td>\n",
       "      <td>1594166400</td>\n",
       "      <td>855</td>\n",
       "      <td>919</td>\n",
       "      <td>1.048390</td>\n",
       "      <td>1.078658</td>\n",
       "      <td>0.957585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919750</td>\n",
       "      <td>0.870564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.108926</td>\n",
       "      <td>0.99542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1514937600  1515456000           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "359  1647216000  1648339200        1533      1546     0.873783     0.889793   \n",
       "360  1629417600  1630108800        1327      1335     1.001120     1.013533   \n",
       "361  1612742400  1613174400        1134      1139     0.984341     1.000241   \n",
       "362  1608940800  1609632000        1090      1098     0.795270     0.875328   \n",
       "363  1588636800  1594166400         855       919     1.048390     1.078658   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "359     0.902754     0.847861     0.840999     0.814315          NaN   \n",
       "360     0.976295     1.031057     0.963152     0.958041     0.944168   \n",
       "361     1.021441     0.949513     0.930585     1.035826          NaN   \n",
       "362     0.805007     0.861264     0.783370          NaN          NaN   \n",
       "363     0.957585          NaN     0.919750     0.870564          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "359          NaN          NaN  \n",
       "360          NaN          NaN  \n",
       "361          NaN          NaN  \n",
       "362          NaN          NaN  \n",
       "363     1.108926      0.99542  \n",
       "\n",
       "[364 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv( \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4c8b3",
   "metadata": {},
   "source": [
    "## xgboost two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "from servers.pre_process.multi_reg_dif_seq import ServerPreprocess, build_pipeline_from_config\n",
    "\n",
    "# ---------------- Flask ----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load models + meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_meta_multireg_*.pkl\")[0]\n",
    "model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_multireg_*.pkl\")[0]\n",
    "len_model_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/xgb_model_seq_len_*.pkl\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\", FEATURES)\n",
    "\n",
    "# Models\n",
    "model = joblib.load(model_path)       # MultiOutputRegressor with XGBRegressor inside\n",
    "len_model = joblib.load(len_model_path)\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"xgboost_seq.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "\n",
    "    if next_idx is None:\n",
    "        # First call → load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls → 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Use your XGBoost + preproc logic\n",
    "        X_np = preproc.prepare_xgboost_seq(seq_len, model=len_model)\n",
    "        pred_len = int(np.round(len_model.predict(X_np))[0])\n",
    "        y_pred_full = model.predict(X_np)[0]\n",
    "        pred_trunc = np.sort(y_pred_full[:pred_len])\n",
    "        last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "        pred_scaled = (last_close * pred_trunc).tolist()\n",
    "\n",
    "        return jsonify({\n",
    "            'pred_length': pred_len,\n",
    "            'pred_lines': pred_scaled\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # <-- This will print the actual exception in the console\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc07d3a",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09e37c",
   "metadata": {},
   "source": [
    "## tensorboard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06403bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "logdir = \"lightning_logs\"\n",
    "\n",
    "# 1. Find all version folders\n",
    "versions = [d for d in os.listdir(logdir) if d.startswith(\"version_\")]\n",
    "if not versions:\n",
    "    raise ValueError(\"No version folders found in lightning_logs\")\n",
    "\n",
    "# 2. Sort numerically and get the latest\n",
    "versions.sort(key=lambda x: int(x.split(\"_\")[1]))\n",
    "latest_version = versions[-1]\n",
    "latest_logdir = os.path.join(logdir, latest_version)\n",
    "print(f\"Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\"tensorboard\", f\"--logdir={latest_logdir}\", f\"--port={port}\"])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264cbc4",
   "metadata": {},
   "source": [
    "## tensoarboard tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec717ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Launching TensorBoard for: /home/iatell/projects/meta-learning/tune_logs/cnn_lstm_tuning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "2025-09-15 01:13:45.519749: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-15 01:13:45.530317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757886225.541026   12159 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757886225.544137   12159 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757886225.554409   12159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757886225.554443   12159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757886225.554446   12159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757886225.554446   12159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-15 01:13:45.557064: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "# Base Ray Tune log directory\n",
    "base_logdir = \"/home/iatell/projects/meta-learning/tune_logs\"\n",
    "\n",
    "# 1. Find all experiment folders\n",
    "experiments = [d for d in os.listdir(base_logdir) if os.path.isdir(os.path.join(base_logdir, d))]\n",
    "if not experiments:\n",
    "    raise ValueError(\"No experiment folders found in tune_logs\")\n",
    "\n",
    "# 2. Sort by modification time and get the latest experiment\n",
    "experiments.sort(key=lambda x: os.path.getmtime(os.path.join(base_logdir, x)))\n",
    "latest_experiment = experiments[-1]\n",
    "latest_logdir = os.path.join(base_logdir, latest_experiment)\n",
    "print(f\"🚀 Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\n",
    "    \"tensorboard\",\n",
    "    f\"--logdir={latest_logdir}\",\n",
    "    f\"--port={port}\"\n",
    "])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609a59a",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd2907",
   "metadata": {},
   "source": [
    "## tuning cnn- attention lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c39a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-09-15 01:27:06</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:08.87        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.9/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=3<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.04365764796379508<br>Logical resource usage: 1.0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00000</td><td>TERMINATED</td><td>172.18.55.78:20512</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00388322 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       -0.207422</td><td style=\"text-align: right;\">-0.0368096 </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00001</td><td>TERMINATED</td><td>172.18.55.78:20511</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00459889 </td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       12.2883  </td><td style=\"text-align: right;\">-0.00670036</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00002</td><td>TERMINATED</td><td>172.18.55.78:20509</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000106559</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       -2.24151 </td><td style=\"text-align: right;\">-0.849925  </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00003</td><td>TERMINATED</td><td>172.18.55.78:20513</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000804682</td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       18.5113  </td><td style=\"text-align: right;\">-0.0437639 </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00004</td><td>TERMINATED</td><td>172.18.55.78:20510</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00227051 </td><td style=\"text-align: right;\">          15</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        3.26849 </td><td style=\"text-align: right;\">-0.00299631</td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00005</td><td>TERMINATED</td><td>172.18.55.78:20514</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00869223 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        2.39504 </td><td style=\"text-align: right;\">-0.105061  </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00006</td><td>TERMINATED</td><td>172.18.55.78:20517</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.00246138 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.960184</td><td style=\"text-align: right;\">-0.0435514 </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00007</td><td>TERMINATED</td><td>172.18.55.78:20515</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.00010214 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        8.81177 </td><td style=\"text-align: right;\">-0.796464  </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00008</td><td>TERMINATED</td><td>172.18.55.78:20518</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000805512</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.260553</td><td style=\"text-align: right;\">-0.0211637 </td></tr>\n",
       "<tr><td>train_cnn_lstm_tune_bbfde_00009</td><td>TERMINATED</td><td>172.18.55.78:20516</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000662411</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        5.90644 </td><td style=\"text-align: right;\">-0.723547  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m 💻 CPU: 32.1% | 🧠 RAM: 64.5% | 🎮 GPU: 0.0% VRAM: 2.4%\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m === DEBUG SAMPLE CHECK (Torch mode) ===\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m --- Sequence 0 ---\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  0.      ]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m [main] Shape: (5, 4)\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m [main] First few rows:\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  [ 0.00938704  0.12409948  0.04899828  0.12622231]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  [ 0.12622082 -0.00192766  0.09665822  0.00645032]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m ==========================\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m GPU available: False, used: False\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m /home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20512)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20512)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20512)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20512)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20510)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20510)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20510)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20510)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20515)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20515)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20515)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20515)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20517)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20517)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20517)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20517)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m  [-0.04985064 -0.0454773  -0.17924407 -0.07724382]]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 2025-09-15 01:26:55.127064: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 2025-09-15 01:26:55.145753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m E0000 00:00:1757887015.170510   21116 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m E0000 00:00:1757887015.178039   21116 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m W0000 00:00:1757887015.185438   21109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m W0000 00:00:1757887015.185491   21109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m W0000 00:00:1757887015.185494   21109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m W0000 00:00:1757887015.185496   21109 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m 2025-09-15 01:26:55.191985: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m   | Name          | Type       | Params | Mode \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 0 | branches      | ModuleList | 3.7 K  | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 1 | fusion_conv2d | Sequential | 15     | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 2 | lstm          | LSTM       | 82.9 K | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 3 | attention     | Attention  | 129    | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 4 | regressor     | Sequential | 8.8 K  | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 5 | loss_fn_reg   | MSELoss    | 0      | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m -----------------------------------------------------\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 95.6 K    Trainable params\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 95.6 K    Total params\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 0.383     Total estimated model params size (MB)\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 35        Modules in train mode\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m /home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m /home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] \n",
      "Epoch 0:  20%|██        | 1/5 [00:00<00:00,  4.18it/s, v_num=0, train_loss=0.847]\n",
      "Epoch 0:  40%|████      | 2/5 [00:00<00:00,  6.58it/s, v_num=0, train_loss=0.915]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m 4 | regressor     | Sequential | 681    | train\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20510)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20515)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20512)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20517)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|██        | 2/10 [00:00<00:00,  9.71it/s, v_num=0, train_loss=0.645]\n",
      "Epoch 0:  40%|████      | 4/10 [00:00<00:00, 12.95it/s, v_num=0, train_loss=0.649]\n",
      "Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, v_num=0, train_loss=0.902]        \n",
      "Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s, v_num=0, train_loss=0.868]         \n",
      "Epoch 2:   0%|          | 0/5 [00:00<?, ?it/s, v_num=0, train_loss=0.845]        \n",
      "Epoch 0: 100%|██████████| 3/3 [00:01<00:00,  2.85it/s, v_num=0, train_loss=0.673]\n",
      "Epoch 0: 100%|██████████| 3/3 [00:01<00:00,  2.85it/s, v_num=0, train_loss=0.673]\n",
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=0, train_loss=0.673]        \n",
      "Epoch 2:  10%|█         | 1/10 [00:00<00:00, 14.91it/s, v_num=0, train_loss=0.549] \n",
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00,  5.20it/s, v_num=0, train_loss=0.518]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m 💻 CPU: 16.5% | 🧠 RAM: 64.6% | 🎮 GPU: 0.0% VRAM: 2.4%\u001b[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m === DEBUG SAMPLE CHECK (Torch mode) ===\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m --- Sequence 0 ---\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m Label: [1.143628 0.       0.       0.       0.       0.       0.       0.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m  0.      ] Encoded (padded): [1.143628 0.       0.       0.       0.       0.       0.       0.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m  0.      ]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m [main] Shape: (5, 4)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m [main] First few rows:\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m  [[ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m  [ 0.00645032 -0.00251821 -0.02505807 -0.05388233]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m ==========================\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s] \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Epoch 1:  33%|███▎      | 1/3 [00:00<00:00,  3.72it/s, v_num=0, train_loss=0.124]\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "Epoch 2:  60%|██████    | 3/5 [00:08<00:05,  0.35it/s, v_num=0, train_loss=0.793]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s, v_num=0, train_loss=0.000766]         \n",
      "Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=0, train_loss=0.793]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Epoch 0: 100%|██████████| 3/3 [00:01<00:00,  2.20it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 0: 100%|██████████| 3/3 [00:01<00:00,  2.20it/s, v_num=0, train_loss=0.143]\n",
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=0, train_loss=0.143]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00,  4.63it/s, v_num=0, train_loss=0.544]\n",
      "Epoch 2: 100%|██████████| 10/10 [00:08<00:00,  1.14it/s, v_num=0, train_loss=0.0278]\n",
      "Epoch 1: 100%|██████████| 3/3 [00:09<00:00,  0.32it/s, v_num=0, train_loss=0.129]\n",
      "Epoch 3:  10%|█         | 1/10 [00:00<00:00, 24.99it/s, v_num=0, train_loss=0.504]  \n",
      "Epoch 2:  10%|█         | 1/10 [00:00<00:00, 15.83it/s, v_num=0, train_loss=0.0426] \n",
      "Epoch 3:   0%|          | 0/5 [00:00<?, ?it/s, v_num=0, train_loss=0.864]        \n",
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00,  6.22it/s, v_num=0, train_loss=0.0607]\n",
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00,  6.19it/s, v_num=0, train_loss=0.0607]\n",
      "Epoch 4:   0%|          | 0/10 [00:00<?, ?it/s, v_num=0, train_loss=0.229]              \n",
      "Epoch 4:  30%|███       | 3/10 [00:00<00:00, 21.84it/s, v_num=0, train_loss=0.301]\n",
      "Epoch 5:  20%|██        | 2/10 [00:00<00:00, 32.76it/s, v_num=0, train_loss=0.153]  \n",
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 10.26it/s, v_num=0, train_loss=0.569]\n",
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00,  8.22it/s, v_num=0, train_loss=0.813]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m 📊 Validation Metrics (Hungarian matched):\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20509)\u001b[0m   Regression → MSE: 0.849925, MAE: 0.913592\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m GPU available: False, used: False\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m TPU available: False, using: 0 TPU cores\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m HPU available: False, using: 0 HPUs\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m /home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m 2025-09-15 01:26:55.543324: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m 2025-09-15 01:26:55.567541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m E0000 00:00:1757887015.594123   21170 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m E0000 00:00:1757887015.601669   21170 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m W0000 00:00:1757887015.620983   21170 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m 2025-09-15 01:26:55.627297: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/10 [00:00<?, ?it/s, v_num=0, train_loss=0.00395]         \n",
      "Epoch 4:  10%|█         | 1/10 [00:00<00:00, 17.12it/s, v_num=0, train_loss=0.00648]\n",
      "Epoch 8:   0%|          | 0/10 [00:00<?, ?it/s, v_num=0, train_loss=0.0235]         \n",
      "Epoch 5: 100%|██████████| 10/10 [00:00<00:00, 17.55it/s, v_num=0, train_loss=0.000168]\n",
      "Epoch 8: 100%|██████████| 3/3 [00:00<00:00,  7.95it/s, v_num=0, train_loss=0.0269]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m   | Name          | Type       | Params | Mode \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m -----------------------------------------------------\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 0 | branches      | ModuleList | 3.7 K  | train\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 1 | fusion_conv2d | Sequential | 15     | train\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 2 | lstm          | LSTM       | 8.4 K  | train\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 3 | attention     | Attention  | 33     | train\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m 4 | regressor     | Sequential | 8.8 K  | train\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 5 | loss_fn_reg   | MSELoss    | 0      | train\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 12.9 K    Trainable params\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 0         Non-trainable params\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 12.9 K    Total params\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 0.052     Total estimated model params size (MB)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 35        Modules in train mode\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 0         Modules in eval mode\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m /home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m /home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20512)\u001b[0m \n",
      "\u001b[36m(train_cnn_lstm_tune pid=20518)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20516)\u001b[0m 4 | regressor     | Sequential | 681    | train\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 10/10 [00:00<00:00, 16.41it/s, v_num=0, train_loss=0.0054]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20515)\u001b[0m \n",
      "Epoch 8:  50%|█████     | 5/10 [00:00<00:00, 15.80it/s, v_num=0, train_loss=0.00807]\n",
      "Epoch 8:  50%|█████     | 5/10 [00:00<00:00, 15.79it/s, v_num=0, train_loss=0.00541]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20517)\u001b[0m \n",
      "Epoch 14:  60%|██████    | 3/5 [00:00<00:00, 10.93it/s, v_num=0, train_loss=0.028] \u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Epoch 9:  20%|██        | 2/10 [00:00<00:00, 17.72it/s, v_num=0, train_loss=0.0126] \u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, v_num=0, train_loss=0.0148]\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=0, train_loss=0.0324]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m \n",
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00,  3.60it/s, v_num=0, train_loss=0.0324]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 8:  10%|█         | 1/10 [00:00<00:00, 27.84it/s, v_num=0, train_loss=0.00787]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 6:  33%|███▎      | 1/3 [00:00<00:00, 15.23it/s, v_num=0, train_loss=0.785]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 14:   0%|          | 0/5 [00:00<?, ?it/s, v_num=0, train_loss=0.0428]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Epoch 7: 100%|██████████| 10/10 [00:00<00:00, 16.37it/s, v_num=0, train_loss=0.00069]\n",
      "Epoch 10:   0%|          | 0/10 [00:00<?, ?it/s, v_num=0, train_loss=0.00119]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Epoch 10:  60%|██████    | 6/10 [00:08<00:05,  0.72it/s, v_num=0, train_loss=0.00456]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Epoch 14: 100%|██████████| 5/5 [00:08<00:00,  0.58it/s, v_num=0, train_loss=0.0144]\n",
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00,  5.51it/s, v_num=0, train_loss=0.0178]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m 📊 Validation Metrics (Hungarian matched):\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m   Regression → MSE: 0.043764, MAE: 0.157687\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Epoch 7:  10%|█         | 1/10 [00:00<00:00, 22.78it/s, v_num=0, train_loss=0.011] \u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20513)\u001b[0m `Trainer.fit` stopped: `max_epochs=15` reached.\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  20%|██        | 2/10 [00:00<00:00, 23.43it/s, v_num=0, train_loss=0.00301]\n",
      "Epoch 12:  70%|███████   | 7/10 [00:00<00:00, 24.71it/s, v_num=0, train_loss=0.00295]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20514)\u001b[0m \n",
      "Epoch 13:  10%|█         | 1/10 [00:00<00:00, 41.02it/s, v_num=0, train_loss=0.00158] \n",
      "Epoch 13:  50%|█████     | 5/10 [00:00<00:00, 39.30it/s, v_num=0, train_loss=0.00817]\n",
      "Epoch 14:  70%|███████   | 7/10 [00:00<00:00, 29.16it/s, v_num=0, train_loss=0.00247]\n",
      "Epoch 14:  70%|███████   | 7/10 [00:00<00:00, 29.13it/s, v_num=0, train_loss=0.00763]\n",
      "Epoch 14: 100%|██████████| 10/10 [00:00<00:00, 26.83it/s, v_num=0, train_loss=9.03e-6]\n",
      "\u001b[36m(train_cnn_lstm_tune pid=20510)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 01:27:06,646\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/iatell/projects/meta-learning/tune_logs/cnn_lstm_tuning' in 0.0070s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_cnn_lstm_tune pid=20511)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 01:27:06,652\tINFO tune.py:1041 -- Total run time: 8.90 seconds (8.86 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Config: {'hidden_dim': 128, 'lr': 0.002270514800819013, 'batch_size': 32, 'max_epochs': 15}\n",
      "Best Accuracy: -0.0030\n",
      "\n",
      "🔁 Retraining best model on full dataset for saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025-09-15 01:27:07.238387: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-15 01:27:07.249708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757887027.262076   18862 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757887027.265594   18862 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757887027.275326   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757887027.275356   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757887027.275358   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757887027.275359   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-15 01:27:07.279100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | branches      | ModuleList | 3.7 K  | train\n",
      "1 | fusion_conv2d | Sequential | 15     | train\n",
      "2 | lstm          | LSTM       | 82.9 K | train\n",
      "3 | attention     | Attention  | 129    | train\n",
      "4 | regressor     | Sequential | 8.8 K  | train\n",
      "5 | loss_fn_reg   | MSELoss    | 0      | train\n",
      "-----------------------------------------------------\n",
      "95.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "95.6 K    Total params\n",
      "0.383     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e5a3cc69354f7fac5a6cffc6f8b248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to models/saved_models/lstm_model_multireg_multihead_20250915_012706.pt\n",
      "✅ Meta saved to models/saved_models/lstm_meta_multireg_multihead_20250915_012706.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "from trainer.cnn_attention_lstm_multi_reg import train_model\n",
    "def resource_usage():\n",
    "    \"\"\"Print current CPU, RAM, and GPU usage.\"\"\"\n",
    "    cpu = psutil.cpu_percent(interval=0.5)\n",
    "    ram = psutil.virtual_memory().percent\n",
    "    usage = f\"💻 CPU: {cpu:.1f}% | 🧠 RAM: {ram:.1f}%\"\n",
    "    try:\n",
    "        import GPUtil\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if gpus:\n",
    "            usage += f\" | 🎮 GPU: {gpus[0].load*100:.1f}% VRAM: {gpus[0].memoryUtil*100:.1f}%\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    print(usage)\n",
    "\n",
    "\n",
    "def train_cnn_lstm_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    Args:\n",
    "        config (dict): hyperparameters for this trial.\n",
    "    \"\"\"\n",
    "    resource_usage()  # Show current hardware usage\n",
    "\n",
    "    # Train using existing train_model function\n",
    "    metrics = train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        # seq_len=config[\"seq_len\"],\n",
    "        hidden_dim=config[\"hidden_dim\"],\n",
    "        # num_layers=config[\"num_layers\"],\n",
    "        lr=config[\"lr\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        max_epochs=config[\"max_epochs\"],\n",
    "        return_val_accuracy=True,  # Expects dict with \"accuracy\" and optionally \"loss\"\n",
    "        save_model=False  # Never save during search\n",
    "    )\n",
    "\n",
    "    # Report metrics to Ray Tune\n",
    "    tune.report(metrics)\n",
    "\n",
    "\n",
    "def run_tuning(save_model=True):\n",
    "    \"\"\"Hyperparameter tuning for CNN LSTM with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # \"seq_len\": tune.choice([3, 5, 7]),\n",
    "        \"hidden_dim\": tune.choice([32, 64, 128]),\n",
    "        # \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"batch_size\": tune.choice([32, 64, 100]),\n",
    "        \"max_epochs\": tune.choice([5, 10, 15]),\n",
    "        # CNN knobs – keep all tuples the same length\n",
    "        # \"cnn_channels\": tune.choice([(32,), (64,), (32, 64), (64, 32)]),\n",
    "        # \"cnn_kernel_sizes\": tune.choice([(2,), (3,), (2, 2), (3, 3)]),\n",
    "        # \"cnn_strides\": tune.choice([(1,), (1, 1)]),\n",
    "        # \"cnn_paddings\": tune.choice([(0,), (0, 0)]),\n",
    "    }\n",
    "    # # Define the working directory\n",
    "    # runtime_env = {\n",
    "    #     \"working_dir\": str(Path(\"/home/iatell/projects/meta-learning\").resolve())\n",
    "# }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"accuracy\",  # must exist in metrics dict from train_model\n",
    "        mode=\"max\",\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        train_cnn_lstm_tune,\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=10\n",
    "        ),\n",
    "    run_config=air.RunConfig(\n",
    "        name=\"cnn_lstm_tuning\",\n",
    "        storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "    ),\n",
    "    # runtime_env=runtime_env\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Best trial\n",
    "    best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")\n",
    "    print(\"\\n🏆 Best Config:\", best_result.config)\n",
    "    print(f\"Best Accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # Optional: retrain best model on full data and save\n",
    "    if save_model:\n",
    "        print(\"\\n🔁 Retraining best model on full dataset for saving...\")\n",
    "        train_model(\n",
    "            \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "            \"/home/iatell/projects/meta-learning/data/line_seq_ordered_added.csv\",\n",
    "            do_validation=False,\n",
    "            model_out_dir=\"models/saved_models\",\n",
    "            # seq_len=best_result.config[\"seq_len\"],\n",
    "            hidden_dim=best_result.config[\"hidden_dim\"],\n",
    "            # num_layers=best_result.config[\"num_layers\"],\n",
    "            # cnn_channels=best_result.config[\"cnn_channels\"],\n",
    "            # cnn_kernel_sizes=best_result.config[\"cnn_kernel_sizes\"],\n",
    "            # cnn_strides=best_result.config[\"cnn_strides\"],\n",
    "            # cnn_paddings=best_result.config[\"cnn_paddings\"],\n",
    "            lr=best_result.config[\"lr\"],\n",
    "            batch_size=best_result.config[\"batch_size\"],\n",
    "            max_epochs=best_result.config[\"max_epochs\"],\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
