{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e5398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e8e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sequencer returned 78 aligned sequences in SequenceCollection.\n",
      "âœ… Padded 78 label sequences to shape: (78, 9)\n",
      "âœ… Calculated input_dim: {'main': 4}\n",
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "\n",
      "--- Sample 0 ---\n",
      "Original index: 0\n",
      "Window range: [not available]\n",
      "y (shape (9,)): [ 0.23053596 -0.79516724 -0.79516724 -0.79516724 -0.79516724 -0.79516724\n",
      " -0.79516724 -0.79516724 -0.79516724]\n",
      "Feature sets:\n",
      "  â€¢ 'main' â†’ DataFrame (3, 4)\n",
      "    Columns: ['open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "    Preview:\n",
      "  open_prop  high_prop  low_prop  close_prop\n",
      "  0.229527   0.301455  0.110293    0.163807\n",
      "  0.163942   0.236210 -0.015501    0.230101\n",
      "  0.234245   0.237839 -0.251339    0.000000\n",
      "\n",
      "--- Sample 1 ---\n",
      "Original index: 1\n",
      "Window range: [not available]\n",
      "y (shape (9,)): [ 0.39999014 -0.79516724 -0.79516724 -0.79516724 -0.79516724 -0.79516724\n",
      " -0.79516724 -0.79516724 -0.79516724]\n",
      "Feature sets:\n",
      "  â€¢ 'main' â†’ DataFrame (3, 4)\n",
      "    Columns: ['open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "    Preview:\n",
      "  open_prop  high_prop  low_prop  close_prop\n",
      "  0.470376   0.482558  0.274163    0.392508\n",
      "  0.392856   0.474184  0.352704    0.400018\n",
      "  0.395415   0.400362 -0.301906    0.000000\n",
      "\n",
      "--- Sample 2 ---\n",
      "Original index: 2\n",
      "Window range: [not available]\n",
      "y (shape (9,)): [ 0.00128339 -0.79516724 -0.79516724 -0.79516724 -0.79516724 -0.79516724\n",
      " -0.79516724 -0.79516724 -0.79516724]\n",
      "Feature sets:\n",
      "  â€¢ 'main' â†’ DataFrame (3, 4)\n",
      "    Columns: ['open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "    Preview:\n",
      "  open_prop  high_prop  low_prop  close_prop\n",
      "  0.386484   0.391501 -0.308949   -0.010796\n",
      " -0.010797   0.123692 -0.308548    0.004673\n",
      "  0.001850   0.156508 -0.091127    0.000000\n",
      "========================\n",
      "\n",
      "\n",
      "==========================================\n",
      "--- Trace Log for: preprocess_pipeline ---\n",
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ Method                â”‚ Add-On                      â”‚ Message                                              â”‚   Time Elapsed (s) â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ run_sequence_on_train â”‚ SequencerAddOn              â”‚                                                      â”‚             0.0576 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_apply_window      â”‚ CandleNormalizationAddOn    â”‚                                                      â”‚             0.0462 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_apply_window      â”‚ DropColumnsAddOn            â”‚                                                      â”‚             0.0119 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_apply_window      â”‚ FilterInvalidSequencesAddOn â”‚                                                      â”‚             0.0021 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_apply_window      â”‚ FeatureColumnTrackerAddOn   â”‚                                                      â”‚             0      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_transformation    â”‚ ArctanMapperAddOn           â”‚ Successfully applied Arctan transform to 78 samples. â”‚             0.0175 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_transformation    â”‚ LabelPadder                 â”‚                                                      â”‚             0.0001 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_transformation    â”‚ InputDimCalculator          â”‚                                                      â”‚             0      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ run_final_output      â”‚ PrepareOutputAddOn          â”‚                                                      â”‚             0.0006 â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
      "==========================================\n",
      "\n",
      "feature_columns {'main': ['open_prop', 'high_prop', 'low_prop', 'close_prop']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | layers  | Sequential | 2.2 K  | train\n",
      "1 | flatten | Flatten    | 0      | train\n",
      "2 | loss_fn | L1Loss     | 0      | train\n",
      "-----------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e82201bdec4d54ad7a0d21557ce690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X {'main': tensor([[[ 3.8798e-02,  6.5966e-02, -2.5274e-02,  4.6991e-03],\n",
      "         [ 4.9695e-03,  2.3351e-02, -1.4256e-02,  1.4746e-02],\n",
      "         [ 1.4794e-02,  1.5481e-02, -7.4300e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 6.9479e-02,  1.0852e-01, -1.0525e-03,  5.0485e-02],\n",
      "         [ 5.0485e-02,  7.6393e-02,  2.1328e-02,  5.6683e-02],\n",
      "         [ 5.6644e-02,  6.7805e-02, -4.1505e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.7609e-01,  1.8077e-01, -6.7597e-02, -2.8602e-02],\n",
      "         [-2.8317e-02,  3.8241e-02, -3.9934e-02,  4.0487e-03],\n",
      "         [ 4.0487e-03,  3.8179e-02, -1.1902e-01,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.6483e-01,  2.8301e-01,  1.6832e-01,  1.8465e-01],\n",
      "         [ 1.8465e-01,  2.5912e-01,  1.6782e-01,  2.2197e-01],\n",
      "         [ 2.2197e-01,  2.2807e-01, -4.0091e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.0669e-02,  1.1356e-01,  3.3766e-02,  6.2449e-02],\n",
      "         [ 6.2096e-02,  9.1314e-02,  3.9795e-02,  8.4277e-02],\n",
      "         [ 8.4277e-02,  9.0075e-02, -1.9993e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.1059e-02,  8.1059e-02, -1.3336e-02,  6.2298e-02],\n",
      "         [ 6.2335e-02,  1.0202e-01,  3.8328e-02,  7.1082e-02],\n",
      "         [ 7.1044e-02,  8.9334e-02, -4.6843e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.2024e-02,  8.9795e-02, -2.6731e-02, -5.1470e-03],\n",
      "         [-5.1467e-03,  2.8085e-02, -4.0435e-02,  1.3636e-02],\n",
      "         [ 1.3636e-02,  2.0324e-02, -4.2045e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.5068e-03,  5.1028e-02, -1.0760e-01, -3.3459e-03],\n",
      "         [-3.5386e-03,  8.3505e-02, -5.7920e-02,  3.9315e-02],\n",
      "         [ 3.8848e-02,  1.0330e-01, -2.5239e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.2660e-02,  9.7902e-02, -3.0474e-02, -2.6089e-02],\n",
      "         [-2.6563e-02,  2.9892e-02, -4.2806e-02,  1.2780e-02],\n",
      "         [ 1.2780e-02,  3.8080e-02, -3.0474e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.2298e-01,  3.4506e-01,  1.8969e-01,  2.0510e-01],\n",
      "         [ 2.0550e-01,  2.5356e-01,  1.3884e-01,  2.2696e-01],\n",
      "         [ 2.2483e-01,  2.7109e-01, -5.2213e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.0234e-01,  1.2129e-01,  5.9425e-02,  1.0042e-01],\n",
      "         [ 1.0042e-01,  1.4408e-01,  8.6672e-02,  1.2287e-01],\n",
      "         [ 1.2292e-01,  1.3846e-01, -3.4417e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.0141e-02,  7.3413e-02, -3.5822e-02, -2.0159e-03],\n",
      "         [-2.0159e-03,  3.5183e-02, -1.4558e-02,  2.2081e-02],\n",
      "         [ 2.2079e-02,  4.4062e-02, -3.4585e-02,  0.0000e+00]],\n",
      "\n",
      "        [[-8.7932e-03, -1.6711e-04, -4.5183e-02, -1.5500e-02],\n",
      "         [-1.5502e-02,  2.0208e-02, -2.3272e-02,  1.2151e-02],\n",
      "         [ 1.2151e-02,  4.6994e-02, -2.0637e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.6598e-02,  9.9634e-02,  1.2375e-02,  3.9275e-02],\n",
      "         [ 3.7254e-02,  8.1820e-02, -7.8918e-03,  6.5074e-02],\n",
      "         [ 6.5074e-02,  8.2888e-02, -6.8312e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.7536e-02,  1.5291e-01,  1.1015e-03,  1.0518e-02],\n",
      "         [ 1.0374e-02,  8.2007e-02, -1.7253e-02,  5.2640e-02],\n",
      "         [ 5.2640e-02,  5.3100e-02, -3.2040e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.8067e-02,  8.1626e-02, -2.3425e-03,  4.2203e-03],\n",
      "         [ 4.2205e-03,  2.9025e-02, -1.5117e-03,  2.6944e-02],\n",
      "         [ 2.6943e-02,  5.6543e-02, -1.3174e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.1942e-02,  3.0339e-02,  6.8325e-04,  9.3478e-03],\n",
      "         [ 9.3458e-03,  1.7011e-02, -1.7562e-02,  1.2094e-02],\n",
      "         [ 1.2094e-02,  1.6378e-02, -7.6887e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.4655e-03,  1.7127e-02, -2.1054e-02, -1.1367e-02],\n",
      "         [-1.1366e-02,  2.1785e-02, -4.8478e-02,  2.7892e-03],\n",
      "         [ 2.7890e-03,  5.2113e-02, -9.5084e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.9752e-01,  2.1188e-01, -2.2979e-02,  1.4658e-03],\n",
      "         [ 1.4658e-03,  3.9855e-02, -6.2761e-02,  9.6895e-03],\n",
      "         [ 9.6895e-03,  1.8682e-02, -2.8300e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.0682e-01,  1.2147e-01,  3.0804e-02,  3.3814e-02],\n",
      "         [ 3.3814e-02,  9.7904e-02,  1.1513e-02,  8.6287e-02],\n",
      "         [ 8.6287e-02,  1.0143e-01, -2.4201e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.5480e-03,  1.6793e-02, -1.2881e-02, -2.1786e-03],\n",
      "         [-2.2875e-03,  2.9356e-02, -9.6101e-02,  1.4216e-02],\n",
      "         [ 1.4105e-02,  2.1105e-02, -2.0128e-02,  0.0000e+00]],\n",
      "\n",
      "        [[-2.4422e-02,  9.5224e-03, -6.7850e-02, -3.0170e-02],\n",
      "         [-3.0047e-02,  7.1307e-02, -3.5716e-02,  2.6560e-02],\n",
      "         [ 2.6667e-02,  4.3773e-02, -9.2632e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5535e-02,  1.9569e-02, -3.6978e-03,  7.4366e-03],\n",
      "         [ 7.4366e-03,  2.9793e-02,  5.6871e-03,  1.0944e-02],\n",
      "         [ 1.1327e-02,  1.3748e-02, -7.3985e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.8141e-02,  7.1783e-02, -5.2253e-02,  2.6278e-03],\n",
      "         [ 2.4684e-03,  1.6465e-01, -1.0792e-02,  7.7600e-02],\n",
      "         [ 7.7600e-02,  1.3229e-01, -3.4476e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.7084e-01,  3.7918e-01,  1.3767e-01,  2.0260e-01],\n",
      "         [ 2.0120e-01,  2.3712e-01,  9.7671e-02,  2.1145e-01],\n",
      "         [ 2.1145e-01,  2.2064e-01, -9.7276e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.9191e-01,  2.0039e-01,  2.8938e-02,  5.7682e-02],\n",
      "         [ 5.8059e-02,  1.5644e-01,  5.6537e-03,  9.1468e-02],\n",
      "         [ 9.1141e-02,  1.0056e-01, -1.2583e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.1455e-01,  1.7529e-01,  2.7281e-02,  9.4894e-02],\n",
      "         [ 9.4890e-02,  1.2478e-01,  4.5241e-02,  1.1242e-01],\n",
      "         [ 1.1239e-01,  1.4276e-01, -2.9445e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.6486e-01,  2.6486e-01,  2.7128e-02,  6.8464e-02],\n",
      "         [ 6.8466e-02,  1.1343e-01,  2.3387e-02,  9.9215e-02],\n",
      "         [ 9.9215e-02,  1.0449e-01, -2.7767e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4208e-01,  2.7454e-01,  1.8741e-01,  2.2435e-01],\n",
      "         [ 2.2435e-01,  2.5844e-01,  1.0343e-01,  2.3052e-01],\n",
      "         [ 2.3052e-01,  2.3840e-01, -2.1604e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.4800e-01,  1.7626e-01, -3.9654e-02, -9.7162e-03],\n",
      "         [-9.7162e-03,  8.3520e-02, -5.6349e-02,  7.4771e-02],\n",
      "         [ 7.4989e-02,  1.0187e-01, -5.6445e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.1377e-03,  1.0490e-02, -1.9004e-02, -1.0423e-03],\n",
      "         [-1.0443e-03,  6.5800e-02, -2.2014e-03,  5.5295e-02],\n",
      "         [ 5.5295e-02,  6.5800e-02, -3.6071e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.0216e-01,  1.0858e-01,  5.0307e-02,  6.1254e-02],\n",
      "         [ 6.1254e-02,  1.7667e-01,  5.8201e-02,  1.6042e-01],\n",
      "         [ 1.6042e-01,  1.6802e-01, -5.1150e-02,  0.0000e+00]],\n",
      "\n",
      "        [[-4.2356e-02, -1.1520e-02, -9.6619e-02, -7.4676e-02],\n",
      "         [-7.4677e-02,  3.6375e-02, -1.1625e-01,  2.7986e-02],\n",
      "         [ 2.7797e-02,  4.6632e-02, -4.1650e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.0305e-01,  1.5577e-01, -1.1370e-01, -2.0576e-02],\n",
      "         [-2.0574e-02,  4.7866e-02, -4.3612e-02,  4.7508e-03],\n",
      "         [ 4.7285e-03,  3.8011e-02, -3.2730e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.9955e-01,  3.1013e-01,  6.0803e-02,  6.3597e-02],\n",
      "         [ 6.3461e-02,  2.2362e-01,  4.1053e-02,  1.2395e-01],\n",
      "         [ 1.2396e-01,  1.9443e-01, -8.6024e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.2731e-01,  2.7741e-01, -1.9224e-02,  8.2081e-02],\n",
      "         [ 8.2533e-02,  1.7758e-01,  1.9158e-02,  1.2556e-01],\n",
      "         [ 1.2556e-01,  1.5085e-01, -1.5293e-02,  0.0000e+00]],\n",
      "\n",
      "        [[-9.5482e-03, -3.3949e-03, -8.9055e-02, -7.3126e-02],\n",
      "         [-7.2884e-02,  3.0729e-02, -9.4322e-02,  5.0736e-03],\n",
      "         [ 5.2441e-03,  3.6577e-02, -1.8615e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.8822e-02,  2.9488e-02, -1.6209e-02,  3.1931e-03],\n",
      "         [ 3.1931e-03,  2.0604e-02, -2.5412e-02,  1.3202e-02],\n",
      "         [ 1.3202e-02,  2.6145e-02, -2.7021e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 9.1040e-02,  9.2733e-02,  3.8878e-02,  5.5789e-02],\n",
      "         [ 5.5547e-02,  7.5771e-02,  2.9844e-02,  6.4077e-02],\n",
      "         [ 6.3917e-02,  6.8190e-02, -1.7019e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.2029e-01,  2.3252e-01, -3.8630e-02, -4.8542e-03],\n",
      "         [-5.3350e-03,  8.5955e-02, -5.4567e-02,  5.2398e-02],\n",
      "         [ 5.2398e-02,  7.4609e-02, -6.3972e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.9276e-03,  2.1959e-02, -5.7967e-02, -1.1803e-02],\n",
      "         [-1.1780e-02,  6.7977e-02, -2.0206e-02,  1.0861e-02],\n",
      "         [ 1.1304e-02,  1.2825e-02, -3.6315e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.6015e-02,  3.6472e-02, -2.7399e-02, -1.3998e-02],\n",
      "         [-1.3998e-02,  1.6888e-01, -1.9331e-02,  1.3494e-01],\n",
      "         [ 1.3531e-01,  1.4034e-01, -5.0468e-02,  0.0000e+00]],\n",
      "\n",
      "        [[-6.6762e-03,  5.0866e-02, -6.4729e-02, -4.3120e-02],\n",
      "         [-4.3120e-02,  2.6982e-02, -4.3464e-02,  1.7624e-02],\n",
      "         [ 1.7625e-02,  2.8408e-02, -2.5520e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.6344e-02,  8.1173e-02,  2.9555e-02,  5.5712e-02],\n",
      "         [ 5.5712e-02,  1.0444e-01,  4.6004e-02,  6.3330e-02],\n",
      "         [ 6.3330e-02,  9.1089e-02, -5.7558e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.4986e-02,  5.0668e-02, -4.2240e-02, -3.1815e-02],\n",
      "         [-3.2965e-02,  4.1708e-02, -3.7730e-02,  3.5725e-02],\n",
      "         [ 3.5719e-02,  1.5358e-01, -3.2905e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.6480e-02,  9.6396e-02,  4.9063e-02,  6.2726e-02],\n",
      "         [ 6.2729e-02,  7.8911e-02,  5.7269e-02,  6.4252e-02],\n",
      "         [ 6.4230e-02,  6.7412e-02, -1.1232e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.4419e-01,  1.4460e-01,  3.9230e-02,  4.1457e-02],\n",
      "         [ 4.1457e-02,  7.4199e-02,  2.1478e-02,  5.3760e-02],\n",
      "         [ 5.3761e-02,  7.7302e-02, -6.5482e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.3402e-02,  1.3089e-01,  1.5405e-02,  6.5299e-02],\n",
      "         [ 6.5299e-02,  1.1549e-01, -1.6247e-02,  9.2979e-02],\n",
      "         [ 9.2979e-02,  1.0452e-01, -8.9334e-03,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.1997e-02,  8.6921e-02,  1.9299e-02,  5.0800e-02],\n",
      "         [ 5.0761e-02,  7.3598e-02, -1.9763e-02,  5.6168e-02],\n",
      "         [ 5.6169e-02,  7.7805e-02, -4.4678e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.3752e-02,  9.0570e-02, -2.0444e-02,  1.5897e-02],\n",
      "         [ 1.5897e-02,  8.6476e-02, -7.5496e-04,  2.3785e-02],\n",
      "         [ 2.3785e-02,  3.0246e-02, -2.3746e-02,  0.0000e+00]]],\n",
      "       device='cuda:0')}\n",
      "y tensor([[ 0.0137, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0575, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0041, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.2202, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0845, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0698, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0123, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0407, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0120, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.2269, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.1229, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0214, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0114, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0659, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0518, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0273, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0127, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0026, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0085, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0865, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0132, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0255, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0104, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0781, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.2112, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0912, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.1121, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0987, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.2302, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0720, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0553, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.1591, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0280, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0039, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.1253, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.1231, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0029, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0128, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0652, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0527, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0094, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.1357, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0179, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0633, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0353, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0643, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0542, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0937, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0557, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952],\n",
      "        [ 0.0229, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "         -0.7952]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8268454c87234d4b92a92230955f9bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([50, 9])\n",
      "  First label in batch: tensor([ 0.0137, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952, -0.7952,\n",
      "        -0.7952])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([50, 3, 4])\n",
      "  First sequence in batch (first steps):\n",
      " tensor([[ 0.0388,  0.0660, -0.0253,  0.0047],\n",
      "        [ 0.0050,  0.0234, -0.0143,  0.0147],\n",
      "        [ 0.0148,  0.0155, -0.0074,  0.0000]])\n",
      "\n",
      "âœ… Combined df_seq shape: (150, 4)\n",
      "âœ… Column names in df_seq: ['open_prop', 'high_prop', 'low_prop', 'close_prop']\n",
      "ArctanMapperAddOn: Inverse-transforming labels/predictions with A=3.0000, B=1.0000...\n",
      "â¡ï¸ Running RealPriceMultiplier on_evaluation...\n",
      "  âœ… RealPriceMultiplier: Scaled predictions and labels to real prices.\n",
      "\n",
      "ğŸ“Š Validation Metrics (Hungarian matched):\n",
      "  Regression â†’ MSE: 440414848.000000, MAE: 15214.421875, MAE/LastClose: 0.882894\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocess.preprocess_final import preprocess_pipeline\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from add_ons.feature_pipeline_base import FeaturePipeline\n",
    "from utils.generate_name import generate_filenames\n",
    "from models.neural_nets.vanilla_fnn import VanillaFNN\n",
    "from models.evaluation.multi_regression import evaluate_model\n",
    "from models.utils.early_stopping import get_early_stopping_callbacks\n",
    "from utils.run_debug_mode import run_debug_mode\n",
    "from utils.save_model_files import save_model_files\n",
    "from sequencer.sequencer import SequencerAddOn\n",
    "from add_ons.feature_tracker_addon import FeatureColumnTrackerAddOn\n",
    "from add_ons.label_padder_add_on import LabelPadder\n",
    "from add_ons.input_dim_calculator import InputDimCalculator\n",
    "from add_ons.candle_norm_reduce_addon import CandleNormalizationAddOn\n",
    "from add_ons.candle_shape_add_on import CandleShapeFeaturesAddOn\n",
    "from add_ons.drop_column_windowing_add_on import DropColumnsAddOn\n",
    "from add_ons.real_price_multiplier import RealPriceMultiplier\n",
    "from utils.filter_sequences import FilterInvalidSequencesAddOn\n",
    "from add_ons.prepare_output import PrepareOutputAddOn\n",
    "from add_ons.RootPower import RootPowerMapperAddOn\n",
    "from add_ons.ArcTanMapper import ArctanMapperAddOn\n",
    "\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    experiment_out_dir=\"experiments\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=50,\n",
    "    max_epochs=200,\n",
    "    save_model=True,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False,\n",
    "    optimizer_name= \"adamw\",\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 5},\n",
    "    activation_function = \"relu\",\n",
    "    use_mse_loss = False,\n",
    "    use_rescue = False,\n",
    "    activation_functions = [\"relu\"]\n",
    "):\n",
    "    \n",
    "    # 2. Create the pipeline and add your modules\n",
    "    feature_pipeline = FeaturePipeline(\n",
    "        add_ons=[\n",
    "            SequencerAddOn(include_cols=None, exclude_cols=None),\n",
    "            CandleNormalizationAddOn(),\n",
    "            ArctanMapperAddOn(\n",
    "                a=3,\n",
    "                  b=1,  # Use a root power for aggressive variance increase\n",
    "            target_features={\"main\":[\"open_prop\", \"high_prop\", \"low_prop\", \"close_prop\"]}, # Apply to features\n",
    "            y=True,\n",
    "        ),\n",
    "            DropColumnsAddOn(cols_map={ \"main\": [\"open\", \"high\", \"low\", \"close\", \"volume\"]}),\n",
    "            FilterInvalidSequencesAddOn(),\n",
    "            LabelPadder(),\n",
    "            FeatureColumnTrackerAddOn(), \n",
    "            InputDimCalculator(),\n",
    "            PrepareOutputAddOn(metadata_keys=[\"last_close_price\"]),\n",
    "            RealPriceMultiplier()\n",
    "        ])\n",
    "    model_save_path, meta_save_path, pipeline_save_path, folder_name = generate_filenames([\n",
    "        (\"model\", \"pt\"),\n",
    "        (\"meta\", \"pkl\"),\n",
    "        (\"pipeline\", \"pkl\"),\n",
    "        \"fnn\"\n",
    "    ])\n",
    "    # feature_pipeline.method_table()\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, returned_state = preprocess_pipeline(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            debug_indices=[0,1,2],\n",
    "            feature_pipeline=feature_pipeline,\n",
    "        )\n",
    "    else:\n",
    "        train_ds, returned_state = preprocess_pipeline(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            debug_indices=[0,1,2],\n",
    "            feature_pipeline=feature_pipeline,\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    input_dim = returned_state['input_dim']\n",
    "    max_len_y = returned_state['max_len_y']\n",
    "    feature_columns = returned_state[\"feature_columns\"]\n",
    "    print(\"feature_columns\",feature_columns)\n",
    "    model = VanillaFNN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=max_len_y,\n",
    "        lr=lr,\n",
    "        optimizer_name= optimizer_name,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params ,\n",
    "        use_mse_loss = use_mse_loss,\n",
    "        activation_functions = activation_functions,\n",
    "        use_rescue = use_rescue\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    if early_stop:\n",
    "        # Define the output directory for this specific experiment/model\n",
    "        model_out_dir = os.path.join(experiment_out_dir, folder_name)\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        callbacks = get_early_stopping_callbacks(model_out_dir) if early_stop else []\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        log_every_n_steps= 3,\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model, df_seq = run_debug_mode(train_loader, feature_columns, test_mode)\n",
    "\n",
    "    if save_model:\n",
    "        save_model_files(\n",
    "            base_dir=experiment_out_dir,\n",
    "            folder_name=folder_name,\n",
    "            trainer=trainer,\n",
    "            model_out=model_save_path,\n",
    "            meta_out=meta_save_path,\n",
    "            pipeline_out=pipeline_save_path,\n",
    "            pipeline=feature_pipeline,\n",
    "            train_model=train_model,\n",
    "        )\n",
    "\n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        metrics = evaluate_model(model, val_loader, feature_pipeline)\n",
    "        if return_val_accuracy:\n",
    "            return {\"accuracy\": metrics[\"mse\"] * (-1)}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/baseline_regression.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True,\n",
    "        max_epochs=200,\n",
    "        hidden_dim=100,\n",
    "        lr=0.001,\n",
    "        batch_size=50,\n",
    "        optimizer_name= \"adamw\",\n",
    "        scheduler_name = None,\n",
    "        optimizer_params={},\n",
    "        scheduler_params={},\n",
    "        save_model= False,\n",
    "        use_mse_loss = True,\n",
    "        use_rescue = False,\n",
    "       activation_functions=[\"elu\", \n",
    "                            #  \"elu\", \"dropout(0.1)\", \"elu\"\n",
    "                             ] #\"leaky_relu\" \"sigmoid\" \"tanh\"  \"elu\" \"relu\" \"swish\" \"mish\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c1b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "high_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "low_prop",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "close_prop",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "2d6c42bd-75e6-40c0-bfda-ff23a9063aeb",
       "rows": [
        [
         "0",
         "0.14261825",
         "0.1861828",
         "-0.11506666",
         "0.049603224"
        ],
        [
         "1",
         "0.051010787",
         "0.11059975",
         "-0.08640336",
         "0.0878757"
        ],
        [
         "2",
         "0.08801871",
         "0.09004256",
         "-0.06237399",
         "0.0"
        ],
        [
         "3",
         "0.19111331",
         "0.23953468",
         "-0.023475615",
         "0.16275594"
        ],
        [
         "4",
         "0.16275594",
         "0.20048064",
         "0.10569513",
         "0.17250396"
        ],
        [
         "5",
         "0.17244522",
         "0.18877865",
         "-0.14752135",
         "0.0"
        ],
        [
         "6",
         "0.3076141",
         "0.31189632",
         "-0.188487",
         "-0.12241845"
        ],
        [
         "7",
         "-0.12180464",
         "0.14158851",
         "-0.14469653",
         "0.04604236"
        ],
        [
         "8",
         "0.04604236",
         "0.14147311",
         "-0.2511087",
         "0.0"
        ],
        [
         "9",
         "0.38374215",
         "0.398477",
         "0.30041045",
         "0.315414"
        ],
        [
         "10",
         "0.315414",
         "0.3790791",
         "0.29994065",
         "0.34810448"
        ],
        [
         "11",
         "0.34810448",
         "0.3532726",
         "-0.14498048",
         "0.0"
        ],
        [
         "12",
         "0.20607205",
         "0.2451544",
         "0.13302864",
         "0.18111746"
        ],
        [
         "13",
         "0.18060137",
         "0.21941438",
         "0.14444298",
         "0.21068218"
        ],
        [
         "14",
         "0.21068218",
         "0.21790013",
         "-0.10233162",
         "0.0"
        ],
        [
         "15",
         "0.206575",
         "0.206575",
         "-0.08356816",
         "0.18089618"
        ],
        [
         "16",
         "0.18095054",
         "0.23212318",
         "0.14174923",
         "0.19332269"
        ],
        [
         "17",
         "0.19327182",
         "0.21699034",
         "-0.049525056",
         "0.0"
        ],
        [
         "18",
         "0.14844473",
         "0.21755601",
         "-0.11834148",
         "-0.05191362"
        ],
        [
         "19",
         "-0.051911898",
         "0.12130424",
         "-0.1456024",
         "0.084502995"
        ],
        [
         "20",
         "0.084502995",
         "0.10317534",
         "-0.14848126",
         "0.0"
        ],
        [
         "21",
         "0.05369762",
         "0.16363214",
         "-0.23849416",
         "-0.0418557"
        ],
        [
         "22",
         "-0.043044284",
         "0.20970301",
         "-0.17438683",
         "0.14356756"
        ],
        [
         "23",
         "0.14271016",
         "0.23359704",
         "-0.036352366",
         "0.0"
        ],
        [
         "24",
         "0.19547631",
         "0.22730948",
         "-0.1263663",
         "-0.11690946"
        ],
        [
         "25",
         "-0.11796894",
         "0.1251525",
         "-0.149824",
         "0.081807874"
        ],
        [
         "26",
         "0.081807874",
         "0.14128804",
         "-0.1263663",
         "0.0"
        ],
        [
         "27",
         "0.43045282",
         "0.44802088",
         "0.31995165",
         "0.3335706"
        ],
        [
         "28",
         "0.3339135",
         "0.37451172",
         "0.2717953",
         "0.3523339"
        ],
        [
         "29",
         "0.3505322",
         "0.38883623",
         "-0.1655304",
         "0.0"
        ],
        [
         "30",
         "0.2324852",
         "0.25354683",
         "0.17665088",
         "0.23025659"
        ],
        [
         "31",
         "0.23025917",
         "0.27704746",
         "0.21369125",
         "0.25524107"
        ],
        [
         "32",
         "0.25528753",
         "0.2714049",
         "-0.13430575",
         "0.0"
        ],
        [
         "33",
         "0.19202928",
         "0.19649513",
         "-0.13702598",
         "-0.032489054"
        ],
        [
         "34",
         "-0.032489054",
         "0.13579662",
         "-0.08731399",
         "0.10754665"
        ],
        [
         "35",
         "0.10754222",
         "0.1520124",
         "-0.13463464",
         "0.0"
        ],
        [
         "36",
         "-0.06785572",
         "-0.009354123",
         "-0.15393971",
         "-0.09009649"
        ],
        [
         "37",
         "-0.09010112",
         "0.10287971",
         "-0.110411234",
         "0.07976714"
        ],
        [
         "38",
         "0.07976714",
         "0.15700538",
         "-0.10396694",
         "0.0"
        ],
        [
         "39",
         "0.2007516",
         "0.22934306",
         "0.08050202",
         "0.14349364"
        ],
        [
         "40",
         "0.13974445",
         "0.20755313",
         "-0.06428321",
         "0.18490973"
        ],
        [
         "41",
         "0.18490973",
         "0.20891877",
         "-0.059807476",
         "0.0"
        ],
        [
         "42",
         "0.20198974",
         "0.28572485",
         "0.024015298",
         "0.074213125"
        ],
        [
         "43",
         "0.07370379",
         "0.2077925",
         "-0.095056646",
         "0.16620795"
        ],
        [
         "44",
         "0.16620795",
         "0.16693579",
         "-0.12957728",
         "0.0"
        ],
        [
         "45",
         "0.17460886",
         "0.20730372",
         "-0.035022054",
         "0.047008324"
        ],
        [
         "46",
         "0.04700959",
         "0.12332026",
         "-0.028134493",
         "0.11881098"
        ],
        [
         "47",
         "0.118810475",
         "0.172291",
         "-0.083059855",
         "0.0"
        ],
        [
         "48",
         "0.107206374",
         "0.12608628",
         "0.018914202",
         "0.069963224"
        ],
        [
         "49",
         "0.06995556",
         "0.0943868",
         "-0.09590626",
         "0.0795816"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 150
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_prop</th>\n",
       "      <th>high_prop</th>\n",
       "      <th>low_prop</th>\n",
       "      <th>close_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142618</td>\n",
       "      <td>0.186183</td>\n",
       "      <td>-0.115067</td>\n",
       "      <td>0.049603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051011</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>-0.086403</td>\n",
       "      <td>0.087876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088019</td>\n",
       "      <td>0.090043</td>\n",
       "      <td>-0.062374</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191113</td>\n",
       "      <td>0.239535</td>\n",
       "      <td>-0.023476</td>\n",
       "      <td>0.162756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162756</td>\n",
       "      <td>0.200481</td>\n",
       "      <td>0.105695</td>\n",
       "      <td>0.172504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.163202</td>\n",
       "      <td>0.196745</td>\n",
       "      <td>-0.101741</td>\n",
       "      <td>0.171715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.171716</td>\n",
       "      <td>0.202343</td>\n",
       "      <td>-0.153074</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.151474</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>-0.103479</td>\n",
       "      <td>0.091243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.091243</td>\n",
       "      <td>0.213446</td>\n",
       "      <td>-0.019882</td>\n",
       "      <td>0.111623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.111623</td>\n",
       "      <td>0.125891</td>\n",
       "      <td>-0.111531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     open_prop  high_prop  low_prop  close_prop\n",
       "0     0.142618   0.186183 -0.115067    0.049603\n",
       "1     0.051011   0.110600 -0.086403    0.087876\n",
       "2     0.088019   0.090043 -0.062374    0.000000\n",
       "3     0.191113   0.239535 -0.023476    0.162756\n",
       "4     0.162756   0.200481  0.105695    0.172504\n",
       "..         ...        ...       ...         ...\n",
       "145   0.163202   0.196745 -0.101741    0.171715\n",
       "146   0.171716   0.202343 -0.153074    0.000000\n",
       "147   0.151474   0.218506 -0.103479    0.091243\n",
       "148   0.091243   0.213446 -0.019882    0.111623\n",
       "149   0.111623   0.125891 -0.111531    0.000000\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
