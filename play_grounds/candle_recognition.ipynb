{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee624fd3",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af322677",
   "metadata": {},
   "source": [
    "## cnn fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from importlib import import_module\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "class candle_model(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_channel, num_classes, lr=1e-3, threshold=0.5, label_weights_tensor=None,\n",
    "                 scheduler_name=None, scheduler_params=None, optimizer_params=None, optimizer_name=\"adamw\", dropout =0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "        # Enhanced Feature Extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # 1D convolution: in_channels=input_dim, out_channels=output_channels\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=output_channel, kernel_size=1),\n",
    "            nn.BatchNorm1d(output_channel),  # Added Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)  # Added Dropout\n",
    "        )\n",
    "\n",
    "        # Linear classifier\n",
    "        self.fc = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        # Loss with optional weights\n",
    "        if label_weights_tensor is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights_tensor)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len=1, input_dim)\n",
    "        x = x.transpose(1, 2)  # (batch, input_dim, 1)\n",
    "        out = self.feature_extractor(x)  # Pass through the sequential block\n",
    "        out = out.squeeze(2)  # (batch, output_channels)\n",
    "        logits = self.fc(out)  # (batch, num_classes)\n",
    "        return logits\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= self.threshold).float()\n",
    "        exact_acc = (preds == y_multi).all(dim=1).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc_exact\", exact_acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return {\"val_loss\": loss, \"probs\": probs, \"targets\": y_multi}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer and learning rate scheduler based on model parameters.\n",
    "        \"\"\"\n",
    "        # 1. Map string names to PyTorch classes\n",
    "        optimizer_map = {\n",
    "            \"adamw\": optim.AdamW,\n",
    "            \"adam\": optim.Adam,\n",
    "            # Add other optimizers here as needed\n",
    "        }\n",
    "        scheduler_map = {\n",
    "            \"reduce_on_plateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "            \"step_lr\": lr_scheduler.StepLR,\n",
    "            \"onecycle\": lr_scheduler.OneCycleLR,\n",
    "            # Add other schedulers here as needed\n",
    "        }\n",
    "\n",
    "        # 2. Get optimizer instance\n",
    "        optimizer_class = optimizer_map[self.optimizer_name]\n",
    "        optimizer = optimizer_class(self.parameters(), lr=self.lr, **self.optimizer_params)\n",
    "\n",
    "        # 3. Handle the \"no scheduler\" case\n",
    "        if self.scheduler_name is None or self.scheduler_name.lower() == \"none\":\n",
    "            return optimizer\n",
    "\n",
    "        # 4. Get scheduler instance with proper parameters\n",
    "        scheduler_class = scheduler_map[self.scheduler_name]\n",
    "\n",
    "        # Handle one-off cases like OneCycleLR which requires a specific total_steps\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = scheduler_class(\n",
    "                optimizer,\n",
    "                max_lr=self.lr,\n",
    "                total_steps=self.trainer.estimated_stepping_batches, # Requires PyTorch Lightning 2.0+\n",
    "                **self.scheduler_params\n",
    "            )\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"interval\": \"step\", # OneCycleLR updates on each step\n",
    "                },\n",
    "            }\n",
    "        \n",
    "        # Handle ReduceLROnPlateau, which requires monitoring a metric\n",
    "        if self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"monitor\": \"val_loss\", # Monitor a specific validation metric\n",
    "                },\n",
    "            }\n",
    "\n",
    "        # Handle all other schedulers (e.g., StepLR)\n",
    "        scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06941a2f",
   "metadata": {},
   "source": [
    "## fnn cnn fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b72be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from importlib import import_module\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "class candle_model(pl.LightningModule):\n",
    "    def __init__(self, input_dim, fnn_hidden_dim, output_channel, num_classes, lr=1e-3, threshold=0.5, label_weights_tensor=None,\n",
    "                 scheduler_name=None, scheduler_params=None, optimizer_params=None, optimizer_name=\"adamw\", dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "\n",
    "        self.fnn_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, fnn_hidden_dim),\n",
    "            nn.BatchNorm1d(fnn_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.cnn_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=fnn_hidden_dim, out_channels=output_channel, kernel_size=1),\n",
    "            nn.BatchNorm1d(output_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        if label_weights_tensor is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights_tensor)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1) # (batch, input_dim)\n",
    "        x = self.fnn_layer(x) # (batch, fnn_hidden_dim)\n",
    "        x = x.unsqueeze(2) # (batch, fnn_hidden_dim, 1) - reshape for Conv1d\n",
    "        out = self.cnn_extractor(x)\n",
    "        out = out.squeeze(2) # (batch, output_channel)\n",
    "        logits = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= self.threshold).float()\n",
    "        exact_acc = (preds == y_multi).all(dim=1).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc_exact\", exact_acc, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"probs\": probs, \"targets\": y_multi}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer and learning rate scheduler based on model parameters.\n",
    "        \"\"\"\n",
    "        # 1. Map string names to PyTorch classes\n",
    "        optimizer_map = {\n",
    "            \"adamw\": optim.AdamW,\n",
    "            \"adam\": optim.Adam,\n",
    "            # Add other optimizers here as needed\n",
    "        }\n",
    "        scheduler_map = {\n",
    "            \"reduce_on_plateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "            \"step_lr\": lr_scheduler.StepLR,\n",
    "            \"onecycle\": lr_scheduler.OneCycleLR,\n",
    "            # Add other schedulers here as needed\n",
    "        }\n",
    "\n",
    "        # 2. Get optimizer instance\n",
    "        optimizer_class = optimizer_map[self.optimizer_name]\n",
    "        optimizer = optimizer_class(self.parameters(), lr=self.lr, **self.optimizer_params)\n",
    "\n",
    "        # 3. Handle the \"no scheduler\" case\n",
    "        if self.scheduler_name is None or self.scheduler_name.lower() == \"none\":\n",
    "            return optimizer\n",
    "\n",
    "        # 4. Get scheduler instance with proper parameters\n",
    "        scheduler_class = scheduler_map[self.scheduler_name]\n",
    "\n",
    "        # Handle one-off cases like OneCycleLR which requires a specific total_steps\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = scheduler_class(\n",
    "                optimizer,\n",
    "                max_lr=self.lr,\n",
    "                total_steps=self.trainer.estimated_stepping_batches, # Requires PyTorch Lightning 2.0+\n",
    "                **self.scheduler_params\n",
    "            )\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"interval\": \"step\", # OneCycleLR updates on each step\n",
    "                },\n",
    "            }\n",
    "        \n",
    "        # Handle ReduceLROnPlateau, which requires monitoring a metric\n",
    "        if self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"monitor\": \"val_loss\", # Monitor a specific validation metric\n",
    "                },\n",
    "            }\n",
    "\n",
    "        # Handle all other schedulers (e.g., StepLR)\n",
    "        scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c3e6a",
   "metadata": {},
   "source": [
    "## full fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8740654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from importlib import import_module\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "class candle_model(pl.LightningModule):\n",
    "    def __init__(self, input_dim,num_classes, hidden_dim =10, lr=1e-3, threshold=0.5, label_weights_tensor=None,\n",
    "                 scheduler_name=None, scheduler_params=None, optimizer_params=None, optimizer_name=\"adamw\", dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "        if label_weights_tensor is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights_tensor)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fcn(x.squeeze(1)) # Squeeze the seq_len=1 dimension\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= self.threshold).float()\n",
    "        \n",
    "        # Calculate exact accuracy\n",
    "        exact_acc = (preds == y_multi).all(dim=1).float().mean()\n",
    "        \n",
    "        # Convert tensors to numpy arrays for sklearn metrics\n",
    "        y_true_np = y_multi.cpu().numpy()\n",
    "        y_preds_np = preds.cpu().numpy()\n",
    "        \n",
    "        # Calculate F1-macro and micro accuracy\n",
    "        f1_macro = f1_score(y_true_np, y_preds_np, average=\"macro\", zero_division=0)\n",
    "        acc_micro = accuracy_score(y_true_np, y_preds_np)\n",
    "        \n",
    "        # Log the metrics to Lightning\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log(\"val_acc_exact\", exact_acc, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc_micro\", acc_micro, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_f1_macro\", f1_macro, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return {\"val_loss\": loss, \"probs\": probs, \"targets\": y_multi}\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer and learning rate scheduler based on model parameters.\n",
    "        \"\"\"\n",
    "        # 1. Map string names to PyTorch classes\n",
    "        optimizer_map = {\n",
    "            \"adamw\": optim.AdamW,\n",
    "            \"adam\": optim.Adam,\n",
    "            # Add other optimizers here as needed\n",
    "        }\n",
    "        scheduler_map = {\n",
    "            \"reduce_on_plateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "            \"step_lr\": lr_scheduler.StepLR,\n",
    "            \"onecycle\": lr_scheduler.OneCycleLR,\n",
    "            # Add other schedulers here as needed\n",
    "        }\n",
    "\n",
    "        # 2. Get optimizer instance\n",
    "        optimizer_class = optimizer_map[self.optimizer_name]\n",
    "        optimizer = optimizer_class(self.parameters(), lr=self.lr, **self.optimizer_params)\n",
    "\n",
    "        # 3. Handle the \"no scheduler\" case\n",
    "        if self.scheduler_name is None or self.scheduler_name.lower() == \"none\":\n",
    "            return optimizer\n",
    "\n",
    "        # 4. Get scheduler instance with proper parameters\n",
    "        scheduler_class = scheduler_map[self.scheduler_name]\n",
    "\n",
    "        # Handle one-off cases like OneCycleLR which requires a specific total_steps\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = scheduler_class(\n",
    "                optimizer,\n",
    "                max_lr=self.lr,\n",
    "                total_steps=self.trainer.estimated_stepping_batches, # Requires PyTorch Lightning 2.0+\n",
    "                **self.scheduler_params\n",
    "            )\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"interval\": \"step\", # OneCycleLR updates on each step\n",
    "                },\n",
    "            }\n",
    "        \n",
    "        # Handle ReduceLROnPlateau, which requires monitoring a metric\n",
    "        if self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"monitor\": \"val_loss\", # Monitor a specific validation metric\n",
    "                },\n",
    "            }\n",
    "\n",
    "        # Handle all other schedulers (e.g., StepLR)\n",
    "        scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf70a7e",
   "metadata": {},
   "source": [
    "## cnn lstm (seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "class candle_cnn_multi_lstm(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        num_classes,\n",
    "        kernels=[1, 3, 5],\n",
    "        cnn_out_channels=32,\n",
    "        fusion_out_channels=64,\n",
    "        hidden_dim=128,\n",
    "        num_lstm_layers=1,\n",
    "        lr=1e-3,\n",
    "        threshold=0.5,\n",
    "        label_weights_tensor=None,\n",
    "        scheduler_name=None,\n",
    "        scheduler_params=None,\n",
    "        optimizer_params=None,\n",
    "        optimizer_name=\"adamw\",\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name or None\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "        self.threshold = threshold\n",
    "        self.lr = lr\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.kernels = kernels\n",
    "        self.num_branches = len(kernels)\n",
    "        self.cnn_out_channels = cnn_out_channels\n",
    "        self.fusion_out_channels = fusion_out_channels\n",
    "\n",
    "        # --- Multi-branch convolutions ---\n",
    "        branches = []\n",
    "        for k in kernels:\n",
    "            pad = (k - 1) // 2  # approximate \"same\" padding\n",
    "            branches.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=input_dim,\n",
    "                        out_channels=cnn_out_channels,\n",
    "                        kernel_size=k,\n",
    "                        padding=pad,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(cnn_out_channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(dropout),\n",
    "                )\n",
    "            )\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "\n",
    "        # --- Fusion conv2d ---\n",
    "        # After stacking, shape = (B, num_branches, C, T)\n",
    "        # We want kernel height = cnn_out_channels to \"collapse\" feature dim\n",
    "        self.fusion_conv2d = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.num_branches,\n",
    "                out_channels=self.fusion_out_channels,\n",
    "                kernel_size=(self.cnn_out_channels, 1),\n",
    "                padding=(0, 0),\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # --- LSTM ---\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.fusion_out_channels,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_lstm_layers > 1 else 0,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "\n",
    "        # --- Final classifier ---\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        # --- Loss ---\n",
    "        if label_weights_tensor is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights_tensor)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, input_dim)\n",
    "        x = x.transpose(1, 2)  # -> (B, input_dim, T)\n",
    "\n",
    "        # Each branch processes the same input\n",
    "        branch_outs = [branch(x) for branch in self.branches]  # list of (B, C, T)\n",
    "\n",
    "        # Stack into (B, num_branches, C, T)\n",
    "        stacked = torch.stack(branch_outs, dim=1)\n",
    "\n",
    "        # Fusion conv2d expects (B, num_branches, C, T)\n",
    "        fused = self.fusion_conv2d(stacked)  # -> (B, fusion_out_channels, 1, T)\n",
    "\n",
    "        fused = fused.squeeze(2).transpose(1, 2)  # -> (B, T, fusion_out_channels)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(fused)  # -> (B, T, hidden_dim)\n",
    "        last_hidden = lstm_out[:, -1, :]  # (B, hidden_dim)\n",
    "\n",
    "        logits = self.fc(last_hidden)  # (B, num_classes)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_multi = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y_multi.float())\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= self.threshold).float()\n",
    "        exact_acc = (preds == y_multi).all(dim=1).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc_exact\", exact_acc, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"probs\": probs, \"targets\": y_multi}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_map = {\n",
    "            \"adamw\": optim.AdamW,\n",
    "            \"adam\": optim.Adam,\n",
    "        }\n",
    "        scheduler_map = {\n",
    "            \"reduce_on_plateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "            \"step_lr\": lr_scheduler.StepLR,\n",
    "            \"onecycle\": lr_scheduler.OneCycleLR,\n",
    "        }\n",
    "\n",
    "        optimizer_class = optimizer_map[self.optimizer_name]\n",
    "        optimizer = optimizer_class(self.parameters(), lr=self.lr, **self.optimizer_params)\n",
    "\n",
    "        if self.scheduler_name is None or self.scheduler_name.lower() == \"none\":\n",
    "            return optimizer\n",
    "\n",
    "        scheduler_class = scheduler_map[self.scheduler_name]\n",
    "\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = scheduler_class(\n",
    "                optimizer,\n",
    "                max_lr=self.lr,\n",
    "                total_steps=self.trainer.estimated_stepping_batches,\n",
    "                **self.scheduler_params,\n",
    "            )\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"},\n",
    "            }\n",
    "\n",
    "        if self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n",
    "            }\n",
    "\n",
    "        scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4f102",
   "metadata": {},
   "source": [
    "## full fnn (seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "class candle_fnn(pl.LightningModule):\n",
    "    def __init__(self, input_dim, seq_len, hidden_dim=128, num_classes=2,\n",
    "                 lr=1e-3, threshold=0.5, label_weights_tensor=None,\n",
    "                 scheduler_name=None, scheduler_params=None,\n",
    "                 optimizer_params=None, optimizer_name=\"adamw\", dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "\n",
    "        # Flatten input to (B, seq_len * input_dim)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(seq_len * input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "        if label_weights_tensor is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights_tensor)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, input_dim)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        logits = self.fc_layers(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y.float())\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= self.threshold).float()\n",
    "        exact_acc = (preds == y).all(dim=1).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc_exact\", exact_acc, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"probs\": probs, \"targets\": y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_map = {\"adamw\": optim.AdamW, \"adam\": optim.Adam}\n",
    "        scheduler_map = {\n",
    "            \"reduce_on_plateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "            \"step_lr\": lr_scheduler.StepLR,\n",
    "            \"onecycle\": lr_scheduler.OneCycleLR,\n",
    "        }\n",
    "\n",
    "        optimizer = optimizer_map[self.optimizer_name](self.parameters(), lr=self.lr, **self.optimizer_params)\n",
    "\n",
    "        if self.scheduler_name is None or self.scheduler_name.lower() == \"none\":\n",
    "            return optimizer\n",
    "\n",
    "        scheduler_class = scheduler_map[self.scheduler_name]\n",
    "\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = scheduler_class(\n",
    "                optimizer,\n",
    "                max_lr=self.lr,\n",
    "                total_steps=self.trainer.estimated_stepping_batches,\n",
    "                **self.scheduler_params\n",
    "            )\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n",
    "\n",
    "        if self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}}\n",
    "\n",
    "        scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cadd31",
   "metadata": {},
   "source": [
    "## cnn fnn (seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb818dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_cnn_fnn(pl.LightningModule):\n",
    "    def __init__(self, input_dim, seq_len, cnn_out_channels=32, hidden_dim=128, num_classes=2,\n",
    "                 kernels=[1,3,5], lr=1e-3, threshold=0.5, label_weights_tensor=None,\n",
    "                 scheduler_name=None, scheduler_params=None,\n",
    "                 optimizer_params=None, optimizer_name=\"adamw\", dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.cnn_out_channels = cnn_out_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.kernels = [k for k in kernels if k <= seq_len]  # sanity check\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.scheduler_name = scheduler_name\n",
    "        self.optimizer_params = optimizer_params or {}\n",
    "        self.scheduler_params = scheduler_params or {}\n",
    "\n",
    "        # --- Multi-kernel CNN branches ---\n",
    "        self.branches = nn.ModuleList()\n",
    "        for k in self.kernels:\n",
    "            pad = (k - 1) // 2\n",
    "            self.branches.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=input_dim, out_channels=cnn_out_channels, kernel_size=k, padding=pad),\n",
    "                    nn.BatchNorm1d(cnn_out_channels),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # LSTM after CNN\n",
    "        self.lstm = nn.LSTM(input_size=cnn_out_channels * len(self.kernels),\n",
    "                            hidden_size=hidden_dim,\n",
    "                            batch_first=True)\n",
    "\n",
    "        # Final linear layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        if label_weights_tensor is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=label_weights_tensor)\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, input_dim)\n",
    "        x = x.transpose(1,2)  # (B, input_dim, seq_len)\n",
    "        branch_outs = [branch(x) for branch in self.branches]  # list of (B, C, seq_len)\n",
    "        x_cat = torch.cat(branch_outs, dim=1)  # (B, C*num_branches, seq_len)\n",
    "        x_cat = x_cat.transpose(1,2)  # (B, seq_len, C*num_branches)\n",
    "        lstm_out, _ = self.lstm(x_cat)  # (B, seq_len, hidden_dim)\n",
    "        logits = self.fc(lstm_out[:, -1, :])  # use last time step\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y.float())\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= self.threshold).float()\n",
    "        exact_acc = (preds == y).all(dim=1).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc_exact\", exact_acc, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"probs\": probs, \"targets\": y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_map = {\"adamw\": optim.AdamW, \"adam\": optim.Adam}\n",
    "        scheduler_map = {\n",
    "            \"reduce_on_plateau\": lr_scheduler.ReduceLROnPlateau,\n",
    "            \"step_lr\": lr_scheduler.StepLR,\n",
    "            \"onecycle\": lr_scheduler.OneCycleLR,\n",
    "        }\n",
    "\n",
    "        optimizer = optimizer_map[self.optimizer_name](self.parameters(), lr=self.lr, **self.optimizer_params)\n",
    "\n",
    "        if self.scheduler_name is None or self.scheduler_name.lower() == \"none\":\n",
    "            return optimizer\n",
    "\n",
    "        scheduler_class = scheduler_map[self.scheduler_name]\n",
    "\n",
    "        if self.scheduler_name == \"onecycle\":\n",
    "            scheduler = scheduler_class(\n",
    "                optimizer,\n",
    "                max_lr=self.lr,\n",
    "                total_steps=self.trainer.estimated_stepping_batches,\n",
    "                **self.scheduler_params\n",
    "            )\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}\n",
    "\n",
    "        if self.scheduler_name == \"reduce_on_plateau\":\n",
    "            scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}}\n",
    "\n",
    "        scheduler = scheduler_class(optimizer, **self.scheduler_params)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc3c22",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e1f85",
   "metadata": {},
   "source": [
    "## lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60570c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from preprocess.multilabel_preprocess2 import preprocess_csv_multilabel\n",
    "from models.LSTM.lstm_multi_label import LSTMMultiLabelClassifier\n",
    "from utils.print_batch import print_batch\n",
    "from utils.json_to_csv import json_to_csv_in_memory  # <-- new util\n",
    "from utils.multilabel_threshold_tuning import tune_thresholds_nn\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "\n",
    "def evaluate_model(model, val_loader, mlb, threshold=0.2, return_probs=False, return_preds=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= threshold).int()\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    # Reporting\n",
    "    print(\"\\nðŸ“Š Validation Report (Multi-label):\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "    print(\"\\nðŸ§® Multi-label Confusion Matrices (per class):\")\n",
    "    mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "    for i, cls in enumerate(mlb.classes_):\n",
    "        print(f\"\\nClass '{cls}':\")\n",
    "        print(mcm[i])\n",
    "\n",
    "    exact_match = np.all(all_preds == all_labels, axis=1).mean()\n",
    "    micro_acc = (all_preds == all_labels).mean()\n",
    "\n",
    "    print(\"\\nâœ… Exact match ratio:\", exact_match)\n",
    "    print(\"âœ… Micro accuracy (per-label):\", micro_acc)\n",
    "\n",
    "    # Flexible return values\n",
    "    if return_probs and return_preds:\n",
    "        return exact_match, micro_acc, all_probs, all_preds\n",
    "    elif return_probs:\n",
    "        return exact_match, micro_acc, all_probs\n",
    "    elif return_preds:\n",
    "        return exact_match, micro_acc, all_preds\n",
    "    else:\n",
    "        return exact_match, micro_acc\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_json=None,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    seq_len=1,\n",
    "    hidden_dim=10,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=200,\n",
    "    save_model=False,\n",
    "    return_val_accuracy=True,\n",
    "    test_mode=False,\n",
    "    tune_thresholds = False,\n",
    "    include_no_label = False,\n",
    "    label_weighting = \"none\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an LSTM classification model with labels coming from JSON (in-memory CSV).\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_class_{timestamp}.pt\"\n",
    "    meta_out = f\"{model_out_dir}/lstm_meta_class_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Prepare labels ---\n",
    "    if labels_json is not None:\n",
    "        csv_string = json_to_csv_in_memory(labels_json)   # returns CSV string\n",
    "        labels_csv = io.StringIO(csv_string)              # file-like for pandas\n",
    "    else:\n",
    "        raise ValueError(\"labels_json must be provided\")\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features),\n",
    "            # make_step(add_candle_rocp),\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        False, \n",
    "        # True\n",
    "                ]\n",
    "    )\n",
    "        # --- Get dataset(s) ---\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=True,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label = include_no_label\n",
    "        )\n",
    "    else:\n",
    "        full_dataset, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=False,\n",
    "            debug_sample=True,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label =include_no_label\n",
    "        )\n",
    "\n",
    "    # --- Model config ---\n",
    "    input_dim = train_ds[0][0].shape[1] if do_validation else full_dataset[0][0].shape[1]\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    label_weights_tensor = torch.tensor(label_weights, dtype=torch.float32)\n",
    "\n",
    "    model = LSTMMultiLabelClassifier(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "        lr=lr,\n",
    "        label_weights_tensor=label_weights_tensor\n",
    "    )\n",
    "\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"lr\": lr,\n",
    "\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    # --- DataLoaders ---\n",
    "    if do_validation:\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "    else:\n",
    "        train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = None\n",
    "\n",
    "    # --- Debug batch ---\n",
    "    if test_mode:\n",
    "        global df_seq\n",
    "        df_seq = print_batch(train_loader, feature_columns, batch_idx=2)\n",
    "\n",
    "    # --- Trainer ---\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        log_every_n_steps=10,\n",
    "        fast_dev_run=test_mode,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Save model & metadata ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"seq_len\": seq_len,\n",
    "            \"lr\": lr,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"label_classes\": label_encoder.classes_,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"include_no_label\":include_no_label\n",
    "        }, meta_out)\n",
    "        print(f\"\\nâœ… Model saved to {model_out}\")\n",
    "        print(f\"âœ… Meta saved to {meta_out}\")\n",
    "\n",
    "    # --- Validation accuracy ---\n",
    "    val_acc_exact, val_acc_micro = None, None\n",
    "\n",
    "    if do_validation:\n",
    "        y_true_val = np.vstack([y for _, y in val_loader.dataset])\n",
    "\n",
    "        # default eval\n",
    "        val_acc_exact_default, val_acc_micro_default, y_probs, y_pred_default = evaluate_model(\n",
    "            model, val_loader, label_encoder, threshold=0.5, return_probs=True, return_preds=True\n",
    "        )\n",
    "\n",
    "        if tune_thresholds:\n",
    "            optimal_thresholds = tune_thresholds_nn(y_true=y_true_val, y_probs=y_probs)\n",
    "            y_pred_tuned = (y_probs >= np.array(optimal_thresholds)).astype(int)\n",
    "\n",
    "            val_acc_exact_tuned = np.all(y_pred_tuned == y_true_val, axis=1).mean()\n",
    "            val_acc_micro_tuned = (y_pred_tuned == y_true_val).mean()\n",
    "        else:\n",
    "            val_acc_exact_tuned, val_acc_micro_tuned = val_acc_exact_default, val_acc_micro_default\n",
    "            y_pred_tuned = y_pred_default   # <-- FIX: ensures it's always defined\n",
    "\n",
    "        if return_val_accuracy:\n",
    "            from sklearn.metrics import f1_score\n",
    "            val_f1_macro = f1_score(y_true_val, y_pred_tuned, average=\"macro\", zero_division=0)\n",
    "\n",
    "            return {\n",
    "                \"accuracy_exact\": val_acc_exact_tuned,\n",
    "                \"accuracy_micro\": val_acc_micro_tuned,\n",
    "                \"f1_macro\": val_f1_macro\n",
    "            }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        labels_json=\"/home/iatell/projects/meta-learning/data/candle_labels.json\",  # JSON labels, no CSV needed on disk\n",
    "        do_validation=True,\n",
    "        save_model=True,\n",
    "        include_no_label = True,\n",
    "        label_weighting=\"scale_pos\",\n",
    "        test_mode= False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02599c",
   "metadata": {},
   "source": [
    "## cnn fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name              | Type              | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | feature_extractor | Sequential        | 140    | train\n",
      "1 | fc                | Linear            | 126    | train\n",
      "2 | criterion         | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------------------\n",
      "266       Trainable params\n",
      "0         Non-trainable params\n",
      "266       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "Total sequences collected: 444\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Original label(s): ['H']\n",
      "Cleaned label(s): ['H']\n",
      "Encoded: [0 1 0 0 0 0]\n",
      "Feature shape: (1, 4)\n",
      "First few timesteps:\n",
      " [[0.0091133  0.06722008 0.05172484 0.3       ]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6453b9d3fc4ede8ba5a41ae4b81a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c760eb872e04a2291894011ae815bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cf8f4c73e54da8b67e7999eb6529af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21ef6cd447b4cd1bf15e8495df36b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5134d387c3b0463ba4dc0a2cdb9e5fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5fe75677d6403394ce5da332e47fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37a4ac622bc4420a85757ec5727c003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e20f68920f74376bc3b3e59128a2646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000512ef388948febcb5773cd463ef49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1eca3153bb4f379f24e2ed0fe47f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f158489343432eb78fa44b89508ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6a993bac54723930a5aa02828612e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5bf43b95b34c3981e91e3ac9d1d01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5793642fbefb4629b38c2f82766cc7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6516e425ee414dc98e062bb6a10c20fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026bdd86e1de41a6bf3b71a6f541173f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46539ac0453a4598bdff63210946b2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b871fe47c0b451ea6fc33a5294d7166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9adfd1d5a0946ee87ecd17e5b229a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b81d485abe4732be7ef91fcbbf86e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5261f071710b4111af0028203ad81b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c291cbb0b64a348de4981bd90a2e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce11af56e6b4a8785ec8096f23d043f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64296e2dde1a4cdd80a5cf34db4cf1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239e6c2e9acf4ec2afd4e4f07ac96bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e63257a4fc04a969a326e3507386d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd4f0b1aab5489eb3dc9a407ec01ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89635176788d49d4878056b59ab2ed32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3713d7801674d74b6d4df5cd0348988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e5cd83540247b5b97ba50beab4b7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0759c1dc1cc4458985bb48d5eb833133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5000607cc54557a14a547d1323d9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09be9761a8e46cf91b7a29a0a923978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32425705bcdd45208a6472cba2fc1bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ebd770b1024f82baf6b6b8d14e6af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d0aeff353b461bbdee300eeea42263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d35bda816a44fa783d6f1224dd197fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51777a5a548a46c7959459d5ae691a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21f5971e233471bba64ca478ae411a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efa2bc14af94c13b11c7977a2491517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d5b444393444c7816c98402b629ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401c0d44536a40538e56a8f3c5b6a282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6aa85ec40045b7be9c225b06db3993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba054f1db81496697e2d2a134096999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcba059f042401cbe704856161bcca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f762b75f0b2c422492a8c6e3c5979905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65b65e5718a4348be1e8fa06283f38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4569a03d594035a5a2b9dd5021de7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab7edcc89924148b5b390125693d5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a98f5d9c1b408f896a8134b398905c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36617f24177247bf84a4e2f48dbdea74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edcecabfb69456f91730d634450e558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75479ac26648408e9df602da6959eb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44607165ee5342e58762244c131adb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98abaaa079054deb9a80068503ce9c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da33710b85f4389bf7f148dc461f968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c36aff13896414590cc90364c59a922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6cea282042247d7a6f468827d9d6f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41ab19d08a1471780299e422457594e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b3f409c7e347f591718632f9a72430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f71f9d2b4d48bcbfbc3697a1f3f4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef9efcea20c4d189440b67763bcdc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913ecebe81564d6eb0c9e35b1a0ca713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524b40bda50847b0a45c95eefe903894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e93654d69ca44dcaa4befe118e82757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d64416ec8b408ebae438455da66b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d327861a4c5b49c4b0d9df69948d4348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0d90f9020040b0b757f0c7e954db08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e77c83a419a400eaaffa73d3d93c123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31111b08a6a448b784c67ea845dad75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752ca8c5e5e543268e7269afac444cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b82c64e314461181b2f78c5b491950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489c182b90844520a7e276c5560d3ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f51be7c5e9a41c4815be04e3ee79f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b843dbe3464bfc8ff51d359fa12b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e3271678d049d68e437aafb555b44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b684c67d0464d43b695db629c0fa574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a0376885ba46b693923a315ba4df5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf1259e898241d5b4ef8b4e58597f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67132e34695a4190a1d6b52e1c558b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bd4aa268aa4dabbce2b3f38a2d84e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c43888a7f1444a2a98db8e316418b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce899175d334788bf7618fc8cd5bf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4218f34926740b1a38414c821fabd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc70f6d276c4702aa5b76e2427fc80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cfdf54a44b4c459998d2642f4738b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c8c7818c2f4c16be892643a3d7faba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd86aaef616646f18a02bd9fa39925f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00e07d8212c45b2b3d098e3f1f8a42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabc393106274db797dbb4ad9dd16463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e223a612e3e146d4b5a14c0451311c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ef851764be4fe596052ae3723619bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910a5ecfdb4c4c6683249235e03df8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfa72dd874b48fe8f584532aa7398d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5107815cb2f34d488cf8cfb385ab8e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e4c3ba27864912873cf49b4e51e49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdbe486bb834f389d05a62e30a4c2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c12da9b1884df1b26aafd8417ac467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b28c9e902b448a0a3f6d16238648f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb054c85f36490c8d570c75ee7e8b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6764823c19064881a7fb1e1599e8c10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00476484a9214c1e9ee19b63d2ce3699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6dacaf7829432fa2f57a15e3eab42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9654a3cd50f64b938f5c8ece691c5a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279a57f8da054719852cda990a9c67ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c166ea18c34cb7b836a4803ec86ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975baa42763f48c2a3ae5f6f99c6ab84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47b4725767c4043b7beae072175c373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de119e6b5017471ba078ac38671a3c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3f9d78ecae4d78ad6b9fdb52b63e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bd281e605d474baaa931c8e236c359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e969383f80b4720b599cb4d0b817956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527ff5d6baac42329c6d96e3722f83fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f77e4e11acd49ba8f06baafb593fe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b02b3a6f2e44df3abeb2ad613f72aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30c89bb6f5740baac6cb5192ebbd6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd8fed29b3a4518bc2fadf38e2bf817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7dbc6861fc4bf581da670eac4f470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5c8fc531c74e8eaad716d21122af5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01aa049a702743c7a4a006005947868e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a53bccee70748c48a23fd4483ea2707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5b827ad05d4e6eacd3f94bdcb1be85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9406187f74ea8ac04dff35d70c509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4537c1430543ca9fde346fdfb4b51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ca9a90d7234c58beb9ab5a6f5d61d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2de2092df7d4680beb2b71deb855c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c8b177248f4ca9aee0157b3ccc388f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d884507001b4bd594501025129a6279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9d4d24bcdc472caed542e362915397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1b75ae0c6743eb9e7e8353fef22479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3940970938fd41d894efe7bef44ef542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35076d1d0adc418b8cbc8726c8434545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bece76bdbd462ebb9b91329e3d6490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840ad8eb0aaf49f5a0e595ac443691c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3491d218d8f54f628310284ae8bca742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9a52d0e8ae4cbabfb352372859366a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8de060add54d52ad06af22e6a45682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a19c81b7ac14c219a0fa46e157690f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e9a0f7efc24720bafbbf1207a97140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611eb90531bf4dd9af350044b9a57dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066ef9f9ee4a4e7faaf1f431ef1827f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371b19be7cbf460f860cc4a83098bded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d5d14273444cd58768a71d6a45ffbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b0aaddc6e74981b34a883d31d5b8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ccc2dd8c2a435eb178a8600ae962b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5472c7911e254a7685079798d241f52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31be4e7451da4ac8987561af6130dabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e9b9d431624bcbac9606bb82c8070f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8c4dad75944571bc617ef8c52715cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f514d93fcbb4a918c3b7cac0dd096af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3e2907e6144ca6ae9902845b6d5642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d458aeb3854e16bc6ab583b7a25a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168d992954ef449287f2b059f0a7dd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45f2dff236642b0a758c033db84b625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf99e759a844272bfa0f18a6f8697f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31110226f9944cdb4f85e6b52430320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f95d97fa8504971956d0b3630ae57c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc6175d445347609073e2f035641ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbeab7c3fc14de28e1cab2e31a363cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af7dba080ae46c08c73e046f4651eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c17556635140788bc86a2d0d838389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26892a6d7a22424698e394f3fd244e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308c08a63cbb4d01ad308866595685c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd011488f704aa298d59e085e70b47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eca4a6a41bc44bc907d97fc7d3d494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9699560403af45beb945df19270cb35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd71a1fb074e4b2d8a485d3cc447ce51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26505841ed84d0f836232d639bee281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc65e56d1ac4aa883684cc9aa5a01a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cf62e7d48a4296810630302bcba4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757dcb2789154df6a33f2499acc3eb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fc47281e3d4a0088b854f4b57f6913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fb24c3141d46108e17db437c24a243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6ad17c58c84679a07a83e6b5648a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6246cececd4736b816edf0d7676aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712de683a9af459f9e839e27b8769e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3149ebe61ed34fbe87da83d0ed0a8e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5ab6c4d42040adaaceff77ad429361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513f2ba20b7e4f79a07d3bd32275ec11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9967ebb3641d4212bc370fbe234179ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b086de5393741b4bc16dd9f1c64f902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d370dddc3d024d8781343cfbe7ac6fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2c8fed367447c6840ce437e3192538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd528fb683048a7bc860649b01a271b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b187eb228fb146c594a82082c8e7fae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e897520859134bb9a55e899c8a91af2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac8c8f5ddc34b62b06a828202eac403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7091f236298f4e8cb39f7f7be556c95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1e4d0bc291468d87496a4f028e9bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecaa45e1f51420eb9a18ac881be02f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17f00cc92474cdea7f85f2244d8731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5c18f0fb9842bdb0d88ac4e717820d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b99106b36741f4a15c715e00e8c1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fc5466973f463c8094051942f63c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7632c6c8495b434abb3b961f9309ccf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98428fb6de5b4a89baecc272eaaf809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98850ef9aaa14369bb3f6be726bae9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d11330ccb241c6802f5a3a75a26877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e1437a04e34b6fbc96841aa5038f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e855f8eac2477f92bce687e29e63bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b89b2b80baa4882bfa7347b6314600f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f05f2238207445d9e25f2bc34fdab95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Validation Report (Multi-label):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.76      0.95      0.85        43\n",
      "           H       0.29      1.00      0.45         7\n",
      "           I       0.33      1.00      0.50         2\n",
      "           q       0.15      0.86      0.26         7\n",
      "           s       0.58      0.92      0.71        38\n",
      "           v       0.98      0.81      0.89        80\n",
      "\n",
      "   micro avg       0.62      0.88      0.73       177\n",
      "   macro avg       0.52      0.92      0.61       177\n",
      "weighted avg       0.78      0.88      0.79       177\n",
      " samples avg       0.59      0.82      0.66       177\n",
      "\n",
      "\n",
      "ðŸ§® Multi-label Confusion Matrices (per class):\n",
      "\n",
      "Class '+':\n",
      "[[33 13]\n",
      " [ 2 41]]\n",
      "\n",
      "Class 'H':\n",
      "[[65 17]\n",
      " [ 0  7]]\n",
      "\n",
      "Class 'I':\n",
      "[[83  4]\n",
      " [ 0  2]]\n",
      "\n",
      "Class 'q':\n",
      "[[48 34]\n",
      " [ 1  6]]\n",
      "\n",
      "Class 's':\n",
      "[[26 25]\n",
      " [ 3 35]]\n",
      "\n",
      "Class 'v':\n",
      "[[ 8  1]\n",
      " [15 65]]\n",
      "\n",
      "âœ… Exact match ratio: 0.2696629213483146\n",
      "âœ… Micro accuracy (per-label): 0.7846441947565543\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from preprocess.multilabel_preprocess2 import preprocess_csv_multilabel\n",
    "from utils.print_batch import print_batch\n",
    "from utils.json_to_csv import json_to_csv_in_memory  # <-- new util\n",
    "from utils.multilabel_threshold_tuning import tune_thresholds_nn\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "def evaluate_model(model, val_loader, mlb, threshold=0.2, return_probs=False, return_preds=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= threshold).int()\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    # Reporting\n",
    "    print(\"\\nðŸ“Š Validation Report (Multi-label):\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "    print(\"\\nðŸ§® Multi-label Confusion Matrices (per class):\")\n",
    "    mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "    for i, cls in enumerate(mlb.classes_):\n",
    "        print(f\"\\nClass '{cls}':\")\n",
    "        print(mcm[i])\n",
    "\n",
    "    exact_match = np.all(all_preds == all_labels, axis=1).mean()\n",
    "    micro_acc = (all_preds == all_labels).mean()\n",
    "\n",
    "    print(\"\\nâœ… Exact match ratio:\", exact_match)\n",
    "    print(\"âœ… Micro accuracy (per-label):\", micro_acc)\n",
    "\n",
    "    # Flexible return values\n",
    "    if return_probs and return_preds:\n",
    "        return exact_match, micro_acc, all_probs, all_preds\n",
    "    elif return_probs:\n",
    "        return exact_match, micro_acc, all_probs\n",
    "    elif return_preds:\n",
    "        return exact_match, micro_acc, all_preds\n",
    "    else:\n",
    "        return exact_match, micro_acc\n",
    "\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_json=None,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    seq_len=1,\n",
    "    # hidden_dim=10,\n",
    "    output_channel=20,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=200,\n",
    "    save_model=False,\n",
    "    return_val_accuracy=True,\n",
    "    test_mode=False,\n",
    "    tune_thresholds = False,\n",
    "    include_no_label = False,\n",
    "    label_weighting = \"none\",\n",
    "    scheduler_name = \"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3} ,\n",
    "    optimizer_name= \"adamw\",\n",
    "    dropout = 0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an LSTM classification model with labels coming from JSON (in-memory CSV).\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_class_{timestamp}.pt\"\n",
    "    meta_out = f\"{model_out_dir}/lstm_meta_class_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Prepare labels ---\n",
    "    if labels_json is not None:\n",
    "        csv_string = json_to_csv_in_memory(labels_json)   # returns CSV string\n",
    "        labels_csv = io.StringIO(csv_string)              # file-like for pandas\n",
    "    else:\n",
    "        raise ValueError(\"labels_json must be provided\")\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features),\n",
    "            # make_step(add_candle_rocp),\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        False, \n",
    "        # True\n",
    "                ]\n",
    "    )\n",
    "        # --- Get dataset(s) ---\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=True,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label = include_no_label\n",
    "        )\n",
    "    else:\n",
    "        full_dataset, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=False,\n",
    "            debug_sample=True,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label =include_no_label\n",
    "        )\n",
    "\n",
    "    # --- Model config ---\n",
    "    input_dim = train_ds[0][0].shape[1] if do_validation else full_dataset[0][0].shape[1]\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    label_weights_tensor = torch.tensor(label_weights, dtype=torch.float32)\n",
    "\n",
    "    model = candle_model(\n",
    "        input_dim=input_dim,\n",
    "        # hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        output_channel=output_channel,\n",
    "        lr=lr,\n",
    "        label_weights_tensor=label_weights_tensor,\n",
    "        scheduler_name = scheduler_name,\n",
    "        optimizer_name= optimizer_name,\n",
    "        optimizer_params= optimizer_params,\n",
    "        scheduler_params= scheduler_params ,\n",
    "        dropout= dropout\n",
    "    )\n",
    "\n",
    "    init_args = {\n",
    "    \"input_dim\": input_dim,\n",
    "    # \"hidden_dim\": hidden_dim,\n",
    "    \"output_channel\": output_channel,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"lr\": lr,\n",
    "    \"scheduler_name\" : scheduler_name,\n",
    "    \"optimizer_params\":optimizer_params,\n",
    "    \"scheduler_params\":scheduler_params,\n",
    "    \"optimizer_name\": optimizer_name,\n",
    "    \"dropout\":dropout\n",
    "}\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    # --- DataLoaders ---\n",
    "    if do_validation:\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "    else:\n",
    "        train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = None\n",
    "\n",
    "    # --- Debug batch ---\n",
    "    if test_mode:\n",
    "        global df_seq\n",
    "        df_seq = print_batch(train_loader, feature_columns, batch_idx=2)\n",
    "\n",
    "    # --- Trainer ---\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        log_every_n_steps=10,\n",
    "        fast_dev_run=test_mode,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Save model & metadata ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            # \"hidden_dim\": hidden_dim,\n",
    "            \"output_channel\": output_channel,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"seq_len\": seq_len,\n",
    "            \"lr\": lr,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"label_classes\": label_encoder.classes_,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"include_no_label\":include_no_label\n",
    "        }, meta_out)\n",
    "        print(f\"\\nâœ… Model saved to {model_out}\")\n",
    "        print(f\"âœ… Meta saved to {meta_out}\")\n",
    "\n",
    "    # --- Validation accuracy ---\n",
    "    val_acc_exact, val_acc_micro = None, None\n",
    "\n",
    "\n",
    "    if do_validation and return_val_accuracy:\n",
    "        y_true_val = np.vstack([y for _, y in val_loader.dataset])\n",
    "\n",
    "        # Always run default evaluation to get probabilities\n",
    "        val_acc_exact_default, val_acc_micro_default, y_probs, y_pred_default = evaluate_model(\n",
    "            model, val_loader, label_encoder, threshold=0.5, return_probs=True, return_preds=True\n",
    "        )\n",
    "\n",
    "        # Use tuned thresholds if the option is enabled\n",
    "        if tune_thresholds:\n",
    "            optimal_thresholds = tune_thresholds_nn(y_true=y_true_val, y_probs=y_probs)\n",
    "            y_pred_tuned = (y_probs >= np.array(optimal_thresholds)).astype(int)\n",
    "        else:\n",
    "            y_pred_tuned = y_pred_default\n",
    "\n",
    "        # Calculate all final metrics based on the chosen prediction set\n",
    "        from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "        # Use the `y_pred_tuned` for all final metrics\n",
    "        final_val_acc_exact = np.all(y_pred_tuned == y_true_val, axis=1).mean()\n",
    "        final_val_acc_micro = (y_pred_tuned == y_true_val).mean()\n",
    "        final_val_f1_macro = f1_score(y_true_val, y_pred_tuned, average=\"macro\", zero_division=0)\n",
    "        return {\n",
    "            \"val_acc_exact\": float(final_val_acc_exact),\n",
    "            \"val_acc_micro\": float(final_val_acc_micro),\n",
    "            \"val_f1_macro\": float(final_val_f1_macro)\n",
    "        }\n",
    "\n",
    "    return {} # Return an empty dict if not returning accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        labels_json=\"/home/iatell/projects/meta-learning/data/candle_labels.json\",  # JSON labels, no CSV needed on disk\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        include_no_label = False,\n",
    "        label_weighting=\"scale_pos\",\n",
    "        test_mode= False,\n",
    "        output_channel = 20\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e82861",
   "metadata": {},
   "source": [
    "## full fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50ada9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "Total sequences collected: 444\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Original label(s): ['H']\n",
      "Cleaned label(s): ['H']\n",
      "Encoded: [0 1 0 0 0 0]\n",
      "Feature shape: (1, 4)\n",
      "First few timesteps:\n",
      " [[0.0091133  0.06722008 0.05172484 0.3       ]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 19:03:18.395508: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-24 19:03:18.629331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758727998.708937   17710 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758727998.732097   17710 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758727998.920936   17710 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758727998.920965   17710 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758727998.920966   17710 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758727998.920967   17710 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-24 19:03:18.943950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | fcn       | Sequential        | 266    | train\n",
      "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
      "--------------------------------------------------------\n",
      "266       Trainable params\n",
      "0         Non-trainable params\n",
      "266       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6433c449526d417b9a459a4f7829c128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c1aa8e2be24cc09f820bc54b01e3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d114bbdfb7de44fd8e3fa0b5c4583a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e154b77abb224e4982f2814279cad115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4f681138ff405f96ca9700f42143a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f568ef6617845718ecc4fd5e147e0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d171d16a6564e3f851eb2d67497a646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac93919c07ec4128934c4d707e91c533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca12adefe88493dbedc173ee7996ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123fe91a3e784cdda32cf1f6b40849a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ee0d6e26a34d06af27a0742439cfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b82262df3644e1f8afe766e31a521a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8503b8ac77b40da8fac45c535a06e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa016d37a62490a92a249016d1e4f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08efabc2f904bdf81281551b88214bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2e1c22c865458489209cfa8cd98688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4287ddc69be41cdaf2446cbf6871e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a1791d749c4b55ab0a56f1963ebe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0208afda7494e2cb01e86ccc797adc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbf47dbc6354dee8eca3b43edf28dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad14c1b4d5d4ea8b8d82b6ca47070e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e133641c91045c98a895a3f321e795a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5337e9441e9542e2bfae2688a99f5bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc85a5a41624a2da708ff1c0751af20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ca7696188641a2ab20a383530d93ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c257680e2aa84690b1049f2c754e3c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7d0d3f56eb4d0c97ddddfb2d8e1b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21559d7a3ddf46da9a26707551e923ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497f3e386fae4df3b745b5f0110aa625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4680d5b4f294c7cb878fbd1ecfe036d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42cb99d32274bd484b8841bcdda0103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7415dae0ea4181997052c6c8817cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456ca74e64b647a1a2b92343f5e60b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b96771f1c549018355148bc82e24be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33308101c57642d6948169b6a1ef381d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d20c1e58e9e4fa69a659b0caabd760a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c5ec0bb86e4bc687bcb94e82a29c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e6883e467b484387a269487b2f3498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61656492b6e94a3e92bc5dbb26dee011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29285ec77db34c7f84b24643265749aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67aa0897015146fe8991742437678550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb8abdf60cb44ce945aafe36224965d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9850cd64cdc64a3ebf355a4786e482ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdb9701250a49cbb41f2a892b6c56f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c187f6287ab546c4b9b01dc5965d9015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620a151cd5f24671bc3a0693d41b4d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f5390b0704141b4cde11102fb1d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a088176325e54498be99fd26f6e070f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce34354bfdd402ba55f22fd088e2017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d6cdda13df42d08cf64b2bbdf3f7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34b411d70614d3da2ad6f9efd68336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda28dab47b5483ba8db293c33ea5605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b608295371ba4a1f9637c891bb56e229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c16d93d2713468398a045ad3da5518b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d270deb3862b48e8a212aaa5f31e0b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf973c95a744e1c924bc49adcadd9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ed285422fd41ccbdc6c4784350a367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c842ff80c4ad4712aeec4774c470c8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d856f2ea2257493793d0d57dcc22e83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a885791fb8243949628469d1fc5b4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e1bebd3d384722a0145114a0e26a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56bf30e45de415d91b478bcf70cca6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82381a20841947dba6f5791b7954754d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef055e6ae71f4fe0b24a6c6ff9c8e428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2df5f037594b9a99ba891c0e751c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f773f4d712a40209cf6a520082dbf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158a5a35c1ff48b6a2f4ce1a2a9114b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f60311ac5bb4fe3bc29620f21278834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac2b85669a24365ab908a1bfa5fd5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434fb56875564981932262d813413932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c84254a34a4ed3a616005d939741a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340f003882ad48978d3d2980030718c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1384a5a97454d35b8d74c2cc5b01525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0883092ea2b54d96b44e33d095ad1105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d471012844451caf2f28e72011940e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd70318e0254ddc8780332fad2689eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7796c73d51e44290b59da7c1e4203a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aae973e2f034bad8c13f43f9d8e8c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fbfe1ae6634e74921f8613a56f11d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a677442289814060b59d21bd01255e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420151ac18084f73aac90c741382d3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde52807db9d4210b6ab081ef20a30cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0137701dee412184b91eda3ffa082e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071820ad534244969431c8c21146a5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a26853bb994415cb096302b78478d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d5039c0ea343edb77ea22959ac6759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290820fb546743728bde6026eccf0137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fea813c96ec472d852f15e737c30f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a6a986a76d424e83b1f856320bafea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06530d112d4a445cb7e47a54238abe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db569e574e74837bdefad29473c522d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907cac94d6894d4f87ce76e7104d8d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92457006ba0d4c61bb3f2b663b0fa6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0eb58bb78e4fc9bb07b6e72d5521de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d125586020e45a2859394153fdf9ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d4de960594451998540afce57247ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6eb329373048aa960d37a34d406396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d70f1d11584915b5e4b5275b5f7f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb9870d7b0d4e0b961000ca35220939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22037e76d71419f80595fd0083b2db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da20fc16eb64157aeb96f2db7a9bab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccb00fe05e5458b91bb0b7196f02d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45400073483408fa93490bfbb2d3b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f40a84df09e475f84083f48a417a1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fca700f76e844a7b29c984ec3288d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e77ae30b5b4df4a1de0052e070ac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d1d8e6d0a147ccad70ba5878ec51b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40608e75338a418e8b0170f803c3c9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b22b77e5264b4cbd36307a4f5ff3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd0978b164e466cb91fd5576b7a5fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab7339850974dcab00c164f58f592fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb3406269024ebbbffcc4b19c7af3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e8336cb9124ccea72c65c6d88bd67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ea00e4a2e0458f8d2f4110e822f0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fe637eb0014a68a008907552dd089e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841fef6f038347e4ba678c2779be89ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2d3aa9bca44737a5d1f20cf7fc173b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dce4b645e864beab3a97a0887327bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c077ccaaab3a442190dc8022ae619077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe69348b4e419f856bc4492d7653dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160cf462b7564dfb9087a5b241a40c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5466d249211a48faa440796664f9153a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412cacd9e3974704871804ba76675f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f85a31f8c9c4546b1177aa95028173d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee6abacca9d4f6d96116b56c3a5748a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed45e1b48774360baf24d73263bbef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bff880c260c438db0bd45c3ecf6f336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0176d657e890410f8c9b27711222d393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a77a7527b4942fda558daa9a8be3212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb984604a5f9408d8427dc12d91c6358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f9a5bac2714d7b89d1e117e0ece289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351beab93d5a4a4eb9bb2f2dfa0726df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a565cd4f764f0bad46bafdeaee9c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0563166aa86488ba586458bef44f264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15df28400d4c408b8115c127e0a7062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a167224ad6f46aebfd4415023456096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13e00150a4e4360946c86f483e18ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19265a3f182e44bdb3fce948c0066a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e01bc9f29904a34811a04339900399d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5709f27c895c4ee18a007729e4d130b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a10dbbc26044c68b3fecc2cc9fa2650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2b4bdc14de457ab2255b9481547f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e564728d0584f6cbdf480e8e04870df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9ade9770c24f67a33a41deab78cbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb3c94b3cd54c15ac08f3dec17f52a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa2230767024eb4aba884ce80c55e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc82a1eb979d4a99bf3d802bfa733056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5839c3e6d94b498ca9380e63e985ac31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ae6d941d4c40ddbf9e553899d38d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46da0f3eadb4b31bf9fa005e20f9c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef86028bdd6480b86909161644818a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce560cba2c849ceb115e43a098332a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2c2814d61746d0896c593aeb58552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9275dc57202f4696922d5b685ff89bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b58fc538e74495be738154122b04d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1156e438bf5a44f998f9deb6635e8ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c6794029cd4b5b86a7bff7040d0bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdd4d5dcee34534850c9180d6c62b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6adc94eeb74f3e8d59570af97a533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245d405b20fb4ade90d0be8b562702d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afed6056e7844d299f468c8de537a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db20566fb9b9437f80cc90fe66c3837b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4ced2735914dfd94a981d2229fd44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7b6f21bcc044f38e26998694315ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2085cb3c36a2491b84186b815d7310c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c4aa909bb9429984469fb22f0e8e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2bd4c1d57a40678c5c0d356ec0af05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7974daa99d494b4099239ff9afab1855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4857f6e1585b470c9e026ac32a9cdf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f858be1db8a41ac9640468abace2fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b3449e129d422399aff51d653ebfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c280bfeb460f49cdadbd1eebae7274b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f40a5a53a364ebaab1eb4ee99e47507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c07a079bdb54b51954816025bdb8fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d100bec9bb9d462aaf30805bfa27e5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2125cc38ee1b4f81a2e1731be9c5c718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dd29d9b3804dc5b96d4b41aed51271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c1bd2b441d44e9bb26203af46509ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140c9169efcc40c39d47c2538a6eb75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3f8cac613d4366b064a3bed65ffc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb348c187464688ace59bb7f12f2cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bc504834b145aaa12cbd7235198dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d1eaab599d4dada02406f3a99e18a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5609cd5370048bc8d59e61f51c68efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d801ebb22cc4844bfa188f98d1c868f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396ee0abca9e4c4b91581b821bc8130b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749fec3f16654b2aaa0789d5f8c79cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbed914022a34aa8ac73aebf21d97c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0264f63830534f39955ef2c643a4c1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484a93c11bda4082adf13853a8a534a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5178cdbc4ce4540af666caa0b035ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774c54929d554edf98707aa0a6600c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b5c3e929e84830bf22bd2f6d64a217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f80afea3ac4d63825fd0e4dfde13d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94715323d9d745afaa5209430d307dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f278bc065f14781beef847318023ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bd872c19154abe97820c3522aaee38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc644d793d6c48ec97855ec21660fccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2446969f1dfe4c49b3946418a685d4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c9340a10f14d0fa87cfd06ea71aff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a705ed5abb8480ebeb507b6aa8b04a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0dc9c72ab04277955407e360245beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Validation Report (Multi-label):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.75      1.00      0.86        43\n",
      "           H       0.43      0.86      0.57         7\n",
      "           I       0.50      1.00      0.67         2\n",
      "           q       0.20      1.00      0.33         7\n",
      "           s       0.64      0.95      0.77        38\n",
      "           v       0.97      0.95      0.96        80\n",
      "\n",
      "   micro avg       0.70      0.96      0.81       177\n",
      "   macro avg       0.58      0.96      0.69       177\n",
      "weighted avg       0.79      0.96      0.85       177\n",
      " samples avg       0.70      0.93      0.78       177\n",
      "\n",
      "\n",
      "ðŸ§® Multi-label Confusion Matrices (per class):\n",
      "\n",
      "Class '+':\n",
      "[[32 14]\n",
      " [ 0 43]]\n",
      "\n",
      "Class 'H':\n",
      "[[74  8]\n",
      " [ 1  6]]\n",
      "\n",
      "Class 'I':\n",
      "[[85  2]\n",
      " [ 0  2]]\n",
      "\n",
      "Class 'q':\n",
      "[[54 28]\n",
      " [ 0  7]]\n",
      "\n",
      "Class 's':\n",
      "[[31 20]\n",
      " [ 2 36]]\n",
      "\n",
      "Class 'v':\n",
      "[[ 7  2]\n",
      " [ 4 76]]\n",
      "\n",
      "âœ… Exact match ratio: 0.4044943820224719\n",
      "âœ… Micro accuracy (per-label): 0.848314606741573\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from preprocess.multilabel_preprocess2 import preprocess_csv_multilabel\n",
    "from utils.print_batch import print_batch\n",
    "from utils.json_to_csv import json_to_csv_in_memory  # <-- new util\n",
    "from utils.multilabel_threshold_tuning import tune_thresholds_nn\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "def evaluate_model(model, val_loader, mlb, threshold=0.2, return_probs=False, return_preds=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= threshold).int()\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    # Reporting\n",
    "    print(\"\\nðŸ“Š Validation Report (Multi-label):\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "    print(\"\\nðŸ§® Multi-label Confusion Matrices (per class):\")\n",
    "    mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "    for i, cls in enumerate(mlb.classes_):\n",
    "        print(f\"\\nClass '{cls}':\")\n",
    "        print(mcm[i])\n",
    "\n",
    "    exact_match = np.all(all_preds == all_labels, axis=1).mean()\n",
    "    micro_acc = (all_preds == all_labels).mean()\n",
    "\n",
    "    print(\"\\nâœ… Exact match ratio:\", exact_match)\n",
    "    print(\"âœ… Micro accuracy (per-label):\", micro_acc)\n",
    "\n",
    "    # Flexible return values\n",
    "    if return_probs and return_preds:\n",
    "        return exact_match, micro_acc, all_probs, all_preds\n",
    "    elif return_probs:\n",
    "        return exact_match, micro_acc, all_probs\n",
    "    elif return_preds:\n",
    "        return exact_match, micro_acc, all_preds\n",
    "    else:\n",
    "        return exact_match, micro_acc\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_json=None,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    seq_len=1,\n",
    "    hidden_dim=20,  # <-- NEW: Renamed output_channel to hidden_dim\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=200,\n",
    "    save_model=False,\n",
    "    return_val_accuracy=True,\n",
    "    test_mode=False,\n",
    "    tune_thresholds=False,\n",
    "    include_no_label=False,\n",
    "    label_weighting=\"none\",\n",
    "    scheduler_name=\"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3},\n",
    "    optimizer_name=\"adamw\",\n",
    "    dropout=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an LSTM classification model with labels coming from JSON (in-memory CSV).\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_class_{timestamp}.pt\"\n",
    "    meta_out = f\"{model_out_dir}/lstm_meta_class_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Prepare labels ---\n",
    "    if labels_json is not None:\n",
    "        csv_string = json_to_csv_in_memory(labels_json)   # returns CSV string\n",
    "        labels_csv = io.StringIO(csv_string)              # file-like for pandas\n",
    "    else:\n",
    "        raise ValueError(\"labels_json must be provided\")\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features),\n",
    "            # make_step(add_candle_rocp),\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        False, \n",
    "        # True\n",
    "                ],\n",
    "    )\n",
    "        # --- Get dataset(s) ---\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=True,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label = include_no_label\n",
    "        )\n",
    "    else:\n",
    "        full_dataset, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=False,\n",
    "            debug_sample=True,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label =include_no_label\n",
    "        )\n",
    "\n",
    "    # --- Model config ---\n",
    "    input_dim = train_ds[0][0].shape[1] if do_validation else full_dataset[0][0].shape[1]\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    label_weights_tensor = torch.tensor(label_weights, dtype=torch.float32)\n",
    "\n",
    "    model = candle_model(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,  \n",
    "        num_classes=num_classes,\n",
    "        lr=lr,\n",
    "        label_weights_tensor=label_weights_tensor,\n",
    "        scheduler_name=scheduler_name,\n",
    "        optimizer_name=optimizer_name,\n",
    "        optimizer_params=optimizer_params,\n",
    "        scheduler_params=scheduler_params,\n",
    "        dropout=dropout\n",
    "    )\n",
    "\n",
    "    init_args = {\n",
    "        \"input_dim\": input_dim,\n",
    "        \"hidden_dim\": hidden_dim, \n",
    "        \"num_classes\": num_classes,\n",
    "        \"lr\": lr,\n",
    "        \"scheduler_name\": scheduler_name,\n",
    "        \"optimizer_params\": optimizer_params,\n",
    "        \"scheduler_params\": scheduler_params,\n",
    "        \"optimizer_name\": optimizer_name,\n",
    "        \"dropout\": dropout\n",
    "    }\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    # --- DataLoaders ---\n",
    "    if do_validation:\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "    else:\n",
    "        train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = None\n",
    "\n",
    "    # --- Debug batch ---\n",
    "    if test_mode:\n",
    "        global df_seq\n",
    "        df_seq = print_batch(train_loader, feature_columns, batch_idx=2)\n",
    "\n",
    "    # --- Trainer ---\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        log_every_n_steps=10,\n",
    "        fast_dev_run=test_mode,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Save model & metadata ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            # \"output_channel\": output_channel,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"seq_len\": seq_len,\n",
    "            \"lr\": lr,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"label_classes\": label_encoder.classes_,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"include_no_label\":include_no_label\n",
    "        }, meta_out)\n",
    "        print(f\"\\nâœ… Model saved to {model_out}\")\n",
    "        print(f\"âœ… Meta saved to {meta_out}\")\n",
    "\n",
    "    # --- Validation accuracy ---\n",
    "    val_acc_exact, val_acc_micro = None, None\n",
    "\n",
    "    if do_validation and return_val_accuracy:\n",
    "        y_true_val = np.vstack([y for _, y in val_loader.dataset])\n",
    "\n",
    "        # Always run default evaluation to get probabilities\n",
    "        val_acc_exact_default, val_acc_micro_default, y_probs, y_pred_default = evaluate_model(\n",
    "            model, val_loader, label_encoder, threshold=0.5, return_probs=True, return_preds=True\n",
    "        )\n",
    "\n",
    "        # Use tuned thresholds if the option is enabled\n",
    "        if tune_thresholds:\n",
    "            optimal_thresholds = tune_thresholds_nn(y_true=y_true_val, y_probs=y_probs)\n",
    "            y_pred_tuned = (y_probs >= np.array(optimal_thresholds)).astype(int)\n",
    "        else:\n",
    "            y_pred_tuned = y_pred_default\n",
    "\n",
    "        # Calculate all final metrics based on the chosen prediction set\n",
    "        from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "        # Use the `y_pred_tuned` for all final metrics\n",
    "        final_val_acc_exact = np.all(y_pred_tuned == y_true_val, axis=1).mean()\n",
    "        final_val_acc_micro = (y_pred_tuned == y_true_val).mean()\n",
    "        final_val_f1_macro = f1_score(y_true_val, y_pred_tuned, average=\"macro\", zero_division=0)\n",
    "        return {\n",
    "            \"val_acc_exact\": float(final_val_acc_exact),\n",
    "            \"val_acc_micro\": float(final_val_acc_micro),\n",
    "            \"val_f1_macro\": float(final_val_f1_macro)\n",
    "        }\n",
    "\n",
    "    return {} # Return an empty dict if not returning accuracy\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        labels_json=\"/home/iatell/projects/meta-learning/data/candle_labels.json\",  # JSON labels, no CSV needed on disk\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        include_no_label = False,\n",
    "        label_weighting=\"scale_pos\",\n",
    "        test_mode= False,\n",
    "        # output_channel = 20\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2622a",
   "metadata": {},
   "source": [
    "## fnn cnn fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4240dcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | fnn_layer     | Sequential        | 140    | train\n",
      "1 | cnn_extractor | Sequential        | 460    | train\n",
      "2 | fc            | Linear            | 126    | train\n",
      "3 | criterion     | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------------\n",
      "726       Trainable params\n",
      "0         Non-trainable params\n",
      "726       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "Total sequences collected: 444\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Original label(s): ['H']\n",
      "Cleaned label(s): ['H']\n",
      "Encoded: [0 1 0 0 0 0]\n",
      "Feature shape: (1, 4)\n",
      "First few timesteps:\n",
      " [[0.0091133  0.06722008 0.05172484 0.3       ]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d133d1933aec4945bae19603eb656898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b816c562838141dd90549b669de88513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fdf8efbb784b5fb9c0bf395940e2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59de6b96980841d3893fd17428469400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69c4364fa0e40c4a5e71484dbaba5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e2e5e915c2468288630e6f0f3d4f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3544c12e6e14b068115b80515ea202c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa7912728d04fba8c91d8ee57960a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811fd4307beb40249602d9e2b221f940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c27f3e6b44099a8f1e0b51ada9f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80880eb7954458b80122e27dfe2799d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03edb2226114e8a88e86af0f8d4c9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07bcc069e364d6390ce9377b6b36b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172921970c394440b1ad74fa1b53489e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e66497db0849d2b89b048d19d58c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddb31ff04284fbda1a3bcb58a5ba8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d519c97b634292af81c11d22fc7398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86827e5dda64401b8dab37551e248336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898d8830577a4bfb8338a804591fc299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773225b4be7a4236a3e21120c02b44c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb9de78b23c40cb81be2502ed995077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54207628a25c43ad98acf685fd0de23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d31c25fb7d4674a4967a93f1d07322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b785c42ac342789e7ebe47fc8c404f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93041e3ec82d4c598161b0308de09448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc287d573124457bfd50a4d3aca167c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc008ae00eb421c97bc039cda41f26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc78605148a4c768435c6396905d5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19a52bddda34923913f71d077133dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0072bdf2955b49c0ace1bc535a3b0378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f5a20d06c240c4b542e95a6b565323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5ad94b1d104df49211bf2e885d045d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f84b79479f40c2aa1a47fe2d674dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a827e5134c433992fe8f869b5b2633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b410bdb206c14c249c8e6c2f79fa5af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d60d0f0fcc340ef930eef3e8f57c6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113f769830c54ea383892758a15c148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c902d165e90d4504aea616f9a42f5fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a41a4db7c44ea49a55e2d78feaa848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6d25f9ab654916b859b7f2502dfd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2bbede3c44445fba23c92e7decea20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3d736fabb9462b8ed00f3cdfa3db91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15ce73501c84047b15114ec85e15bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dc8fdd0313440287bc7efdc5ccbb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d295f1109f854ae1b318d2b01be2ed3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f31501539a74dd0834d947a617237fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682185a929e448f1a32de82001802bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730ed00a01d548fca12b3912c2c3c4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb9f59d560541c09c3c5e0f1bb41426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bf4a16c91b4581b8ea83e4602943a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001e6767cfe64d53a48f92cb42850ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acf919c6dbd4627bcfe5df787d5339a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6806295e878c4502ba8a2521e7207f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a43e8c0b0e4036b234a8971839c668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5906732faf284a3583ef0fd92132b591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bff4d509544d2897c6c7ed5c8234ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebedec831c648138771ed9d24ac42cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af5528b7fee473687896ba28407f3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bc13739b06481a80b2eee19df61fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668977c0669e4687bb7275d43ba4ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd44f821b2754f1a925dc0f12791ce15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3df88516c664a6f985e9ed79ee29de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2724cbe233784b6e886b0741b16f25d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a15f195c744931898e9051c71194c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2647235787cb45f99bd801c92aeac7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ed113e869c44d0b9517b3e2a15ae9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe1044ee07840f0ba87337af2ef5223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2439a65b56c44c31b7b968801f0ac59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf76be6b27f4953a6aba5b3b6e25a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f3108eaf784f9c8b1c66c1d86e0efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc958de7d554b27a4440e674193ef1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3b0b02cfe640aabed1c271cc4a634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fea1e5e5c12407caf48968efe60deb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1d5ba57a5e49ccb97ad3b92a8e48d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f014957fd5c84f538d28cd29512f2a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599b1f24f6f74e0a98f883528e00eb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daae22f307d0439b93ddebdab9c401d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6215912f5ba74568ba8f45f44d730cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacffca81d874fbf92deb80698c80952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f63287867647a9a169e90e65d00805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645c32fe1cfc463dbeba161c4565c768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd6307bc8ae484c9e14ed54c8cbcb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f4b5ec2fee42498637706e0312bfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a308f42e504737aecf0650c7b1fb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1282b06c96fd4b98980e851a0b19861b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663bfb874e7947b39a7c190a7e124f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce01bef4ec48018b5eb381efcb3018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011484457dc347139a7893be13cd874b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae424a6713042e68144001ecdc2daf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a09d56cdcd4c40b010e21253339072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a9998c78ef4b459306c223b07fb527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f33e107af184032accd6c2320e4acea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c333aa66831e4f178bdf3a278a128d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6055d379d3844ecf8d72d4508f0b6fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f75667c37742dd884c5ff317f5dc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4802ee9fe64943a6d353f7691add67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255cc3ec8b1d4bdabedc8f9d5bca24d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76d626dd425406d994b7a681069ec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4b76bf1cd543099c7ff3eb31b82562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070c34a52fb74808889720fe2c944434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64703836fee24d83855541d5e2b2a31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2dc6ae0d3a4b3d9ac34885e850591f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e964e06a22374f8e9327610fbcbb8aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50bbaefbec24fea8dda203f14f20849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f77620e0054b5c9e1adc0b8b0962b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215be18d3fc74ec68bb474c4f1d20ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d503e9926e7430c897602a4f7ecc8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfdbfacc06a4bceb4dbca38fb299a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe9148f3ede494497118fdc85c2f4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254ec171847e46bf9baec4241d4b2e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb21777aa2449caba787dbba7c9aa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555e6d7e3fd74198b53f8e615d37086b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bea7da9b2ff4c228db35b4fa4658ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313218b5b38a471782a11cd9e5d2755e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c3e60c7284977be32fb2aa5148a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933e6152155443858180573839f99591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744f2830d01e4d43b302d5f76fb202d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c251de968a4408a4e432d2bf6ac135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec38c5941f3468ea55bedaf212672ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9debd9c370ea408ba0e8b7ffe2a3b1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb20ce33f89440dac64d5534dc4571e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab427c26509490b83f32f616678585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bdd67d5e0046f48e2a5e4bebf9c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d9a20b4e2444a893f5569fb48de2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f888ee9e37e3456980855615f48bd5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7db553e2824f91a30b26574cb86f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956339b4d4c543f38b09acd144590c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba05597aaecf4adeb48b3cc084c19bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de80cad1d104bcc8a9b10187fc239b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de66d77335764b439decb0a4744057dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83d68ab0e8e4088890a5e2089e1d158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04a1f5e8c204f7482f400564d86641d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681968712d9249dcbcaf3bb8a93b5344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0c8b19d6894493bdb7787ed96bd292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157d02e1aa244c3890d048c6e9f5f731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23e36d27a9a48a6b061e99fe02cd0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d18f8455bbe4acd83e2c55ad2a5c88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df83dcb3608e4c959457fd260f9f4412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99f4e76d913412eb413de52b824ac5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3344211bbe34a9fa33973d3f06f095b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c775a4e334b41eea2945cd5874acde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8ad6a9350f4ab3a4caba71592f102c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e2538ef9c04ab0a7fa1d117a1be950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7a09f2d87f4320926275f9906e6f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b711b189ef4d60814134c146209f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cc94d0aa5d45efb95100129abb8415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05073e05d28b4a999ec5d9698e6d477a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd93e52c693549e797f7ffcd4f198407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a384e70d9da746559954472989453bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56fdb7e7b1645f2af1361dd371a8102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784cdf50a5d8459baf1c256385e30950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c656930b120349838e0525cdb1a62a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16de45b702f54a128bed71cc5755c924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4a9fabe8d24ef886973be7a17a1b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1653288e76194f06b1f47e0f57c4cdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459d2da194f840aaabc12ac578ae0278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161cae44ed484d6c850549853c809f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dfc9e47a484cf0aba73f9090423553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5248d076c4f4332bf5c4421305b4631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d0830a20fd4d03bd6a0c5b12a3d43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad13494ab34be080e3a7d74a9eb875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541805b356cc424daf9a486a65494ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b93a8b9ec74f65a1df5fbf9db10e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c730a21be0b04f9da44aa33bec921ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0d85237f9f427ca7fbd5284dcbda1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5de473570344209bf9998b13eff61ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a6542977864184ae91cf61e1701d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11065f91b0fd49029225834461b1172f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7996b9c1500941cba178dc052bccbc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256e7d06e81a487f8c5e2df5a569217d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450800e1154a48eba222c53d3b6b6b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1264d08c6647908581180b254eb15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac76972b5b54f42be4d40d007160d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b797d9843e4749a03792af46207430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a29734125b441b8e2191bf46ed2711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c006eb6773524aae9804cd7098a710b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a9e55a70ec4d4d874aa55c2db81311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa43adba94f4735be65cfcce6d3a238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4be8ab51954400ca99147929750d8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3cbf435c7c48ca9396f1534de4bca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b5f7b749d482982e59a22bbab2e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1af4c7a8a249b1b62e68e40853ad37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421e061ac2744995bda9fd88c20265cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa852b23cde74407a56d55dc0cfef7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d331b1be44084cc7a68e8af2d07d13e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5fdb7bbcb74465b9b5bd05d83db992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99616c90717b4b9da19f85ee897d96a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28eebde533c4785a37db89a4f4f1fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291d06f504e94266bcd0efae85779be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1e1d872b2840cd8a24989d7502f85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc97a4911ac74530827d3db358aca740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a41db0a87ab49d68c87da2e46140e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4613430631c243a19ec33b029ad01be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dd97856d874421881e7ef8963a135f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6dd2d232bb4d1f8007b382b0e5f2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c94f2d9e6142eeacc17822cfca70ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec59bbc9a94450f8f8c86659d50f248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7d018bfaa44278b08d897c12afdda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef271444a77941aaa2198d1814668843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981d632dc59949fa96f407334da1db83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24e0024e763443f88e45ed8343264a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d6e182fca4150b0888f4cae1bec8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Validation Report (Multi-label):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.59      1.00      0.74        43\n",
      "           H       0.40      0.57      0.47         7\n",
      "           I       0.50      1.00      0.67         2\n",
      "           q       0.17      1.00      0.29         7\n",
      "           s       0.49      0.95      0.65        38\n",
      "           v       0.96      1.00      0.98        80\n",
      "\n",
      "   micro avg       0.61      0.97      0.75       177\n",
      "   macro avg       0.52      0.92      0.63       177\n",
      "weighted avg       0.71      0.97      0.80       177\n",
      " samples avg       0.60      0.96      0.71       177\n",
      "\n",
      "\n",
      "ðŸ§® Multi-label Confusion Matrices (per class):\n",
      "\n",
      "Class '+':\n",
      "[[16 30]\n",
      " [ 0 43]]\n",
      "\n",
      "Class 'H':\n",
      "[[76  6]\n",
      " [ 3  4]]\n",
      "\n",
      "Class 'I':\n",
      "[[85  2]\n",
      " [ 0  2]]\n",
      "\n",
      "Class 'q':\n",
      "[[48 34]\n",
      " [ 0  7]]\n",
      "\n",
      "Class 's':\n",
      "[[14 37]\n",
      " [ 2 36]]\n",
      "\n",
      "Class 'v':\n",
      "[[ 6  3]\n",
      " [ 0 80]]\n",
      "\n",
      "âœ… Exact match ratio: 0.23595505617977527\n",
      "âœ… Micro accuracy (per-label): 0.7808988764044944\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from preprocess.multilabel_preprocess2 import preprocess_csv_multilabel\n",
    "from utils.print_batch import print_batch\n",
    "from utils.json_to_csv import json_to_csv_in_memory  # <-- new util\n",
    "from utils.multilabel_threshold_tuning import tune_thresholds_nn\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from utils.make_step import make_step\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "def evaluate_model(model, val_loader, mlb, threshold=0.2, return_probs=False, return_preds=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= threshold).int()\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(y_batch.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    # Reporting\n",
    "    print(\"\\nðŸ“Š Validation Report (Multi-label):\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "    print(\"\\nðŸ§® Multi-label Confusion Matrices (per class):\")\n",
    "    mcm = multilabel_confusion_matrix(all_labels, all_preds)\n",
    "    for i, cls in enumerate(mlb.classes_):\n",
    "        print(f\"\\nClass '{cls}':\")\n",
    "        print(mcm[i])\n",
    "\n",
    "    exact_match = np.all(all_preds == all_labels, axis=1).mean()\n",
    "    micro_acc = (all_preds == all_labels).mean()\n",
    "\n",
    "    print(\"\\nâœ… Exact match ratio:\", exact_match)\n",
    "    print(\"âœ… Micro accuracy (per-label):\", micro_acc)\n",
    "\n",
    "    # Flexible return values\n",
    "    if return_probs and return_preds:\n",
    "        return exact_match, micro_acc, all_probs, all_preds\n",
    "    elif return_probs:\n",
    "        return exact_match, micro_acc, all_probs\n",
    "    elif return_preds:\n",
    "        return exact_match, micro_acc, all_preds\n",
    "    else:\n",
    "        return exact_match, micro_acc\n",
    "\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_json=None,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    seq_len=1,\n",
    "    fnn_hidden_dim=20,  # <-- NEW: Hidden dimension of the FNN layer\n",
    "    output_channel=20,  # <-- NEW: Output channels of the CNN layer\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=200,\n",
    "    save_model=False,\n",
    "    return_val_accuracy=True,\n",
    "    test_mode=False,\n",
    "    tune_thresholds=False,\n",
    "    include_no_label=False,\n",
    "    label_weighting=\"none\",\n",
    "    scheduler_name=\"reduce_on_plateau\",\n",
    "    optimizer_params={\"weight_decay\": 0.01},\n",
    "    scheduler_params={\"factor\": 0.2, \"patience\": 3},\n",
    "    optimizer_name=\"adamw\",\n",
    "    dropout=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an LSTM classification model with labels coming from JSON (in-memory CSV).\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_class_{timestamp}.pt\"\n",
    "    meta_out = f\"{model_out_dir}/lstm_meta_class_{timestamp}.pkl\"\n",
    "\n",
    "    # --- Prepare labels ---\n",
    "    if labels_json is not None:\n",
    "        csv_string = json_to_csv_in_memory(labels_json)   # returns CSV string\n",
    "        labels_csv = io.StringIO(csv_string)              # file-like for pandas\n",
    "    else:\n",
    "        raise ValueError(\"labels_json must be provided\")\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features),\n",
    "            # make_step(add_candle_rocp),\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        False, \n",
    "        # True\n",
    "                ]\n",
    "    )\n",
    "        # --- Get dataset(s) ---\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=True,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label = include_no_label\n",
    "        )\n",
    "    else:\n",
    "        full_dataset, df, feature_columns, label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=False,\n",
    "            debug_sample=True,\n",
    "            label_weighting=label_weighting,\n",
    "            include_no_label =include_no_label\n",
    "        )\n",
    "\n",
    "    # --- Model config ---\n",
    "    input_dim = train_ds[0][0].shape[1] if do_validation else full_dataset[0][0].shape[1]\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    label_weights_tensor = torch.tensor(label_weights, dtype=torch.float32)\n",
    "\n",
    "    model = candle_model(\n",
    "        input_dim=input_dim,\n",
    "        fnn_hidden_dim=fnn_hidden_dim,  # <-- UPDATED\n",
    "        output_channel=output_channel,  # <-- UPDATED\n",
    "        num_classes=num_classes,\n",
    "        lr=lr,\n",
    "        label_weights_tensor=label_weights_tensor,\n",
    "        scheduler_name=scheduler_name,\n",
    "        optimizer_name=optimizer_name,\n",
    "        optimizer_params=optimizer_params,\n",
    "        scheduler_params=scheduler_params,\n",
    "        dropout=dropout\n",
    "    )\n",
    "\n",
    "    init_args = {\n",
    "        \"input_dim\": input_dim,\n",
    "        \"fnn_hidden_dim\": fnn_hidden_dim,  # <-- UPDATED\n",
    "        \"output_channel\": output_channel,  # <-- UPDATED\n",
    "        \"num_classes\": num_classes,\n",
    "        \"lr\": lr,\n",
    "        \"scheduler_name\": scheduler_name,\n",
    "        \"optimizer_params\": optimizer_params,\n",
    "        \"scheduler_params\": scheduler_params,\n",
    "        \"optimizer_name\": optimizer_name,\n",
    "        \"dropout\": dropout\n",
    "    }\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__ ,\n",
    "        \"class\": model.__class__.__name__ ,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "    # --- DataLoaders ---\n",
    "    if do_validation:\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "    else:\n",
    "        train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = None\n",
    "\n",
    "    # --- Debug batch ---\n",
    "    if test_mode:\n",
    "        global df_seq\n",
    "        df_seq = print_batch(train_loader, feature_columns, batch_idx=2)\n",
    "\n",
    "    # --- Trainer ---\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        log_every_n_steps=10,\n",
    "        fast_dev_run=test_mode,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Save model & metadata ---\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            # \"hidden_dim\": hidden_dim,\n",
    "            \"output_channel\": output_channel,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"seq_len\": seq_len,\n",
    "            \"lr\": lr,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"label_classes\": label_encoder.classes_,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info,\n",
    "            \"include_no_label\":include_no_label\n",
    "        }, meta_out)\n",
    "        print(f\"\\nâœ… Model saved to {model_out}\")\n",
    "        print(f\"âœ… Meta saved to {meta_out}\")\n",
    "\n",
    "    # --- Validation accuracy ---\n",
    "    val_acc_exact, val_acc_micro = None, None\n",
    "\n",
    "\n",
    "    if do_validation and return_val_accuracy:\n",
    "        y_true_val = np.vstack([y for _, y in val_loader.dataset])\n",
    "\n",
    "        # Always run default evaluation to get probabilities\n",
    "        val_acc_exact_default, val_acc_micro_default, y_probs, y_pred_default = evaluate_model(\n",
    "            model, val_loader, label_encoder, threshold=0.5, return_probs=True, return_preds=True\n",
    "        )\n",
    "\n",
    "        # Use tuned thresholds if the option is enabled\n",
    "        if tune_thresholds:\n",
    "            optimal_thresholds = tune_thresholds_nn(y_true=y_true_val, y_probs=y_probs)\n",
    "            y_pred_tuned = (y_probs >= np.array(optimal_thresholds)).astype(int)\n",
    "        else:\n",
    "            y_pred_tuned = y_pred_default\n",
    "\n",
    "        # Calculate all final metrics based on the chosen prediction set\n",
    "        from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "        # Use the `y_pred_tuned` for all final metrics\n",
    "        final_val_acc_exact = np.all(y_pred_tuned == y_true_val, axis=1).mean()\n",
    "        final_val_acc_micro = (y_pred_tuned == y_true_val).mean()\n",
    "        final_val_f1_macro = f1_score(y_true_val, y_pred_tuned, average=\"macro\", zero_division=0)\n",
    "        return {\n",
    "            \"val_acc_exact\": float(final_val_acc_exact),\n",
    "            \"val_acc_micro\": float(final_val_acc_micro),\n",
    "            \"val_f1_macro\": float(final_val_f1_macro)\n",
    "        }\n",
    "\n",
    "    return {} # Return an empty dict if not returning accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        labels_json=\"/home/iatell/projects/meta-learning/data/candle_labels.json\",  # JSON labels, no CSV needed on disk\n",
    "        do_validation=True,\n",
    "        save_model=False,\n",
    "        include_no_label = False,\n",
    "        label_weighting=\"scale_pos\",\n",
    "        test_mode= False,\n",
    "        output_channel = 20\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc679611",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376870a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "Total sequences collected: 1603\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Original label(s): ['no_label']\n",
      "Cleaned label(s): ['no_label']\n",
      "Encoded: [0 0 0 1 0 0 0]\n",
      "Feature shape: (1, 4)\n",
      "First few timesteps:\n",
      " [[0.05440368 0.03677583 0.08810496 0.7       ]]\n",
      "\n",
      "--- Sequence 1 ---\n",
      "Original label(s): ['no_label']\n",
      "Cleaned label(s): ['no_label']\n",
      "Encoded: [0 0 0 1 0 0 0]\n",
      "Feature shape: (1, 4)\n",
      "First few timesteps:\n",
      " [[0.02600957 0.0367597  0.01538321 0.7       ]]\n",
      "==========================\n",
      "\n",
      "\n",
      "ðŸ“Š Validation Report (Multi-label):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.94      0.96      0.95        51\n",
      "           H       0.67      0.29      0.40         7\n",
      "           I       0.00      0.00      0.00         3\n",
      "    no_label       0.92      1.00      0.96       231\n",
      "           q       0.00      0.00      0.00         3\n",
      "           s       0.76      0.84      0.80        44\n",
      "           v       0.96      0.94      0.95        81\n",
      "\n",
      "   micro avg       0.90      0.94      0.92       420\n",
      "   macro avg       0.61      0.57      0.58       420\n",
      "weighted avg       0.90      0.94      0.91       420\n",
      " samples avg       0.92      0.94      0.93       420\n",
      "\n",
      "\n",
      "ðŸ§® Multi-label Confusion Matrices (per class):\n",
      "\n",
      "Class '+':\n",
      "[[267   3]\n",
      " [  2  49]]\n",
      "\n",
      "Class 'H':\n",
      "[[313   1]\n",
      " [  5   2]]\n",
      "\n",
      "Class 'I':\n",
      "[[318   0]\n",
      " [  3   0]]\n",
      "\n",
      "Class 'no_label':\n",
      "[[ 70  20]\n",
      " [  1 230]]\n",
      "\n",
      "Class 'q':\n",
      "[[312   6]\n",
      " [  3   0]]\n",
      "\n",
      "Class 's':\n",
      "[[265  12]\n",
      " [  7  37]]\n",
      "\n",
      "Class 'v':\n",
      "[[237   3]\n",
      " [  5  76]]\n",
      "\n",
      "Exact match ratio: 0.8286604361370716\n",
      "Micro accuracy (per-label): 0.9684023141967067\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, f1_score\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from preprocess.multilabel_preprocess2 import preprocess_csv_multilabel\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.multilabel_threshold_tuning import tune_thresholds\n",
    "from add_ons.feature_pipeline5 import FeaturePipeline\n",
    "from utils.make_step import make_step\n",
    "from add_ons.drop_columns2 import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage2 import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from add_ons.candle_proportion_simple import add_candle_shape_features\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "\n",
    "def evaluate_multilabel_model(model, X_val, y_val, mlb, thresholds=None):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-label XGBoost model and print metrics.\n",
    "    Optionally apply per-label thresholds.\n",
    "    \"\"\"\n",
    "    # Predict probabilities per label\n",
    "    y_probs = np.column_stack([est.predict_proba(X_val)[:, 1] for est in model.estimators_])\n",
    "\n",
    "    # Apply thresholds\n",
    "    if thresholds is None:\n",
    "        thresholds = [0.5] * y_val.shape[1]\n",
    "    y_pred = np.zeros_like(y_val)\n",
    "    for i, t in enumerate(thresholds):\n",
    "        y_pred[:, i] = (y_probs[:, i] >= t).astype(int)\n",
    "\n",
    "    print(\"\\nðŸ“Š Validation Report (Multi-label):\")\n",
    "    print(classification_report(y_val, y_pred, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "    print(\"\\nðŸ§® Multi-label Confusion Matrices (per class):\")\n",
    "    mcm = multilabel_confusion_matrix(y_val, y_pred)\n",
    "    for i, cls in enumerate(mlb.classes_):\n",
    "        print(f\"\\nClass '{cls}':\")\n",
    "        print(mcm[i])\n",
    "\n",
    "    exact_match = np.all(y_pred == y_val, axis=1).mean()\n",
    "    print(\"\\nExact match ratio:\", exact_match)\n",
    "\n",
    "    micro_acc = (y_pred == y_val).mean()\n",
    "    print(\"Micro accuracy (per-label):\", micro_acc)\n",
    "\n",
    "    return exact_match, micro_acc, y_probs\n",
    "\n",
    "\n",
    "def train_model_xgb_multilabel(\n",
    "    data_csv,\n",
    "    labels_json,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    seq_len=1,\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    save_model=False,\n",
    "    return_val_accuracy=True,\n",
    "    label_weighting=\"none\",  # \"none\", dict, or \"scale_pos\"\n",
    "    threshold_tuning = False,\n",
    "    include_no_label = False,\n",
    "):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/xgb_model_multilabel_{timestamp}.pkl\"\n",
    "    meta_out = f\"{model_out_dir}/xgb_meta_multilabel_{timestamp}.pkl\"\n",
    "\n",
    "    csv_string = json_to_csv_in_memory(labels_json)\n",
    "    labels_csv = io.StringIO(csv_string)\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            make_step(add_candle_shape_features),\n",
    "            # make_step(add_candle_rocp),\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "        ],\n",
    "        # norm_methods={\n",
    "            # \"main\": {\n",
    "            #     \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "            #     \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "            #     \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\",\n",
    "                \n",
    "            # }\n",
    "        #         \"candle_shape\": {\n",
    "        #             \"upper_shadow\": \"standard\",\n",
    "        #             \"lower_shadow\": \"standard\",\n",
    "        #             \"body\": \"standard\",\n",
    "        #             \"color\": \"standard\",\n",
    "        #         }\n",
    "        # },flatten\n",
    "        # window_norms={\n",
    "        # \"main\": {\"open_prop\": \"standard\", \"high_prop\": \"standard\",\"low_prop\": \"standard\", \"close_prop\": \"standard\"},},\n",
    "        # transformations={\"mode\": \"rocket\", \"num_kernels\": 500, \"normalise\": True, \"strategy\": \"forward_fill\"},\n",
    "        transformations={\"mode\": \"flatten\"},\n",
    "        per_window_flags=[\n",
    "        False, \n",
    "        False, \n",
    "        # True\n",
    "                ]\n",
    "    )\n",
    "    if do_validation:\n",
    "        X_train,y_train, X_val, y_val, df, feature_columns,label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=True,\n",
    "            for_xgboost=True,\n",
    "            debug_sample=[0, 1],\n",
    "            label_weighting=label_weighting,\n",
    "            feature_pipeline=pipeline,\n",
    "            include_no_label = include_no_label\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train, df, feature_columns,label_encoder, label_weights = preprocess_csv_multilabel(\n",
    "            data_csv, labels_csv,\n",
    "            n_candles=seq_len,\n",
    "            val_split=False,\n",
    "            for_xgboost=True,\n",
    "            label_weighting=label_weighting,\n",
    "            feature_pipeline=pipeline,\n",
    "            include_no_label=include_no_label\n",
    "        )\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "    xgb_models = []\n",
    "    for w in label_weights:\n",
    "        xgb_model = xgb.XGBClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            eval_metric='logloss',\n",
    "            scale_pos_weight=w,\n",
    "        )\n",
    "        xgb_models.append(xgb_model)\n",
    "\n",
    "    model = MultiOutputClassifier(xgb_models[0], n_jobs=-1)\n",
    "    model.estimators_ = xgb_models\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Tune thresholds if validation set exists\n",
    "    optimal_thresholds = None\n",
    "    val_acc_exact, val_acc_micro = None, None\n",
    "    if do_validation:\n",
    "        # --- Step 1: Predict probabilities once ---\n",
    "        y_probs = np.column_stack([est.predict_proba(X_val)[:, 1] for est in model.estimators_])\n",
    "\n",
    "        # --- Step 2: Evaluate with default threshold 0.5 ---\n",
    "        val_acc_exact_default, val_acc_micro_default, _ = evaluate_multilabel_model(\n",
    "            model, X_val, y_val, label_encoder, thresholds=[0.5]*y_val.shape[1]\n",
    "        )\n",
    "        if threshold_tuning:\n",
    "        # --- Step 3: Tune optimal thresholds per label ---\n",
    "            optimal_thresholds = tune_thresholds(y_val, y_probs)\n",
    "            print(\"\\nðŸ“Œ Optimal thresholds per label:\", dict(zip(label_encoder.classes_, optimal_thresholds)))\n",
    "\n",
    "            # --- Step 4: Evaluate with tuned thresholds ---\n",
    "            val_acc_exact_tuned, val_acc_micro_tuned, _ = evaluate_multilabel_model(\n",
    "                model, X_val, y_val, label_encoder, thresholds=optimal_thresholds\n",
    "            )\n",
    "    if return_val_accuracy:\n",
    "        return {\n",
    "            \"exact_match\": val_acc_exact_default,\n",
    "            \"micro_accuracy\": val_acc_micro_default,\n",
    "            \"label_weights\": label_weights,\n",
    "            \"optimal_thresholds\": optimal_thresholds\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        joblib.dump(model, model_out)\n",
    "        joblib.dump({\n",
    "            'seq_len': seq_len,\n",
    "            'label_classes': label_encoder.classes_,\n",
    "            'optimal_thresholds': optimal_thresholds,\n",
    "            \"feature_columns\": feature_columns,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"window_scalers\": pipeline.window_scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"include_no_label\":include_no_label\n",
    "        }, meta_out)\n",
    "        print(f\"âœ… Model saved to {model_out}\")\n",
    "        print(f\"âœ… Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_xgb_multilabel(\n",
    "        data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        labels_json=\"/home/iatell/projects/meta-learning/data/candle_labels.json\",\n",
    "        do_validation=True,\n",
    "        label_weighting=\"scale_pos\"# \"none\", dict, or \"scale_pos\"\n",
    "        ,include_no_label= True,\n",
    "        save_model = False\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af998810",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "# ---------------- Imports ----------------\n",
    "from servers.pre_process.multi_reg_dif_seq2 import (\n",
    "    ServerPreprocess, build_pipeline_from_config\n",
    ")\n",
    "from models.LSTM.lstm_multi_label import LSTMMultiLabelClassifier  # adjust path/class name\n",
    "\n",
    "\n",
    "# ---------------- Flask app ----------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model + meta ----------------\n",
    "meta_files = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_class_*.pkl\")\n",
    "state_files = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_class_*.pt\")\n",
    "\n",
    "if not meta_files or not state_files:\n",
    "    raise FileNotFoundError(\"No multilabel model/meta found!\")\n",
    "\n",
    "meta_path = max(meta_files, key=os.path.getmtime)\n",
    "state_path = max(state_files, key=os.path.getmtime)\n",
    "\n",
    "print(\"Using meta:\", meta_path)\n",
    "print(\"Using state:\", state_path)\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta[\"feature_columns\"]\n",
    "LABEL_CLASSES = meta[\"label_classes\"]\n",
    "print(\"Features:\", FEATURES)\n",
    "print(\"Label classes:\", LABEL_CLASSES)\n",
    "\n",
    "# Init model\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "init_args = model_cls_info[\"init_args\"]\n",
    "model = LSTMMultiLabelClassifier.load_from_checkpoint(state_path, **init_args)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "pipeline.window_scalers = meta[\"window_scalers\"]\n",
    "\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "# ---------------- Load dataset ----------------\n",
    "DATA_FILE = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"  # change path as needed\n",
    "df = pd.read_csv(DATA_FILE, parse_dates=[\"timestamp\"])\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"multi_label.html\")\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    # Convert timestamp column to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')  # or unit='ms' if needed\n",
    "    # print(\"[DEBUG] df['timestamp'] head:\", df['timestamp'].head())\n",
    "\n",
    "    # Reindex to daily frequency and forward-fill missing\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    # print(\"[DEBUG] dense head:\", dense.head())\n",
    "\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "    # print(f\"[DEBUG] next_idx from request: {next_idx}\")\n",
    "\n",
    "    if next_idx is None:\n",
    "        # --- First load ---\n",
    "        if len(preproc.dataset) == 0:\n",
    "            # print(\"[DEBUG] Adding initial candles to preproc.dataset\")\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "\n",
    "        candles = []\n",
    "        for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "            # Use row.name which is the timestamp index\n",
    "            time_val = int(row.name.timestamp())\n",
    "            # print(f\"[DEBUG] Candle time: {time_val}, high: {row.high}\")\n",
    "            candles.append({\n",
    "                \"time\": time_val,\n",
    "                \"open\": float(row.open),\n",
    "                \"high\": float(row.high),\n",
    "                \"low\": float(row.low),\n",
    "                \"close\": float(row.close),\n",
    "            })\n",
    "\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        # --- Step forward ---\n",
    "        if next_idx >= len(dense):\n",
    "            # print(\"[DEBUG] End of data reached\")\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        time_val = int(row.name.timestamp())\n",
    "        # print(f\"[DEBUG] Step candle time: {time_val}, high: {row.high}\")\n",
    "\n",
    "        candle = {\n",
    "            \"time\": time_val,\n",
    "            \"open\": float(row.open),\n",
    "            \"high\": float(row.high),\n",
    "            \"low\": float(row.low),\n",
    "            \"close\": float(row.close),\n",
    "        }\n",
    "\n",
    "        preproc.add_candle(row)\n",
    "        # print(f\"[DEBUG] Added candle to preproc, next_idx will be {next_idx + 1}\")\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    # Use seq_len from meta (training config)\n",
    "    seq_len = meta.get(\"seq_len\")\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Server meta is missing a valid 'seq_len'\"}), 500\n",
    "\n",
    "    # Build sequence from file / preprocessor\n",
    "    try:\n",
    "        seq_dict = preproc.prepare_seq(seq_len)  \n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    # Convert dict of DataFrames â†’ tensors\n",
    "    dict_x = {k: torch.from_numpy(v.values.astype(np.float32)).unsqueeze(0)\n",
    "              for k, v in seq_dict.items()}\n",
    "    lengths = torch.tensor([seq_len], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        y_probs = model(dict_x[\"main\"]).sigmoid().cpu().numpy()[0]\n",
    "\n",
    "    # Decode labels above threshold\n",
    "    threshold = 0.5\n",
    "    predicted_labels = [LABEL_CLASSES[i] for i, p in enumerate(y_probs) if p >= threshold]\n",
    "\n",
    "    # Get last candle time directly (it's already an int timestamp)\n",
    "    return jsonify({\n",
    "        \"raw_probs\": dict(zip(LABEL_CLASSES, y_probs.tolist())),\n",
    "        \"predicted_labels\": predicted_labels\n",
    "    })\n",
    "\n",
    "\n",
    "# ---------------- Run ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2bd155",
   "metadata": {},
   "source": [
    "# Tuning neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e04b6",
   "metadata": {},
   "source": [
    "##  lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f800957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from utils.flatten_config import flatten_config\n",
    "from utils.resoure_usage import resource_usage\n",
    "\n",
    "# --- Data paths ---\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_json = \"/home/iatell/projects/meta-learning/data/candle_labels.json\"\n",
    "\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    \"\"\"\n",
    "    resource_usage()  # Show hardware usage\n",
    "    \n",
    "    # --- Fixed arguments ---\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_json=labels_json,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "    \n",
    "    # --- Build training args ---\n",
    "    train_args = fixed_args.copy()\n",
    "\n",
    "    # Model hyperparams\n",
    "    train_args[\"seq_len\"] = config[\"seq_len\"]\n",
    "    train_args[\"hidden_dim\"] = config[\"hidden_dim\"]\n",
    "\n",
    "    # Training hyperparams\n",
    "    train_args[\"lr\"] = config[\"lr\"]\n",
    "    train_args[\"batch_size\"] = config[\"batch_size\"]\n",
    "    train_args[\"max_epochs\"] = config[\"max_epochs\"]\n",
    "    train_args[\"dropout\"] = config[\"dropout\"]\n",
    "\n",
    "    # Optimizer\n",
    "    train_args[\"optimizer_name\"] = config[\"optimizer_name\"]\n",
    "    if train_args[\"optimizer_name\"] in [\"adamw\", \"adam\"]:\n",
    "        train_args[\"optimizer_params\"] = {\"weight_decay\": config[\"weight_decay\"]}\n",
    "    else:\n",
    "        train_args[\"optimizer_params\"] = {}\n",
    "\n",
    "    # Scheduler\n",
    "    train_args[\"scheduler_name\"] = config[\"scheduler_name\"]\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": config[\"scheduler_params\"][\"factor\"],\n",
    "            \"patience\": config[\"scheduler_params\"][\"patience\"]\n",
    "        }\n",
    "    elif train_args[\"scheduler_name\"] == \"cosine\":\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"T_max\": config[\"scheduler_params\"][\"T_max\"],\n",
    "            \"eta_min\": config[\"scheduler_params\"][\"eta_min\"]\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # --- Run training ---\n",
    "    metrics = train_model(**train_args)\n",
    "\n",
    "    # Report back to Ray Tune\n",
    "    tune.report(metrics)\n",
    "\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for CNN-LSTM with Ray Tune.\"\"\"\n",
    "    \n",
    "    search_space = {\n",
    "        # Model\n",
    "        \"seq_len\": tune.choice([1, 5, 10, 20]),\n",
    "        \"hidden_dim\": tune.choice([32, 64, 128, 256]),\n",
    "        \"dropout\": tune.uniform(0.1, 0.5),\n",
    "\n",
    "        # Training\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-3),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        \"max_epochs\": tune.choice([50, 100, 150]),\n",
    "\n",
    "        # Optimizer\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"weight_decay\": tune.loguniform(1e-5, 1e-2),\n",
    "\n",
    "        # Scheduler\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"cosine\", \"none\"]),\n",
    "        \"scheduler_params\": {\n",
    "            \"factor\": tune.uniform(0.1, 0.5),\n",
    "            \"patience\": tune.choice([3, 5, 10]),\n",
    "            \"T_max\": tune.choice([10, 20, 50]),\n",
    "            \"eta_min\": tune.loguniform(1e-6, 1e-4),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"f1_macro\",\n",
    "        mode=\"max\",\n",
    "        grace_period=5,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    # --- Add timestamp to run name ---\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"cnn_lstm_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=10,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # --- Best trial ---\n",
    "    best_result = results.get_best_result(metric=\"f1_macro\", mode=\"max\")\n",
    "    print(\"\\nðŸ† Best Config:\", best_result.config)\n",
    "    print(f\"Best F1 Macro: {best_result.metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    # --- Retrain with best config ---\n",
    "    if save_model:\n",
    "        print(\"\\nðŸ” Retraining best model on full dataset for saving...\")\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_json\": labels_json,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"seq_len\": best_result.config.get(\"seq_len\", 1),\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"dropout\": best_result.config[\"dropout\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \"optimizer_params\": {\"weight_decay\": best_result.config[\"weight_decay\"]},\n",
    "            \"scheduler_params\": best_result.config[\"scheduler_params\"],\n",
    "        }\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d5ecd",
   "metadata": {},
   "source": [
    "## full fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "082b3043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-09-22 21:01:06</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:36.41        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.8/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None<br>Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_dim</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  max_epochs</th><th>optimizer_name  </th><th>scheduler_name   </th><th style=\"text-align: right;\">         scheduler_params/fac\n",
       "tor</th><th style=\"text-align: right;\">   scheduler_params/pat\n",
       "ience</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_acc_exact</th><th style=\"text-align: right;\">  val_acc_micro</th><th style=\"text-align: right;\">  val_f1_macro</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_tune_b20c4_00000</td><td>TERMINATED</td><td>172.18.55.78:46216</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.146725</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.00233054 </td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td>none             </td><td style=\"text-align: right;\">0.336545</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">   0.000168005</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.11896</td><td style=\"text-align: right;\">       0.505618</td><td style=\"text-align: right;\">       0.902622</td><td style=\"text-align: right;\">      0.622005</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00001</td><td>TERMINATED</td><td>172.18.55.78:46292</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 0.163754</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.00129125 </td><td style=\"text-align: right;\">         150</td><td>adam            </td><td>none             </td><td style=\"text-align: right;\">0.371677</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">   0.00205038 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.83933</td><td style=\"text-align: right;\">       0.516854</td><td style=\"text-align: right;\">       0.883895</td><td style=\"text-align: right;\">      0.575386</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00002</td><td>TERMINATED</td><td>172.18.55.78:46372</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.187617</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.00869308 </td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.371453</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">   0.000973905</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.20872</td><td style=\"text-align: right;\">       0.629213</td><td style=\"text-align: right;\">       0.932584</td><td style=\"text-align: right;\">      0.71199 </td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00003</td><td>TERMINATED</td><td>172.18.55.78:46452</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.396824</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000101339</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td>none             </td><td style=\"text-align: right;\">0.138885</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">   0.000177778</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.2359 </td><td style=\"text-align: right;\">       0.258427</td><td style=\"text-align: right;\">       0.801498</td><td style=\"text-align: right;\">      0.344278</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00004</td><td>TERMINATED</td><td>172.18.55.78:46538</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.32764 </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.00236401 </td><td style=\"text-align: right;\">         200</td><td>adam            </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.121329</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">   0.00030863 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.80829</td><td style=\"text-align: right;\">       0.58427 </td><td style=\"text-align: right;\">       0.921348</td><td style=\"text-align: right;\">      0.688833</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00005</td><td>TERMINATED</td><td>172.18.55.78:46623</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.247201</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000124039</td><td style=\"text-align: right;\">         200</td><td>adam            </td><td>none             </td><td style=\"text-align: right;\">0.425405</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">   0.00783089 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.93301</td><td style=\"text-align: right;\">       0.258427</td><td style=\"text-align: right;\">       0.771536</td><td style=\"text-align: right;\">      0.296584</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00006</td><td>TERMINATED</td><td>172.18.55.78:46702</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.116095</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00202816 </td><td style=\"text-align: right;\">         150</td><td>adam            </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.440663</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">   0.000329765</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.17124</td><td style=\"text-align: right;\">       0.573034</td><td style=\"text-align: right;\">       0.917603</td><td style=\"text-align: right;\">      0.683598</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00007</td><td>TERMINATED</td><td>172.18.55.78:46784</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.47778 </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.0002674  </td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td>none             </td><td style=\"text-align: right;\">0.104732</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">   0.000234781</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.18564</td><td style=\"text-align: right;\">       0.505618</td><td style=\"text-align: right;\">       0.883895</td><td style=\"text-align: right;\">      0.572829</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00008</td><td>TERMINATED</td><td>172.18.55.78:46864</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\"> 0.351046</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000696843</td><td style=\"text-align: right;\">         100</td><td>adam            </td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.361365</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">   5.60894e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.85271</td><td style=\"text-align: right;\">       0.314607</td><td style=\"text-align: right;\">       0.812734</td><td style=\"text-align: right;\">      0.376475</td></tr>\n",
       "<tr><td>train_model_tune_b20c4_00009</td><td>TERMINATED</td><td>172.18.55.78:46940</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.275815</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000574177</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td>none             </td><td style=\"text-align: right;\">0.18886 </td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">   0.000615849</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.85176</td><td style=\"text-align: right;\">       0.505618</td><td style=\"text-align: right;\">       0.889513</td><td style=\"text-align: right;\">      0.569812</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:01:06,349\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/iatell/projects/meta-learning/tune_logs/fullfnn_multilabel_tuning_20250922_205929' in 0.0034s.\n",
      "2025-09-22 21:01:06,354\tINFO tune.py:1041 -- Total run time: 96.43 seconds (96.41 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best Config: {'hidden_dim': 512, 'dropout': 0.18761731714766047, 'lr': 0.008693076055154599, 'batch_size': 128, 'max_epochs': 150, 'optimizer_name': 'adamw', 'weight_decay': 0.0009739052977471559, 'scheduler_name': 'reduce_on_plateau', 'scheduler_params': {'factor': 0.3714526069181563, 'patience': 10}}\n",
      "Best Macro F1 Score: 0.6292\n",
      "\n",
      "ðŸ” Retraining best model on full dataset for saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | fcn       | Sequential        | 7.2 K  | train\n",
      "1 | criterion | BCEWithLogitsLoss | 0      | train\n",
      "--------------------------------------------------------\n",
      "7.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.2 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "Total sequences collected: 444\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Original label(s): ['H']\n",
      "Cleaned label(s): ['H']\n",
      "Encoded: [0 1 0 0 0 0]\n",
      "Feature shape: (1, 5)\n",
      "First few timesteps:\n",
      " [[14210.    14339.5   12569.2   13474.99  17017.633]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28102d043de349c488810e1ffd99736d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: ['train_loss', 'train_loss_step', 'train_loss_epoch']. Condition can be set using `monitor` key in lr scheduler dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m         train_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretrain_args)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mrun_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 152\u001b[0m, in \u001b[0;36mrun_tuning\u001b[0;34m(save_model)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# ðŸ› ï¸ CORRECTED: Create a clean dictionary from the best config\u001b[39;00m\n\u001b[1;32m    130\u001b[0m retrain_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_csv,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_json\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels_json,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_result\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler_params\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    150\u001b[0m }\n\u001b[0;32m--> 152\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mretrain_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 217\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_csv, labels_json, model_out_dir, do_validation, seq_len, hidden_dim, lr, batch_size, max_epochs, save_model, return_val_accuracy, test_mode, tune_thresholds, include_no_label, label_weighting, scheduler_name, optimizer_params, scheduler_params, optimizer_name, dropout)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# --- Trainer ---\u001b[39;00m\n\u001b[1;32m    209\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m    210\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m    211\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     fast_dev_run\u001b[38;5;241m=\u001b[39mtest_mode,\n\u001b[1;32m    215\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# --- Save model & metadata ---\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_model:\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:217\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance()\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:477\u001b[0m, in \u001b[0;36m_FitLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_epoch_end()\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39m_num_ready_batches_reached():\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# since metric-based schedulers require access to metrics and those are not currently saved in the\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# checkpoint, the plateau schedulers shouldn't be updated\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_plateau_schedulers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestarting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# we manually decrease here because loggers expect that the same step is used when logging epoch-end metrics\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# even when the batch loop has finished\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39m_batches_that_stepped \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:448\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.update_lr_schedulers\u001b[0;34m(self, interval, update_plateau_schedulers)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_accumulate():\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_learning_rates\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_plateau_schedulers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_plateau_schedulers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:483\u001b[0m, in \u001b[0;36m_TrainingEpochLoop._update_learning_rates\u001b[0;34m(self, interval, update_plateau_schedulers)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mstrict:\n\u001b[1;32m    482\u001b[0m     avail_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(trainer\u001b[38;5;241m.\u001b[39mcallback_metrics)\n\u001b[0;32m--> 483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduceLROnPlateau conditioned on metric \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonitor_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is not available. Available metrics are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavail_metrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Condition can be set using `monitor` key in lr scheduler dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n\u001b[1;32m    488\u001b[0m rank_zero_warn(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduceLROnPlateau conditioned on metric \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonitor_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is not available but strict is set to `False`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Skipping learning rate update.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    492\u001b[0m     category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ReduceLROnPlateau conditioned on metric val_loss which is not available. Available metrics are: ['train_loss', 'train_loss_step', 'train_loss_epoch']. Condition can be set using `monitor` key in lr scheduler dict"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils.flatten_config import flatten_config\n",
    "from utils.resoure_usage import resource_usage\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "\n",
    "import io\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air import session as air\n",
    "from ray.air import RunConfig\n",
    "from ray import air\n",
    "from ray.tune import TuneConfig\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_json = \"/home/iatell/projects/meta-learning/data/candle_labels.json\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    \"\"\"\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_json=labels_json,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "    \n",
    "    # Start with the fixed arguments\n",
    "    train_args = fixed_args.copy()\n",
    "    \n",
    "    # Manually add the top-level hyperparameters\n",
    "    train_args['lr'] = config['lr']\n",
    "    train_args['batch_size'] = config['batch_size']\n",
    "    train_args['max_epochs'] = config['max_epochs']\n",
    "    train_args['dropout'] = config['dropout']\n",
    "    \n",
    "    # ðŸŒŸ Conditional Logic for Optimizer and its params\n",
    "    train_args['optimizer_name'] = config['optimizer_name']\n",
    "    if train_args['optimizer_name'] in ['adamw', 'adam']:\n",
    "        # Pass the weight_decay key and value directly\n",
    "        train_args['optimizer_params'] = {'weight_decay': config['weight_decay']}\n",
    "    else:\n",
    "        # For other optimizers (e.g., SGD), weight decay might not be needed or handled differently\n",
    "        train_args['optimizer_params'] = {}\n",
    "\n",
    "    # ðŸŒŸ Conditional Logic for Scheduler\n",
    "    train_args['scheduler_name'] = config['scheduler_name']\n",
    "    if train_args['scheduler_name'] == 'reduce_on_plateau':\n",
    "        # Pass the scheduler params as a nested dictionary\n",
    "        train_args['scheduler_params'] = {\n",
    "            'factor': config['scheduler_params']['factor'],\n",
    "            'patience': config['scheduler_params']['patience']\n",
    "        }\n",
    "    else:\n",
    "        # If no scheduler is chosen, pass an empty dictionary\n",
    "        train_args['scheduler_params'] = {}\n",
    "        \n",
    "    # Manually add model-specific parameters\n",
    "    if 'hidden_dim' in config:\n",
    "        train_args['hidden_dim'] = config['hidden_dim']\n",
    "    elif 'fnn_hidden_dim' in config and 'output_channel' in config:\n",
    "        train_args['fnn_hidden_dim'] = config['fnn_hidden_dim']\n",
    "        train_args['output_channel'] = config['output_channel']\n",
    "    \n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for FNN model with Ray Tune.\"\"\"\n",
    "    search_space = {\n",
    "        \"hidden_dim\": tune.choice([32, 64, 128, 256, 512]),\n",
    "        \"dropout\": tune.uniform(0.1, 0.5),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"batch_size\": tune.choice([32, 64, 128, 256]),\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "        \n",
    "        # ðŸŒŸ Define optimizer and scheduler parameters at the top level\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"weight_decay\": tune.loguniform(1e-5, 1e-2), # <-- NEW: weight_decay is now at the top-level\n",
    "        \n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"none\"]),\n",
    "        \"scheduler_params\": {\n",
    "            \"factor\": tune.uniform(0.1, 0.5),\n",
    "            \"patience\": tune.choice([3, 5, 10]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"val_acc_exact\",\n",
    "        mode=\"max\",\n",
    "        grace_period=10,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    # --- Add timestamp to run name ---\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"fullfnn_multilabel_tuning_{timestamp}\"\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=10\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(metric=\"val_acc_exact\", mode=\"max\")\n",
    "    print(\"\\nðŸ† Best Config:\", best_result.config)\n",
    "    print(f\"Best Macro F1 Score: {best_result.metrics['val_acc_exact']:.4f}\")\n",
    "\n",
    "    if save_model:\n",
    "        print(\"\\nðŸ” Retraining best model on full dataset for saving...\")\n",
    "        \n",
    "        # ðŸ› ï¸ CORRECTED: Create a clean dictionary from the best config\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_json\": labels_json,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"seq_len\": best_result.config.get(\"seq_len\", 1), # Example, if you add this to your search space\n",
    "            \"hidden_dim\": best_result.config[\"hidden_dim\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"dropout\": best_result.config[\"dropout\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "            \n",
    "            # Manually construct the nested parameter dictionaries\n",
    "            \"optimizer_params\": {\n",
    "                'weight_decay': best_result.config['weight_decay']\n",
    "            },\n",
    "            \"scheduler_params\": best_result.config['scheduler_params']\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f8297",
   "metadata": {},
   "source": [
    "## fnn cnn fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77f8178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-09-22 21:30:48</td></tr>\n",
       "<tr><td>Running for: </td><td>00:04:00.94        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.9/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None<br>Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  fnn_hidden_dim</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  max_epochs</th><th>optimizer_name  </th><th style=\"text-align: right;\">            optimizer_params/wei\n",
       "ght_decay</th><th style=\"text-align: right;\">  output_channel</th><th>scheduler_name   </th><th style=\"text-align: right;\">         scheduler_params/fac\n",
       "tor</th><th style=\"text-align: right;\">   scheduler_params/pat\n",
       "ience</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_acc_exact</th><th style=\"text-align: right;\">  val_acc_micro</th><th style=\"text-align: right;\">  val_f1_macro</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_tune_82288_00000</td><td>TERMINATED</td><td>172.18.55.78:50322</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.285438</td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">0.00416382 </td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">0.00444891 </td><td style=\"text-align: right;\">              64</td><td>none             </td><td style=\"text-align: right;\">0.259638</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.8545 </td><td style=\"text-align: right;\">      0.595506 </td><td style=\"text-align: right;\">       0.91573 </td><td style=\"text-align: right;\">      0.697855</td></tr>\n",
       "<tr><td>train_model_tune_82288_00001</td><td>TERMINATED</td><td>172.18.55.78:50407</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.209157</td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">0.000851726</td><td style=\"text-align: right;\">         100</td><td>adam            </td><td style=\"text-align: right;\">4.5322e-05 </td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.18362 </td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.21036</td><td style=\"text-align: right;\">      0.52809  </td><td style=\"text-align: right;\">       0.893258</td><td style=\"text-align: right;\">      0.629924</td></tr>\n",
       "<tr><td>train_model_tune_82288_00002</td><td>TERMINATED</td><td>172.18.55.78:50493</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.151895</td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">0.00298882 </td><td style=\"text-align: right;\">         200</td><td>adam            </td><td style=\"text-align: right;\">0.00650009 </td><td style=\"text-align: right;\">              32</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.42502 </td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.8401 </td><td style=\"text-align: right;\">      0.550562 </td><td style=\"text-align: right;\">       0.913858</td><td style=\"text-align: right;\">      0.528167</td></tr>\n",
       "<tr><td>train_model_tune_82288_00003</td><td>TERMINATED</td><td>172.18.55.78:50578</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.469524</td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">0.00132371 </td><td style=\"text-align: right;\">         200</td><td>adamw           </td><td style=\"text-align: right;\">2.50201e-05</td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.185167</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.28417</td><td style=\"text-align: right;\">      0.561798 </td><td style=\"text-align: right;\">       0.904494</td><td style=\"text-align: right;\">      0.546279</td></tr>\n",
       "<tr><td>train_model_tune_82288_00004</td><td>TERMINATED</td><td>172.18.55.78:50658</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.439316</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">0.000352101</td><td style=\"text-align: right;\">         100</td><td>adam            </td><td style=\"text-align: right;\">0.000337987</td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.461883</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.23264</td><td style=\"text-align: right;\">      0        </td><td style=\"text-align: right;\">       0.47191 </td><td style=\"text-align: right;\">      0.290282</td></tr>\n",
       "<tr><td>train_model_tune_82288_00005</td><td>TERMINATED</td><td>172.18.55.78:50744</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.441145</td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">0.000768923</td><td style=\"text-align: right;\">         100</td><td>adam            </td><td style=\"text-align: right;\">0.00132363 </td><td style=\"text-align: right;\">              32</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.268667</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.40803</td><td style=\"text-align: right;\">      0.550562 </td><td style=\"text-align: right;\">       0.906367</td><td style=\"text-align: right;\">      0.634463</td></tr>\n",
       "<tr><td>train_model_tune_82288_00006</td><td>TERMINATED</td><td>172.18.55.78:50824</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.231609</td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">0.0001426  </td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">2.32886e-05</td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.230562</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.07362</td><td style=\"text-align: right;\">      0.258427 </td><td style=\"text-align: right;\">       0.775281</td><td style=\"text-align: right;\">      0.466145</td></tr>\n",
       "<tr><td>train_model_tune_82288_00007</td><td>TERMINATED</td><td>172.18.55.78:50899</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.39108 </td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">0.000464423</td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.00470494 </td><td style=\"text-align: right;\">             128</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.423039</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.02558</td><td style=\"text-align: right;\">      0.561798 </td><td style=\"text-align: right;\">       0.910112</td><td style=\"text-align: right;\">      0.627951</td></tr>\n",
       "<tr><td>train_model_tune_82288_00008</td><td>TERMINATED</td><td>172.18.55.78:50979</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.473848</td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">0.00700293 </td><td style=\"text-align: right;\">         200</td><td>adam            </td><td style=\"text-align: right;\">0.00314909 </td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.297694</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.0385 </td><td style=\"text-align: right;\">      0.573034 </td><td style=\"text-align: right;\">       0.90824 </td><td style=\"text-align: right;\">      0.476613</td></tr>\n",
       "<tr><td>train_model_tune_82288_00009</td><td>TERMINATED</td><td>172.18.55.78:51065</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.283777</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">0.000263853</td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.00890639 </td><td style=\"text-align: right;\">              64</td><td>none             </td><td style=\"text-align: right;\">0.424474</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.55555</td><td style=\"text-align: right;\">      0.505618 </td><td style=\"text-align: right;\">       0.889513</td><td style=\"text-align: right;\">      0.424908</td></tr>\n",
       "<tr><td>train_model_tune_82288_00010</td><td>TERMINATED</td><td>172.18.55.78:51150</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.138608</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">0.00036855 </td><td style=\"text-align: right;\">         200</td><td>adam            </td><td style=\"text-align: right;\">0.00278701 </td><td style=\"text-align: right;\">             128</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.396137</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        13.1055 </td><td style=\"text-align: right;\">      0.595506 </td><td style=\"text-align: right;\">       0.917603</td><td style=\"text-align: right;\">      0.670021</td></tr>\n",
       "<tr><td>train_model_tune_82288_00011</td><td>TERMINATED</td><td>172.18.55.78:51235</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.211855</td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">0.00102234 </td><td style=\"text-align: right;\">         150</td><td>adam            </td><td style=\"text-align: right;\">0.00556701 </td><td style=\"text-align: right;\">              16</td><td>none             </td><td style=\"text-align: right;\">0.408565</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.6389 </td><td style=\"text-align: right;\">      0.595506 </td><td style=\"text-align: right;\">       0.919476</td><td style=\"text-align: right;\">      0.556855</td></tr>\n",
       "<tr><td>train_model_tune_82288_00012</td><td>TERMINATED</td><td>172.18.55.78:51326</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.408867</td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">0.000175913</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">3.05966e-05</td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.174269</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.23209</td><td style=\"text-align: right;\">      0.0674157</td><td style=\"text-align: right;\">       0.595506</td><td style=\"text-align: right;\">      0.187391</td></tr>\n",
       "<tr><td>train_model_tune_82288_00013</td><td>TERMINATED</td><td>172.18.55.78:51406</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.356666</td><td style=\"text-align: right;\">              64</td><td style=\"text-align: right;\">0.000480545</td><td style=\"text-align: right;\">         200</td><td>adam            </td><td style=\"text-align: right;\">0.000195408</td><td style=\"text-align: right;\">              16</td><td>none             </td><td style=\"text-align: right;\">0.444239</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.8947 </td><td style=\"text-align: right;\">      0.516854 </td><td style=\"text-align: right;\">       0.893258</td><td style=\"text-align: right;\">      0.469528</td></tr>\n",
       "<tr><td>train_model_tune_82288_00014</td><td>TERMINATED</td><td>172.18.55.78:51491</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.380519</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">0.000320915</td><td style=\"text-align: right;\">         200</td><td>adam            </td><td style=\"text-align: right;\">0.000319151</td><td style=\"text-align: right;\">             128</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.260965</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.54488</td><td style=\"text-align: right;\">      0.460674 </td><td style=\"text-align: right;\">       0.882022</td><td style=\"text-align: right;\">      0.544856</td></tr>\n",
       "<tr><td>train_model_tune_82288_00015</td><td>TERMINATED</td><td>172.18.55.78:51577</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.389325</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">0.000297215</td><td style=\"text-align: right;\">         200</td><td>adamw           </td><td style=\"text-align: right;\">0.00172065 </td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.395508</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.4426 </td><td style=\"text-align: right;\">      0.460674 </td><td style=\"text-align: right;\">       0.870787</td><td style=\"text-align: right;\">      0.417716</td></tr>\n",
       "<tr><td>train_model_tune_82288_00016</td><td>TERMINATED</td><td>172.18.55.78:51666</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.354745</td><td style=\"text-align: right;\">              32</td><td style=\"text-align: right;\">0.00127604 </td><td style=\"text-align: right;\">         100</td><td>adam            </td><td style=\"text-align: right;\">0.00772856 </td><td style=\"text-align: right;\">              64</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.385205</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.71577</td><td style=\"text-align: right;\">      0.494382 </td><td style=\"text-align: right;\">       0.878277</td><td style=\"text-align: right;\">      0.422013</td></tr>\n",
       "<tr><td>train_model_tune_82288_00017</td><td>TERMINATED</td><td>172.18.55.78:51746</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.252408</td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">0.00815564 </td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.0073836  </td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.135067</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.35836</td><td style=\"text-align: right;\">      0.595506 </td><td style=\"text-align: right;\">       0.921348</td><td style=\"text-align: right;\">      0.688773</td></tr>\n",
       "<tr><td>train_model_tune_82288_00018</td><td>TERMINATED</td><td>172.18.55.78:51828</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.319544</td><td style=\"text-align: right;\">             256</td><td style=\"text-align: right;\">0.000281164</td><td style=\"text-align: right;\">         150</td><td>adam            </td><td style=\"text-align: right;\">0.0062336  </td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.186094</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.5084 </td><td style=\"text-align: right;\">      0.325843 </td><td style=\"text-align: right;\">       0.846442</td><td style=\"text-align: right;\">      0.397196</td></tr>\n",
       "<tr><td>train_model_tune_82288_00019</td><td>TERMINATED</td><td>172.18.55.78:51912</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.36938 </td><td style=\"text-align: right;\">             128</td><td style=\"text-align: right;\">0.00083915 </td><td style=\"text-align: right;\">         200</td><td>adam            </td><td style=\"text-align: right;\">0.00168062 </td><td style=\"text-align: right;\">              32</td><td>none             </td><td style=\"text-align: right;\">0.190651</td><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.52587</td><td style=\"text-align: right;\">      0.617978 </td><td style=\"text-align: right;\">       0.928839</td><td style=\"text-align: right;\">      0.702688</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:30:48,523\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/iatell/projects/meta-learning/tune_logs/fnn_cnn_multilabel_tuning_20250922_212647' in 0.0047s.\n",
      "2025-09-22 21:30:48,529\tINFO tune.py:1041 -- Total run time: 240.97 seconds (240.94 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best Config: {'fnn_hidden_dim': 128, 'output_channel': 32, 'dropout': 0.36937982977776407, 'lr': 0.0008391502158343265, 'batch_size': 64, 'max_epochs': 200, 'optimizer_name': 'adam', 'optimizer_params': {'weight_decay': 0.001680623888451716}, 'scheduler_name': 'none', 'scheduler_params': {'factor': 0.19065116293646933, 'patience': 3}}\n",
      "Best Macro F1 Score: 0.6180\n",
      "\n",
      "ðŸ” Retraining best model on full dataset for saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | fnn_layer     | Sequential        | 1.0 K  | train\n",
      "1 | cnn_extractor | Sequential        | 4.2 K  | train\n",
      "2 | fc            | Linear            | 198    | train\n",
      "3 | criterion     | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "Total sequences collected: 444\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Original label(s): ['H']\n",
      "Cleaned label(s): ['H']\n",
      "Encoded: [0 1 0 0 0 0]\n",
      "Feature shape: (1, 5)\n",
      "First few timesteps:\n",
      " [[14210.    14339.5   12569.2   13474.99  17017.633]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a06615be5d40efb154d121572faa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model saved to models/saved_models/lstm_model_class_20250922_213048.pt\n",
      "âœ… Meta saved to models/saved_models/lstm_meta_class_20250922_213048.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils.resoure_usage import resource_usage\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "from datetime import datetime\n",
    "\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_json = \"/home/iatell/projects/meta-learning/data/candle_labels.json\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial.\n",
    "    \"\"\"\n",
    "    # resource_usage()  # Show current hardware usage if needed\n",
    "\n",
    "    # Fixed args (constants)\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_json=labels_json,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Start with fixed args\n",
    "    train_args = fixed_args.copy()\n",
    "\n",
    "    # ðŸŒŸ Top-level hyperparameters\n",
    "    train_args[\"dropout\"] = config[\"dropout\"]\n",
    "    train_args[\"lr\"] = config[\"lr\"]\n",
    "    train_args[\"batch_size\"] = config[\"batch_size\"]\n",
    "    train_args[\"max_epochs\"] = config[\"max_epochs\"]\n",
    "\n",
    "    # ðŸŒŸ Optimizer\n",
    "    train_args[\"optimizer_name\"] = config[\"optimizer_name\"]\n",
    "    train_args[\"optimizer_params\"] = {\"weight_decay\": config[\"optimizer_params\"][\"weight_decay\"]}\n",
    "\n",
    "    # ðŸŒŸ Scheduler\n",
    "    train_args[\"scheduler_name\"] = config[\"scheduler_name\"]\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": config[\"scheduler_params\"][\"factor\"],\n",
    "            \"patience\": config[\"scheduler_params\"][\"patience\"],\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # ðŸŒŸ Model-specific (fnn+cnn hybrid)\n",
    "    train_args[\"fnn_hidden_dim\"] = config[\"fnn_hidden_dim\"]\n",
    "    train_args[\"output_channel\"] = config[\"output_channel\"]\n",
    "\n",
    "    # Train\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for FNN-CNN hybrid model with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # Model hyperparameters\n",
    "        \"fnn_hidden_dim\": tune.choice([32, 64, 128, 256]),\n",
    "        \"output_channel\": tune.choice([16, 32, 64, 128]),\n",
    "        \"dropout\": tune.uniform(0.1, 0.5),\n",
    "\n",
    "        # Optimizer / training params\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Optimizer params\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adam\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2),\n",
    "        },\n",
    "\n",
    "        # Scheduler params\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"none\"]),\n",
    "        \"scheduler_params\": {\n",
    "            \"factor\": tune.uniform(0.1, 0.5),\n",
    "            \"patience\": tune.choice([3, 5, 10]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"val_acc_exact\",\n",
    "        mode=\"max\",\n",
    "        grace_period=10,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    # --- Add timestamp to run name ---\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"fnn_cnn_fnn_multilabel_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            train_model_tune,\n",
    "            {\"cpu\": 1, \"gpu\": 1},  # adjust as needed\n",
    "        ),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=20,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Get the best trial\n",
    "    best_result = results.get_best_result(metric=\"val_acc_exact\", mode=\"max\")\n",
    "    print(\"\\nðŸ† Best Config:\", best_result.config)\n",
    "    print(f\"Best Macro F1 Score: {best_result.metrics['val_acc_exact']:.4f}\")\n",
    "\n",
    "    # Retrain with best config\n",
    "    if save_model:\n",
    "        print(\"\\nðŸ” Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_json\": labels_json,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "            \"dropout\": best_result.config[\"dropout\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "\n",
    "            # Nested dicts\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_params\": best_result.config[\"scheduler_params\"],\n",
    "\n",
    "            # Model-specific\n",
    "            \"fnn_hidden_dim\": best_result.config[\"fnn_hidden_dim\"],\n",
    "            \"output_channel\": best_result.config[\"output_channel\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be3f4ad",
   "metadata": {},
   "source": [
    "## cnn fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-09-22 21:10:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:08.02        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.0/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None<br>Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_tune_3003a_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-09-22_16-18-46_397439_920/artifacts/2025-09-22_21-10-10/cnn_fnn_multilabel_tuning_20250922_211010/driver_artifacts/train_model_tune_3003a_00000_0_batch_size=32,dropout=0.2529,lr=0.0004,max_epochs=100,optimizer_name=adagrad,weight_decay=0.0003,ou_2025-09-22_21-10-10/error.txt</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-09-22_16-18-46_397439_920/artifacts/2025-09-22_21-10-10/cnn_fnn_multilabel_tuning_20250922_211010/driver_artifacts/train_model_tune_3003a_00001_1_batch_size=128,dropout=0.4930,lr=0.0011,max_epochs=200,optimizer_name=adamw,weight_decay=0.0010,out_2025-09-22_21-10-10/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  max_epochs</th><th>optimizer_name  </th><th style=\"text-align: right;\">            optimizer_params/wei\n",
       "ght_decay</th><th style=\"text-align: right;\">  output_channel</th><th>scheduler_name   </th><th style=\"text-align: right;\">         scheduler_params/fac\n",
       "tor</th><th style=\"text-align: right;\">   scheduler_params/pat\n",
       "ience</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_tune_3003a_00002</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.333275</td><td style=\"text-align: right;\">0.000381318</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">0.00176112 </td><td style=\"text-align: right;\">              64</td><td>                 </td><td style=\"text-align: right;\">0.441044</td><td style=\"text-align: right;\"> 5</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00003</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.145248</td><td style=\"text-align: right;\">0.00118484 </td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.000110861</td><td style=\"text-align: right;\">              32</td><td>                 </td><td style=\"text-align: right;\">0.282015</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00004</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.433787</td><td style=\"text-align: right;\">0.0014138  </td><td style=\"text-align: right;\">         100</td><td>adagrad         </td><td style=\"text-align: right;\">0.00608336 </td><td style=\"text-align: right;\">              64</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.434585</td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00005</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.17881 </td><td style=\"text-align: right;\">0.000106994</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">0.000796994</td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.296599</td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00006</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.463945</td><td style=\"text-align: right;\">0.000793157</td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.00102768 </td><td style=\"text-align: right;\">              16</td><td>                 </td><td style=\"text-align: right;\">0.421675</td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00007</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.125348</td><td style=\"text-align: right;\">0.000125795</td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.000270966</td><td style=\"text-align: right;\">              64</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.389477</td><td style=\"text-align: right;\"> 5</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00008</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.15443 </td><td style=\"text-align: right;\">0.000449333</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">0.00287609 </td><td style=\"text-align: right;\">              32</td><td>                 </td><td style=\"text-align: right;\">0.496165</td><td style=\"text-align: right;\"> 5</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00009</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.356014</td><td style=\"text-align: right;\">0.00922952 </td><td style=\"text-align: right;\">         100</td><td>adagrad         </td><td style=\"text-align: right;\">3.70224e-05</td><td style=\"text-align: right;\">             128</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.198082</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00010</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.395979</td><td style=\"text-align: right;\">0.000627097</td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">1.87936e-05</td><td style=\"text-align: right;\">              16</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.376752</td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00011</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.280532</td><td style=\"text-align: right;\">0.00184524 </td><td style=\"text-align: right;\">         200</td><td>adamw           </td><td style=\"text-align: right;\">0.00584331 </td><td style=\"text-align: right;\">              32</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.462529</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00012</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.269254</td><td style=\"text-align: right;\">0.00868807 </td><td style=\"text-align: right;\">         100</td><td>adamw           </td><td style=\"text-align: right;\">0.00626354 </td><td style=\"text-align: right;\">              32</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.48147 </td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00013</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.112298</td><td style=\"text-align: right;\">0.000433837</td><td style=\"text-align: right;\">         200</td><td>adamw           </td><td style=\"text-align: right;\">1.00922e-05</td><td style=\"text-align: right;\">              64</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.470188</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00014</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.474148</td><td style=\"text-align: right;\">0.000605371</td><td style=\"text-align: right;\">         200</td><td>adagrad         </td><td style=\"text-align: right;\">6.13722e-05</td><td style=\"text-align: right;\">              64</td><td>                 </td><td style=\"text-align: right;\">0.362525</td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00015</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.409412</td><td style=\"text-align: right;\">0.00583302 </td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">2.65139e-05</td><td style=\"text-align: right;\">              64</td><td>                 </td><td style=\"text-align: right;\">0.170555</td><td style=\"text-align: right;\"> 5</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00016</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.27658 </td><td style=\"text-align: right;\">0.000857111</td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">0.00119555 </td><td style=\"text-align: right;\">              64</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.195369</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00017</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.111513</td><td style=\"text-align: right;\">0.000639475</td><td style=\"text-align: right;\">         200</td><td>adagrad         </td><td style=\"text-align: right;\">1.86758e-05</td><td style=\"text-align: right;\">              64</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.227742</td><td style=\"text-align: right;\"> 3</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00018</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.45685 </td><td style=\"text-align: right;\">0.00843429 </td><td style=\"text-align: right;\">         150</td><td>adamw           </td><td style=\"text-align: right;\">0.00344402 </td><td style=\"text-align: right;\">             128</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.183816</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00019</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.288779</td><td style=\"text-align: right;\">0.000112126</td><td style=\"text-align: right;\">         100</td><td>adagrad         </td><td style=\"text-align: right;\">4.81408e-05</td><td style=\"text-align: right;\">              32</td><td>reduce_on_plateau</td><td style=\"text-align: right;\">0.244767</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00000</td><td>ERROR   </td><td>172.18.55.78:48122</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.252944</td><td style=\"text-align: right;\">0.000424717</td><td style=\"text-align: right;\">         100</td><td>adagrad         </td><td style=\"text-align: right;\">0.000268542</td><td style=\"text-align: right;\">              32</td><td>                 </td><td style=\"text-align: right;\">0.322436</td><td style=\"text-align: right;\">10</td></tr>\n",
       "<tr><td>train_model_tune_3003a_00001</td><td>ERROR   </td><td>172.18.55.78:48190</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.493018</td><td style=\"text-align: right;\">0.00109386 </td><td style=\"text-align: right;\">         200</td><td>adamw           </td><td style=\"text-align: right;\">0.00103725 </td><td style=\"text-align: right;\">             128</td><td>                 </td><td style=\"text-align: right;\">0.228116</td><td style=\"text-align: right;\">10</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:13,922\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_tune_3003a_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 937, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=48122, ip=172.18.55.78, actor_id=19c4f346a7365e276342971701000000, repr=train_model_tune)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 330, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_920/300549532.py\", line 35, in train_model_tune\n",
      "TypeError: train_model() got an unexpected keyword argument 'output_channel'\n",
      "2025-09-22 21:10:17,581\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_tune_3003a_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 937, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=48190, ip=172.18.55.78, actor_id=13b6907a2d82da7ba01270f601000000, repr=train_model_tune)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 330, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_920/300549532.py\", line 35, in train_model_tune\n",
      "TypeError: train_model() got an unexpected keyword argument 'output_channel'\n",
      "2025-09-22 21:10:18,788\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-09-22 21:10:18,792\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010' in 0.0034s.\n",
      "2025-09-22 21:10:20,726\tERROR tune.py:1037 -- Trials did not complete: [train_model_tune_3003a_00000, train_model_tune_3003a_00001]\n",
      "2025-09-22 21:10:20,727\tINFO tune.py:1041 -- Total run time: 9.97 seconds (8.02 seconds for the tuning loop).\n",
      "2025-09-22 21:10:20,728\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010\", trainable=...)\n",
      "2025-09-22 21:10:20,732\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 18 trial(s):\n",
      "- train_model_tune_3003a_00002: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00002: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00002_2_batch_size=64,dropout=0.3333,lr=0.0004,max_epochs=150,optimizer_name=adamw,weight_decay=0.0018,outp_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00003: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00003: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00003_3_batch_size=128,dropout=0.1452,lr=0.0012,max_epochs=100,optimizer_name=adamw,weight_decay=0.0001,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00004: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00004: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00004_4_batch_size=128,dropout=0.4338,lr=0.0014,max_epochs=100,optimizer_name=adagrad,weight_decay=0.0061,o_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00005: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00005: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00005_5_batch_size=128,dropout=0.1788,lr=0.0001,max_epochs=150,optimizer_name=adamw,weight_decay=0.0008,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00006: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00006: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00006_6_batch_size=128,dropout=0.4639,lr=0.0008,max_epochs=100,optimizer_name=adamw,weight_decay=0.0010,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00007: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00007: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00007_7_batch_size=32,dropout=0.1253,lr=0.0001,max_epochs=100,optimizer_name=adamw,weight_decay=0.0003,outp_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00008: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00008: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00008_8_batch_size=64,dropout=0.1544,lr=0.0004,max_epochs=150,optimizer_name=adamw,weight_decay=0.0029,outp_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00009: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00009: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00009_9_batch_size=128,dropout=0.3560,lr=0.0092,max_epochs=100,optimizer_name=adagrad,weight_decay=0.0000,o_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00010: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00010: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00010_10_batch_size=64,dropout=0.3960,lr=0.0006,max_epochs=100,optimizer_name=adamw,weight_decay=0.0000,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00011: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00011: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00011_11_batch_size=64,dropout=0.2805,lr=0.0018,max_epochs=200,optimizer_name=adamw,weight_decay=0.0058,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00012: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00012: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00012_12_batch_size=32,dropout=0.2693,lr=0.0087,max_epochs=100,optimizer_name=adamw,weight_decay=0.0063,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00013: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00013: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00013_13_batch_size=32,dropout=0.1123,lr=0.0004,max_epochs=200,optimizer_name=adamw,weight_decay=0.0000,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00014: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00014: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00014_14_batch_size=64,dropout=0.4741,lr=0.0006,max_epochs=200,optimizer_name=adagrad,weight_decay=0.0001,o_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00015: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00015: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00015_15_batch_size=64,dropout=0.4094,lr=0.0058,max_epochs=150,optimizer_name=adamw,weight_decay=0.0000,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00016: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00016: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00016_16_batch_size=64,dropout=0.2766,lr=0.0009,max_epochs=150,optimizer_name=adamw,weight_decay=0.0012,out_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00017: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00017: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00017_17_batch_size=64,dropout=0.1115,lr=0.0006,max_epochs=200,optimizer_name=adagrad,weight_decay=0.0000,o_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00018: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00018: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00018_18_batch_size=128,dropout=0.4568,lr=0.0084,max_epochs=150,optimizer_name=adamw,weight_decay=0.0034,ou_2025-09-22_21-10-10')\n",
      "- train_model_tune_3003a_00019: FileNotFoundError('Could not fetch metrics for train_model_tune_3003a_00019: both result.json and progress.csv were not found at /home/iatell/projects/meta-learning/tune_logs/cnn_fnn_multilabel_tuning_20250922_211010/train_model_tune_3003a_00019_19_batch_size=32,dropout=0.2888,lr=0.0001,max_epochs=100,optimizer_name=adagrad,weight_decay=0.0000,o_2025-09-22_21-10-10')\n",
      "2025-09-22 21:10:20,733\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: val_f1_macro. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m     train_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretrain_args)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[43mrun_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 97\u001b[0m, in \u001b[0;36mrun_tuning\u001b[0;34m(save_model)\u001b[0m\n\u001b[1;32m     94\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Get the best trial\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_f1_macro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ† Best Config:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_result\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Macro F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/Rllib2.43/lib/python3.11/site-packages/ray/tune/result_grid.py:161\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    150\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    155\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: val_f1_macro. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils.resoure_usage import resource_usage\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "from datetime import datetime\n",
    "\n",
    "data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "labels_json = \"/home/iatell/projects/meta-learning/data/candle_labels.json\"\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial for CNN-FNN model.\n",
    "    \"\"\"\n",
    "    # resource_usage()  # Uncomment to log hardware usage\n",
    "\n",
    "    # Fixed args\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_json=labels_json,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Start with fixed args\n",
    "    train_args = fixed_args.copy()\n",
    "\n",
    "    # ðŸŒŸ Core hyperparameters\n",
    "    train_args[\"output_channel\"] = config[\"output_channel\"]\n",
    "    train_args[\"dropout\"] = config[\"dropout\"]\n",
    "    train_args[\"lr\"] = config[\"lr\"]\n",
    "    train_args[\"batch_size\"] = config[\"batch_size\"]\n",
    "    train_args[\"max_epochs\"] = config[\"max_epochs\"]\n",
    "\n",
    "    # ðŸŒŸ Optimizer\n",
    "    train_args[\"optimizer_name\"] = config[\"optimizer_name\"]\n",
    "    train_args[\"optimizer_params\"] = {\n",
    "        \"weight_decay\": config[\"optimizer_params\"][\"weight_decay\"]\n",
    "    }\n",
    "\n",
    "    # ðŸŒŸ Scheduler\n",
    "    train_args[\"scheduler_name\"] = config[\"scheduler_name\"]\n",
    "    if train_args[\"scheduler_name\"] == \"reduce_on_plateau\":\n",
    "        train_args[\"scheduler_params\"] = {\n",
    "            \"factor\": config[\"scheduler_params\"][\"factor\"],\n",
    "            \"patience\": config[\"scheduler_params\"][\"patience\"],\n",
    "        }\n",
    "    else:\n",
    "        train_args[\"scheduler_params\"] = {}\n",
    "\n",
    "    # Train\n",
    "    metrics = train_model(**train_args)\n",
    "    tune.report(metrics)\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for CNN-FNN model with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # Model hyperparameters\n",
    "        \"output_channel\": tune.choice([16, 32, 64, 128]),\n",
    "        \"dropout\": tune.uniform(0.1, 0.5),\n",
    "\n",
    "        # Optimizer / training\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        \"max_epochs\": tune.choice([100, 150, 200]),\n",
    "\n",
    "        # Optimizer params\n",
    "        \"optimizer_name\": tune.choice([\"adamw\", \"adagrad\"]),\n",
    "        \"optimizer_params\": {\n",
    "            \"weight_decay\": tune.loguniform(1e-5, 1e-2),\n",
    "        },\n",
    "\n",
    "        # Scheduler params\n",
    "        \"scheduler_name\": tune.choice([\"reduce_on_plateau\", \"none\"]),\n",
    "        \"scheduler_params\": {\n",
    "            \"factor\": tune.uniform(0.1, 0.5),\n",
    "            \"patience\": tune.choice([3, 5, 10]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"val_f1_macro\",\n",
    "        mode=\"max\",\n",
    "        grace_period=10,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    # Unique run name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"cnn_fnn_multilabel_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model_tune, {\"cpu\": 1, \"gpu\": 1}),\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=20,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Best result\n",
    "    best_result = results.get_best_result(metric=\"val_f1_macro\", mode=\"max\")\n",
    "    print(\"\\nðŸ† Best Config:\", best_result.config)\n",
    "    print(f\"Best Macro F1 Score: {best_result.metrics['val_f1_macro']:.4f}\")\n",
    "\n",
    "    # Retrain with best config\n",
    "    if save_model:\n",
    "        print(\"\\nðŸ” Retraining best model on full dataset for saving...\")\n",
    "\n",
    "        retrain_args = {\n",
    "            \"data_csv\": data_csv,\n",
    "            \"labels_json\": labels_json,\n",
    "            \"do_validation\": False,\n",
    "            \"model_out_dir\": \"models/saved_models\",\n",
    "            \"save_model\": True,\n",
    "\n",
    "            # From best config\n",
    "            \"output_channel\": best_result.config[\"output_channel\"],\n",
    "            \"dropout\": best_result.config[\"dropout\"],\n",
    "            \"lr\": best_result.config[\"lr\"],\n",
    "            \"batch_size\": best_result.config[\"batch_size\"],\n",
    "            \"max_epochs\": best_result.config[\"max_epochs\"],\n",
    "            \"optimizer_name\": best_result.config[\"optimizer_name\"],\n",
    "            \"scheduler_name\": best_result.config[\"scheduler_name\"],\n",
    "\n",
    "            # Nested dicts\n",
    "            \"optimizer_params\": {\n",
    "                \"weight_decay\": best_result.config[\"optimizer_params\"][\"weight_decay\"]\n",
    "            },\n",
    "            \"scheduler_params\": best_result.config[\"scheduler_params\"],\n",
    "        }\n",
    "\n",
    "        train_model(**retrain_args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422bae68",
   "metadata": {},
   "source": [
    "# tuning xg boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a4be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-09-22 21:49:21</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:05.38        </td></tr>\n",
       "<tr><td>Memory:      </td><td>14.6/15.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 18.0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_tune_a6313_00018</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-09-22_16-18-46_397439_920/artifacts/2025-09-22_21-49-16/xgb_multilabel_tuning_20250922_214916/driver_artifacts/train_model_tune_a6313_00018_18_colsample_bytree=0.9544,n_estimators=100,subsample=0.6405_2025-09-22_21-49-16/error.txt</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00019</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-09-22_16-18-46_397439_920/artifacts/2025-09-22_21-49-16/xgb_multilabel_tuning_20250922_214916/driver_artifacts/train_model_tune_a6313_00019_19_colsample_bytree=0.7223,n_estimators=800,subsample=0.8013_2025-09-22_21-49-16/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_tune_a6313_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.82697 </td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.860083</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.701383</td><td style=\"text-align: right;\">           800</td><td style=\"text-align: right;\">   0.899947</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.777384</td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.970725</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.628927</td><td style=\"text-align: right;\">           800</td><td style=\"text-align: right;\">   0.795867</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.672065</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">   0.887323</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.639714</td><td style=\"text-align: right;\">           800</td><td style=\"text-align: right;\">   0.783664</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.636122</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">   0.959508</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.787888</td><td style=\"text-align: right;\">           400</td><td style=\"text-align: right;\">   0.902323</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.973862</td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.834074</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.636695</td><td style=\"text-align: right;\">           800</td><td style=\"text-align: right;\">   0.936192</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.63059 </td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.752133</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.866059</td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.778711</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.937572</td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.836214</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.621455</td><td style=\"text-align: right;\">           200</td><td style=\"text-align: right;\">   0.886258</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.957261</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">   0.749742</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.708524</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">   0.606741</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.926621</td><td style=\"text-align: right;\">           800</td><td style=\"text-align: right;\">   0.625356</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          0.897343</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">   0.703638</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00018</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          0.954361</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">   0.640542</td></tr>\n",
       "<tr><td>train_model_tune_a6313_00019</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">          0.722261</td><td style=\"text-align: right;\">           800</td><td style=\"text-align: right;\">   0.801316</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:49:21,396\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_tune_a6313_00019\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 939, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.18.55.78, ID: 185813a906bfe3e6ad45d8fd38df5113cde2aaf2e0aa59c1aafa10bb) where the task (task ID: ffffffffffffffffe239e0ef284bc4913f20954a01000000, name=ImplicitFunc.__init__, pid=52689, memory used=0.28GB) was running was 14.81GB / 15.49GB (0.956307), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: f4f04c356a30c6ce745104174aa3662c284e78c60e00b361ccfb0888) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.18.55.78`. To see the logs of the worker, use `ray logs worker-f4f04c356a30c6ce745104174aa3662c284e78c60e00b361ccfb0888*out -ip 172.18.55.78. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "1537\t1.51\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node /home/iatell/.vscode-s...\n",
      "920\t1.31\t/home/iatell/envs/Rllib2.43/bin/python -m ipykernel_launcher --f=/run/user/1000/jupyter/runtime/kern...\n",
      "434\t0.99\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node --dns-result-order=ipv...\n",
      "52563\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52562\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52548\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52561\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52566\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52554\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52551\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "2025-09-22 21:49:21,801\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_tune_a6313_00018\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 939, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.18.55.78, ID: 185813a906bfe3e6ad45d8fd38df5113cde2aaf2e0aa59c1aafa10bb) where the task (task ID: fffffffffffffffff63177bbf9844212f7f7d18201000000, name=ImplicitFunc.__init__, pid=52682, memory used=0.29GB) was running was 14.75GB / 15.49GB (0.952359), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 637e2c39991cbaabdc5fcea1e9a134a1c1134a272f7d64dfbe13d8a7) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.18.55.78`. To see the logs of the worker, use `ray logs worker-637e2c39991cbaabdc5fcea1e9a134a1c1134a272f7d64dfbe13d8a7*out -ip 172.18.55.78. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "1537\t1.51\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node /home/iatell/.vscode-s...\n",
      "920\t1.32\t/home/iatell/envs/Rllib2.43/bin/python -m ipykernel_launcher --f=/run/user/1000/jupyter/runtime/kern...\n",
      "434\t0.99\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node --dns-result-order=ipv...\n",
      "52563\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52562\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52548\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52561\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52566\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52554\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52551\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "2025-09-22 21:49:22,443\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_tune_a6313_00017\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 939, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.18.55.78, ID: 185813a906bfe3e6ad45d8fd38df5113cde2aaf2e0aa59c1aafa10bb) where the task (task ID: ffffffffffffffff008a8690ab23885d7de5e30801000000, name=ImplicitFunc.__init__, pid=52691, memory used=0.30GB) was running was 14.74GB / 15.49GB (0.951799), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: b50b70a60ab08660f8f294a0bd5d64e7c97f4b2728293a9991fdf91f) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.18.55.78`. To see the logs of the worker, use `ray logs worker-b50b70a60ab08660f8f294a0bd5d64e7c97f4b2728293a9991fdf91f*out -ip 172.18.55.78. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "1537\t1.51\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node /home/iatell/.vscode-s...\n",
      "920\t1.32\t/home/iatell/envs/Rllib2.43/bin/python -m ipykernel_launcher --f=/run/user/1000/jupyter/runtime/kern...\n",
      "434\t0.99\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node --dns-result-order=ipv...\n",
      "52563\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52562\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52548\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52561\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52566\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52554\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52551\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "2025-09-22 21:49:23,095\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_tune_a6313_00016\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/ray/_private/worker.py\", line 939, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.18.55.78, ID: 185813a906bfe3e6ad45d8fd38df5113cde2aaf2e0aa59c1aafa10bb) where the task (task ID: ffffffffffffffff23bca333d74d6b215406dd9c01000000, name=ImplicitFunc.__init__, pid=52693, memory used=0.33GB) was running was 14.79GB / 15.49GB (0.95466), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 8efea1ab16745ca5ed586301bfabcf2837ce414ea1e7bf626550ea81) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.18.55.78`. To see the logs of the worker, use `ray logs worker-8efea1ab16745ca5ed586301bfabcf2837ce414ea1e7bf626550ea81*out -ip 172.18.55.78. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "1537\t1.51\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node /home/iatell/.vscode-s...\n",
      "920\t1.32\t/home/iatell/envs/Rllib2.43/bin/python -m ipykernel_launcher --f=/run/user/1000/jupyter/runtime/kern...\n",
      "434\t0.99\t/home/iatell/.vscode-server/bin/0f0d87fa9e96c856c5212fc86db137ac0d783365/node --dns-result-order=ipv...\n",
      "52563\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52562\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52548\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52561\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52566\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52554\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "52551\t0.47\t/home/iatell/envs/Rllib2.43/bin/python -m joblib.externals.loky.backend.popen_loky_posix --process-n...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils.flatten_config import flatten_config\n",
    "from utils.resoure_usage import resource_usage\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import air\n",
    "from datetime import datetime\n",
    "\n",
    "def train_model_tune(config):\n",
    "    \"\"\"\n",
    "    Single Ray Tune trial for XGB Multilabel model.\n",
    "    \"\"\"\n",
    "    resource_usage()  # Show current hardware usage\n",
    "\n",
    "    # Always required data sources\n",
    "    data_csv = \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\"\n",
    "    labels_json = \"/home/iatell/projects/meta-learning/data/candle_labels.json\"\n",
    "\n",
    "    # Fixed args\n",
    "    fixed_args = dict(\n",
    "        data_csv=data_csv,\n",
    "        labels_json=labels_json,\n",
    "        do_validation=True,\n",
    "        model_out_dir=\"models/tuned\",\n",
    "        return_val_accuracy=True,\n",
    "        save_model=False,\n",
    "    )\n",
    "\n",
    "    # Flatten (in case config has nested dicts)\n",
    "    flat_config = flatten_config(config)\n",
    "\n",
    "    # Merge everything\n",
    "    train_args = {**fixed_args, **flat_config}\n",
    "\n",
    "    # Train and collect metrics\n",
    "    metrics = train_model_xgb_multilabel(**train_args)\n",
    "\n",
    "    # Report to Ray Tune\n",
    "    tune.report(metrics)\n",
    "\n",
    "\n",
    "def run_tuning(save_model=False):\n",
    "    \"\"\"Hyperparameter tuning for XGB Multilabel with Ray Tune.\"\"\"\n",
    "\n",
    "    search_space = {\n",
    "        # Sequence length\n",
    "        # \"seq_len\": tune.choice([1, 3, 5, 10, 20]),\n",
    "\n",
    "        # Core XGB hyperparameters\n",
    "        \"n_estimators\": tune.choice([100, 200, 400, 800]),\n",
    "        # \"max_depth\": tune.choice([3, 6, 9]),\n",
    "        # \"learning_rate\": tune.loguniform(1e-3, 0.3),   # typical XGB LR range\n",
    "        \"subsample\": tune.uniform(0.6, 1.0),\n",
    "        \"colsample_bytree\": tune.uniform(0.6, 1.0),\n",
    "\n",
    "        # Label handling\n",
    "        # \"label_weighting\": tune.choice([\"none\", \"scale_pos\"]),\n",
    "        # \"include_no_label\": tune.choice([False, True]),\n",
    "\n",
    "        # Threshold tuning\n",
    "        # \"threshold_tuning\": tune.choice([False, True]),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"exact_match\",   # use micro accuracy from your return dict\n",
    "        mode=\"max\",\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    # --- Add timestamp to run name ---\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"xgb_multilabel_tuning_{timestamp}\"\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        train_model_tune,\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            scheduler=scheduler,\n",
    "            num_samples=20,   # try more samples, adjust depending on compute\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=run_name,\n",
    "            storage_path=\"/home/iatell/projects/meta-learning/tune_logs\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Best trial\n",
    "    best_result = results.get_best_result(metric=\"exact_match\", mode=\"max\")\n",
    "    print(\"\\nðŸ† Best Config:\", best_result.config)\n",
    "    print(f\"Best Micro Accuracy: {best_result.metrics['exact_match']:.4f}\")\n",
    "    # Optional: retrain best model on full data and save\n",
    "    if save_model:\n",
    "        print(\"\\nðŸ” Retraining best XGB model on full dataset for saving...\")\n",
    "\n",
    "        # Re-train using the best configuration found\n",
    "        final_model_metrics = train_model_xgb_multilabel(\n",
    "            data_csv=\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "            labels_json=\"/home/iatell/projects/meta-learning/data/candle_labels.json\",\n",
    "            do_validation=True,\n",
    "            return_val_accuracy=True,\n",
    "            model_out_dir=\"models/saved_models\",\n",
    "            save_model=True,  # <--- actually save model here\n",
    "            seq_len=best_result.config.get(\"seq_len\", 5),\n",
    "            n_estimators=best_result.config.get(\"n_estimators\", 200),\n",
    "            max_depth=best_result.config.get(\"max_depth\", 6),\n",
    "            learning_rate=best_result.config.get(\"learning_rate\", 0.05),\n",
    "            subsample=best_result.config.get(\"subsample\", 0.8),\n",
    "            colsample_bytree=best_result.config.get(\"colsample_bytree\", 0.8),\n",
    "            label_weighting=best_result.config.get(\"label_weighting\", \"none\"),\n",
    "            include_no_label=best_result.config.get(\"include_no_label\", False),\n",
    "            threshold_tuning=best_result.config.get(\"threshold_tuning\", False),\n",
    "        )\n",
    "\n",
    "        print(\"\\nðŸ’¾ Final saved model metrics:\", final_model_metrics)\n",
    "if __name__ == \"__main__\":\n",
    "    run_tuning(save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25963f07",
   "metadata": {},
   "source": [
    "# tensorboard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f540a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching TensorBoard for: lightning_logs/version_37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "2025-09-22 21:46:06.967861: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-22 21:46:06.979429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758564966.992070   52360 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758564966.995816   52360 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758564967.005953   52360 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758564967.005987   52360 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758564967.005990   52360 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758564967.005991   52360 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-22 21:46:07.009201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0922 21:46:10.913562 135752092991616 program.py:300] TensorBoard could not bind to port 6006, it was already in use\n",
      "ERROR: TensorBoard could not bind to port 6006, it was already in use\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "logdir = \"lightning_logs\"\n",
    "\n",
    "# 1. Find all version folders\n",
    "versions = [d for d in os.listdir(logdir) if d.startswith(\"version_\") and d.split(\"_\")[1].isdigit()]\n",
    "if not versions:\n",
    "    raise ValueError(\"No version folders found in lightning_logs\")\n",
    "\n",
    "# 2. Pick the latest numerically\n",
    "latest_version = max(versions, key=lambda x: int(x.split(\"_\")[1]))\n",
    "latest_logdir = os.path.join(logdir, latest_version)\n",
    "print(f\"Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\"tensorboard\", f\"--logdir={latest_logdir}\", f\"--port={port}\"])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba3cdd",
   "metadata": {},
   "source": [
    "# tensorboard tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Launching TensorBoard for: /home/iatell/projects/meta-learning/tune_logs/fnn_cnn_multilabel_tuning_20250922_212647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: http://localhost:6006: Operation not supported\n",
      "2025-09-22 21:31:21.759277: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-22 21:31:21.768925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758564081.779705   52013 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758564081.782822   52013 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758564081.790998   52013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758564081.791044   52013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758564081.791047   52013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758564081.791048   52013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-22 21:31:21.793794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "# Base Ray Tune log directory\n",
    "base_logdir = \"/home/iatell/projects/meta-learning/tune_logs\"\n",
    "\n",
    "# Prefix filter (set to \"\" to disable filtering)\n",
    "# start_with = \"xgb_multilabel_tuning_\"   # e.g., only load runs that start with this\n",
    "# start_with = \"fullfnn_multilabel_tuning\"\n",
    "start_with =  \"fnn_cnn_multilabel_tuning\"\n",
    "# 1. Find all experiment folders\n",
    "experiments = [\n",
    "    d for d in os.listdir(base_logdir)\n",
    "    if os.path.isdir(os.path.join(base_logdir, d))\n",
    "    and d.startswith(start_with)\n",
    "]\n",
    "\n",
    "if not experiments:\n",
    "    raise ValueError(f\"No experiment folders found in tune_logs starting with '{start_with}'\")\n",
    "\n",
    "# 2. Sort by modification time and get the latest experiment\n",
    "experiments.sort(key=lambda x: os.path.getmtime(os.path.join(base_logdir, x)))\n",
    "latest_experiment = experiments[-1]\n",
    "latest_logdir = os.path.join(base_logdir, latest_experiment)\n",
    "print(f\"ðŸš€ Launching TensorBoard for: {latest_logdir}\")\n",
    "\n",
    "# 3. Choose a port\n",
    "port = 6006\n",
    "\n",
    "# 4. Launch TensorBoard as a background process\n",
    "subprocess.Popen([\n",
    "    \"tensorboard\",\n",
    "    f\"--logdir={latest_logdir}\",\n",
    "    f\"--port={port}\"\n",
    "])\n",
    "\n",
    "# 5. Open TensorBoard in default browser\n",
    "webbrowser.open(f\"http://localhost:{port}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
