{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv(\"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\")\n",
    "label[\"seq_len\"] = label[\"endIndex\"] - label[\"startIndex\"]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e027af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_shadow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Candle_Color",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "upper_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "upper_lower_body_ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "276b5b3c-e85b-4fb2-8da6-147dc065c148",
       "rows": [
        [
         "0",
         "2018-01-01",
         "13707.91",
         "13818.55",
         "12750.0",
         "13380.0",
         "8607.1564",
         "0.0760030099500053",
         "-0.2252544015971292",
         "0.4327720197804016",
         "1",
         "0.3374096550882847",
         "1.9212588820103085",
         "0.1756190476190467"
        ],
        [
         "1",
         "2018-01-02",
         "13382.16",
         "15473.49",
         "12890.02",
         "14675.11",
         "20078.1654",
         "0.5400711938112452",
         "0.8746274330998404",
         "0.3329124443526468",
         "2",
         "0.6174871418074936",
         "0.3806334351676392",
         "1.622261957979437"
        ],
        [
         "2",
         "2018-01-03",
         "14690.0",
         "15307.56",
         "14150.0",
         "14919.51",
         "15905.4821",
         "0.263643840163752",
         "0.1559306732534026",
         "0.3668797157284533",
         "2",
         "1.6907760010457011",
         "2.352838656267698",
         "0.7186111111111099"
        ],
        [
         "3",
         "2018-01-04",
         "14919.51",
         "15280.0",
         "13918.04",
         "15059.54",
         "25224.415",
         "0.1500060750668053",
         "0.0952796457026441",
         "0.6814233148741451",
         "2",
         "1.5743769192315795",
         "5.0",
         "0.2201363994927449"
        ],
        [
         "4",
         "2018-01-05",
         "15059.56",
         "17176.24",
         "14600.0",
         "16960.39",
         "23251.352",
         "0.144690479328261",
         "1.27418116201777",
         "0.3080563200375024",
         "2",
         "0.1135556572655114",
         "0.2417680697379563",
         "0.4696883975977073"
        ],
        [
         "5",
         "2018-01-06",
         "16960.39",
         "17143.13",
         "16011.21",
         "17069.79",
         "18571.4216",
         "0.0494002646223289",
         "0.0736895139035021",
         "0.639347466242461",
         "2",
         "0.6703839122486213",
         "5.0",
         "0.0772666933563708"
        ],
        [
         "6",
         "2018-01-07",
         "17069.79",
         "17099.96",
         "15610.0",
         "16150.03",
         "12493.3283",
         "0.0203204052621319",
         "-0.6194861101723416",
         "0.3637264982999586",
         "1",
         "0.0328020353135581",
         "0.5871422979907808",
         "0.0558672666333318"
        ],
        [
         "7",
         "2018-01-08",
         "16218.85",
         "16322.3",
         "12812.0",
         "14902.54",
         "26600.3888",
         "0.0678260053683906",
         "-0.863026091120997",
         "1.370642602830709",
         "1",
         "0.0785909094362262",
         "1.588182115155246",
         "0.0494848221033794"
        ],
        [
         "8",
         "2018-01-09",
         "14902.54",
         "15500.0",
         "14011.05",
         "14400.0",
         "14314.7761",
         "0.391905370614885",
         "-0.3296423609091905",
         "0.2551327183420815",
         "1",
         "1.188880487125399",
         "0.7739682413340233",
         "1.5360843296053426"
        ],
        [
         "9",
         "2018-01-10",
         "14401.0",
         "14955.66",
         "13131.31",
         "14907.09",
         "17411.0159",
         "0.0317347758076065",
         "0.3306702221221266",
         "0.8295929070446817",
         "2",
         "0.0959710723389114",
         "2.508822541445198",
         "0.0382534319400796"
        ],
        [
         "10",
         "2018-01-11",
         "14940.0",
         "14968.68",
         "11400.0",
         "13238.78",
         "33554.2284",
         "0.0182528519860017",
         "-1.0827097927345044",
         "1.1702572934037654",
         "1",
         "0.0168584897896805",
         "1.0808596183915082",
         "0.0155972982085949"
        ],
        [
         "11",
         "2018-01-12",
         "13238.76",
         "14109.78",
         "12500.0",
         "13740.01",
         "16417.08194",
         "0.235217906458799",
         "0.3188548979432428",
         "0.4699396397098256",
         "2",
         "0.7376957605985046",
         "1.473835411471322",
         "0.5005279116357143"
        ],
        [
         "12",
         "2018-01-13",
         "13749.95",
         "14580.0",
         "13706.15",
         "14210.0",
         "12221.5188",
         "0.2374735824307884",
         "0.2952695178304975",
         "0.0281117375958616",
         "2",
         "0.804260406477558",
         "0.0952070427127511",
         "5.0"
        ],
        [
         "13",
         "2018-01-14",
         "14210.0",
         "14339.5",
         "12569.2",
         "13474.99",
         "17017.6324",
         "0.0828899370954448",
         "-0.4704628004982467",
         "0.5797751051867408",
         "1",
         "0.176188079073754",
         "1.2323505802642123",
         "0.1429691208779078"
        ],
        [
         "14",
         "2018-01-15",
         "13477.98",
         "14249.99",
         "13147.79",
         "13539.93",
         "14652.0545",
         "0.4571857780873803",
         "0.0398876981558087",
         "0.2125991776281886",
         "2",
         "5.0",
         "5.0",
         "2.150458826736129"
        ],
        [
         "15",
         "2018-01-16",
         "13500.0",
         "13542.93",
         "9035.0",
         "10900.0",
         "63401.866",
         "0.026628097247025",
         "-1.612696315915788",
         "1.156799472762671",
         "1",
         "0.0165115384615385",
         "0.7173076923076923",
         "0.0230187667560323"
        ],
        [
         "16",
         "2018-01-17",
         "10899.99",
         "11680.99",
         "9037.94",
         "10988.79",
         "72330.098",
         "0.4239281967322686",
         "0.0543843164834238",
         "1.14038644716169",
         "2",
         "5.0",
         "5.0",
         "0.3717408232861626"
        ],
        [
         "17",
         "2018-01-18",
         "10972.59",
         "11878.82",
         "10435.33",
         "10961.97",
         "48464.707",
         "0.556297981065909",
         "-0.0065191889022879",
         "0.3232830172787815",
         "1",
         "5.0",
         "5.0",
         "1.7207770013671588"
        ],
        [
         "18",
         "2018-01-19",
         "10960.0",
         "11795.0",
         "10360.0",
         "11474.98",
         "34129.545",
         "0.1969164478876865",
         "0.3168802960227503",
         "0.3691952650853439",
         "2",
         "0.6214221911530559",
         "1.1650937900501002",
         "0.5333666666666673"
        ],
        [
         "19",
         "2018-01-20",
         "11474.98",
         "13099.0",
         "11412.45",
         "12799.94",
         "28768.4576",
         "0.1838802972519933",
         "0.814666082548658",
         "0.0384472513447701",
         "2",
         "0.2257124743388474",
         "0.0471938775510194",
         "4.7826643211259405"
        ],
        [
         "20",
         "2018-01-21",
         "12799.8",
         "12799.8",
         "10965.0",
         "11530.0",
         "41380.038",
         "0.0",
         "-0.778753121487601",
         "0.3465077284930657",
         "1",
         "0.0",
         "0.4449519609387308",
         "0.0"
        ],
        [
         "21",
         "2018-01-22",
         "11530.0",
         "11926.35",
         "9900.24",
         "10760.05",
         "43752.644",
         "0.2419030445007765",
         "-0.4699211533073619",
         "0.524765123482307",
         "1",
         "0.5147736866030262",
         "1.1167088771998166",
         "0.4609739361021628"
        ],
        [
         "22",
         "2018-01-23",
         "10760.05",
         "11399.0",
         "9905.0",
         "10799.18",
         "37474.2905",
         "0.3667329567204366",
         "0.0239242782776017",
         "0.5227818589640378",
         "2",
         "5.0",
         "5.0",
         "0.7015028360914569"
        ],
        [
         "23",
         "2018-01-24",
         "10799.14",
         "11570.48",
         "10500.0",
         "11349.99",
         "27158.7906",
         "0.1357467103297209",
         "0.3391359036016458",
         "0.1841683111616521",
         "2",
         "0.4002723064355081",
         "0.5430516474539334",
         "0.7370796282677015"
        ],
        [
         "24",
         "2018-01-25",
         "11349.96",
         "11794.05",
         "10950.21",
         "11175.27",
         "20840.207",
         "0.2760609679748225",
         "-0.1085930565775436",
         "0.1399047072719807",
         "1",
         "2.5421603984200782",
         "1.288339343980783",
         "1.973207144761386"
        ],
        [
         "25",
         "2018-01-26",
         "11184.7",
         "11643.0",
         "10311.15",
         "11089.0",
         "33056.907",
         "0.2858782400689901",
         "-0.0596957180331717",
         "0.4852070456854996",
         "1",
         "4.788923719958159",
         "5.0",
         "0.5891881468149374"
        ],
        [
         "26",
         "2018-01-27",
         "11089.0",
         "11650.0",
         "10842.69",
         "11491.0",
         "18860.9225",
         "0.1001755492535675",
         "0.253274030188265",
         "0.1551838964568941",
         "2",
         "0.3955223880597014",
         "0.6127114427860684",
         "0.6455279931793282"
        ],
        [
         "27",
         "2018-01-28",
         "11499.98",
         "12244.0",
         "11408.0",
         "11879.95",
         "16887.593",
         "0.2315560729827031",
         "0.2416820795254447",
         "0.0585044021231945",
         "2",
         "0.9581019554175282",
         "0.2420717425059854",
         "3.957925636007839"
        ],
        [
         "28",
         "2018-01-29",
         "11879.95",
         "11975.02",
         "11139.55",
         "11251.0",
         "14170.438",
         "0.0610418921628765",
         "-0.4038318930876343",
         "0.0715590499795167",
         "1",
         "0.1511566897209628",
         "0.1772000953970913",
         "0.8530282637954159"
        ],
        [
         "29",
         "2018-01-30",
         "11250.11",
         "11308.42",
         "9900.0",
         "10237.51",
         "25554.3345",
         "0.0375110737407957",
         "-0.6514099343153862",
         "0.2171216343381256",
         "1",
         "0.0575844361050755",
         "0.3333102903416947",
         "0.1727652513999569"
        ],
        [
         "30",
         "2018-01-31",
         "10230.0",
         "10425.85",
         "9700.0",
         "10285.1",
         "18015.6952",
         "0.0915207973272331",
         "0.0358280350460431",
         "0.3446253824755492",
         "2",
         "2.5544464609800195",
         "5.0",
         "0.265566037735849"
        ],
        [
         "31",
         "2018-02-01",
         "10285.1",
         "10335.0",
         "8750.99",
         "9224.52",
         "33564.9054",
         "0.0324273606349695",
         "-0.6892146321089428",
         "0.3077220056408268",
         "1",
         "0.0470497275075898",
         "0.4464821135605052",
         "0.1053787510822958"
        ],
        [
         "32",
         "2018-02-02",
         "9224.52",
         "9250.0",
         "8010.02",
         "8873.03",
         "49970.757",
         "0.01662266254104",
         "-0.2293053240404337",
         "0.5630111459789321",
         "1",
         "0.0724913937807607",
         "2.455290335429175",
         "0.0295245709783195"
        ],
        [
         "33",
         "2018-02-03",
         "8873.03",
         "9473.01",
         "8229.0",
         "9199.96",
         "28725.049",
         "0.1788064310925536",
         "0.2140896777772864",
         "0.4217421930655082",
         "2",
         "0.8351940782430561",
         "1.9699324014315105",
         "0.4239709330310712"
        ],
        [
         "34",
         "2018-02-04",
         "9199.96",
         "9368.0",
         "7930.0",
         "8184.81",
         "32014.443",
         "0.1101692897958844",
         "-0.6655460279474611",
         "0.1670568717739181",
         "1",
         "0.1655321873614747",
         "0.2510072403093146",
         "0.6594717632745991"
        ],
        [
         "35",
         "2018-02-05",
         "8179.99",
         "8382.8",
         "6625.0",
         "6939.99",
         "63402.168",
         "0.1325608261183738",
         "-0.8104897410718603",
         "0.2058840028550202",
         "1",
         "0.1635564516129028",
         "0.2540241935483869",
         "0.643861709895551"
        ],
        [
         "36",
         "2018-02-06",
         "6939.63",
         "7878.0",
         "6000.01",
         "7652.14",
         "100203.043",
         "0.1469581448945251",
         "0.4636020004374316",
         "0.6113734707597357",
         "2",
         "0.3169920422169508",
         "1.3187464035592478",
         "0.2403737681190265"
        ],
        [
         "37",
         "2018-02-07",
         "7655.02",
         "8476.0",
         "7150.01",
         "7599.0",
         "60777.498",
         "0.5356492803379135",
         "-0.036550309002083",
         "0.2929440064056612",
         "1",
         "5.0",
         "5.0",
         "1.8285039755896568"
        ],
        [
         "38",
         "2018-02-08",
         "7599.0",
         "8280.286",
         "7572.09",
         "8269.3955",
         "19947.321",
         "0.0071827961920388",
         "0.4421573155098645",
         "0.0177484087532961",
         "2",
         "0.0162448882786347",
         "0.0401404842365437",
         "0.4047008547008391"
        ],
        [
         "39",
         "2018-02-09",
         "8250.868",
         "8775.638",
         "8247.343",
         "8764.747",
         "31033.86",
         "0.0072779672878884",
         "0.3434023094235884",
         "0.0023555995491507",
         "2",
         "0.0211937051329232",
         "0.0068595914602457",
         "3.0896453900716496"
        ],
        [
         "40",
         "2018-02-10",
         "8720.666",
         "9065.78",
         "8120.0",
         "8533.98",
         "49473.936",
         "0.2323340969647822",
         "-0.1256788285203355",
         "0.2786953570747059",
         "1",
         "1.8486335343839493",
         "2.217520328251718",
         "0.8336489685492096"
        ],
        [
         "41",
         "2018-02-11",
         "8533.99",
         "8549.0",
         "7726.53",
         "8063.88",
         "47457.823",
         "0.0101958873475835",
         "-0.3193330180527918",
         "0.2291527379551797",
         "1",
         "0.0319286975388743",
         "0.7175980089766238",
         "0.0444938491181271"
        ],
        [
         "42",
         "2018-02-12",
         "8063.82",
         "8989.0",
         "8053.0",
         "8903.0",
         "41987.984",
         "0.058846111468448",
         "0.574214881652235",
         "0.0074036619312626",
         "2",
         "0.1024809933506517",
         "0.0128935389308607",
         "5.0"
        ],
        [
         "43",
         "2018-02-13",
         "8903.0",
         "8950.0",
         "8351.0",
         "8539.9",
         "35455.1325",
         "0.0325441902283817",
         "-0.2514211802537326",
         "0.1307999475349213",
         "1",
         "0.1294409253649131",
         "0.5202423574772775",
         "0.2488088935944949"
        ],
        [
         "44",
         "2018-02-14",
         "8535.17",
         "9489.6",
         "8533.0",
         "9449.99",
         "40812.275",
         "0.0276135947036951",
         "0.6377548272364056",
         "0.0015127871877561",
         "2",
         "0.043298135152271",
         "0.0023720513325026",
         "5.0"
        ],
        [
         "45",
         "2018-02-15",
         "9449.98",
         "10219.5",
         "9301.5",
         "10000.09",
         "52427.447",
         "0.1540681969828395",
         "0.386283468584978",
         "0.1042616375188549",
         "2",
         "0.3988475032266267",
         "0.2699096544327487",
         "1.477707435344831"
        ],
        [
         "46",
         "2018-02-16",
         "10000.89",
         "10323.37",
         "9666.0",
         "10159.98",
         "38161.297",
         "0.1159802105173432",
         "0.1129279129151356",
         "0.2377171962797767",
         "2",
         "1.0270287258784403",
         "2.105034885913628",
         "0.4878915464779525"
        ],
        [
         "47",
         "2018-02-17",
         "10156.07",
         "11075.07",
         "10050.0",
         "11039.55",
         "41882.537",
         "0.0253514964652467",
         "0.630561376607993",
         "0.0757047643600417",
         "2",
         "0.0402046452664468",
         "0.120059310906868",
         "0.3348731969454184"
        ],
        [
         "48",
         "2018-02-18",
         "11039.55",
         "11274.0",
         "10080.0",
         "10383.43",
         "61137.679",
         "0.1678288690562156",
         "-0.4696774474948333",
         "0.2172075655266683",
         "1",
         "0.3573279278180837",
         "0.4624611351582039",
         "0.77266585373892"
        ],
        [
         "49",
         "2018-02-19",
         "10375.01",
         "11250.0",
         "10270.33",
         "11153.0",
         "40831.479",
         "0.0698538791260975",
         "0.560264117745491",
         "0.0753845780094836",
         "2",
         "0.1246802658131852",
         "0.1345518579930337",
         "0.9266335498662563"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 1604
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>upper_shadow</th>\n",
       "      <th>body</th>\n",
       "      <th>lower_shadow</th>\n",
       "      <th>Candle_Color</th>\n",
       "      <th>upper_body_ratio</th>\n",
       "      <th>lower_body_ratio</th>\n",
       "      <th>upper_lower_body_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13707.91</td>\n",
       "      <td>13818.55</td>\n",
       "      <td>12750.00</td>\n",
       "      <td>13380.00</td>\n",
       "      <td>8607.15640</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>-0.225254</td>\n",
       "      <td>0.432772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337410</td>\n",
       "      <td>1.921259</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13382.16</td>\n",
       "      <td>15473.49</td>\n",
       "      <td>12890.02</td>\n",
       "      <td>14675.11</td>\n",
       "      <td>20078.16540</td>\n",
       "      <td>0.540071</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617487</td>\n",
       "      <td>0.380633</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14690.00</td>\n",
       "      <td>15307.56</td>\n",
       "      <td>14150.00</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15905.48210</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.155931</td>\n",
       "      <td>0.366880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.690776</td>\n",
       "      <td>2.352839</td>\n",
       "      <td>0.718611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>14919.51</td>\n",
       "      <td>15280.00</td>\n",
       "      <td>13918.04</td>\n",
       "      <td>15059.54</td>\n",
       "      <td>25224.41500</td>\n",
       "      <td>0.150006</td>\n",
       "      <td>0.095280</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>2</td>\n",
       "      <td>1.574377</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.220136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15059.56</td>\n",
       "      <td>17176.24</td>\n",
       "      <td>14600.00</td>\n",
       "      <td>16960.39</td>\n",
       "      <td>23251.35200</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>1.274181</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.469688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>28715.33</td>\n",
       "      <td>30545.18</td>\n",
       "      <td>28691.38</td>\n",
       "      <td>30319.23</td>\n",
       "      <td>67877.36415</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>2</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>30319.22</td>\n",
       "      <td>30777.33</td>\n",
       "      <td>28730.00</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>60517.25325</td>\n",
       "      <td>0.221063</td>\n",
       "      <td>-0.539597</td>\n",
       "      <td>0.227288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409682</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.972612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>29201.01</td>\n",
       "      <td>29656.18</td>\n",
       "      <td>28947.28</td>\n",
       "      <td>29445.06</td>\n",
       "      <td>20987.13124</td>\n",
       "      <td>0.103235</td>\n",
       "      <td>0.119338</td>\n",
       "      <td>0.124071</td>\n",
       "      <td>2</td>\n",
       "      <td>0.865069</td>\n",
       "      <td>1.039664</td>\n",
       "      <td>0.832066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>29445.07</td>\n",
       "      <td>30487.99</td>\n",
       "      <td>29255.11</td>\n",
       "      <td>30293.94</td>\n",
       "      <td>36158.98748</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>1.021531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>30293.93</td>\n",
       "      <td>30670.51</td>\n",
       "      <td>30048.77</td>\n",
       "      <td>30472.79</td>\n",
       "      <td>20776.30953</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105446</td>\n",
       "      <td>1.370681</td>\n",
       "      <td>0.806494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp      open      high       low     close       volume  \\\n",
       "0     2018-01-01  13707.91  13818.55  12750.00  13380.00   8607.15640   \n",
       "1     2018-01-02  13382.16  15473.49  12890.02  14675.11  20078.16540   \n",
       "2     2018-01-03  14690.00  15307.56  14150.00  14919.51  15905.48210   \n",
       "3     2018-01-04  14919.51  15280.00  13918.04  15059.54  25224.41500   \n",
       "4     2018-01-05  15059.56  17176.24  14600.00  16960.39  23251.35200   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "1599  2022-05-19  28715.33  30545.18  28691.38  30319.23  67877.36415   \n",
       "1600  2022-05-20  30319.22  30777.33  28730.00  29201.01  60517.25325   \n",
       "1601  2022-05-21  29201.01  29656.18  28947.28  29445.06  20987.13124   \n",
       "1602  2022-05-22  29445.07  30487.99  29255.11  30293.94  36158.98748   \n",
       "1603  2022-05-23  30293.93  30670.51  30048.77  30472.79  20776.30953   \n",
       "\n",
       "      upper_shadow      body  lower_shadow  Candle_Color  upper_body_ratio  \\\n",
       "0         0.076003 -0.225254      0.432772             1          0.337410   \n",
       "1         0.540071  0.874627      0.332912             2          0.617487   \n",
       "2         0.263644  0.155931      0.366880             2          1.690776   \n",
       "3         0.150006  0.095280      0.681423             2          1.574377   \n",
       "4         0.144690  1.274181      0.308056             2          0.113556   \n",
       "...            ...       ...           ...           ...               ...   \n",
       "1599      0.109006  0.773779      0.011554             2          0.140875   \n",
       "1600      0.221063 -0.539597      0.227288             1          0.409682   \n",
       "1601      0.103235  0.119338      0.124071             2          0.865069   \n",
       "1602      0.095648  0.418411      0.093632             2          0.228598   \n",
       "1603      0.098828  0.089401      0.122540             2          1.105446   \n",
       "\n",
       "      lower_body_ratio  upper_lower_body_ratio  \n",
       "0             1.921259                0.175619  \n",
       "1             0.380633                1.622262  \n",
       "2             2.352839                0.718611  \n",
       "3             5.000000                0.220136  \n",
       "4             0.241768                0.469688  \n",
       "...                ...                     ...  \n",
       "1599          0.014932                5.000000  \n",
       "1600          0.421218                0.972612  \n",
       "1601          1.039664                0.832066  \n",
       "1602          0.223780                1.021531  \n",
       "1603          1.370681                0.806494  \n",
       "\n",
       "[1604 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles_prop.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b8d98",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab1e7f",
   "metadata": {},
   "source": [
    "## two head lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccb5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMMultiRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, max_len_y, lr=0.001, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Main regression output: predict all linePrices up to max_len_y\n",
    "        self.fc_reg = nn.Linear(hidden_dim, max_len_y)\n",
    "        # Length prediction branch: logits per possible line (max_len_y)\n",
    "        self.fc_len = nn.Linear(hidden_dim, max_len_y)\n",
    "        self.lr = lr\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.loss_fn_reg = nn.MSELoss(reduction=\"none\")  # we'll mask padded values\n",
    "        self.loss_fn_len = nn.BCEWithLogitsLoss()        # treat as multi-label classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x[\"main\"] \n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        last_h = hn[-1]\n",
    "\n",
    "        y_pred = self.fc_reg(last_h)      # regression outputs\n",
    "        len_logits = self.fc_len(last_h)  # logits per possible line\n",
    "        return y_pred, len_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        y_pred, len_logits = self(X, lengths)\n",
    "\n",
    "        # --- Regression loss with masking ---\n",
    "        mask = (y != 0).float()  # assume padding = 0\n",
    "        loss_reg = (self.loss_fn_reg(y_pred, y) * mask).sum() / mask.sum()\n",
    "\n",
    "        # --- Length loss ---\n",
    "        target_lengths = torch.zeros_like(len_logits, dtype=torch.float32)\n",
    "        for i, l in enumerate(lengths):\n",
    "            target_lengths[i, :l] = 1.0   # first l positions are 1, rest are 0\n",
    "\n",
    "        loss_len = self.loss_fn_len(len_logits, target_lengths)\n",
    "\n",
    "        loss = loss_reg + 0.1 * loss_len\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def predict_length(self, len_logits):\n",
    "        \"\"\"\n",
    "        Convert logits to predicted number of lines using threshold.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(len_logits)\n",
    "        pred_len = (probs > self.threshold).sum(dim=1)\n",
    "        return pred_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b75a48",
   "metadata": {},
   "source": [
    "## FNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c70fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b1d4",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368a03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "    B = y_true.shape[0]\n",
    "\n",
    "    # Keep track if any valid lines are found\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]  # (B,1)\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "\n",
    "        mask = (y_target != 0).squeeze()\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        valid_line_found = True\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_loss = -log_likelihood.mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        # Avoid returning a Python float; create a tensor with requires_grad\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a057d",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening with pi order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce6729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    Splits raw MDN output into mixture weights (pi), means (mu), and stds (sigma)\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)           # mixture probabilities\n",
    "    mu = raw[..., 1]                              # means\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4       # stds\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def weighted_mdn_nll(y_true, mdn_params, weights):\n",
    "    \"\"\"\n",
    "    y_true: (B, num_lines)\n",
    "    mdn_params: dict with 'pi', 'mu', 'sigma' each of shape (B, n_components)\n",
    "    weights: (num_lines,) tensor\n",
    "    \"\"\"\n",
    "    B, num_lines = y_true.shape\n",
    "    pi, mu, sigma = mdn_params['pi'], mdn_params['mu'], mdn_params['sigma']  # (B, n_components)\n",
    "\n",
    "    # Sort components by pi descending\n",
    "    _, idx = torch.sort(pi, descending=True, dim=1)  # (B, n_components)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    valid_line_found = False\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i]  # (B,)\n",
    "\n",
    "        # Skip masked/padded targets\n",
    "        mask = (y_target != 0)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        valid_line_found = True\n",
    "\n",
    "        # Select top pi component for this line\n",
    "        top_mu = mu.gather(1, idx[:, i].unsqueeze(1)).squeeze(1)      # (B,)\n",
    "        top_sigma = sigma.gather(1, idx[:, i].unsqueeze(1)).squeeze(1) # (B,)\n",
    "        y_target_masked = y_target[mask]\n",
    "        top_mu_masked = top_mu[mask]\n",
    "        top_sigma_masked = top_sigma[mask]\n",
    "\n",
    "        dist = Normal(top_mu_masked, top_sigma_masked)\n",
    "        line_loss = -dist.log_prob(y_target_masked).mean()\n",
    "        total_loss += weights[i] * line_loss\n",
    "\n",
    "    if not valid_line_found:\n",
    "        total_loss = torch.tensor(0.0, device=y_true.device, requires_grad=True)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, n_components=9, num_lines=9, lr=1e-3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_lines = num_lines\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Base network\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Single MDN head predicting n_components Gaussians\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "\n",
    "        # Importance weights for lines\n",
    "        weights = torch.tensor([0.9**i for i in range(num_lines)], dtype=torch.float)\n",
    "        self.register_buffer(\"loss_weights\", weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        \"\"\"\n",
    "        X: (B, T, input_dim)\n",
    "        \"\"\"\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        \n",
    "        if lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(x)\n",
    "\n",
    "        last_h = h_last[-1]  # (B, hidden_dim)\n",
    "        raw_params = self.mdn_head(last_h)  # (B, 3*n_components)\n",
    "        pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X)\n",
    "        loss = weighted_mdn_nll(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e7f3",
   "metadata": {},
   "source": [
    "## CNNLSTM weightening with sigma confidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e3bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import pytorch_lightning as pl\n",
    "# Your mdn_split_params function remains the same\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "    pi = F.softmax(raw[..., 0], dim=-1)\n",
    "    mu = raw[..., 1]\n",
    "    sigma = F.softplus(raw[..., 2]) + 1e-4\n",
    "    return pi, mu, sigma\n",
    "\n",
    "def weighted_mdn_nll_with_sigma_penalty(y_true, mdn_params, weights, lambda_sigma=0.01):\n",
    "    \"\"\"\n",
    "    Calculates weighted MDN NLL and adds a penalty for large sigmas.\n",
    "    \n",
    "    Args:\n",
    "        lambda_sigma (float): The strength of the sigma penalty.\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    num_lines = y_true.shape[1]\n",
    "\n",
    "    for i in range(num_lines):\n",
    "        y_target = y_true[:, i:i+1]\n",
    "        pi, mu, sigma = mdn_params['pi'][i], mdn_params['mu'][i], mdn_params['sigma'][i]\n",
    "        mask = (y_target != -1).squeeze()\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        y_target_masked = y_target[mask]\n",
    "        pi_masked, mu_masked, sigma_masked = pi[mask], mu[mask], sigma[mask]\n",
    "        \n",
    "        # --- 1. NLL Loss Calculation (same as before) ---\n",
    "        dist = Normal(loc=mu_masked, scale=sigma_masked)\n",
    "        log_prob = dist.log_prob(y_target_masked.expand_as(mu_masked))\n",
    "        log_mix_prob = torch.log(pi_masked + 1e-8) + log_prob\n",
    "        log_likelihood = torch.logsumexp(log_mix_prob, dim=1)\n",
    "        line_nll_loss = -log_likelihood.mean()\n",
    "\n",
    "        # --- 2. NEW: Sigma Penalty Calculation ---\n",
    "        # We penalize the mean of the sigmas for the most likely component\n",
    "        # This focuses the penalty on the component the model actually uses\n",
    "        most_likely_idx = torch.argmax(pi_masked, dim=1)\n",
    "        most_likely_sigma = sigma_masked.gather(1, most_likely_idx.unsqueeze(1)).squeeze()\n",
    "        sigma_penalty = torch.mean(most_likely_sigma)\n",
    "        \n",
    "        # --- 3. Combine and Weight ---\n",
    "        combined_line_loss = line_nll_loss + (lambda_sigma * sigma_penalty)\n",
    "        total_loss += weights[i] * combined_line_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# In your training_step, you would call this new function:\n",
    "# loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights, lambda_sigma=0.01)\n",
    "\n",
    "class CNNLSTM_MDN_MultiHead(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1, num_lines=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # --- Your CNN and LSTM base remains the same ---\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels)\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "        fused_dim = cnn_channels\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                              batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # === MODIFICATION: Create a list of MDN heads ===\n",
    "        self.num_lines = num_lines\n",
    "        self.mdn_heads = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, 3 * n_components) for _ in range(num_lines)]\n",
    "        )\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # === Define importance weights here ===\n",
    "        # Using exponential decay: w_i = 0.9^(i-1)\n",
    "        weights = torch.tensor([0.9**i for i in range(self.num_lines)])\n",
    "        self.register_buffer('loss_weights', weights)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module): # Your init function is fine\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # --- Your forward pass for the base model is the same ---\n",
    "        x = X[\"main\"]\n",
    "        x = F.relu(self.ln1(self.fc1(x)))\n",
    "        x = F.relu(self.ln2(self.fc2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        x3 = F.relu(self.bn3(self.conv3(x)))\n",
    "        paired = torch.stack([x1, x3], dim=1)\n",
    "        mixed = self.mixer(paired)\n",
    "        xf = mixed.squeeze(1).transpose(1, 2)\n",
    "        \n",
    "        # We'll assume lengths is None for simplicity here, but your implementation is fine\n",
    "        _, (h_last, _) = self.lstm(xf)\n",
    "        last_h = h_last[-1]\n",
    "\n",
    "        # === MODIFICATION: Get parameters from all heads ===\n",
    "        all_params = {'pi': [], 'mu': [], 'sigma': []}\n",
    "        for i in range(self.num_lines):\n",
    "            raw_params = self.mdn_heads[i](last_h)\n",
    "            pi, mu, sigma = mdn_split_params(raw_params, self.n_components)\n",
    "            all_params['pi'].append(pi)\n",
    "            all_params['mu'].append(mu)\n",
    "            all_params['sigma'].append(sigma)\n",
    "\n",
    "        return all_params\n",
    "    \n",
    "\n",
    "    # This would be inside your CNNLSTM_MDN_MultiHead class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Assuming your batch now provides a y tensor of shape (B, 9)\n",
    "        # where y has your target line values, padded with -1.\n",
    "        X, y, lengths = batch\n",
    "\n",
    "        # Get the dictionary of parameter lists from the forward pass\n",
    "        mdn_params = self(X, lengths)\n",
    "\n",
    "        # Calculate loss using the new weighted function\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    # NOTE: You'll also need a validation_step that mirrors the training_step logic\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y, lengths = batch\n",
    "        mdn_params = self(X, lengths)\n",
    "        loss = weighted_mdn_nll_with_sigma_penalty(y, mdn_params, self.loss_weights)\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6484b7d",
   "metadata": {},
   "source": [
    "## CNNlSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2139f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components):\n",
    "    \"\"\"\n",
    "    raw_params: (B, 3K) tensor from mdn_head\n",
    "    returns:\n",
    "        pi    (B, K) mixture weights\n",
    "        mu    (B, K) means\n",
    "        sigma (B, K) std devs\n",
    "    \"\"\"\n",
    "    B, threeK = raw_params.shape\n",
    "    assert threeK == 3 * n_components\n",
    "\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi = raw[..., 0]                 # (B,K)\n",
    "    mu = raw[..., 1]                 # (B,K)\n",
    "    sigma = raw[..., 2]              # (B,K)\n",
    "\n",
    "    pi = F.softmax(pi, dim=-1)       # weights sum to 1\n",
    "    sigma = F.softplus(sigma) + 1e-4 # strictly positive\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] # REMOVED redundant transposes\n",
    "\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # Inside your CNNLSTM_MDN class\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 50% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    \n",
    "    def configure_optimizers(self): \n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode=\"min\",\n",
    "    #         factor=0.2,   # Reduce LR by 80%\n",
    "    #         patience=5,   # After 5 epochs of no val_loss improvement\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # Important!\n",
    "    #         },\n",
    "        # }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e8361",
   "metadata": {},
   "source": [
    "## CNNLSTM scalie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a359387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def mdn_split_params(raw_params, n_components, mu_scale=10, mu_bias=.9, sigma_scale=10.0):\n",
    "    \"\"\"\n",
    "    Split raw MDN parameters into (pi, mu, sigma).\n",
    "\n",
    "    Args:\n",
    "        raw_params: (B, 3 * K) from the network\n",
    "        n_components: number of mixture components\n",
    "        mu_scale: scaling factor for mu (default 1.0 = no scaling)\n",
    "        mu_bias: shift/bias applied after scaling\n",
    "        sigma_scale: scaling factor for sigma (default 10.0)\n",
    "    \"\"\"\n",
    "    B = raw_params.size(0)\n",
    "    raw = raw_params.view(B, n_components, 3)\n",
    "\n",
    "    pi_raw = raw[..., 0]\n",
    "    mu_raw = raw[..., 1]\n",
    "    sigma_raw = raw[..., 2]\n",
    "\n",
    "    pi = F.softmax(pi_raw, dim=-1)\n",
    "    mu = mu_raw / mu_scale + mu_bias\n",
    "    sigma = F.softplus(sigma_raw / sigma_scale) + 1e-4\n",
    "\n",
    "    return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_nll_multitarget(y_line, pi, mu, sigma):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for MDN with multiple valid targets per sample.\n",
    "    Args:\n",
    "        y_line : (B, L) padded targets (0 where invalid)\n",
    "        pi, mu, sigma : (B, K) MDN params\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    B, K = mu.shape\n",
    "    losses = []\n",
    "\n",
    "    for b in range(B):\n",
    "        valid_y = y_line[b][y_line[b] > 0]  # (M,)\n",
    "        if len(valid_y) == 0:\n",
    "            continue\n",
    "\n",
    "        # expand to (M, K)\n",
    "        y_exp = valid_y.unsqueeze(-1).expand(-1, K)\n",
    "\n",
    "        log_prob = -0.5 * ((y_exp - mu[b]) / (sigma[b] + 1e-8))**2 \\\n",
    "                   - torch.log(sigma[b] + 1e-8) \\\n",
    "                   - 0.5 * torch.log(torch.tensor(2.0 * torch.pi, device=y_line.device))\n",
    "\n",
    "        log_mix = torch.log(pi[b] + 1e-8) + log_prob\n",
    "        log_sum = torch.logsumexp(log_mix, dim=-1)  # (M,)\n",
    "\n",
    "        losses.append(-log_sum.mean())\n",
    "\n",
    "    if len(losses) == 0:\n",
    "        return torch.tensor(0.0, device=y_line.device, requires_grad=True)\n",
    "\n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "\n",
    "class CNNLSTM_MDN(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=1, hidden_features=64, out_features=32,\n",
    "                 lr=1e-3, n_components=5, cnn_channels=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Time-distributed feature extractor\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_features)\n",
    "        self.ln1 = nn.LayerNorm(hidden_features) # ADDED: LayerNorm for time-step features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features) # ADDED: LayerNorm\n",
    "\n",
    "        # CNN feature extractors\n",
    "        self.conv1 = nn.Conv1d(out_features, cnn_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm for convolutional features\n",
    "        self.conv3 = nn.Conv1d(out_features, cnn_channels, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(cnn_channels) # ADDED: BatchNorm\n",
    "\n",
    "        # Learnable mixer for CNN outputs\n",
    "        self.mixer = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1, bias=True)\n",
    "\n",
    "        # LSTM for temporal dependency\n",
    "        fused_dim = cnn_channels # Input to LSTM is the mixed CNN output\n",
    "        self.lstm = nn.LSTM(fused_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "\n",
    "        # MDN Head\n",
    "        self.mdn_head = nn.Linear(hidden_dim, 3 * n_components)\n",
    "        self.n_components = n_components\n",
    "        self.lr = lr\n",
    "\n",
    "        # Apply weight initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, X, lengths=None):\n",
    "        # Input shape X[\"main\"]: (B, T, F_in)\n",
    "        x = X[\"main\"] \n",
    "\n",
    "        # --- Debug print first candle ---\n",
    "        # if x.ndim == 3:  # batched: (B, T, F)\n",
    "        #     first_candle = x[0, 0, :]   # first sample, first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # elif x.ndim == 2:  # single sequence: (T, F)\n",
    "        #     first_candle = x[0, :]      # first time step, all features\n",
    "        #     print(\"First candle features:\", first_candle.detach().cpu().numpy())\n",
    "        # else:\n",
    "        #     print(\"Unexpected shape for x:\", x.shape)\n",
    "        # 1. Time-distributed feature extraction\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.ln1(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.ln2(x)) # CHANGED: Apply LayerNorm before ReLU\n",
    "\n",
    "        # 2. CNN feature extraction\n",
    "        x = x.transpose(1, 2)   # Shape: (B, C_in, L=T)\n",
    "        x1 = F.relu(self.bn1(self.conv1(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "        x3 = F.relu(self.bn3(self.conv3(x))) # CHANGED: Apply BatchNorm before ReLU\n",
    "\n",
    "        # 3. Mix CNN outputs\n",
    "        paired = torch.stack([x1, x3], dim=1) # Shape: (B, 2, C_out, L)\n",
    "        mixed = self.mixer(paired)            # Shape: (B, 1, C_out, L)\n",
    "        \n",
    "        # Prepare for LSTM\n",
    "        xf = mixed.squeeze(1).transpose(1, 2) # Shape: (B, L, C_out)\n",
    "\n",
    "        # 4. LSTM for sequence summary\n",
    "        if lengths is not None:\n",
    "            packed_input = pack_padded_sequence(\n",
    "                xf, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, (h_last, _) = self.lstm(packed_input)\n",
    "        else:\n",
    "            _, (h_last, _) = self.lstm(xf)\n",
    "        \n",
    "        last_h = h_last[-1] # Shape: (B, H)\n",
    "        \n",
    "        # 5. MDN head for distribution parameters\n",
    "        raw = self.mdn_head(last_h)\n",
    "        pi, mu, sigma = mdn_split_params(raw, self.n_components)\n",
    "        return {\"pi\": pi, \"mu\": mu, \"sigma\": sigma}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y_line, lengths = batch\n",
    "        mdn = self(X, lengths)\n",
    "        loss = mdn_nll_multitarget(y_line, mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"])\n",
    "    # Log everything to progress bar\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/pi_mean\", mdn[\"pi\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/pi_std\", mdn[\"pi\"].std(), prog_bar=True)\n",
    "        self.log(\"val/mu_mean\", mdn[\"mu\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/mu_std\", mdn[\"mu\"].std(), prog_bar=True)\n",
    "        self.log(\"val/sigma_mean\", mdn[\"sigma\"].mean(), prog_bar=True)\n",
    "        self.log(\"val/sigma_std\", mdn[\"sigma\"].std(), prog_bar=True)\n",
    "        \n",
    "    # # Inside your CNNLSTM_MDN class\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    #     # Define the scheduler\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #         optimizer,\n",
    "    #         mode='min',      # We want to minimize the validation loss\n",
    "    #         factor=0.5,      # Reduce LR by 80% (1.0 -> 0.2)\n",
    "    #         patience=10,      # Wait 5 validation epochs with no improvement before reducing\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "        \n",
    "    #     return {\n",
    "    #         \"optimizer\": optimizer,\n",
    "    #         \"lr_scheduler\": {\n",
    "    #             \"scheduler\": scheduler,\n",
    "    #             \"monitor\": \"val/loss\",  # The metric to watch\n",
    "    #         },\n",
    "    #     }\n",
    "    # def configure_optimizers(self):\n",
    "    #     return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefa26",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95badad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endTime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "startIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "endIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "linePrice_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linePrice_9",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6d37502b-8844-4574-b3cd-d3f9d9cfeb6c",
       "rows": [
        [
         "0",
         "1514764800",
         "1515110400",
         "0",
         "4",
         null,
         "0.878016",
         "0.788209",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "1514764800",
         "1515283200",
         "0",
         "6",
         null,
         "1.05529",
         "0.923251",
         "0.828937",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "1515024000",
         "1515369600",
         "3",
         "7",
         "1.143628",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "1515456000",
         "1514937600",
         "2",
         "8",
         "1.139775",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "1515110400",
         "1515542400",
         "4",
         "9",
         "1.143279",
         "0.964469",
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "1515196800",
         "1515628800",
         "5",
         "10",
         "1.290228",
         "1.126277",
         "1.086008",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "1515283200",
         "1515888000",
         "6",
         "13",
         "1.105121",
         "1.041538",
         "0.982194",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "1515369600",
         "1516060800",
         "7",
         "15",
         "1.236932",
         "1.364445",
         "1.299815",
         null,
         "1.177543",
         "1.053524",
         null,
         null,
         null
        ],
        [
         "8",
         "1515801600",
         "1516320000",
         "12",
         "18",
         "0.954276",
         "1.173294",
         "0.785035",
         "1.238004",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "1516492800",
         "1516147200",
         "16",
         "20",
         "0.996497",
         null,
         "1.16283",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "1516060800",
         "1516924800",
         "15",
         "25",
         null,
         "0.989209",
         "1.026983",
         "0.922247",
         "1.154039",
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "1515974400",
         "1517443200",
         "14",
         "31",
         "1.259327",
         null,
         "1.143742",
         "1.218046",
         "1.042605",
         "1.383168",
         null,
         null,
         null
        ],
        [
         "12",
         "1516838400",
         "1517788800",
         "24",
         "35",
         null,
         "1.67662",
         "1.476347",
         "1.322714",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "1517443200",
         "1518134400",
         "31",
         "39",
         "0.866167",
         "1.044538",
         "0.790359",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "1517702400",
         "1518048000",
         "34",
         "38",
         "0.913325",
         "0.840066",
         "0.77626",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "1517875200",
         "1518566400",
         "36",
         "44",
         "0.908825",
         "0.803359",
         null,
         "0.962592",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "1518134400",
         "1518825600",
         "39",
         "47",
         "0.772655",
         null,
         "0.723089",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "1518307200",
         "1518912000",
         "41",
         "48",
         "0.82336",
         null,
         "0.776309",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "1518480000",
         "1518912000",
         "43",
         "48",
         null,
         null,
         "0.819596",
         "1.0605",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "1518480000",
         "1519171200",
         "43",
         "51",
         "1.068102",
         "0.991338",
         null,
         "0.817215",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "1518652800",
         "1519344000",
         "45",
         "53",
         "1.106209",
         "1.015549",
         null,
         "0.965396",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "1518912000",
         "1519689600",
         "48",
         "57",
         "1.058517",
         "0.977161",
         null,
         "0.919841",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "1518825600",
         "1518998400",
         "47",
         "49",
         null,
         "0.929502",
         "0.989077",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "1517875200",
         "1518048000",
         "36",
         "38",
         "0.918052",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "1518134400",
         "1518566400",
         "39",
         "44",
         "0.902621",
         null,
         "0.855058",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "1519084800",
         "1519516800",
         "50",
         "55",
         "1.168618",
         null,
         "1.060616",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "1519516800",
         "1519948800",
         "55",
         "60",
         "0.93202",
         "0.866519",
         null,
         "0.988669",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "1519776000",
         "1520121600",
         "58",
         "62",
         null,
         null,
         "0.898584",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "1520121600",
         "1519862400",
         "59",
         "62",
         null,
         null,
         null,
         "0.999443",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "1518566400",
         "1518825600",
         "44",
         "47",
         null,
         null,
         null,
         null,
         "0.90719",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "1520035200",
         "1520640000",
         "61",
         "68",
         "1.311277",
         null,
         "1.055028",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "1520380800",
         "1520726400",
         "65",
         "69",
         null,
         "0.923406",
         null,
         "0.970552",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "1520467200",
         "1520985600",
         "66",
         "72",
         "1.137321",
         null,
         "1.070346",
         null,
         "1.18516",
         "1.022507",
         null,
         null,
         null
        ],
        [
         "33",
         "1520640000",
         "1521244800",
         "68",
         "75",
         "1.17662",
         "1.057056",
         "1.111053",
         "1.236402",
         "0.97799",
         "0.933635",
         null,
         null,
         null
        ],
        [
         "34",
         "1521158400",
         "1521504000",
         "74",
         "78",
         "0.924926",
         "0.869038",
         null,
         "0.830086",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "1521244800",
         "1521504000",
         "75",
         "78",
         null,
         null,
         "0.875812",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "1521331200",
         "1521676800",
         "76",
         "80",
         "1.022609",
         null,
         null,
         "1.048557",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "1521590400",
         "1521849600",
         "79",
         "82",
         "1.04014",
         null,
         null,
         "0.987174",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "1521676800",
         "1522022400",
         "80",
         "84",
         null,
         "1.092904",
         null,
         "1.039106",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "1521763200",
         "1522108800",
         "81",
         "85",
         null,
         null,
         "1.086192",
         "1.140392",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "1521936000",
         "1522281600",
         "83",
         "87",
         null,
         null,
         "1.121892",
         "1.198509",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "1522108800",
         "1522368000",
         "85",
         "88",
         "1.158468",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "1522195200",
         "1522540800",
         "86",
         "90",
         null,
         null,
         "0.999198",
         "1.167526",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "1522281600",
         "1522627200",
         "87",
         "91",
         null,
         "0.981897",
         null,
         "0.93271",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "1522368000",
         "1522800000",
         "88",
         "93",
         null,
         null,
         null,
         null,
         "1.010566",
         "1.088278",
         null,
         null,
         null
        ],
        [
         "46",
         "1522454400",
         "1523059200",
         "89",
         "96",
         null,
         null,
         "0.98939",
         "1.074732",
         "0.93906",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "1522713600",
         "1523059200",
         "92",
         "96",
         null,
         null,
         "0.982825",
         "1.074732",
         "0.95219",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "1522281600",
         "1523404800",
         "87",
         "100",
         null,
         "0.987649",
         "1.044069",
         null,
         "0.937739",
         "1.078789",
         null,
         null,
         null
        ],
        [
         "49",
         "1522886400",
         "1523059200",
         "94",
         "96",
         null,
         null,
         "0.971884",
         null,
         "0.947813",
         null,
         null,
         null,
         null
        ],
        [
         "50",
         "1522972800",
         "1523404800",
         "95",
         "100",
         null,
         null,
         "0.991989",
         null,
         null,
         "1.024539",
         "0.948589",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 320
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>linePrice_1</th>\n",
       "      <th>linePrice_2</th>\n",
       "      <th>linePrice_3</th>\n",
       "      <th>linePrice_4</th>\n",
       "      <th>linePrice_5</th>\n",
       "      <th>linePrice_6</th>\n",
       "      <th>linePrice_7</th>\n",
       "      <th>linePrice_8</th>\n",
       "      <th>linePrice_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515110400</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.788209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514764800</td>\n",
       "      <td>1515283200</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.923251</td>\n",
       "      <td>0.828937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1515024000</td>\n",
       "      <td>1515369600</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.143628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1515456000</td>\n",
       "      <td>1514937600</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.139775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1515110400</td>\n",
       "      <td>1515542400</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.143279</td>\n",
       "      <td>0.964469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1651795200</td>\n",
       "      <td>1649116800</td>\n",
       "      <td>1555</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.873150</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.938913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1652054400</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1589</td>\n",
       "      <td>1591</td>\n",
       "      <td>1.063729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1652572800</td>\n",
       "      <td>1651881600</td>\n",
       "      <td>1587</td>\n",
       "      <td>1595</td>\n",
       "      <td>0.813907</td>\n",
       "      <td>0.870793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788406</td>\n",
       "      <td>0.904141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1653264000</td>\n",
       "      <td>1652227200</td>\n",
       "      <td>1591</td>\n",
       "      <td>1603</td>\n",
       "      <td>1.042211</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>0.958532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1648598400</td>\n",
       "      <td>1640304000</td>\n",
       "      <td>1453</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.884394</td>\n",
       "      <td>0.71872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      startTime     endTime  startIndex  endIndex  linePrice_1  linePrice_2  \\\n",
       "0    1514764800  1515110400           0         4          NaN     0.878016   \n",
       "1    1514764800  1515283200           0         6          NaN     1.055290   \n",
       "2    1515024000  1515369600           3         7     1.143628          NaN   \n",
       "3    1515456000  1514937600           2         8     1.139775          NaN   \n",
       "4    1515110400  1515542400           4         9     1.143279     0.964469   \n",
       "..          ...         ...         ...       ...          ...          ...   \n",
       "328  1651795200  1649116800        1555      1586     0.873150     0.825739   \n",
       "330  1652054400  1652227200        1589      1591     1.063729          NaN   \n",
       "331  1652572800  1651881600        1587      1595     0.813907     0.870793   \n",
       "332  1653264000  1652227200        1591      1603     1.042211     1.075683   \n",
       "333  1648598400  1640304000        1453      1549     0.781703     0.741996   \n",
       "\n",
       "     linePrice_3  linePrice_4  linePrice_5  linePrice_6  linePrice_7  \\\n",
       "0       0.788209          NaN          NaN          NaN          NaN   \n",
       "1       0.923251     0.828937          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "328     0.905267     0.938913          NaN          NaN          NaN   \n",
       "330          NaN     1.023085          NaN          NaN          NaN   \n",
       "331          NaN          NaN          NaN          NaN          NaN   \n",
       "332     0.992004     0.958532          NaN          NaN          NaN   \n",
       "333     0.993930     0.847425     0.884394      0.71872          NaN   \n",
       "\n",
       "     linePrice_8  linePrice_9  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "328     0.955736          NaN  \n",
       "330          NaN          NaN  \n",
       "331     0.788406     0.904141  \n",
       "332          NaN          NaN  \n",
       "333          NaN     0.647521  \n",
       "\n",
       "[320 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_labels = pd.read_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\")\n",
    "cols = [f'price_line{i}' for i in range(1, 10)]\n",
    "df_labels = df_labels.dropna(subset=cols, how='all')\n",
    "df_labels = df_labels.rename(columns={c: c.replace('price_line', 'linePrice_') \n",
    "                        for c in df_labels.columns if c.startswith('price_line')})\n",
    "df_labels.to_csv(\"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\", index=False)      \n",
    "#     # overwrites the old file\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4dd53",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677dbff",
   "metadata": {},
   "source": [
    "## simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e281d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# ---------------- Evaluation ---------------- #\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, zero_idx=0, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNNâ€“LSTMâ€“MDN model (last-output version).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    zero_idx : which mixture component is considered \"no-line\" (usually 0)\n",
    "    threshold : if pi[:,zero_idx] > threshold â†’ predict invalid\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            if isinstance(X_batch, dict):\n",
    "                X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            else:\n",
    "                X_batch = X_batch.to(device)\n",
    "\n",
    "            y_batch = y_batch.to(device)\n",
    "            mdn = model(X_batch, lengths)\n",
    "            pi, mu, sigma = mdn[\"pi\"], mdn[\"mu\"], mdn[\"sigma\"]  # (B,K)\n",
    "\n",
    "            # regression expectation\n",
    "            y_pred = (pi * mu).sum(dim=-1)  # (B,)\n",
    "            B = y_batch.size(0)\n",
    "            y_len = (y_batch > 0).sum(dim=1)                # (B,)\n",
    "            idx = torch.clamp(y_len - 1, min=0)             # last valid index\n",
    "            y_true = y_batch[torch.arange(B, device=y_batch.device), idx]  # (B,)\n",
    "            # only last step\n",
    "            # print(\"lengths(features):\", lengths[:10])\n",
    "            # print(\"lengths(labels):\", y_len[:10])\n",
    "\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "            # validity classification\n",
    "            pi_zero = pi[:, zero_idx]  # (B,)\n",
    "            pred_valid = (pi_zero < (1 - threshold)).long()\n",
    "            true_valid = torch.ones_like(pred_valid)  # last step always valid\n",
    "\n",
    "            all_preds_len.extend(pred_valid.cpu().numpy().tolist())\n",
    "            all_labels_len.extend(true_valid.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "        # ----- Regression metrics -----\n",
    "    all_preds_reg = np.concatenate(all_preds_reg)  # (N,)\n",
    "    all_labels_reg = np.concatenate(all_labels_reg)\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "    # ----- Validity metrics -----\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\nðŸ“Š Validation Metrics (MDN, last-output):\")\n",
    "    print(f\"  Regression â†’ MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Validity   â†’ Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=1000,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNLSTM_MDN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"ðŸ” Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\nâœ… Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"âœ… Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # âœ… save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a7940",
   "metadata": {},
   "source": [
    "## ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import joblib\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.make_step import make_step\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "from utils.get_init_argumens import get_init_args\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.normalize_candle_seq import add_label_normalized_candles\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from sklearn.metrics import accuracy_score, f1_score,mean_squared_error,mean_absolute_error\n",
    "from utils.to_address import to_address\n",
    "# ---------------- Evaluation ---------------- #\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_mdn(model, val_loader, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate CNNâ€“LSTMâ€“MDN model (multi-head, top-pi selection per line).\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    model : pl.LightningModule with multi-head MDN forward\n",
    "    val_loader : DataLoader yielding (X, y, lengths)\n",
    "    threshold : optional threshold for validity classification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with mse, mae, acc, f1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for X_batch, y_batch, lengths in val_loader:\n",
    "        # Move to device\n",
    "        if isinstance(X_batch, dict):\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "        else:\n",
    "            X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        mdn_params = model(X_batch, lengths)\n",
    "\n",
    "        B, num_lines = y_batch.shape\n",
    "        y_pred_lines = []\n",
    "\n",
    "        for i in range(num_lines):\n",
    "            pi, mu = mdn_params['pi'], mdn_params['mu']  # both (B, n_components)\n",
    "            \n",
    "            # Pick component with highest pi per sample\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)     # (B,1)\n",
    "            selected_mu = mu.gather(1, top_idx).squeeze(1)     # (B,)\n",
    "\n",
    "            # Mask padded targets\n",
    "            mask = (y_batch[:, i] != 0)\n",
    "            selected_mu[~mask] = 0.0\n",
    "\n",
    "            y_pred_lines.append(selected_mu)\n",
    "\n",
    "        y_pred_all = torch.stack(y_pred_lines, dim=1)  # (B, num_lines)\n",
    "\n",
    "        # Last valid step per sample\n",
    "        y_len = (y_batch > 0).sum(dim=1)\n",
    "        idx = torch.clamp(y_len - 1, min=0)\n",
    "        y_true = y_batch[torch.arange(B), idx]\n",
    "        y_pred = y_pred_all[torch.arange(B), idx]\n",
    "\n",
    "        all_preds_reg.append(y_pred.cpu().numpy())\n",
    "        all_labels_reg.append(y_true.cpu().numpy())\n",
    "\n",
    "        # --- Validity classification ---\n",
    "        pred_valid_lines = []\n",
    "        for i in range(num_lines):\n",
    "            pi = mdn_params['pi']    # (B, n_components)\n",
    "            top_idx = torch.argmax(pi, dim=1, keepdim=True)\n",
    "            pi_max = pi.gather(1, top_idx).squeeze(1)\n",
    "            pred_valid_lines.append((pi_max > threshold).long())\n",
    "\n",
    "        pred_valid_all = torch.stack(pred_valid_lines, dim=1)\n",
    "        pred_valid_last = pred_valid_all[torch.arange(B), idx]\n",
    "        true_valid_last = torch.ones_like(pred_valid_last)\n",
    "\n",
    "        all_preds_len.extend(pred_valid_last.cpu().numpy().tolist())\n",
    "        all_labels_len.extend(true_valid_last.cpu().numpy().tolist())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    y_pred_reg = np.concatenate(all_preds_reg)\n",
    "    y_true_reg = np.concatenate(all_labels_reg)\n",
    "\n",
    "    mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len)\n",
    "\n",
    "    print(\"mse:\", mse, \"mae:\", mae, \"acc:\", acc, \"f1:\", f1)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=200,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=1000,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = False,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False,\n",
    "            feature_pipeline=pipeline,\n",
    "            preserve_order= True\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = CNNLSTM_MDN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_lines=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    \n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"ðŸ” Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\nâœ… Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"âœ… Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"max_len_y\": max_len_y,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"scalers\": pipeline.scalers,\n",
    "    \"pipeline_config\": pipeline.export_config(),\n",
    "    \"model_class_info\": model_class_info   # âœ… save model class info\n",
    "}, meta_out)\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model_mdn(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/line_seq_ordered.csv\",\n",
    "        save_model=True,\n",
    "        do_validation=True,\n",
    "        test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3023ae",
   "metadata": {},
   "source": [
    "## two head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91951ca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm        | LSTM              | 68.6 K | train\n",
      "1 | fc_reg      | Linear            | 774    | train\n",
      "2 | fc_len      | Linear            | 774    | train\n",
      "3 | loss_fn_reg | MSELoss           | 0      | train\n",
      "4 | loss_fn_len | BCEWithLogitsLoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "70.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "70.2 K    Total params\n",
      "0.281     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG SAMPLE CHECK ===\n",
      "\n",
      "--- Sequence 0 ---\n",
      "Label: [0.774234 0.941543 1.004005 0.       0.       0.      ] Encoded: [0.774234 0.941543 1.004005 0.       0.       0.      ]\n",
      "Shape: (6, 4)\n",
      "First few rows:\n",
      " [[ 0.          0.          0.          0.        ]\n",
      " [-0.02376365  0.1197622   0.01098196  0.09679447]\n",
      " [ 0.09773012 -0.0107235   0.09774849  0.01665405]\n",
      " [ 0.01562355 -0.00180042 -0.01639293  0.0093857 ]\n",
      " [ 0.00938704  0.12409948  0.04899828  0.12622231]]\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iatell/envs/Rllib2.43/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980bf9e2f3954715bf2d660594a5bf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Debug batch:\n",
      "  Keys in X_batch: ['main']\n",
      "  y_batch shape: torch.Size([32, 6])\n",
      "  First label in batch: tensor([0.9305, 0.9831, 1.0201, 0.9013, 0.9481, 0.0000])\n",
      "\n",
      "Feature group: main\n",
      "  X_batch shape: torch.Size([32, 53, 4])\n",
      "  First sequence in batch (first  steps):\n",
      " tensor([[-4.1796e-03,  5.3411e-03,  9.4225e-03,  5.2775e-03],\n",
      "        [ 5.4519e-03,  8.8342e-02,  9.4162e-03,  8.6850e-02],\n",
      "        [ 8.6649e-02,  2.6106e-02,  6.4823e-02,  4.1008e-02],\n",
      "        [ 4.1028e-02,  6.3649e-02,  5.7843e-02,  2.5294e-03],\n",
      "        [ 1.9190e-03,  5.2973e-02,  3.4368e-03,  1.0578e-01],\n",
      "        [ 1.0706e-01,  4.8519e-03,  3.5488e-02, -5.2094e-02],\n",
      "        [-5.2225e-02, -3.8887e-02,  5.5792e-03,  2.8721e-02],\n",
      "        [ 2.8295e-02,  1.0689e-02,  2.2457e-02, -4.8621e-03],\n",
      "        [-4.8621e-03,  4.3881e-02,  1.4168e-02,  1.9925e-02],\n",
      "        [ 2.0460e-02, -4.2401e-02, -7.0938e-02, -6.5424e-02],\n",
      "        [-6.5971e-02, -4.5485e-02,  2.8329e-03,  8.5296e-03],\n",
      "        [ 8.5915e-03, -6.0383e-03, -3.3292e-02, -5.5544e-02],\n",
      "        [-5.5549e-02,  1.9211e-02,  1.4257e-03,  7.6053e-02],\n",
      "        [ 7.5986e-02,  1.2219e-03,  3.6711e-02, -3.7492e-02],\n",
      "        [-3.7064e-02,  2.9548e-03, -3.2970e-03,  2.8845e-02],\n",
      "        [ 2.8785e-02, -2.3953e-02, -7.5371e-03, -2.6042e-02],\n",
      "        [-2.6791e-02,  4.1995e-05,  3.2146e-03,  2.5450e-02],\n",
      "        [ 2.5727e-02,  1.8892e-02,  2.9778e-02,  1.6175e-02],\n",
      "        [ 1.6099e-02, -4.9972e-03, -5.4527e-03, -2.3786e-02],\n",
      "        [-2.3427e-02, -1.0122e-02, -7.0858e-03,  6.6980e-03],\n",
      "        [ 6.0761e-03,  4.5376e-03,  1.2807e-02, -5.5511e-03],\n",
      "        [-5.0052e-03,  4.8612e-02, -2.9326e-03,  5.7450e-02],\n",
      "        [ 5.7410e-02, -2.4356e-03,  4.8537e-02, -3.0469e-03],\n",
      "        [-2.7234e-03,  1.2917e-02, -4.7252e-03, -5.1114e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "\n",
      "âœ… Combined df_seq shape: (1696, 4)\n",
      "âœ… Column names in df_seq: ['open_dif', 'high_dif', 'low_dif', 'close_dif']\n",
      "\n",
      "ðŸ“Š Validation Metrics:\n",
      "  Regression â†’ MSE: 0.497850, MAE: 0.516262\n",
      "  Length     â†’ Acc: 0.0000, F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "from preprocess.multi_regression_seq_dif import preprocess_sequences_csv_multilines\n",
    "# from models.LSTM.lstm_multi_line_reg_seq_dif import LSTMMultiRegressor\n",
    "from utils.print_batch import print_batch\n",
    "from utils.to_address import to_address\n",
    "from utils.json_to_csv import json_to_csv_in_memory\n",
    "from utils.padding_batch_reg import collate_batch\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from add_ons.feature_pipeline3 import FeaturePipeline\n",
    "from add_ons.drop_column import drop_columns\n",
    "from add_ons.candle_dif_rate_of_change_percentage import add_candle_rocp\n",
    "from add_ons.candle_proportion import add_candle_proportions\n",
    "from add_ons.candle_rate_of_change import add_candle_ratios\n",
    "from utils.make_step import make_step\n",
    "# ---------------- Evaluation ---------------- #\n",
    "def evaluate_model(model, val_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds_reg, all_labels_reg = [], []\n",
    "    all_preds_len, all_labels_len = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in val_loader:\n",
    "            # Send to same device as model\n",
    "            device = next(model.parameters()).device\n",
    "            X_batch = {k: v.to(device) for k, v in X_batch.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass: regression + length logits\n",
    "            y_pred, len_logits = model(X_batch, lengths)\n",
    "\n",
    "            # Regression targets\n",
    "            all_preds_reg.append(y_pred.cpu().numpy())\n",
    "            all_labels_reg.append(y_batch.cpu().numpy())\n",
    "\n",
    "            # Length targets\n",
    "            true_lengths = lengths.cpu().numpy()\n",
    "            pred_lengths = model.predict_length(len_logits).cpu().numpy()\n",
    "\n",
    "            all_labels_len.extend(true_lengths.tolist())\n",
    "            all_preds_len.extend(pred_lengths.tolist())\n",
    "\n",
    "    # ----- Regression metrics -----\n",
    "    all_preds_reg = np.vstack(all_preds_reg)\n",
    "    all_labels_reg = np.vstack(all_labels_reg)\n",
    "\n",
    "    mse = ((all_preds_reg - all_labels_reg) ** 2).mean()\n",
    "    mae = np.abs(all_preds_reg - all_labels_reg).mean()\n",
    "\n",
    "    # ----- Length metrics -----\n",
    "\n",
    "\n",
    "    acc = accuracy_score(all_labels_len, all_preds_len)\n",
    "    f1 = f1_score(all_labels_len, all_preds_len, average=\"macro\")\n",
    "\n",
    "    print(\"\\nðŸ“Š Validation Metrics:\")\n",
    "    print(f\"  Regression â†’ MSE: {mse:.6f}, MAE: {mae:.6f}\")\n",
    "    print(f\"  Length     â†’ Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "# ---------------- Train ---------------- #\n",
    "def train_model(\n",
    "    data_csv,\n",
    "    labels_csv,\n",
    "    model_out_dir=\"models/saved_models\",\n",
    "    do_validation=True,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=50,\n",
    "    save_model=False,\n",
    "    return_val_accuracy = True,\n",
    "    test_mode = True,\n",
    "    early_stop = False\n",
    "):\n",
    "\n",
    "    pipeline = FeaturePipeline(\n",
    "        steps=[\n",
    "            # make_step(add_label_normalized_candles),\n",
    "            make_step(add_candle_rocp),\n",
    "            make_step(drop_columns, cols_to_drop=[\"open\",\"high\",\"low\",\"close\",\"volume\"]),\n",
    "            \n",
    "        ],\n",
    "        # norm_methods={\n",
    "        #     \"main\": {\n",
    "        #         \"upper_shadow\": \"robust\", \"body\": \"standard\", \"lower_shadow\": \"standard\",\n",
    "        #         \"upper_body_ratio\": \"standard\", \"lower_body_ratio\": \"standard\",\n",
    "        #         \"upper_lower_body_ratio\": \"standard\", \"Candle_Color\": \"standard\"\n",
    "        #     }\n",
    "        # },\n",
    "        per_window_flags=[\n",
    "            False, \n",
    "          False, \n",
    "        #   True\n",
    "                ]\n",
    "    )\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_out = f\"{model_out_dir}/lstm_model_multireg_{timestamp}.pt\"\n",
    "    meta_out  = f\"{model_out_dir}/lstm_meta_multireg_{timestamp}.pkl\"\n",
    "\n",
    "    # Preprocess: pad linePrices and sequences\n",
    "    if do_validation:\n",
    "        train_ds, val_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=True,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=True,\n",
    "            feature_pipeline=pipeline\n",
    "        )\n",
    "    else:\n",
    "        train_ds, df, feature_cols, max_len_y = preprocess_sequences_csv_multilines(\n",
    "            data_csv, labels_csv,\n",
    "            val_split=False,\n",
    "            for_xgboost=False,\n",
    "            debug_sample=False\n",
    "        )\n",
    "        val_ds = None\n",
    "\n",
    "    sample = train_ds[0][0]  # first sample's features\n",
    "    if isinstance(sample, dict):  # multiple feature groups\n",
    "        input_dim = sample['main'].shape[1]\n",
    "    else:  # single tensor\n",
    "        input_dim = sample.shape[1]\n",
    "\n",
    "    model = LSTMMultiRegressor(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        max_len_y=max_len_y,\n",
    "        lr=lr\n",
    "    )\n",
    "    init_args = get_init_args(model, input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, lr=lr,max_len_y=max_len_y)\n",
    "\n",
    "    model_class_info = {\n",
    "        \"module\": model.__class__.__module__,\n",
    "        \"class\": model.__class__.__name__,\n",
    "        \"init_args\": init_args\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_batch) if val_ds else None\n",
    "    # --- Early stopping --- #\n",
    "    if early_stop == True:\n",
    "        from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",   # metric to monitor (must be logged in your LightningModule)\n",
    "            patience=10,          # number of epochs with no improvement before stopping\n",
    "            min_delta=0.001,      # minimum improvement to qualify as \"better\"\n",
    "            mode=\"min\",           # \"min\" for loss, \"max\" for accuracy\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=model_out_dir,\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "        callbacks=[early_stop_callback,checkpoint_callback]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        fast_dev_run=test_mode,\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks= callbacks if early_stop else None\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # --- Debug / Test mode --- #\n",
    "    if test_mode:\n",
    "        save_model = False\n",
    "        from itertools import islice\n",
    "\n",
    "        # Try to grab 3rd batch; if not available, take first\n",
    "        try:\n",
    "            batch = next(islice(iter(train_loader), 2, 3))\n",
    "        except StopIteration:\n",
    "            batch = next(iter(train_loader))\n",
    "\n",
    "        X_batch_dict, y_batch, lengths = batch\n",
    "\n",
    "        print(\"ðŸ” Debug batch:\")\n",
    "        if isinstance(X_batch_dict, dict):\n",
    "            print(\"  Keys in X_batch:\", list(X_batch_dict.keys()))\n",
    "        print(\"  y_batch shape:\", y_batch.shape)\n",
    "        print(\"  First label in batch:\", y_batch[0])\n",
    "\n",
    "        # --- Track real column names for each feature group ---\n",
    "        feature_names_dict = {}\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            if name == \"main\":\n",
    "                # Use actual feature columns after preprocessing\n",
    "                feature_names_dict[name] = feature_cols\n",
    "            else:\n",
    "                # For extra feature groups, fallback to generic names\n",
    "                feature_names_dict[name] = [f\"{name}_{i}\" for i in range(X_batch.shape[2])]\n",
    "\n",
    "        dfs = []\n",
    "        for name, X_batch in X_batch_dict.items():\n",
    "            print(f\"\\nFeature group: {name}\")\n",
    "            print(\"  X_batch shape:\", X_batch.shape)\n",
    "            print(\"  First sequence in batch (first  steps):\\n\", X_batch[0][:])\n",
    "\n",
    "            batch_size_, seq_len, feature_dim = X_batch.shape\n",
    "            df_part = pd.DataFrame(\n",
    "                X_batch.reshape(batch_size_ * seq_len, feature_dim).numpy(),\n",
    "                columns=feature_names_dict[name]\n",
    "            )\n",
    "            dfs.append(df_part)\n",
    "\n",
    "        # Combine all feature groups horizontally\n",
    "        global df_seq\n",
    "        df_seq = pd.concat(dfs, axis=1)\n",
    "        print(\"\\nâœ… Combined df_seq shape:\", df_seq.shape)\n",
    "        print(\"âœ… Column names in df_seq:\", df_seq.columns.tolist())\n",
    "\n",
    "        \n",
    "    if save_model:\n",
    "        os.makedirs(model_out_dir, exist_ok=True)\n",
    "        trainer.save_checkpoint(model_out)\n",
    "        joblib.dump({\n",
    "            \"input_dim\": input_dim,\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"max_len_y\": max_len_y,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"scalers\": pipeline.scalers,\n",
    "            \"pipeline_config\": pipeline.export_config(),\n",
    "            \"model_class_info\": model_class_info \n",
    "        }, meta_out)\n",
    "        print(f\"âœ… Model saved to {model_out}\")\n",
    "        print(f\"âœ… Meta saved to {meta_out}\")\n",
    "\n",
    "\n",
    "        \n",
    "    # --- Evaluation --- #\n",
    "    if do_validation:\n",
    "        mse, mae, acc, f1 = evaluate_model(model, val_loader)\n",
    "        if return_val_accuracy:\n",
    "            return {\"mse\": mse, \"mae\": mae, \"acc\": acc, \"f1\": f1}\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_model(\n",
    "        \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\",\n",
    "        \"/home/iatell/projects/meta-learning/data/seq_line_labels.csv\",\n",
    "        do_validation=True,\n",
    "        test_mode = True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399de860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "open_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "high_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "low_dif",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "close_dif",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "fad25275-2a8d-4a0c-8cb5-39c5fd06a51b",
       "rows": [
        [
         "0",
         "-0.0025242148",
         "0.089635044",
         "-0.0049852505",
         "0.07669491"
        ],
        [
         "1",
         "0.07705685",
         "-0.014345481",
         "0.07471762",
         "0.0016780357"
        ],
        [
         "2",
         "0.001341431",
         "0.0013505361",
         "-0.004239848",
         "0.004059828"
        ],
        [
         "3",
         "0.003975248",
         "-2.4423403e-05",
         "0.0015984442",
         "-0.013317717"
        ],
        [
         "4",
         "-0.013234595",
         "-0.0046948357",
         "-0.009179844",
         "0.000112915"
        ],
        [
         "5",
         "0.00012668512",
         "0.0006543789",
         "0.0026267746",
         "-0.0060746917"
        ],
        [
         "6",
         "-0.006380266",
         "-0.011880109",
         "-0.0065817498",
         "-0.005219704"
        ],
        [
         "7",
         "-0.004924702",
         "0.007398522",
         "0.0014965907",
         "0.0033170313"
        ],
        [
         "8",
         "0.0033198071",
         "-0.0013768638",
         "0.0068449257",
         "0.004424742"
        ],
        [
         "9",
         "0.0040888386",
         "0.014228934",
         "0.001803825",
         "0.013588841"
        ],
        [
         "10",
         "0.013933352",
         "0.060779274",
         "0.014038398",
         "0.062989764"
        ],
        [
         "11",
         "0.06263735",
         "0.017712101",
         "0.05499316",
         "0.0023572564"
        ],
        [
         "12",
         "0.002565846",
         "-0.001887586",
         "0.0038018671",
         "0.01585295"
        ],
        [
         "13",
         "0.015967343",
         "0.007399084",
         "0.007846207",
         "-0.008169301"
        ],
        [
         "14",
         "-0.008169301",
         "-0.007090786",
         "0.0065674963",
         "0.006270779"
        ],
        [
         "15",
         "0.006270779",
         "0.04363591",
         "0.0016553551",
         "0.039313477"
        ],
        [
         "16",
         "0.039374053",
         "0.008644841",
         "-0.056059394",
         "-0.09087465"
        ],
        [
         "53",
         "0.013527893",
         "0.07152741",
         "0.012888759",
         "0.09225499"
        ],
        [
         "54",
         "0.09218671",
         "-0.0030833415",
         "0.075823076",
         "-0.018664384"
        ],
        [
         "55",
         "-0.018653555",
         "-0.01212739",
         "-0.019062338",
         "-0.02659283"
        ],
        [
         "56",
         "-0.026624436",
         "-0.03423557",
         "-0.14737394",
         "-0.085606016"
        ],
        [
         "57",
         "-0.08557726",
         "-0.04248953",
         "0.0102254525",
         "-0.0184861"
        ],
        [
         "58",
         "-0.018426485",
         "-0.020695899",
         "0.04009512",
         "0.029115157"
        ],
        [
         "59",
         "0.029076014",
         "0.046750706",
         "0.030978639",
         "0.056587435"
        ],
        [
         "60",
         "0.05656118",
         "0.05756544",
         "0.05274315",
         "0.05184132"
        ],
        [
         "61",
         "0.051842503",
         "-0.009395312",
         "-0.011533193",
         "-0.048566274"
        ],
        [
         "62",
         "-0.04861228",
         "-0.02616595",
         "0.0076502734",
         "0.0069608283"
        ],
        [
         "63",
         "0.006961172",
         "0.03128911",
         "0.011073752",
         "0.0318475"
        ],
        [
         "64",
         "0.03201216",
         "0.0062702266",
         "0.0152465645",
         "0.005567126"
        ],
        [
         "65",
         "0.005455986",
         "-0.0053055277",
         "0.001032308",
         "0.004273711"
        ],
        [
         "66",
         "0.004232617",
         "-0.0055783396",
         "-0.015621701",
         "-0.027016439"
        ],
        [
         "67",
         "-0.026976623",
         "-0.026776062",
         "-0.054793052",
         "-0.046552412"
        ],
        [
         "68",
         "-0.046672266",
         "-0.032100115",
         "0.013445264",
         "0.011175864"
        ],
        [
         "69",
         "0.011302993",
         "0.00397476",
         "0.015277293",
         "0.000997819"
        ],
        [
         "70",
         "0.0009825518",
         "-0.0010582466",
         "-0.040793825",
         "-0.04998393"
        ],
        [
         "71",
         "-0.05020912",
         "-0.03423747",
         "-0.006583908",
         "0.020642543"
        ],
        [
         "72",
         "0.0209001",
         "0.0042328998",
         "0.0066275434",
         "-0.006648053"
        ],
        [
         "73",
         "-0.006668277",
         "0.022991527",
         "0.0128425285",
         "0.041045427"
        ],
        [
         "74",
         "0.04106662",
         "0.04341138",
         "0.0338492",
         "0.040397346"
        ],
        [
         "75",
         "0.040395174",
         "-0.0020996376",
         "0.024149286",
         "-0.015541114"
        ],
        [
         "76",
         "-0.01558814",
         "0.014027731",
         "0.0001318328",
         "0.028709875"
        ],
        [
         "77",
         "0.028761165",
         "-0.0041067763",
         "0.0053776405",
         "-0.02572254"
        ],
        [
         "78",
         "-0.02572254",
         "0.070103094",
         "0.004291466",
         "0.07964421"
        ],
        [
         "79",
         "0.07984954",
         "-0.014548169",
         "-0.01652255",
         "-0.06692926"
        ],
        [
         "106",
         "-0.046248164",
         "0.020571811",
         "-0.0080659",
         "0.05875319"
        ],
        [
         "107",
         "0.059290618",
         "0.03634762",
         "0.070247404",
         "0.031002337"
        ],
        [
         "108",
         "0.031165294",
         "-0.013467627",
         "0.010502697",
         "-0.005204951"
        ],
        [
         "109",
         "-0.004734724",
         "0.03787265",
         "0.0032986721",
         "0.040661905"
        ],
        [
         "110",
         "0.040005848",
         "-0.00084517576",
         "0.030516837",
         "-0.015332662"
        ],
        [
         "111",
         "-0.015763482",
         "0.01580543",
         "-0.003388514",
         "0.011225295"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 732
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_dif</th>\n",
       "      <th>high_dif</th>\n",
       "      <th>low_dif</th>\n",
       "      <th>close_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.089635</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>0.076695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077057</td>\n",
       "      <td>-0.014345</td>\n",
       "      <td>0.074718</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>-0.004240</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003975</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>-0.013318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013235</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>-0.009180</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>-0.020200</td>\n",
       "      <td>-0.011237</td>\n",
       "      <td>-0.006991</td>\n",
       "      <td>0.003566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>0.003566</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.016342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>-0.016342</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>-0.014226</td>\n",
       "      <td>-0.023502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>-0.023502</td>\n",
       "      <td>-0.055281</td>\n",
       "      <td>-0.126078</td>\n",
       "      <td>-0.104118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>-0.104118</td>\n",
       "      <td>-0.103766</td>\n",
       "      <td>-0.040419</td>\n",
       "      <td>-0.037697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      open_dif  high_dif   low_dif  close_dif\n",
       "0    -0.002524  0.089635 -0.004985   0.076695\n",
       "1     0.077057 -0.014345  0.074718   0.001678\n",
       "2     0.001341  0.001351 -0.004240   0.004060\n",
       "3     0.003975 -0.000024  0.001598  -0.013318\n",
       "4    -0.013235 -0.004695 -0.009180   0.000113\n",
       "...        ...       ...       ...        ...\n",
       "1691 -0.020200 -0.011237 -0.006991   0.003566\n",
       "1692  0.003566 -0.003089 -0.002702  -0.016342\n",
       "1693 -0.016342  0.022225 -0.014226  -0.023502\n",
       "1694 -0.023502 -0.055281 -0.126078  -0.104118\n",
       "1695 -0.104118 -0.103766 -0.040419  -0.037697\n",
       "\n",
       "[732 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seq = df_seq.loc[~(df_seq==0).all(axis=1)]\n",
    "df_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc099c49",
   "metadata": {},
   "source": [
    "# server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current notebook location\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Add parent folder (meta/) to sys.path\n",
    "sys.path.append(str(notebook_path.parent))\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from servers.pre_process.multi_reg_dif_seq import ServerPreprocess, import_class, build_pipeline_from_config\n",
    "# from models.LSTM.cnn_lstm_mdn import CNNLSTM_MDN  # <-- your updated \"last-output\" model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------- Load model and meta ----------------\n",
    "meta_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_meta_multireg_*.pkl\")[0]\n",
    "state_path = glob.glob(\"/home/iatell/projects/meta-learning/play_grounds/models/saved_models/lstm_model_multireg*.pt\")[0]\n",
    "\n",
    "meta = joblib.load(meta_path)\n",
    "FEATURES = meta['feature_cols']\n",
    "print(\"features\",FEATURES)\n",
    "# ---------------- Model ----------------\n",
    "# Reconstruct model class\n",
    "#for python file:\n",
    "# model_cls_info = meta[\"model_class_info\"]\n",
    "# ModelClass = import_class(model_cls_info[\"module\"], model_cls_info[\"class\"])\n",
    "model_cls_info = meta[\"model_class_info\"]\n",
    "ModelClass = CNNLSTM_MDN\n",
    "# Initialize model with original args\n",
    "model = ModelClass(**model_cls_info[\"init_args\"])\n",
    "model = CNNLSTM_MDN.load_from_checkpoint(state_path)\n",
    "model.eval()\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv( \"/home/iatell/projects/meta-learning/data/Bitcoin_BTCUSDT_kaggle_1D_candles.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# ---------------- Setup pipeline ----------------\n",
    "pipeline = build_pipeline_from_config(meta[\"pipeline_config\"])\n",
    "pipeline.scalers = meta[\"scalers\"]\n",
    "\n",
    "# Stateful preprocessing instance\n",
    "preproc = ServerPreprocess(feature_pipeline=pipeline)\n",
    "\n",
    "\n",
    "# ---------------- Routes ----------------\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"sequential.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get_and_add_data\")\n",
    "def get_and_add_data():\n",
    "    dense = df.set_index('timestamp').asfreq('D').ffill()\n",
    "    initial_seq_len = 21\n",
    "    next_idx = request.args.get(\"idx\", type=int)\n",
    "    if next_idx is None:\n",
    "        # First call â†’ load initial candles\n",
    "        if len(preproc.dataset) == 0:\n",
    "            for _, row in dense.iloc[:initial_seq_len].iterrows():\n",
    "                preproc.add_candle(row)\n",
    "        candles = [\n",
    "            {'time': int(ts.timestamp()),\n",
    "             'open': float(row.open),\n",
    "             'high': float(row.high),\n",
    "             'low': float(row.low),\n",
    "             'close': float(row.close)}\n",
    "            for ts, row in dense.iloc[:initial_seq_len].iterrows()\n",
    "        ]\n",
    "        print(\"Returning initial candles:\", candles)\n",
    "\n",
    "        return jsonify({\n",
    "            \"initial_seq_len\": initial_seq_len,\n",
    "            \"next_idx\": initial_seq_len,\n",
    "            \"candles\": candles\n",
    "        })\n",
    "    else:\n",
    "        # Subsequent calls â†’ 1 candle\n",
    "        if next_idx >= len(dense):\n",
    "            print(\"Reached end of data at index:\", next_idx)\n",
    "            return jsonify({\"error\": \"End of data\"}), 404\n",
    "\n",
    "        row = dense.iloc[next_idx]\n",
    "        candle = {\n",
    "            'time': int(row.name.timestamp()),\n",
    "            'open': float(row.open),\n",
    "            'high': float(row.high),\n",
    "            'low': float(row.low),\n",
    "            'close': float(row.close)\n",
    "        }\n",
    "\n",
    "        # âœ… Add to preproc automatically\n",
    "        preproc.add_candle(row)\n",
    "\n",
    "        return jsonify({\n",
    "            \"next_idx\": next_idx + 1,\n",
    "            \"candle\": candle\n",
    "        })\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    seq_len = data.get(\"seq_len\")\n",
    "\n",
    "    if not seq_len or not isinstance(seq_len, int):\n",
    "        return jsonify({\"error\": \"Provide 'seq_len' as an int\"}), 400\n",
    "\n",
    "    try:\n",
    "        # prepare subsequence from current state\n",
    "        seq_df = preproc.prepare_seq(seq_len)\n",
    "    except ValueError as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "    X_np = seq_df[FEATURES].values.astype(np.float32)\n",
    "    X_t = torch.from_numpy(X_np).unsqueeze(0)\n",
    "    dict_x = {\"main\": X_t}\n",
    "    with torch.no_grad():\n",
    "        mdn_out = model(dict_x)\n",
    "\n",
    "    pi    = mdn_out['pi'][0].cpu().numpy()\n",
    "    mu    = mdn_out['mu'][0].cpu().numpy()\n",
    "    sigma = mdn_out['sigma'][0].cpu().numpy()\n",
    "    last_close = preproc.reference_dataset.iloc[-1]['close']\n",
    "    return jsonify({\n",
    "        'pred_prices': (last_close * mu).tolist(),\n",
    "        'pred_sigmas': (last_close * sigma).tolist(),\n",
    "        'pi': pi.tolist()\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rllib2.43 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
